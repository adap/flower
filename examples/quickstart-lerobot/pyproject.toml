[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.metadata]
allow-direct-references = true

[project]
name = "lerobot_example"
version = "1.0.0"
description = "Federated Learning with Hugging Face LeRobot transformers and Flower (Quickstart Example)"
license = "Apache-2.0"
authors = [
    { name = "Ivelin Ivanov", email = "ivelin@zk0.bot" },
    { name = "The Flower Authors", email = "hello@flower.ai" },
]

dependencies = [
    "flwr[simulation]==1.14.0",
    "transformers>=4.30.0,<5.0",
    "lerobot[pusht] @ git+https://github.com/huggingface/lerobot.git@96c7052777aca85d4e55dfba8f81586103ba8f61",
    "flwr-datasets>=0.5.0",
    "torch>=2.5.0",
    "evaluate>=0.4.0,<1.0",
    "scikit-learn>=1.3.1, <2.0",
]

[tool.hatch.build.targets.wheel]
packages = ["."]

[tool.flwr.app]
publisher = "flwrlabs"

[tool.flwr.app.components]
serverapp = "lerobot_example.server_app:app"
clientapp = "lerobot_example.client_app:app"

[tool.flwr.app.config]
num-server-rounds = 50 # for good results, total number of training rounds should be over 100,000: num-server-rounds*local_epochs > 50,000
model-name = "lerobot/pusht"
fraction-fit = 0.4
fraction-evaluate = 0.4
local-epochs = 200
server-device = "cpu"
use-wandb = true

[tool.flwr.federations]
default = "local-simulation"

[tool.flwr.federations.local-simulation]
options.num-supernodes = 10 # relatively low number of supernodes because lerobot diffusion model is memory hungry

[tool.flwr.federations.local-simulation-gpu]
options.num-supernodes = 10
options.backend.client-resources.num-cpus = 4 # each ClientApp assumes to use 4CPUs
options.backend.client-resources.num-gpus = 0.5 # When this value is 0.5 at most 2 ClientApp will run in a given GPU (lower it to increase parallelism)
