# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022 Flower Labs GmbH
# This file is distributed under the same license as the Flower package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2023.
#
msgid ""
msgstr ""
"Project-Id-Version: Flower main\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2024-12-08 00:35+0000\n"
"PO-Revision-Date: 2024-05-25 11:09+0000\n"
"Last-Translator: Gustavo Bertoli <gubertoli@gmail.com>\n"
"Language: pt_BR\n"
"Language-Team: Portuguese (Brazil) <https://hosted.weblate.org/projects"
"/flower-docs/framework/pt_BR/>\n"
"Plural-Forms: nplurals=2; plural=n > 1;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.16.0\n"

#: ../../source/contributor-explanation-public-and-private-apis.rst:2
msgid "Public and private APIs"
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:4
msgid ""
"In Python, everything is public. To enable developers to understand which"
" components can be relied upon, Flower declares a public API. Components "
"that are part of the public API can be relied upon. Changes to the public"
" API are announced in the release notes and are subject to deprecation "
"policies."
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:9
msgid ""
"Everything that is not part of the public API is part of the private API."
" Even though Python allows accessing them, user code should never use "
"those components. Private APIs can change at any time, even in patch "
"releases."
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:13
msgid ""
"How can you determine whether a component is part of the public API or "
"not? Easy:"
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:15
msgid "`Use the Flower API reference documentation <ref-api/flwr.html>`_"
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:16
msgid "`Use the Flower CLI reference documentation <ref-api-cli.html>`_"
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:18
msgid ""
"Everything listed in the reference documentation is part of the public "
"API. This document explains how Flower maintainers define the public API "
"and how you can determine whether a component is part of the public API "
"or not by reading the Flower source code."
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:23
msgid "Flower public API"
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:25
msgid "Flower has a well-defined public API. Let's look at this in more detail."
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:29
msgid ""
"Every component that is reachable by recursively following "
"``__init__.__all__`` starting from the root package (``flwr``) is part of"
" the public API."
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:32
msgid ""
"If you want to determine whether a component "
"(class/function/generator/...) is part of the public API or not, you need"
" to start at the root of the ``flwr`` package. Let's use ``tree -L 1 -d "
"src/py/flwr`` to look at the Python sub-packages contained ``flwr``:"
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:46
msgid ""
"Contrast this with the definition of ``__all__`` in the root "
"``src/py/flwr/__init__.py``:"
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:59
msgid ""
"You can see that ``flwr`` has six subpackages (``cli``, ``client``, "
"``common``, ``proto``, ``server``, ``simulation``), but only four of them"
" are \"exported\" via ``__all__`` (``client``, ``common``, ``server``, "
"``simulation``)."
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:63
msgid ""
"What does this mean? It means that ``client``, ``common``, ``server`` and"
" ``simulation`` are part of the public API, but ``cli`` and ``proto`` are"
" not. The ``flwr`` subpackages ``cli`` and ``proto`` are private APIs. A "
"private API can change completely from one release to the next (even in "
"patch releases). It can change in a breaking way, it can be renamed (for "
"example, ``flwr.cli`` could be renamed to ``flwr.command``) and it can "
"even be removed completely."
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:70
msgid "Therefore, as a Flower user:"
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:72
msgid "``from flwr import client`` ✅ Ok, you're importing a public API."
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:73
msgid ""
"``from flwr import proto`` ❌ Not recommended, you're importing a private "
"API."
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:75
msgid ""
"What about components that are nested deeper in the hierarchy? Let's look"
" at Flower strategies to see another typical pattern. Flower strategies "
"like ``FedAvg`` are often imported using ``from flwr.server.strategy "
"import FedAvg``. Let's look at "
"``src/py/flwr/server/strategy/__init__.py``:"
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:91
msgid ""
"What's notable here is that all strategies are implemented in dedicated "
"modules (e.g., ``fedavg.py``). In ``__init__.py``, we *import* the "
"components we want to make part of the public API and then *export* them "
"via ``__all__``. Note that we export the component itself (for example, "
"the ``FedAvg`` class), but not the module it is defined in (for example, "
"``fedavg.py``). This allows us to move the definition of ``FedAvg`` into "
"a different module (or even a module in a subpackage) without breaking "
"the public API (as long as we update the import path in ``__init__.py``)."
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:99
msgid "Therefore:"
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:101
msgid ""
"``from flwr.server.strategy import FedAvg`` ✅ Ok, you're importing a "
"class that is part of the public API."
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:103
msgid ""
"``from flwr.server.strategy import fedavg`` ❌ Not recommended, you're "
"importing a private module."
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:106
msgid ""
"This approach is also implemented in the tooling that automatically "
"builds API reference docs."
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:110
msgid "Flower public API of private packages"
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:112
msgid ""
"We also use this to define the public API of private subpackages. Public,"
" in this context, means the API that other ``flwr`` subpackages should "
"use. For example, ``flwr.server.driver`` is a private subpackage (it's "
"not exported via ``src/py/flwr/server/__init__.py``'s ``__all__``)."
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:117
msgid ""
"Still, the private sub-package ``flwr.server.driver`` defines a "
"\"public\" API using ``__all__`` in "
"``src/py/flwr/server/driver/__init__.py``:"
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:132
msgid ""
"The interesting part is that both ``GrpcDriver`` and ``InMemoryDriver`` "
"are never used by Flower framework users, only by other parts of the "
"Flower framework codebase. Those other parts of the codebase import, for "
"example, ``InMemoryDriver`` using ``from flwr.server.driver import "
"InMemoryDriver`` (i.e., the ``InMemoryDriver`` exported via ``__all__``),"
" not ``from flwr.server.driver.in_memory_driver import InMemoryDriver`` "
"(``in_memory_driver.py`` is the module containing the actual "
"``InMemoryDriver`` class definition)."
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:140
msgid ""
"This is because ``flwr.server.driver`` defines a public interface for "
"other ``flwr`` subpackages. This allows codeowners of "
"``flwr.server.driver`` to refactor the package without breaking other "
"``flwr``-internal users."
msgstr ""

#: ../../source/contributor-how-to-build-docker-images.rst:2
#, fuzzy
msgid "How to Build Docker Flower Images Locally"
msgstr "Como construir imagens Docker do Flower localmente"

#: ../../source/contributor-how-to-build-docker-images.rst:4
#, fuzzy
msgid ""
"Flower provides pre-made docker images on `Docker Hub "
"<https://hub.docker.com/u/flwr>`_ that include all necessary dependencies"
" for running the SuperLink, SuperNode or ServerApp. You can also build "
"your own custom docker images from scratch with a different version of "
"Python or Linux distribution (Ubuntu/Alpine) if that is what you need. In"
" this guide, we will explain what images exist and how to build them "
"locally."
msgstr ""
"Flower disponibiliza imagens docker em `Docker Hub "
"<https://hub.docker.com/r/flwr/server/tags>`_ que incluem todas as "
"dependências necesárias para executar o servidor. Você pode também "
"compilar suas próprias imagens docker customizadas do zero com uma versão"
" diferente do Python ou do Ubuntu se isso for o que você precisa. Neste "
"guia, explicaremos quais imagens existem e como compilar localmente."

#: ../../source/contributor-how-to-build-docker-images.rst:10
msgid ""
"Before we can start, we need to meet a few prerequisites in our local "
"development environment."
msgstr ""
"Antes de começarmos, precisamos encontrar alguns pré-requisitos em nosso "
"ambiente de desenvolvimento local."

#: ../../source/contributor-how-to-build-docker-images.rst:13
#, fuzzy
msgid "Clone the ``flower`` repository."
msgstr "Clone o repositório do flower."

#: ../../source/contributor-how-to-build-docker-images.rst:19
msgid "Verify the Docker daemon is running."
msgstr "Verifique que o serviço Docker está rodando."

#: ../../source/contributor-how-to-build-docker-images.rst:21
msgid ""
"The build instructions that assemble the images are located in the "
"respective Dockerfiles. You can find them in the subdirectories of "
"``src/docker``."
msgstr ""
"As instruções de compilação que montam as imagens estão localizadas nos "
"respectivos Dockerfiles. Você pode encontrá-los nos subdiretórios "
"``src/docker```."

#: ../../source/contributor-how-to-build-docker-images.rst:24
#, fuzzy
msgid ""
"Flower Docker images are configured via build arguments. Through build "
"arguments, we can make the creation of images more flexible. For example,"
" in the base image, we can specify the version of Python to install using"
" the ``PYTHON_VERSION`` build argument. Some of the build arguments have "
"default values, others must be specified when building the image. All "
"available build arguments for each image are listed in one of the tables "
"below."
msgstr ""
"Ambas, imagens base e do servidor são configuradas através dos argumentos"
" de compilação. Através dos argumentos de compilação, podemos tornar "
"nossa compilação mais flexível. Por exemplo, na imagem base, podemos "
"especificar a versão do Python para instalar usando o argumento de "
"compilação `PYTHON_VERSION`. Alguns dos argumentos de compilação têm "
"valores padrão, outros devem ser especificados ao compilar a imagem. "
"Todos os argumentos de compilação disponíveis para cada imagem estão "
"listados em uma das tabelas abaixo."

#: ../../source/contributor-how-to-build-docker-images.rst:32
#, fuzzy
msgid "Building the Base Image"
msgstr "Construindo a imagem base"

#: ../../source/contributor-how-to-build-docker-images.rst:38
#: ../../source/contributor-how-to-build-docker-images.rst:104
msgid "Build argument"
msgstr "Argumento de compilação"

#: ../../source/contributor-how-to-build-docker-images.rst:39
#: ../../source/contributor-how-to-build-docker-images.rst:105
msgid "Description"
msgstr "Descrição"

#: ../../source/contributor-how-to-build-docker-images.rst:40
#: ../../source/contributor-how-to-build-docker-images.rst:106
msgid "Required"
msgstr "Necessário"

#: ../../source/contributor-how-to-build-docker-images.rst:41
#: ../../source/contributor-how-to-build-docker-images.rst:107
#: ../../source/docker/persist-superlink-state.rst:19
#: ../../source/docker/pin-version.rst:12
#: ../../source/docker/set-environment-variables.rst:8
msgid "Example"
msgstr "Exemplo"

#: ../../source/contributor-how-to-build-docker-images.rst:42
msgid "``DISTRO``"
msgstr ""

#: ../../source/contributor-how-to-build-docker-images.rst:43
#, fuzzy
msgid "The Linux distribution to use as the base image."
msgstr "O nome do repositório da imagem base."

#: ../../source/contributor-how-to-build-docker-images.rst:44
#: ../../source/contributor-how-to-build-docker-images.rst:48
#: ../../source/contributor-how-to-build-docker-images.rst:52
#: ../../source/contributor-how-to-build-docker-images.rst:68
#: ../../source/contributor-how-to-build-docker-images.rst:75
#: ../../source/contributor-how-to-build-docker-images.rst:110
msgid "No"
msgstr ""

#: ../../source/contributor-how-to-build-docker-images.rst:45
#, fuzzy
msgid "``ubuntu``"
msgstr "``UBUNTU_VERSION``"

#: ../../source/contributor-how-to-build-docker-images.rst:46
#, fuzzy
msgid "``DISTRO_VERSION``"
msgstr "``PIP_VERSION``"

#: ../../source/contributor-how-to-build-docker-images.rst:47
msgid "Version of the Linux distribution."
msgstr ""

#: ../../source/contributor-how-to-build-docker-images.rst:49
msgid ":substitution-code:`|ubuntu_version|`"
msgstr ""

#: ../../source/contributor-how-to-build-docker-images.rst:50
msgid "``PYTHON_VERSION``"
msgstr "``PYTHON_VERSION``"

#: ../../source/contributor-how-to-build-docker-images.rst:51
msgid "Version of ``python`` to be installed."
msgstr "Versão do ``python`` a ser instalada."

#: ../../source/contributor-how-to-build-docker-images.rst:53
msgid "``3.11`` or ``3.11.1``"
msgstr ""

#: ../../source/contributor-how-to-build-docker-images.rst:54
msgid "``PIP_VERSION``"
msgstr "``PIP_VERSION``"

#: ../../source/contributor-how-to-build-docker-images.rst:55
msgid "Version of ``pip`` to be installed."
msgstr "Versão do ``pip`` a ser instalada."

#: ../../source/contributor-how-to-build-docker-images.rst:56
#: ../../source/contributor-how-to-build-docker-images.rst:60
#: ../../source/contributor-how-to-build-docker-images.rst:64
#: ../../source/contributor-how-to-build-docker-images.rst:114
msgid "Yes"
msgstr "Sim"

#: ../../source/contributor-how-to-build-docker-images.rst:57
msgid ":substitution-code:`|pip_version|`"
msgstr ""

#: ../../source/contributor-how-to-build-docker-images.rst:58
msgid "``SETUPTOOLS_VERSION``"
msgstr "``SETUPTOOLS_VERSION``"

#: ../../source/contributor-how-to-build-docker-images.rst:59
msgid "Version of ``setuptools`` to be installed."
msgstr "Versão do ``setuptools`` a ser instalada."

#: ../../source/contributor-how-to-build-docker-images.rst:61
#, fuzzy
msgid ":substitution-code:`|setuptools_version|`"
msgstr "``SETUPTOOLS_VERSION``"

#: ../../source/contributor-how-to-build-docker-images.rst:62
msgid "``FLWR_VERSION``"
msgstr "``FLWR_VERSION``"

#: ../../source/contributor-how-to-build-docker-images.rst:63
msgid "Version of Flower to be installed."
msgstr "Versão do Flower a ser instalada."

#: ../../source/contributor-how-to-build-docker-images.rst:65
msgid ":substitution-code:`|stable_flwr_version|`"
msgstr ""

#: ../../source/contributor-how-to-build-docker-images.rst:66
#, fuzzy
msgid "``FLWR_PACKAGE``"
msgstr "``FLWR_VERSION``"

#: ../../source/contributor-how-to-build-docker-images.rst:67
#, fuzzy
msgid "The Flower package to be installed."
msgstr "Versão do Flower a ser instalada."

#: ../../source/contributor-how-to-build-docker-images.rst:69
msgid "``flwr`` or ``flwr-nightly``"
msgstr ""

#: ../../source/contributor-how-to-build-docker-images.rst:70
#, fuzzy
msgid "``FLWR_VERSION_REF``"
msgstr "``FLWR_VERSION``"

#: ../../source/contributor-how-to-build-docker-images.rst:71
msgid ""
"A `direct reference "
"<https://packaging.python.org/en/latest/specifications/version-specifiers"
"/#direct-references>`_ without the ``@`` specifier. If both "
"``FLWR_VERSION`` and ``FLWR_VERSION_REF`` are specified, the "
"``FLWR_VERSION_REF`` has precedence."
msgstr ""

#: ../../source/contributor-how-to-build-docker-images.rst:76
msgid "`Direct Reference Examples`_"
msgstr ""

#: ../../source/contributor-how-to-build-docker-images.rst:78
#, fuzzy
msgid ""
"The following example creates a base Ubuntu/Alpine image with Python "
"``3.11.0``, pip :substitution-code:`|pip_version|`, setuptools "
":substitution-code:`|setuptools_version|` and Flower :substitution-"
"code:`|stable_flwr_version|`:"
msgstr ""
"O exemplo seguinte cria uma imagem base com Python 3.11.0, pip 23.0.1 e "
"setuptools 69.0.2:"

#: ../../source/contributor-how-to-build-docker-images.rst:93
#, fuzzy
msgid ""
"In this example, we specify our image name as ``flwr_base`` and the tag "
"as ``0.1.0``. Remember that the build arguments as well as the name and "
"tag can be adapted to your needs. These values serve as examples only."
msgstr ""
"O nome da imagem é ``flwr_base`` com a tag ``0.1.0``. Lembre-se que os "
"argumentos de construção assim como o nome e a tag podem ser adaptados de"
" acordo com suas necessidades. Estes valores servem apenas como exemplo."

#: ../../source/contributor-how-to-build-docker-images.rst:98
#, fuzzy
msgid "Building a Flower Binary Image"
msgstr "Construindo a imagem base"

#: ../../source/contributor-how-to-build-docker-images.rst:108
msgid "``BASE_REPOSITORY``"
msgstr "``BASE_REPOSITORY``"

#: ../../source/contributor-how-to-build-docker-images.rst:109
msgid "The repository name of the base image."
msgstr "O nome do repositório da imagem base."

#: ../../source/contributor-how-to-build-docker-images.rst:111
#, fuzzy
msgid "``flwr/base``"
msgstr "``FLWR_VERSION``"

#: ../../source/contributor-how-to-build-docker-images.rst:112
#, fuzzy
msgid "``BASE_IMAGE``"
msgstr "``BASE_REPOSITORY``"

#: ../../source/contributor-how-to-build-docker-images.rst:113
#, fuzzy
msgid "The Tag of the Flower base image."
msgstr "O nome do repositório da imagem base."

#: ../../source/contributor-how-to-build-docker-images.rst:115
msgid ":substitution-code:`|stable_flwr_version|-py3.11-ubuntu|ubuntu_version|`"
msgstr ""

#: ../../source/contributor-how-to-build-docker-images.rst:117
msgid ""
"For example, to build a SuperLink image with the latest Flower version, "
"Python 3.11 and Ubuntu 22.04, run the following:"
msgstr ""

#: ../../source/contributor-how-to-build-docker-images.rst:128
#, fuzzy
msgid ""
"If you want to use your own base image instead of the official Flower "
"base image, all you need to do is set the ``BASE_REPOSITORY`` build "
"argument to ``flwr_base`` (as we've specified above)."
msgstr ""
"Se você quiser usar sua própria imagem base ao invés da imagem oficial "
"base do Flower, tudo que você precisa fazer é definir os argumentos "
"``BASE_REPOSITORY`` e ``BASE_IMAGE_TAG`` como parte do comando de "
"compilação. O valor de ``BASE_REPOSITORY`` deve corresponder ao nome da "
"sua imagem e o valor de ``BASE_IMAGE_TAG`` deve corresponder à tag da sua"
" imagem."

#: ../../source/contributor-how-to-build-docker-images.rst:140
msgid "After creating the image, we can test whether the image is working:"
msgstr "Depois de criar a imagem, podemos testar se a imagem está funcionando:"

#: ../../source/contributor-how-to-build-docker-images.rst:147
msgid "Direct Reference Examples"
msgstr ""

#: ../../source/contributor-how-to-contribute-translations.rst:2
msgid "Contribute translations"
msgstr "Contribua com traduções"

#: ../../source/contributor-how-to-contribute-translations.rst:4
msgid ""
"Since `Flower 1.5 <https://flower.ai/docs/framework/ref-"
"changelog.html#v1-5-0-2023-08-31>`_ we have introduced translations to "
"our doc pages, but, as you might have noticed, the translations are often"
" imperfect. If you speak languages other than English, you might be able "
"to help us in our effort to make Federated Learning accessible to as many"
" people as possible by contributing to those translations! This might "
"also be a great opportunity for those wanting to become open source "
"contributors with little prerequisites."
msgstr ""
"Desde o `Flower 1.5 <https://flower.ai/docs/framework/ref-"
"changelog.html#v1-5-0-2023-08-31>`_ nós introduzimos traduções para "
"nossas páginas de documentação, mas, como você pode ter notado, as "
"traduções são muitas vezes imperfeitas. Se você fala línguas diferentes "
"do inglês, você pode ser capaz de nos ajudar neste esforço para tornar o "
"aprendizado federado acessível a tantas pessoas quanto possível, "
"contribuindo para essas traduções! Isso também pode ser uma grande "
"oportunidade para aqueles que querem se tornar contribuintes de código "
"aberto com poucos pré-requisitos."

#: ../../source/contributor-how-to-contribute-translations.rst:13
#, fuzzy
msgid ""
"Our translation project is publicly available over on `Weblate "
"<https://hosted.weblate.org/projects/flower-docs/framework/>`_, this "
"where most of the work will happen."
msgstr ""
"Nosso projeto de tradução está disponível publicamente em `Weblate "
"<https://hosted.weblate.org/projects/flower-docs/framework/>`_, onde a "
"maioria do trabalho acontecerá."

#: ../../source/contributor-how-to-contribute-translations.rst:18
#, fuzzy
msgid "Contribute to existing languages"
msgstr "Contribuir para as línguas existentes"

#: ../../source/contributor-how-to-contribute-translations.rst:23
msgid ""
"The first thing you will need to do in order to contribute is to create a"
" free Weblate account on this `page "
"<https://hosted.weblate.org/accounts/register/>`_. More information about"
" profile settings can be found `here "
"<https://docs.weblate.org/en/latest/user/profile.html>`_."
msgstr ""
"A primeira coisa que você precisa fazer para contribuir é criar uma conta"
" Weblate gratuita nesta `página "
"<https://hosted.weblate.org/accounts/register/>`_. Mais informações sobre"
" as configurações de perfil podem ser encontradas `aqui "
"<https://docs.weblate.org/en/latest/user/profile.html>`_."

#: ../../source/contributor-how-to-contribute-translations.rst:28
msgid ""
"Once you are signed in to Weblate, you can navigate to the `Flower "
"Framework project <https://hosted.weblate.org/projects/flower-"
"docs/framework/>`_. Here, you should see the different existing languages"
" that can be found on the website."
msgstr ""
"Uma vez que você esteja conectado ao Weblate, você pode navegar até o "
"projeto `Flower Framework <https://hosted.weblate.org/projects/flower-"
"docs/framework/>`_. Aqui, você deve ver os diferentes idiomas existentes "
"que podem ser encontrados no site."

#: ../../source/contributor-how-to-contribute-translations.rst:32
msgid ""
"Once you have selected the language you want to contribute to, you should"
" see a similar interface to this:"
msgstr ""
"Uma vez que você tenha selecionado o idioma que deseja contribuir, você "
"deve ver uma interface semelhante a esta:"

#: ../../source/contributor-how-to-contribute-translations.rst:37
msgid ""
"The most straight forward option here is to click on the ``Translate`` "
"button on the top right (in the ``Translation status`` section). This "
"will automatically bring you to the translation interface for "
"untranslated strings."
msgstr ""
"A opção mais direta aqui é clicar no botão ``Translate`` no canto "
"superior direito (na seção ``Translation status``). Isso te levará "
"automaticamente para a interface de tradução de strings ainda não "
"traduzidas."

#: ../../source/contributor-how-to-contribute-translations.rst:41
#, fuzzy
msgid "This is what the interface looks like:"
msgstr "É assim que a interface se parece:"

#: ../../source/contributor-how-to-contribute-translations.rst:45
msgid ""
"You input your translation in the text box at the top and then, once you "
"are happy with it, you either press ``Save and continue`` (to save the "
"translation and go to the next untranslated string), ``Save and stay`` "
"(to save the translation and stay on the same page), ``Suggest`` (to add "
"your translation to suggestions for other users to view), or ``Skip`` (to"
" go to the next untranslated string without saving anything)."
msgstr ""
"Você insire sua tradução na caixa de texto no topo e depois, uma vez que "
"você está satisfeito com ela, você pressiona ``Save and continue`` (para "
"salvar a tradução e ir para a próxima string não traduzida), ``Save and "
"stay`` (para salvar a tradução e ficar na mesma página), ``Suggest`` "
"(para adicionar sua tradução para sugestões para outros usuários verem), "
"ou ``Skip`` (para ir para a próxima string não traduzida sem salvar nada "
"na atual)."

#: ../../source/contributor-how-to-contribute-translations.rst:51
msgid ""
"In order to help with the translations, you can see on the bottom the "
"``Nearby strings``, the ``Comments`` (from other contributors), the "
"``Automatic suggestions`` (from machine translation engines), the "
"translations in ``Other languages``, and the ``History`` of translations "
"for this string."
msgstr ""
"Para ajudar com as traduções, você pode ver na parte inferior o ``Nearby "
"strings`` (strings próximas), o ``Comments`` (comentários de outros "
"contribuidores), o ``Automatic suggestions`` (sugestões atuomáticas de "
"sistemas de tradução automática), as traduções em ``Other languages`` "
"(outras línguas), e o ``History`` (histórico) de traduções para esta "
"string."

#: ../../source/contributor-how-to-contribute-translations.rst:56
msgid ""
"On the right, under the ``String information`` section, you can also "
"click the link under ``Source string location`` in order to view the "
"source of the doc file containing the string."
msgstr ""
"À direita, sob a seção ``String information``, você também pode clicar no"
" link sob ``Source string location`` para visualizar a fonte do arquivo "
"doc que contém a string."

#: ../../source/contributor-how-to-contribute-translations.rst:60
msgid ""
"For more information about translating using Weblate, you can check out "
"this `in-depth guide "
"<https://docs.weblate.org/en/latest/user/translating.html>`_."
msgstr ""
"Para obter mais informações sobre como traduzir usando o Weblate, você "
"pode conferir este `guia detalhado "
"<https://docs.weblate.org/en/latest/user/translating.html>`_."

#: ../../source/contributor-how-to-contribute-translations.rst:64
#, fuzzy
msgid "Add new languages"
msgstr "Adicionar novos idiomas"

#: ../../source/contributor-how-to-contribute-translations.rst:66
msgid ""
"If you want to add a new language, you will first have to contact us, "
"either on `Slack <https://flower.ai/join-slack>`_, or by opening an issue"
" on our `GitHub repo <https://github.com/adap/flower>`_."
msgstr ""
"Se você quiser adicionar uma nova língua, primeiro você terá que entrar "
"em contato conosco, no `Slack <https://flower.ai/join-slack>`_, ou "
"abrindo uma issue no nosso `repositório GitHub "
"<https://github.com/adap/flower>`_."

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:2
msgid "Develop in VSCode Dev Containers"
msgstr ""

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:4
msgid ""
"When working on the Flower framework we want to ensure that all "
"contributors use the same developer environment to format code or run "
"tests. For this purpose we are using the VSCode Remote Containers "
"extension. What is it? Read the following quote:"
msgstr ""

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:8
msgid ""
"The Visual Studio Code Remote - Containers extension lets you use a "
"Docker container as a fully-featured development environment. It allows "
"you to open any folder inside (or mounted into) a container and take "
"advantage of Visual Studio Code's full feature set. A "
"``devcontainer.json`` file in your project tells VS Code how to access "
"(or create) a development container with a well-defined tool and runtime "
"stack. This container can be used to run an application or to separate "
"tools, libraries, or runtimes needed for working with a codebase."
msgstr ""

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:16
msgid ""
"Workspace files are mounted from the local file system or copied or "
"cloned into the container. Extensions are installed and run inside the "
"container, where they have full access to the tools, platform, and file "
"system. This means that you can seamlessly switch your entire development"
" environment just by connecting to a different container."
msgstr ""

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:22
msgid ""
"Source: `Official VSCode documentation "
"<https://code.visualstudio.com/docs/devcontainers/containers>`_"
msgstr ""

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:26
msgid "Getting started"
msgstr ""

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:28
msgid ""
"Configuring and setting up the ``Dockerfile`` as well the configuration "
"for the devcontainer can be a bit more involved. The good thing is you "
"don't have to do it. Usually it should be enough to install `Docker "
"<https://docs.docker.com/engine/install/>`_ on your system and ensure its"
" available on your command line. Additionally, install the `VSCode "
"Containers Extension <vscode:extension/ms-vscode-remote.remote-"
"containers>`_."
msgstr ""

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:35
msgid ""
"Now you should be good to go. When starting VSCode, it will ask you to "
"run in the container environment and - if you confirm - automatically "
"build the container and use it. To manually instruct VSCode to use the "
"devcontainer, you can, after installing the extension, click the green "
"area in the bottom left corner of your VSCode window and select the "
"option *(Re)Open Folder in Container*."
msgstr ""

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:41
msgid ""
"In some cases your setup might be more involved. For those cases consult "
"the following sources:"
msgstr ""

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:44
msgid ""
"`Developing inside a Container "
"<https://code.visualstudio.com/docs/devcontainers/containers#_system-"
"requirements>`_"
msgstr ""

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:46
msgid ""
"`Remote development in Containers "
"<https://code.visualstudio.com/docs/devcontainers/tutorial>`_"
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:2
msgid "Install development versions"
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:5
msgid "Install development versions of Flower"
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:8
msgid "Using Poetry (recommended)"
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:10
msgid ""
"Install a ``flwr`` pre-release from PyPI: update the ``flwr`` dependency "
"in ``pyproject.toml`` and then reinstall (don't forget to delete "
"``poetry.lock`` (``rm poetry.lock``) before running ``poetry install``)."
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:14
msgid ""
"``flwr = { version = \"1.0.0a0\", allow-prereleases = true }`` (without "
"extras)"
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:15
msgid ""
"``flwr = { version = \"1.0.0a0\", allow-prereleases = true, extras = "
"[\"simulation\"] }`` (with extras)"
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:18
msgid ""
"Install ``flwr`` from a local copy of the Flower source code via "
"``pyproject.toml``:"
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:20
msgid "``flwr = { path = \"../../\", develop = true }`` (without extras)"
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:21
msgid ""
"``flwr = { path = \"../../\", develop = true, extras = [\"simulation\"] "
"}`` (with extras)"
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:23
msgid "Install ``flwr`` from a local wheel file via ``pyproject.toml``:"
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:25
msgid ""
"``flwr = { path = \"../../dist/flwr-1.8.0-py3-none-any.whl\" }`` (without"
" extras)"
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:26
msgid ""
"``flwr = { path = \"../../dist/flwr-1.8.0-py3-none-any.whl\", extras = "
"[\"simulation\"] }`` (with extras)"
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:29
msgid ""
"Please refer to the Poetry documentation for further details: `Poetry "
"Dependency Specification <https://python-poetry.org/docs/dependency-"
"specification/>`_"
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:33
msgid "Using pip (recommended on Colab)"
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:35
msgid "Install a ``flwr`` pre-release from PyPI:"
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:37
msgid "``pip install -U --pre flwr`` (without extras)"
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:38
msgid "``pip install -U --pre 'flwr[simulation]'`` (with extras)"
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:40
msgid ""
"Python packages can be installed from git repositories. Use one of the "
"following commands to install the Flower directly from GitHub."
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:43
msgid "Install ``flwr`` from the default GitHub branch (``main``):"
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:45
msgid ""
"``pip install flwr@git+https://github.com/adap/flower.git`` (without "
"extras)"
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:46
msgid ""
"``pip install 'flwr[simulation]@git+https://github.com/adap/flower.git'``"
" (with extras)"
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:49
msgid "Install ``flwr`` from a specific GitHub branch (``branch-name``):"
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:51
msgid ""
"``pip install flwr@git+https://github.com/adap/flower.git@branch-name`` "
"(without extras)"
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:53
msgid ""
"``pip install 'flwr[simulation]@git+https://github.com/adap/flower.git"
"@branch-name'`` (with extras)"
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:57
msgid "Open Jupyter Notebooks on Google Colab"
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:59
msgid ""
"Open the notebook ``doc/source/tutorial-series-get-started-with-flower-"
"pytorch.ipynb``:"
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:61
msgid ""
"https://colab.research.google.com/github/adap/flower/blob/main/doc/source"
"/tutorial-series-get-started-with-flower-pytorch.ipynb"
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:63
msgid ""
"Open a development version of the same notebook from branch `branch-name`"
" by changing ``main`` to ``branch-name`` (right after ``blob``):"
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:66
msgid ""
"https://colab.research.google.com/github/adap/flower/blob/branch-"
"name/doc/source/tutorial-series-get-started-with-flower-pytorch.ipynb"
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:68
msgid "Install a `whl` on Google Colab:"
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:70
msgid ""
"In the vertical icon grid on the left hand side, select ``Files`` > "
"``Upload to session storage``"
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:72
msgid "Upload the whl (e.g., ``flwr-1.8.0-py3-none-any.whl``)"
msgstr ""

#: ../../source/contributor-how-to-install-development-versions.rst:73
msgid ""
"Change ``!pip install -q 'flwr[simulation]' torch torchvision "
"matplotlib`` to ``!pip install -q 'flwr-1.8.0-py3-none-"
"any.whl[simulation]' torch torchvision matplotlib``"
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:2
msgid "Release Flower"
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:4
msgid ""
"This document describes the current release process. It may or may not "
"change in the future."
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:8
msgid "During the release"
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:10
msgid ""
"The version number of a release is stated in ``pyproject.toml``. To "
"release a new version of Flower, the following things need to happen (in "
"that order):"
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:13
msgid ""
"Run ``python3 ./dev/update_changelog.py <YOUR_GH_TOKEN>`` in order to add"
" every new change to the changelog (feel free to make manual changes to "
"the changelog afterwards until it looks good)."
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:16
msgid ""
"Once the changelog has been updated with all the changes, run ``./dev"
"/prepare-release-changelog.sh v<NEW_VERSION>``, where ``<NEW_VERSION>`` "
"is the version stated in ``pyproject.toml`` (notice the ``v`` added "
"before it). This will replace the ``Unreleased`` header of the changelog "
"by the version and current date, and it will add a thanking message for "
"the contributors. Open a pull request with those changes."
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:22
msgid ""
"Once the pull request is merged, tag the release commit with the version "
"number as soon as the PR is merged: ``git tag v<NEW_VERSION>`` (notice "
"the ``v`` added before the version number), then ``git push --tags``. "
"This will create a draft release on GitHub containing the correct "
"artifacts and the relevant part of the changelog."
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:26
msgid "Check the draft release on GitHub, and if everything is good, publish it."
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:29
msgid "After the release"
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:31
msgid "Create a pull request which contains the following changes:"
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:33
msgid "Increase the minor version in ``pyproject.toml`` by one."
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:34
msgid "Update all files which contain the current version number if necessary."
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:35
msgid "Add a new ``Unreleased`` section in ``changelog.md``."
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:37
msgid ""
"Merge the pull request on the same day (i.e., before a new nightly "
"release gets published to PyPI)."
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:41
msgid "Publishing a pre-release"
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:44
msgid "Pre-release naming"
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:46
msgid ""
"PyPI supports pre-releases (alpha, beta, release candidate). Pre-releases"
" MUST use one of the following naming patterns:"
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:49
msgid "Alpha: ``MAJOR.MINOR.PATCHaN``"
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:50
msgid "Beta: ``MAJOR.MINOR.PATCHbN``"
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:51
msgid "Release candidate (RC): ``MAJOR.MINOR.PATCHrcN``"
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:53
msgid "Examples include:"
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:55
msgid "``1.0.0a0``"
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:56
msgid "``1.0.0b0``"
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:57
msgid "``1.0.0rc0``"
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:58
msgid "``1.0.0rc1``"
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:60
msgid ""
"This is in line with PEP-440 and the recommendations from the Python "
"Packaging Authority (PyPA):"
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:63
msgid "`PEP-440 <https://peps.python.org/pep-0440/>`_"
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:64
msgid ""
"`PyPA Choosing a versioning scheme "
"<https://packaging.python.org/en/latest/guides/distributing-packages-"
"using-setuptools/#choosing-a-versioning-scheme>`_"
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:67
msgid ""
"Note that the approach defined by PyPA is not compatible with SemVer "
"2.0.0 spec, for details consult the `Semantic Versioning Specification "
"<https://semver.org/spec/v2.0.0.html#spec-item-11>`_ (specifically item "
"11 on precedence)."
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:73
msgid "Pre-release classification"
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:75
msgid "Should the next pre-release be called alpha, beta, or release candidate?"
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:77
msgid ""
"RC: feature complete, no known issues (apart from issues that are "
"classified as \"won't fix\" for the next stable release) - if no issues "
"surface this will become the next stable release"
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:80
msgid "Beta: feature complete, allowed to have known issues"
msgstr ""

#: ../../source/contributor-how-to-release-flower.rst:81
msgid "Alpha: not feature complete, allowed to have known issues"
msgstr ""

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:2
msgid "Set up a virtual env"
msgstr ""

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:4
msgid ""
"It is recommended to run your Python setup within a virtual environment. "
"This guide shows three different examples how to create a virtual "
"environment with pyenv virtualenv, poetry, or Anaconda. You can follow "
"the instructions or choose your preferred setup."
msgstr ""

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:10
msgid "Python Version"
msgstr ""

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:12
#: ../../source/how-to-install-flower.rst:7
msgid ""
"Flower requires at least `Python 3.9 <https://docs.python.org/3.9/>`_, "
"but `Python 3.10 <https://docs.python.org/3.10/>`_ or above is "
"recommended."
msgstr ""

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:17
msgid ""
"Due to a known incompatibility with `ray "
"<https://docs.ray.io/en/latest/>`_, we currently recommend utilizing at "
"most `Python 3.11 <https://docs.python.org/3.11/>`_ for running Flower "
"simulations."
msgstr ""

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:22
msgid "Virtualenv with Pyenv/Virtualenv"
msgstr ""

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:24
msgid ""
"One of the recommended virtual environment is `pyenv "
"<https://github.com/pyenv/pyenv>`_/`virtualenv <https://github.com/pyenv"
"/pyenv-virtualenv>`_. Please see `Flower examples "
"<https://github.com/adap/flower/tree/main/examples/>`_ for details."
msgstr ""

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:29
msgid ""
"Once Pyenv is set up, you can use it to install `Python Version 3.10 "
"<https://docs.python.org/3.10/>`_ or above:"
msgstr ""

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:36
msgid "Create the virtualenv with:"
msgstr ""

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:42
msgid "Activate the virtualenv by running the following command:"
msgstr ""

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:49
msgid "Virtualenv with Poetry"
msgstr ""

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:51
msgid ""
"The Flower examples are based on `Poetry <https://python-"
"poetry.org/docs/>`_ to manage dependencies. After installing Poetry you "
"simply create a virtual environment with:"
msgstr ""

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:58
msgid ""
"If you open a new terminal you can activate the previously created "
"virtual environment with the following command:"
msgstr ""

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:66
msgid "Virtualenv with Anaconda"
msgstr ""

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:68
msgid ""
"If you prefer to use Anaconda for your virtual environment then install "
"and setup the `conda <https://docs.conda.io/projects/conda/en/latest"
"/user-guide/install/index.html>`_ package. After setting it up you can "
"create a virtual environment with:"
msgstr ""

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:76
msgid "and activate the virtual environment with:"
msgstr ""

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:83
msgid "And then?"
msgstr ""

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:85
msgid ""
"As soon as you created your virtual environment you clone one of the "
"`Flower examples <https://github.com/adap/flower/tree/main/examples/>`_."
msgstr ""

#: ../../source/contributor-how-to-write-documentation.rst:2
msgid "Write documentation"
msgstr ""

#: ../../source/contributor-how-to-write-documentation.rst:5
msgid "Project layout"
msgstr ""

#: ../../source/contributor-how-to-write-documentation.rst:7
msgid ""
"The Flower documentation lives in the ``doc`` directory. The Sphinx-based"
" documentation system supports both reStructuredText (``.rst`` files) and"
" Markdown (``.md`` files)."
msgstr ""

#: ../../source/contributor-how-to-write-documentation.rst:10
#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:196
msgid ""
"Note that, in order to build the documentation locally (with ``poetry run"
" make html``, like described below), `Pandoc "
"<https://pandoc.org/installing.html>`_ needs to be installed on the "
"system."
msgstr ""

#: ../../source/contributor-how-to-write-documentation.rst:15
msgid "Edit an existing page"
msgstr ""

#: ../../source/contributor-how-to-write-documentation.rst:17
msgid "Edit an existing ``.rst`` (or ``.md``) file under ``doc/source/``"
msgstr ""

#: ../../source/contributor-how-to-write-documentation.rst:18
#: ../../source/contributor-how-to-write-documentation.rst:27
msgid "Compile the docs: ``cd doc``, then ``poetry run make html``"
msgstr ""

#: ../../source/contributor-how-to-write-documentation.rst:19
#: ../../source/contributor-how-to-write-documentation.rst:28
msgid "Open ``doc/build/html/index.html`` in the browser to check the result"
msgstr ""

#: ../../source/contributor-how-to-write-documentation.rst:22
msgid "Create a new page"
msgstr ""

#: ../../source/contributor-how-to-write-documentation.rst:24
msgid "Add new ``.rst`` file under ``doc/source/``"
msgstr ""

#: ../../source/contributor-how-to-write-documentation.rst:25
msgid "Add content to the new ``.rst`` file"
msgstr ""

#: ../../source/contributor-how-to-write-documentation.rst:26
msgid "Link to the new rst from ``index.rst``"
msgstr ""

#: ../../source/contributor-ref-good-first-contributions.rst:2
msgid "Good first contributions"
msgstr ""

#: ../../source/contributor-ref-good-first-contributions.rst:4
msgid ""
"We welcome contributions to Flower! However, it is not always easy to "
"know where to start. We therefore put together a few recommendations on "
"where to start to increase your chances of getting your PR accepted into "
"the Flower codebase."
msgstr ""

#: ../../source/contributor-ref-good-first-contributions.rst:9
msgid "Where to start"
msgstr ""

#: ../../source/contributor-ref-good-first-contributions.rst:11
msgid ""
"In general, it is easier to get PR's accepted if they only touch non-core"
" areas of the codebase. Good candidates to get started are:"
msgstr ""

#: ../../source/contributor-ref-good-first-contributions.rst:14
msgid "Documentation: What's missing? What could be expressed more clearly?"
msgstr ""

#: ../../source/contributor-ref-good-first-contributions.rst:15
#, python-format
msgid ""
"Open issues: Issues with the tag `good first issue "
"<https://github.com/adap/flower/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22>`_."
msgstr ""

#: ../../source/contributor-ref-good-first-contributions.rst:17
msgid "Baselines: See below."
msgstr ""

#: ../../source/contributor-ref-good-first-contributions.rst:18
msgid "Examples: See below."
msgstr ""

#: ../../source/contributor-ref-good-first-contributions.rst:21
#, fuzzy
msgid "Flower Baselines"
msgstr "``FLWR_VERSION``"

#: ../../source/contributor-ref-good-first-contributions.rst:23
msgid ""
"If you are not familiar with Flower Baselines, please check our "
"`contributing guide for baselines <https://flower.ai/docs/baselines/how-"
"to-contribute-baselines.html>`_."
msgstr ""

#: ../../source/contributor-ref-good-first-contributions.rst:26
msgid ""
"Then take a look at the open `issues "
"<https://github.com/adap/flower/issues?q=is%3Aopen+is%3Aissue+label%3A%22new+baseline%22>`_"
" for baseline requests. If you find a baseline that you'd like to work "
"on, and it has no assignees, feel free to assign it to yourself and get "
"started!"
msgstr ""

#: ../../source/contributor-ref-good-first-contributions.rst:31
msgid ""
"If you don't find the baseline you'd like to work on, be sure to open a "
"new issue with the baseline request template!"
msgstr ""

#: ../../source/contributor-ref-good-first-contributions.rst:35
#, fuzzy
msgid "Usage examples"
msgstr "Exemplo"

#: ../../source/contributor-ref-good-first-contributions.rst:37
msgid ""
"We wish we had more time to write usage examples because they help users "
"to get started with building what they want. If you notice any missing "
"examples that could help others, feel free to contribute!"
msgstr ""

#: ../../source/contributor-ref-secure-aggregation-protocols.rst:2
msgid "Secure Aggregation Protocols"
msgstr ""

#: ../../source/contributor-ref-secure-aggregation-protocols.rst:6
msgid ""
"While this term might be used in other places, here it refers to a series"
" of protocols, including ``SecAgg``, ``SecAgg+``, ``LightSecAgg``, "
"``FastSecAgg``, etc. This concept was first proposed by Bonawitz et al. "
"in `Practical Secure Aggregation for Federated Learning on User-Held Data"
" <https://arxiv.org/abs/1611.04482>`_."
msgstr ""

#: ../../source/contributor-ref-secure-aggregation-protocols.rst:11
msgid ""
"Secure Aggregation protocols are used to securely aggregate model updates"
" from multiple clients while keeping the updates private. This is done by"
" encrypting the model updates before sending them to the server. The "
"server can decrypt only the aggregated model update without being able to"
" inspect individual updates."
msgstr ""

#: ../../source/contributor-ref-secure-aggregation-protocols.rst:16
msgid ""
"Flower now provides the ``SecAgg`` and ``SecAgg+`` protocols. While we "
"plan to implement more protocols in the future, one may also implement "
"their own custom secure aggregation protocol via low-level APIs."
msgstr ""

#: ../../source/contributor-ref-secure-aggregation-protocols.rst:21
msgid "The ``SecAgg+`` protocol in Flower"
msgstr ""

#: ../../source/contributor-ref-secure-aggregation-protocols.rst:23
msgid ""
"The ``SecAgg+`` protocol is implemented using the ``SecAggPlusWorkflow`` "
"in the ``ServerApp`` and the ``secaggplus_mod`` in the ``ClientApp``. The"
" ``SecAgg`` protocol is a special case of the ``SecAgg+`` protocol, and "
"one may use ``SecAggWorkflow`` and ``secagg_mod`` for that."
msgstr ""

#: ../../source/contributor-ref-secure-aggregation-protocols.rst:28
msgid ""
"You may find a detailed example in the `Secure Aggregation Example "
"<https://flower.ai/docs/examples/flower-secure-aggregation.html>`_. The "
"documentation for the ``SecAgg+`` protocol configuration is available at "
"`SecAggPlusWorkflow <https://flower.ai/docs/framework/ref-"
"api/flwr.server.workflow.SecAggPlusWorkflow.html>`_."
msgstr ""

#: ../../source/contributor-ref-secure-aggregation-protocols.rst:33
msgid ""
"The logic of the ``SecAgg+`` protocol is illustrated in the following "
"sequence diagram: the dashed lines represent communication over the "
"network, and the solid lines represent communication within the same "
"process. The ``ServerApp`` is connected to ``SuperLink``, and the "
"``ClientApp`` is connected to the ``SuperNode``; thus, the communication "
"between the ``ServerApp`` and the ``ClientApp`` is done via the "
"``SuperLink`` and the ``SuperNode``."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:2
msgid "Contribute on GitHub"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:4
msgid ""
"This guide is for people who want to get involved with Flower, but who "
"are not used to contributing to GitHub projects."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:7
msgid ""
"If you're familiar with how contributing on GitHub works, you can "
"directly checkout our :doc:`getting started guide for contributors "
"<contributor-tutorial-get-started-as-a-contributor>`."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:12
msgid "Setting up the repository"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:29
msgid "**Create a GitHub account and setup Git**"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:15
msgid ""
"Git is a distributed version control tool. This allows for an entire "
"codebase's history to be stored and every developer's machine. It is a "
"software that will need to be installed on your local machine, you can "
"follow this `guide <https://docs.github.com/en/get-started/getting-"
"started-with-git/set-up-git>`_ to set it up."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:21
msgid ""
"GitHub, itself, is a code hosting platform for version control and "
"collaboration. It allows for everyone to collaborate and work from "
"anywhere on remote repositories."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:25
msgid ""
"If you haven't already, you will need to create an account on `GitHub "
"<https://github.com/signup>`_."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:28
msgid ""
"The idea behind the generic Git and GitHub workflow boils down to this: "
"you download code from a remote repository on GitHub, make changes "
"locally and keep track of them using Git and then you upload your new "
"history back to GitHub."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:42
msgid "**Forking the Flower repository**"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:32
msgid ""
"A fork is a personal copy of a GitHub repository. To create one for "
"Flower, you must navigate to https://github.com/adap/flower (while "
"connected to your GitHub account) and click the ``Fork`` button situated "
"on the top right of the page."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:38
msgid ""
"You can change the name if you want, but this is not necessary as this "
"version of Flower will be yours and will sit inside your own account "
"(i.e., in your own list of repositories). Once created, you should see on"
" the top left corner that you are looking at your own version of Flower."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:59
msgid "**Cloning your forked repository**"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:45
msgid ""
"The next step is to download the forked repository on your machine to be "
"able to make changes to it. On your forked repository page, you should "
"first click on the ``Code`` button on the right, this will give you the "
"ability to copy the HTTPS link of the repository."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:52
msgid ""
"Once you copied the \\<URL\\>, you can open a terminal on your machine, "
"navigate to the place you want to download the repository to and type:"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:59
msgid ""
"This will create a ``flower/`` (or the name of your fork if you renamed "
"it) folder in the current working directory."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:78
msgid "**Add origin**"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:62
msgid "You can then go into the repository folder:"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:68
msgid ""
"And here we will need to add an origin to our repository. The origin is "
"the \\<URL\\> of the remote fork repository. To obtain it, we can do as "
"previously mentioned by going to our fork repository on our GitHub "
"account and copying the link."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:75
msgid ""
"Once the \\<URL\\> is copied, we can type the following command in our "
"terminal:"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:102
msgid "**Add upstream**"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:81
msgid ""
"Now we will add an upstream address to our repository. Still in the same "
"directory, we must run the following command:"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:88
msgid "The following diagram visually explains what we did in the previous steps:"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:92
msgid ""
"The upstream is the GitHub remote address of the parent repository (in "
"this case Flower), i.e. the one we eventually want to contribute to and "
"therefore need an up-to-date history of. The origin is just the GitHub "
"remote address of the forked repository we created, i.e. the copy (fork) "
"in our own account."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:97
msgid ""
"To make sure our local version of the fork is up-to-date with the latest "
"changes from the Flower repository, we can execute the following command:"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:105
msgid "Setting up the coding environment"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:107
msgid ""
"This can be achieved by following this :doc:`getting started guide for "
"contributors <contributor-tutorial-get-started-as-a-contributor>` (note "
"that you won't need to clone the repository). Once you are able to write "
"code and test it, you can finally start making changes!"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:113
msgid "Making changes"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:115
msgid ""
"Before making any changes make sure you are up-to-date with your "
"repository:"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:121
msgid "And with Flower's repository:"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:134
msgid "**Create a new branch**"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:128
msgid ""
"To make the history cleaner and easier to work with, it is good practice "
"to create a new branch for each feature/project that needs to be "
"implemented."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:131
msgid ""
"To do so, just run the following command inside the repository's "
"directory:"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:136
msgid "**Make changes**"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:137
msgid "Write great code and create wonderful changes using your favorite editor!"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:149
msgid "**Test and format your code**"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:139
msgid ""
"Don't forget to test and format your code! Otherwise your code won't be "
"able to be merged into the Flower repository. This is done so the "
"codebase stays consistent and easy to understand."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:143
msgid "To do so, we have written a few scripts that you can execute:"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:162
msgid "**Stage changes**"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:152
msgid ""
"Before creating a commit that will update your history, you must specify "
"to Git which files it needs to take into account."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:155
msgid "This can be done with:"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:161
msgid ""
"To check which files have been modified compared to the last version "
"(last commit) and to see which files are staged for commit, you can use "
"the ``git status`` command."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:173
msgid "**Commit changes**"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:165
msgid ""
"Once you have added all the files you wanted to commit using ``git add``,"
" you can finally create your commit using this command:"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:172
msgid ""
"The \\<commit_message\\> is there to explain to others what the commit "
"does. It should be written in an imperative style and be concise. An "
"example would be ``git commit -m \"Add images to README\"``."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:185
msgid "**Push the changes to the fork**"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:176
msgid ""
"Once we have committed our changes, we have effectively updated our local"
" history, but GitHub has no way of knowing this unless we push our "
"changes to our origin's remote address:"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:184
msgid ""
"Once this is done, you will see on the GitHub that your forked repo was "
"updated with the changes you have made."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:188
msgid "Creating and merging a pull request (PR)"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:226
msgid "**Create the PR**"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:191
msgid ""
"Once you have pushed changes, on the GitHub webpage of your repository "
"you should see the following message:"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:196
msgid "Otherwise you can always find this option in the ``Branches`` page."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:198
msgid ""
"Once you click the ``Compare & pull request`` button, you should see "
"something similar to this:"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:203
msgid "At the top you have an explanation of which branch will be merged where:"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:207
msgid ""
"In this example you can see that the request is to merge the branch "
"``doc-fixes`` from my forked repository to branch ``main`` from the "
"Flower repository."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:210
msgid ""
"The title should be changed to adhere to the :ref:`pr_title_format` "
"guidelines, otherwise it won't be possible to merge the PR. So in this "
"case, a correct title might be ``docs(framework:skip) Fix typos``."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:214
msgid ""
"The input box in the middle is there for you to describe what your PR "
"does and to link it to existing issues. We have placed comments (that "
"won't be rendered once the PR is opened) to guide you through the "
"process."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:218
msgid "It is important to follow the instructions described in comments."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:220
msgid ""
"At the bottom you will find the button to open the PR. This will notify "
"reviewers that a new PR has been opened and that they should look over it"
" to merge or to request changes."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:224
msgid ""
"If your PR is not yet ready for review, and you don't want to notify "
"anyone, you have the option to create a draft pull request:"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:230
msgid "**Making new changes**"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:229
msgid ""
"Once the PR has been opened (as draft or not), you can still push new "
"commits to it the same way we did before, by making changes to the branch"
" associated with the PR."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:253
msgid "**Review the PR**"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:233
msgid ""
"Once the PR has been opened or once the draft PR has been marked as "
"ready, a review from code owners will be automatically requested:"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:238
msgid ""
"Code owners will then look into the code, ask questions, request changes "
"or validate the PR."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:241
msgid "Merging will be blocked if there are ongoing requested changes."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:245
msgid ""
"To resolve them, just push the necessary changes to the branch associated"
" with the PR:"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:250
msgid "And resolve the conversation:"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:254
msgid ""
"Once all the conversations have been resolved, you can re-request a "
"review."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:274
msgid "**Once the PR is merged**"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:256
msgid ""
"If all the automatic tests have passed and reviewers have no more changes"
" to request, they can approve the PR and merge it."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:261
msgid ""
"Once it is merged, you can delete the branch on GitHub (a button should "
"appear to do so) and also delete it locally by doing:"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:269
msgid "Then you should update your forked repository by doing:"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:277
msgid "Example of first contribution"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:280
msgid "Problem"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:282
msgid ""
"For our documentation, we've started to use the `Diàtaxis framework "
"<https://diataxis.fr/>`_."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:285
msgid ""
"Our \"How to\" guides should have titles that continue the sentence \"How"
" to …\", for example, \"How to upgrade to Flower 1.0\"."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:288
msgid ""
"Most of our guides do not follow this new format yet, and changing their "
"title is (unfortunately) more involved than one might think."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:291
msgid ""
"This issue is about changing the title of a doc from present continuous "
"to present simple."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:294
msgid ""
"Let's take the example of \"Saving Progress\" which we changed to \"Save "
"Progress\". Does this pass our check?"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:297
msgid "Before: \"How to saving progress\" ❌"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:299
msgid "After: \"How to save progress\" ✅"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:302
msgid "Solution"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:304
msgid ""
"This is a tiny change, but it'll allow us to test your end-to-end setup. "
"After cloning and setting up the Flower repo, here's what you should do:"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:307
msgid "Find the source file in ``doc/source``"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:308
msgid ""
"Make the change in the ``.rst`` file (beware, the dashes under the title "
"should be the same length as the title itself)"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:310
msgid ""
"Build the docs and `check the result <contributor-how-to-write-"
"documentation.html#edit-an-existing-page>`_"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:314
msgid "Rename file"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:316
msgid ""
"You might have noticed that the file name still reflects the old wording."
" If we just change the file, then we break all existing links to it - it "
"is **very important** to avoid that, breaking links can harm our search "
"engine ranking."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:320
msgid "Here's how to change the file name:"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:322
msgid "Change the file name to ``save-progress.rst``"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:323
msgid "Add a redirect rule to ``doc/source/conf.py``"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:325
msgid ""
"This will cause a redirect from ``saving-progress.html`` to ``save-"
"progress.html``, old links will continue to work."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:329
msgid "Apply changes in the index file"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:331
msgid ""
"For the lateral navigation bar to work properly, it is very important to "
"update the ``index.rst`` file as well. This is where we define the whole "
"arborescence of the navbar."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:335
msgid "Find and modify the file name in ``index.rst``"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:338
msgid "Open PR"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:340
msgid ""
"Commit the changes (commit messages are always imperative: \"Do "
"something\", in this case \"Change …\")"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:342
msgid "Push the changes to your fork"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:343
msgid ""
"Open a PR (as shown above) with title ``docs(framework) Update how-to "
"guide title``"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:344
msgid "Wait for it to be approved!"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:345
msgid "Congrats! 🥳 You're now officially a Flower contributor!"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:348
#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:573
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:1012
#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:811
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:857
#: ../../source/tutorial-series-what-is-federated-learning.ipynb:367
msgid "Next steps"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:350
msgid ""
"Once you have made your first PR, and want to contribute more, be sure to"
" check out the following :"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:353
msgid ""
":doc:`Good first contributions <contributor-ref-good-first-"
"contributions>`, where you should particularly look into the "
"``baselines`` contributions."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:357
msgid "Appendix"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:362
msgid "PR title format"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:364
msgid "We enforce the following PR title format:"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:370
msgid ""
"(or ``<type>(<project>:skip) <subject>`` to ignore the PR in the "
"changelog)"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:372
msgid ""
"Where ``<type>`` needs to be in ``{ci, fix, feat, docs, refactor, "
"break}``, ``<project>`` should be in ``{framework, baselines, datasets, "
"examples, or '*' when modifying multiple projects which requires the "
"':skip' flag to be used}``, and ``<subject>`` starts with a capitalised "
"verb in the imperative mood."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:377
#, fuzzy
msgid "Valid examples:"
msgstr "Exemplo"

#: ../../source/contributor-tutorial-contribute-on-github.rst:379
msgid "``feat(framework) Add flwr build CLI command``"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:380
msgid "``refactor(examples:skip) Improve quickstart-pytorch logging``"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:381
msgid "``ci(*:skip) Enforce PR title format``"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:383
msgid "Invalid examples:"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:385
msgid "``feat(framework): Add flwr build CLI command`` (extra ``:``)"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:386
msgid ""
"``feat(*) Add flwr build CLI command`` (missing ``skip`` flag along with "
"``*``)"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:387
msgid "``feat(skip) Add flwr build CLI command`` (missing ``<project>``)"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:388
msgid "``feat(framework) add flwr build CLI command`` (non capitalised verb)"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:389
msgid "``feat(framework) Add flwr build CLI command.`` (dot at the end)"
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:390
msgid "``Add flwr build CLI command.`` (missing ``<type>(<project>)``)"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:2
msgid "Get started as a contributor"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:5
#: ../../source/docker/run-quickstart-examples-docker-compose.rst:16
#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:18
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:13
#: ../../source/docker/tutorial-quickstart-docker.rst:11
msgid "Prerequisites"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:7
msgid "`Python 3.9 <https://docs.python.org/3.9/>`_ or above"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:8
msgid "`Poetry 1.3 <https://python-poetry.org/>`_ or above"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:9
msgid "(Optional) `pyenv <https://github.com/pyenv/pyenv>`_"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:10
msgid "(Optional) `pyenv-virtualenv <https://github.com/pyenv/pyenv-virtualenv>`_"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:12
msgid ""
"Flower uses ``pyproject.toml`` to manage dependencies and configure "
"development tools (the ones which support it). Poetry is a build tool "
"which supports `PEP 517 <https://peps.python.org/pep-0517/>`_."
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:17
msgid "Developer Machine Setup"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:20
msgid "Preliminaries"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:22
msgid "Some system-wide dependencies are needed."
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:25
msgid "For macOS"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:27
msgid ""
"Install `homebrew <https://brew.sh/>`_. Don't forget the post-"
"installation actions to add `brew` to your PATH."
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:29
msgid ""
"Install `xz` (to install different Python versions) and `pandoc` to build"
" the docs:"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:36
msgid "For Ubuntu"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:38
msgid ""
"Ensure you system (Ubuntu 22.04+) is up-to-date, and you have all "
"necessary packages:"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:47
msgid "Create Flower Dev Environment"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:49
msgid ""
"Clone the `Flower repository <https://github.com/adap/flower>`_ from "
"GitHub:"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:56
msgid ""
"Let's create the Python environment for all-things Flower. If you wish to"
" use ``pyenv``, we provide two convenience scripts that you can use. If "
"you prefer using something else than ``pyenv``, create a new environment,"
" activate and skip to the last point where all packages are installed."
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:61
msgid ""
"If you don't have ``pyenv`` installed, the following script that will "
"install it, set it up, and create the virtual environment (with "
":substitution-code:`Python |python_full_version|` by default):"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:69
msgid ""
"If you already have ``pyenv`` installed (along with the ``pyenv-"
"virtualenv`` plugin), you can use the following convenience script (with "
":substitution-code:`Python |python_full_version|` by default):"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:77
msgid ""
"3. Install the Flower package in development mode (think ``pip install "
"-e``) along with all necessary dependencies:"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:85
msgid "Convenience Scripts"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:87
msgid ""
"The Flower repository contains a number of convenience scripts to make "
"recurring development tasks easier and less error-prone. See the ``/dev``"
" subdirectory for a full list. The following scripts are amongst the most"
" important ones:"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:92
msgid "Create/Delete Virtual Environment"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:101
msgid "Compile ProtoBuf Definitions"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:108
msgid "Auto-Format Code"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:115
msgid "Run Linters and Tests"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:122
msgid "Add a pre-commit hook"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:124
msgid ""
"Developers may integrate a pre-commit hook into their workflow utilizing "
"the `pre-commit <https://pre-commit.com/#install>`_ library. The pre-"
"commit hook is configured to execute two primary operations: "
"``./dev/format.sh`` and ``./dev/test.sh`` scripts."
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:128
msgid "There are multiple ways developers can use this:"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:130
msgid "Install the pre-commit hook to your local git directory by simply running:"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:136
msgid ""
"Each ``git commit`` will trigger the execution of formatting and "
"linting/test scripts."
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:138
msgid ""
"If in a hurry, bypass the hook using ``--no-verify`` with the ``git "
"commit`` command."
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:145
msgid ""
"For developers who prefer not to install the hook permanently, it is "
"possible to execute a one-time check prior to committing changes by using"
" the following command:"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:152
msgid ""
"This executes the formatting and linting checks/tests on all the files "
"without modifying the default behavior of ``git commit``."
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:156
msgid "Run Github Actions (CI) locally"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:158
msgid ""
"Developers could run the full set of Github Actions workflows under their"
" local environment by using `Act <https://github.com/nektos/act>`_. "
"Please refer to the installation instructions under the linked repository"
" and run the next command under Flower main cloned repository folder:"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:167
msgid ""
"The Flower default workflow would run by setting up the required Docker "
"machines underneath."
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:171
msgid "Build Release"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:173
msgid ""
"Flower uses Poetry to build releases. The necessary command is wrapped in"
" a simple script:"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:180
msgid ""
"The resulting ``.whl`` and ``.tar.gz`` releases will be stored in the "
"``/dist`` subdirectory."
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:184
msgid "Build Documentation"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:186
msgid ""
"Flower's documentation uses `Sphinx <https://www.sphinx-doc.org/>`_. "
"There's no convenience script to re-build the documentation yet, but it's"
" pretty easy:"
msgstr ""

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:194
msgid "This will generate HTML documentation in ``doc/build/html``."
msgstr ""

#: ../../source/docker/enable-tls.rst:2
msgid "Enable TLS for Secure Connections"
msgstr ""

#: ../../source/docker/enable-tls.rst:4
msgid ""
"When operating in a production environment, it is strongly recommended to"
" enable Transport Layer Security (TLS) for each Flower component to "
"ensure secure communication."
msgstr ""

#: ../../source/docker/enable-tls.rst:9
msgid ""
"For testing purposes, you can generate your own self-signed certificates."
" The `Enable SSL connections <https://flower.ai/docs/framework/how-to-"
"enable-ssl-connections.html#certificates>`__ page contains a section that"
" will guide you through the process."
msgstr ""

#: ../../source/docker/enable-tls.rst:16
msgid ""
"Because Flower containers, by default, run with a non-root user ``app``, "
"the mounted files and directories must have the proper permissions for "
"the user ID ``49999``."
msgstr ""

#: ../../source/docker/enable-tls.rst:19
msgid ""
"For example, to change the user ID of all files in the ``certificates/`` "
"directory, you can run ``sudo chown -R 49999:49999 certificates/*``."
msgstr ""

#: ../../source/docker/enable-tls.rst:22
msgid ""
"If you later want to delete the directory, you can change the user ID "
"back to the current user ID by running ``sudo chown -R $USER:$(id -gn) "
"certificates``."
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid "Isolation Mode ``subprocess``"
msgstr ""

#: ../../source/docker/enable-tls.rst:29
msgid ""
"By default, the ServerApp is executed as a subprocess within the "
"SuperLink Docker container, and the ClientApp is run as a subprocess "
"within the SuperNode Docker container. You can learn more about the "
"different process modes here: :doc:`run-as-subprocess`."
msgstr ""

#: ../../source/docker/enable-tls.rst:34 ../../source/docker/enable-tls.rst:119
msgid ""
"To enable TLS between the SuperLink and SuperNode, as well as between the"
" SuperLink and the ``flwr`` CLI, you will need a PEM-encoded root "
"certificate, private key, and certificate chain."
msgstr ""

#: ../../source/docker/enable-tls.rst:37
msgid "**SuperLink**"
msgstr ""

#: ../../source/docker/enable-tls.rst:39
msgid ""
"Assuming all files we need are in the local ``superlink-certificates`` "
"directory, we can use the flag ``--volume`` to mount the local "
"directories into the SuperLink container:"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid "Understanding the command"
msgstr ""

#: ../../source/docker/enable-tls.rst:54 ../../source/docker/enable-tls.rst:96
#: ../../source/docker/enable-tls.rst:140
#: ../../source/docker/enable-tls.rst:179
#: ../../source/docker/enable-tls.rst:206
#: ../../source/docker/enable-tls.rst:231
#: ../../source/docker/tutorial-quickstart-docker.rst:68
#: ../../source/docker/tutorial-quickstart-docker.rst:109
#: ../../source/docker/tutorial-quickstart-docker.rst:221
#: ../../source/docker/tutorial-quickstart-docker.rst:303
msgid "``docker run``: This tells Docker to run a container from an image."
msgstr ""

#: ../../source/docker/enable-tls.rst:55 ../../source/docker/enable-tls.rst:97
#: ../../source/docker/enable-tls.rst:141
#: ../../source/docker/enable-tls.rst:180
#: ../../source/docker/enable-tls.rst:207
#: ../../source/docker/enable-tls.rst:232
#: ../../source/docker/tutorial-quickstart-docker.rst:69
#: ../../source/docker/tutorial-quickstart-docker.rst:110
#: ../../source/docker/tutorial-quickstart-docker.rst:222
#: ../../source/docker/tutorial-quickstart-docker.rst:304
msgid "``--rm``: Remove the container once it is stopped or the command exits."
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"``--volume ./superlink-certificates/:/app/certificates/:ro``: Mount the "
"``superlink-certificates``"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"directory in the current working directory of the host machine as a read-"
"only volume"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid "at the ``/app/certificates`` directory inside the container."
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"This allows the container to access the TLS certificates that are stored "
"in the certificates"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid "directory."
msgstr ""

#: ../../source/docker/enable-tls.rst:62
msgid "``<superlink-image>``: The name of your SuperLink image to be run."
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"``--ssl-ca-certfile certificates/ca.crt``: Specify the location of the CA"
" certificate file"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid "inside the container."
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"The ``certificates/ca.crt`` file is a certificate that is used to verify "
"the identity of the"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid "SuperLink."
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"``--ssl-certfile certificates/server.pem``: Specify the location of the "
"SuperLink's"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid "TLS certificate file inside the container."
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"The ``certificates/server.pem`` file is used to identify the SuperLink "
"and to encrypt the"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid "data that is transmitted over the network."
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"``--ssl-keyfile certificates/server.key``: Specify the location of the "
"SuperLink's"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid "TLS private key file inside the container."
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"The ``certificates/server.key`` file is used to decrypt the data that is "
"transmitted over"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid "the network."
msgstr ""

#: ../../source/docker/enable-tls.rst:79
msgid "**SuperNode**"
msgstr ""

#: ../../source/docker/enable-tls.rst:83 ../../source/docker/enable-tls.rst:189
msgid ""
"If you're generating self-signed certificates and the ``ca.crt`` "
"certificate doesn't exist on the SuperNode, you can copy it over after "
"the generation step."
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"``--volume ./superlink-certificates/ca.crt:/app/ca.crt/:ro``: Mount the "
"``ca.crt``"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"file from the ``superlink-certificates`` directory of the host machine as"
" a read-only"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid "volume at the ``/app/ca.crt`` directory inside the container."
msgstr ""

#: ../../source/docker/enable-tls.rst:101
msgid "``<supernode-image>``: The name of your SuperNode image to be run."
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"``--root-certificates ca.crt``: This specifies the location of the CA "
"certificate file"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid "The ``ca.crt`` file is used to verify the identity of the SuperLink."
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid "Isolation Mode ``process``"
msgstr ""

#: ../../source/docker/enable-tls.rst:109
msgid ""
"In isolation mode ``process``, the ServerApp and ClientApp run in their "
"own processes. Unlike in isolation mode ``subprocess``, the SuperLink or "
"SuperNode does not attempt to create the respective processes; instead, "
"they must be created externally."
msgstr ""

#: ../../source/docker/enable-tls.rst:113
msgid ""
"It is possible to run only the SuperLink in isolation mode ``subprocess``"
" and the SuperNode in isolation mode ``process``, or vice versa, or even "
"both with isolation mode ``process``."
msgstr ""

#: ../../source/docker/enable-tls.rst:117
msgid "**SuperLink and ServerApp**"
msgstr ""

#: ../../source/docker/enable-tls.rst:122
msgid ""
"Assuming all files we need are in the local ``superlink-certificates`` "
"directory, we can use the flag ``--volume`` to mount the local directory "
"into the SuperLink container:"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid "``--volume ./superlink-certificates/:/app/certificates/:ro``: Mount the"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"``superlink-certificates`` directory in the current working directory of "
"the host"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"machine as a read-only volume at the ``/app/certificates`` directory "
"inside the container."
msgstr ""

#: ../../source/docker/enable-tls.rst
#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
":substitution-code:`flwr/superlink:|stable_flwr_version|`: The name of "
"the image to be run and the specific"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"tag of the image. The tag :substitution-code:`|stable_flwr_version|` "
"represents a specific version of the image."
msgstr ""

#: ../../source/docker/enable-tls.rst
#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"``--isolation process``: Tells the SuperLink that the ServerApp is "
"created by separate"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid "independent process. The SuperLink does not attempt to create it."
msgstr ""

#: ../../source/docker/enable-tls.rst:168
#: ../../source/docker/tutorial-quickstart-docker.rst:207
msgid "Start the ServerApp container:"
msgstr ""

#: ../../source/docker/enable-tls.rst
#: ../../source/docker/tutorial-quickstart-docker-compose.rst
#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "Understand the command"
msgstr ""

#: ../../source/docker/enable-tls.rst:181
msgid "``<serverapp-image>``: The name of your ServerApp image to be run."
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"``--insecure``:  This flag tells the container to operate in an insecure "
"mode, allowing"
msgstr ""

#: ../../source/docker/enable-tls.rst
#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"unencrypted communication. Secure connections will be added in future "
"releases."
msgstr ""

#: ../../source/docker/enable-tls.rst:185
msgid "**SuperNode and ClientApp**"
msgstr ""

#: ../../source/docker/enable-tls.rst:192
msgid "Start the SuperNode container:"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"``--volume ./superlink-certificates/ca.crt:/app/ca.crt/:ro``: Mount the "
"``ca.crt`` file from the"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"``superlink-certificates`` directory of the host machine as a read-only "
"volume at the ``/app/ca.crt``"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid "directory inside the container."
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
":substitution-code:`flwr/supernode:|stable_flwr_version|`: The name of "
"the image to be run and the specific"
msgstr ""

#: ../../source/docker/enable-tls.rst
#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"``--isolation process``: Tells the SuperNode that the ClientApp is "
"created by separate"
msgstr ""

#: ../../source/docker/enable-tls.rst
#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "independent process. The SuperNode does not attempt to create it."
msgstr ""

#: ../../source/docker/enable-tls.rst:220
msgid "Start the ClientApp container:"
msgstr ""

#: ../../source/docker/enable-tls.rst:233
msgid "``<clientapp-image>``: The name of your ClientApp image to be run."
msgstr ""

#: ../../source/docker/enable-tls.rst:237
#: ../../source/docker/run-quickstart-examples-docker-compose.rst:54
msgid ""
"Append the following lines to the end of the ``pyproject.toml`` file and "
"save it:"
msgstr ""

#: ../../source/docker/enable-tls.rst:239
#: ../../source/docker/run-quickstart-examples-docker-compose.rst:56
#: ../../source/docker/tutorial-quickstart-docker.rst:330
msgid "pyproject.toml"
msgstr ""

#: ../../source/docker/enable-tls.rst:246
#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:152
msgid ""
"The path of the ``root-certificates`` should be relative to the location "
"of the ``pyproject.toml`` file."
msgstr ""

#: ../../source/docker/enable-tls.rst:251
#: ../../source/docker/run-quickstart-examples-docker-compose.rst:65
msgid ""
"You can customize the string that follows ``tool.flwr.federations.`` to "
"fit your needs. However, please note that the string cannot contain a dot"
" (``.``)."
msgstr ""

#: ../../source/docker/enable-tls.rst:254
msgid ""
"In this example, ``local-deployment-tls`` has been used. Just remember to"
" replace ``local-deployment-tls`` with your chosen name in both the "
"``tool.flwr.federations.`` string and the corresponding ``flwr run .`` "
"command."
msgstr ""

#: ../../source/docker/index.rst:2
msgid "Run Flower using Docker"
msgstr ""

#: ../../source/docker/index.rst:4
msgid ""
"Start your Flower journey with our pre-made Docker images on Docker Hub, "
"supporting ``amd64`` and ``arm64v8`` architectures."
msgstr ""

#: ../../source/docker/index.rst:7
msgid ""
"Our Quickstart guide walks you through containerizing a Flower project "
"and running it end to end using Docker."
msgstr ""

#: ../../source/docker/index.rst:11
msgid "Getting Started"
msgstr ""

#: ../../source/docker/index.rst:19
msgid "Running in Production"
msgstr ""

#: ../../source/docker/index.rst:28
msgid "Advanced Options"
msgstr ""

#: ../../source/docker/index.rst:40
msgid "Run Flower using Docker Compose"
msgstr ""

#: ../../source/docker/persist-superlink-state.rst:2
msgid "Persist the State of the SuperLink"
msgstr ""

#: ../../source/docker/persist-superlink-state.rst:4
msgid ""
"By default, the Flower SuperLink keeps its state in-memory. When using "
"the Docker flag ``--rm``, the state is not persisted between container "
"starts."
msgstr ""

#: ../../source/docker/persist-superlink-state.rst:7
msgid ""
"If you want to persist the state of the SuperLink on your host system, "
"all you need to do is specify a directory where you want to save the file"
" on your host system and a name for the database file."
msgstr ""

#: ../../source/docker/persist-superlink-state.rst:11
msgid ""
"By default, the SuperLink container runs with a non-root user called "
"``app`` with the user ID ``49999``. It is recommended to create a new "
"directory and change the user ID of the directory to ``49999`` to ensure "
"the mounted directory has the proper permissions."
msgstr ""

#: ../../source/docker/persist-superlink-state.rst:15
msgid ""
"If you later want to delete the directory, you can change the user ID "
"back to the current user ID by running ``sudo chown -R $USER:$(id -gn) "
"state``."
msgstr ""

#: ../../source/docker/persist-superlink-state.rst:21
msgid ""
"In the example below, we create a new directory called ``state``, change "
"the user ID and tell Docker via the flag ``--volume`` to mount the local "
"``state`` directory into the ``/app/state`` directory of the container. "
"Lastly, we use the flag ``--database`` to specify the name of the "
"database file."
msgstr ""

#: ../../source/docker/persist-superlink-state.rst:36
msgid ""
"As soon as the SuperLink starts, the file ``state.db`` is created in the "
"``state`` directory on your host system. If the file already exists, the "
"SuperLink tries to restore the state from the file. To start the "
"SuperLink with an empty database, ensure that there is no database called"
" ``state.db`` in the ``state`` directory (``rm state.db``) before you "
"execute the ``docker run`` command above."
msgstr ""

#: ../../source/docker/pin-version.rst:2
msgid "Pin a Docker Image to a Specific Version"
msgstr ""

#: ../../source/docker/pin-version.rst:4
msgid ""
"It may happen that we update the images behind the tags. Such updates "
"usually include security updates of system dependencies that should not "
"change the functionality of Flower. However, if you want to ensure that "
"you use a fixed version of the Docker image in your deployments, you can "
"`specify the digest "
"<https://docs.docker.com/reference/cli/docker/image/pull/#pull-an-image-"
"by-digest-immutable-identifier>`_ of the image instead of the tag."
msgstr ""

#: ../../source/docker/pin-version.rst:14
msgid ""
"The following command returns the current image digest referenced by the "
":substitution-code:`superlink:|stable_flwr_version|` tag:"
msgstr ""

#: ../../source/docker/pin-version.rst:23
msgid "This will output"
msgstr ""

#: ../../source/docker/pin-version.rst:30
msgid "Next, we can pin the digest when running a new SuperLink container:"
msgstr ""

#: ../../source/docker/run-as-root-user.rst:2
msgid "Run with Root User Privileges"
msgstr ""

#: ../../source/docker/run-as-root-user.rst:4
msgid ""
"Flower Docker images, by default, run with a non-root user "
"(username/groupname: ``app``, UID/GID: ``49999``). Using root user is "
"**not recommended** unless it is necessary for specific tasks during the "
"build process."
msgstr ""

#: ../../source/docker/run-as-root-user.rst:8
msgid ""
"Always make sure to run the container as a non-root user in production to"
" maintain security best practices."
msgstr ""

#: ../../source/docker/run-as-root-user.rst:12
msgid "Run a Container with Root User Privileges"
msgstr ""

#: ../../source/docker/run-as-root-user.rst:14
msgid ""
"Run the Docker image with the ``-u`` flag and specify ``root`` as the "
"username:"
msgstr ""

#: ../../source/docker/run-as-root-user.rst:21
msgid "This command will run the Docker container with root user privileges."
msgstr ""

#: ../../source/docker/run-as-root-user.rst:24
msgid "Run the Build Process with Root User Privileges"
msgstr ""

#: ../../source/docker/run-as-root-user.rst:26
msgid ""
"If you want to switch to the root user during the build process of the "
"Docker image to install missing system dependencies, you can use the "
"``USER root`` directive within your Dockerfile."
msgstr ""

#: ../../source/docker/run-as-root-user.rst:30
#, fuzzy
msgid "SuperNode Dockerfile"
msgstr "Construindo a imagem do servidor"

#: ../../source/docker/run-as-subprocess.rst:2
msgid "Run ServerApp or ClientApp as a Subprocess"
msgstr ""

#: ../../source/docker/run-as-subprocess.rst:4
msgid ""
"The SuperLink and SuperNode components support two distinct isolation "
"modes, allowing for flexible deployment and control:"
msgstr ""

#: ../../source/docker/run-as-subprocess.rst:7
msgid ""
"Subprocess Mode: In this configuration (default), the SuperLink and "
"SuperNode take responsibility for launching the ServerApp and ClientApp "
"processes internally. This differs from the ``process`` isolation-mode "
"which uses separate containers, as demonstrated in the :doc:`tutorial-"
"quickstart-docker` guide."
msgstr ""

#: ../../source/docker/run-as-subprocess.rst:12
msgid ""
"Using the ``subprocess`` approach reduces the number of running "
"containers, which can be beneficial for environments with limited "
"resources. However, it also means that the applications are not isolated "
"from their parent containers, which may introduce additional security "
"concerns."
msgstr ""

#: ../../source/docker/run-as-subprocess.rst:17
msgid ""
"Process Mode: In this mode, the ServerApp and ClientApps run in "
"completely separate processes. Unlike the alternative Subprocess mode, "
"the SuperLink or SuperNode does not attempt to create or manage these "
"processes. Instead, they must be started externally."
msgstr ""

#: ../../source/docker/run-as-subprocess.rst:22
msgid ""
"Both modes can be mixed for added flexibility. For instance, you can run "
"the SuperLink in ``subprocess`` mode while keeping the SuperNode in "
"``process`` mode, or vice versa."
msgstr ""

#: ../../source/docker/run-as-subprocess.rst:25
msgid ""
"To run the SuperLink and SuperNode in isolation mode ``process``, refer "
"to the :doc:`tutorial-quickstart-docker` guide. To run them in "
"``subprocess`` mode, follow the instructions below."
msgstr ""

#: ../../source/docker/run-as-subprocess.rst
#: ../../source/ref-api/flwr.server.ServerApp.rst:2
msgid "ServerApp"
msgstr ""

#: ../../source/docker/run-as-subprocess.rst:33
#: ../../source/docker/run-as-subprocess.rst:74
msgid "**Prerequisites**"
msgstr ""

#: ../../source/docker/run-as-subprocess.rst:35
msgid ""
"1. Before running the ServerApp as a subprocess, ensure that the FAB "
"dependencies have been installed in the SuperLink images. This can be "
"done by extending the SuperLink image:"
msgstr ""

#: ../../source/docker/run-as-subprocess.rst:38
#, fuzzy
msgid "superlink.Dockerfile"
msgstr "Construindo a imagem do servidor"

#: ../../source/docker/run-as-subprocess.rst:52
msgid ""
"2. Next, build the SuperLink Docker image by running the following "
"command in the directory where Dockerfile is located:"
msgstr ""

#: ../../source/docker/run-as-subprocess.rst:59
msgid "**Run the ServerApp as a Subprocess**"
msgstr ""

#: ../../source/docker/run-as-subprocess.rst:61
msgid ""
"Start the SuperLink and run the ServerApp as a subprocess (note that the "
"subprocess mode is the default, so you do not have to explicitly set the "
"``--isolation`` flag):"
msgstr ""

#: ../../source/docker/run-as-subprocess.rst
#: ../../source/ref-api/flwr.client.ClientApp.rst:2
msgid "ClientApp"
msgstr ""

#: ../../source/docker/run-as-subprocess.rst:76
msgid ""
"1. Before running the ClientApp as a subprocess, ensure that the FAB "
"dependencies have been installed in the SuperNode images. This can be "
"done by extending the SuperNode image:"
msgstr ""

#: ../../source/docker/run-as-subprocess.rst:80
#, fuzzy
msgid "supernode.Dockerfile"
msgstr "Construindo a imagem do servidor"

#: ../../source/docker/run-as-subprocess.rst:94
msgid ""
"2. Next, build the SuperNode Docker image by running the following "
"command in the directory where Dockerfile is located:"
msgstr ""

#: ../../source/docker/run-as-subprocess.rst:101
msgid "**Run the ClientApp as a Subprocess**"
msgstr ""

#: ../../source/docker/run-as-subprocess.rst:103
msgid ""
"Start the SuperNode and run the ClientApp as a subprocess (note that the "
"subprocess mode is the default, so you do not have to explicitly set the "
"``--isolation`` flag):"
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:2
msgid "Run Flower Quickstart Examples with Docker Compose"
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:4
msgid ""
"Flower provides a set of `quickstart examples "
"<https://github.com/adap/flower/tree/main/examples>`_ to help you get "
"started with the framework. These examples are designed to demonstrate "
"the capabilities of Flower and by default run using the Simulation "
"Engine. This guide demonstrates how to run them using Flower's Deployment"
" Engine via Docker Compose."
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:12
msgid ""
"Some quickstart examples may have limitations or requirements that "
"prevent them from running on every environment. For more information, "
"please see Limitations_."
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:18
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:15
#: ../../source/docker/tutorial-quickstart-docker.rst:13
msgid "Before you start, make sure that:"
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:20
#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:22
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:17
#: ../../source/docker/tutorial-quickstart-docker.rst:15
msgid "The ``flwr`` CLI is :doc:`installed <../how-to-install-flower>` locally."
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:21
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:18
#: ../../source/docker/tutorial-quickstart-docker.rst:16
#, fuzzy
msgid "The Docker daemon is running."
msgstr "Verifique que o serviço Docker está rodando."

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:22
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:19
msgid ""
"Docker Compose V2 is `installed "
"<https://docs.docker.com/compose/install/>`_."
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:25
msgid "Run the Quickstart Example"
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:27
msgid ""
"Clone the quickstart example you like to run. For example, ``quickstart-"
"pytorch``:"
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:35
msgid ""
"Download the `compose.yml "
"<https://github.com/adap/flower/blob/main/src/docker/complete/compose.yml>`_"
" file into the example directory:"
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:45
msgid ""
"Export the version of Flower that your environment uses. Then, build and "
"start the services using the following command:"
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:68
msgid ""
"In this example, ``local-deployment`` has been used. Just remember to "
"replace ``local-deployment`` with your chosen name in both the "
"``tool.flwr.federations.`` string and the corresponding ``flwr run .`` "
"command."
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:72
msgid "Run the example and follow the logs of the ``ServerApp`` :"
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:78
msgid ""
"That is all it takes! You can monitor the progress of the run through the"
" logs of the ``ServerApp``."
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:82
msgid "Run a Different Quickstart Example"
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:84
msgid ""
"To run a different quickstart example, such as ``quickstart-tensorflow``,"
" first, shut down the Docker Compose services of the current example:"
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:91
msgid "After that, you can repeat the steps above."
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:94
#: ../../source/docker/run-quickstart-examples-docker-compose.rst:100
msgid "Limitations"
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:99
msgid "Quickstart Example"
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:101
msgid "quickstart-fastai"
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:102
#: ../../source/docker/run-quickstart-examples-docker-compose.rst:104
#: ../../source/docker/run-quickstart-examples-docker-compose.rst:106
#: ../../source/docker/run-quickstart-examples-docker-compose.rst:113
#: ../../source/docker/run-quickstart-examples-docker-compose.rst:115
#: ../../source/docker/run-quickstart-examples-docker-compose.rst:119
#: ../../source/docker/run-quickstart-examples-docker-compose.rst:121
#: ../../source/docker/run-quickstart-examples-docker-compose.rst:125
#: ../../source/ref-changelog.md:236 ../../source/ref-changelog.md:602
#: ../../source/ref-changelog.md:879 ../../source/ref-changelog.md:943
#: ../../source/ref-changelog.md:1001 ../../source/ref-changelog.md:1070
#: ../../source/ref-changelog.md:1132
msgid "None"
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:103
msgid "quickstart-huggingface"
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:105
msgid "quickstart-jax"
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:107
msgid "quickstart-mlcube"
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:108
#: ../../source/docker/run-quickstart-examples-docker-compose.rst:123
msgid ""
"The example has not yet been updated to work with the latest ``flwr`` "
"version."
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:109
msgid "quickstart-mlx"
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:110
msgid ""
"`Requires to run on macOS with Apple Silicon <https://ml-"
"explore.github.io/mlx/build/html/install.html#python-installation>`_."
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:112
msgid "quickstart-monai"
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:114
msgid "quickstart-pandas"
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:116
msgid "quickstart-pytorch-lightning"
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:117
msgid ""
"Requires an older pip version that is not supported by the Flower Docker "
"images."
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:118
msgid "quickstart-pytorch"
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:120
msgid "quickstart-sklearn-tabular"
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:122
msgid "quickstart-tabnet"
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:124
msgid "quickstart-tensorflow"
msgstr ""

#: ../../source/docker/set-environment-variables.rst:2
msgid "Set Environment Variables"
msgstr ""

#: ../../source/docker/set-environment-variables.rst:4
msgid ""
"To set a variable inside a Docker container, you can use the ``-e "
"<name>=<value>`` flag. Multiple ``-e`` flags can be used to set multiple "
"environment variables for a container."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:2
msgid "Deploy Flower on Multiple Machines with Docker Compose"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:4
msgid ""
"This guide will help you set up a Flower project on multiple machines "
"using Docker Compose."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:7
msgid ""
"You will learn how to run the Flower client and server components on two "
"separate machines, with Flower configured to use TLS encryption and "
"persist SuperLink state across restarts. A server consists of a SuperLink"
" and a ``ServerApp``. For more details about the Flower architecture, "
"refer to the :doc:`../explanation-flower-architecture` explainer page."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:13
msgid ""
"This guide assumes you have completed the :doc:`tutorial-quickstart-"
"docker-compose` tutorial. It is highly recommended that you follow and "
"understand the contents of that tutorial before proceeding with this "
"guide."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:20
msgid "Before you begin, make sure you have the following prerequisites:"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:23
msgid "The Docker daemon is running on your local machine and the remote machine."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:24
msgid ""
"Docker Compose V2 is installed on both your local machine and the remote "
"machine."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:25
msgid "You can connect to the remote machine from your local machine."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:26
msgid "Ports ``9091`` and ``9093`` are accessible on the remote machine."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:30
msgid ""
"The guide uses the |quickstart_sklearn_tabular|_ example as an example "
"project."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:32
msgid ""
"If your project has a different name or location, please remember to "
"adjust the commands/paths accordingly."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:36
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:22
#: ../../source/docker/tutorial-quickstart-docker.rst:19
msgid "Step 1: Set Up"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:38
msgid "Clone the Flower repository and change to the ``distributed`` directory:"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:46
msgid "Get the IP address from the remote machine and save it for later."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:47
msgid ""
"Use the ``certs.yml`` Compose file to generate your own self-signed "
"certificates. If you have certificates, you can continue with Step 2."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:52
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:212
msgid "These certificates should be used only for development purposes."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:54
msgid ""
"For production environments, you may have to use dedicated services to "
"obtain your certificates."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:57
msgid ""
"First, set the environment variable ``SUPERLINK_IP`` with the IP address "
"from the remote machine. For example, if the IP is ``192.168.2.33``, "
"execute:"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:64
msgid "Next, generate the self-signed certificates:"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:71
msgid "Step 2: Copy the Server Compose Files"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:73
msgid ""
"Use the method that works best for you to copy the ``server`` directory, "
"the certificates, and the ``pyproject.toml`` file of your Flower project "
"to the remote machine."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:77
msgid "For example, you can use ``scp`` to copy the directories:"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:86
msgid "Step 3: Start the Flower Server Components"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:88
msgid ""
"Log into the remote machine using ``ssh`` and run the following command "
"to start the SuperLink and ``ServerApp`` services:"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:102
msgid ""
"The path to the ``PROJECT_DIR`` containing the ``pyproject.toml`` file "
"should be relative to the location of the server ``compose.yml`` file."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:107
msgid ""
"When working with Docker Compose on Linux, you may need to create the "
"``state`` directory first and change its ownership to ensure proper "
"access and permissions. After exporting the ``PROJECT_DIR`` (after line "
"4), run the following commands:"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:116
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:165
msgid ""
"For more information, consult the following page: :doc:`persist-"
"superlink-state`."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:118
msgid "Go back to your terminal on your local machine."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:121
msgid "Step 4: Start the Flower Client Components"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:123
msgid ""
"On your local machine, run the following command to start the client "
"components:"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:133
msgid ""
"The path to the ``PROJECT_DIR`` containing the ``pyproject.toml`` file "
"should be relative to the location of the client ``compose.yml`` file."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:137
msgid "Step 5: Run Your Flower Project"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:139
msgid ""
"Specify the remote SuperLink IP addresses and the path to the root "
"certificate in the ``[tool.flwr.federations.remote-deployment]`` table in"
" the ``pyproject.toml`` file. Here, we have named our remote federation "
"``remote-deployment``:"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:143
msgid "examples/quickstart-sklearn-tabular/pyproject.toml"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:155
msgid "Run the project and follow the ``ServerApp`` logs:"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:161
msgid ""
"That's it! With these steps, you've set up Flower on two separate "
"machines and are ready to start using it."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:165
msgid "Step 6: Clean Up"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:167
msgid "Shut down the Flower client components:"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:174
msgid "Shut down the Flower server components and delete the SuperLink state:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:2
msgid "Quickstart with Docker"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:4
msgid ""
"This quickstart aims to guide you through the process of containerizing a"
" Flower project and running it end to end using Docker on your local "
"machine."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:7
msgid ""
"This tutorial does not use production-ready settings, so you can focus on"
" understanding the basic workflow that uses the minimum configurations."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:33
#: ../../source/docker/tutorial-quickstart-docker.rst:21
msgid "Create a new Flower project (PyTorch):"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:38
msgid "Create a new Docker bridge network called ``flwr-network``:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:44
msgid ""
"User-defined networks, such as ``flwr-network``, enable IP resolution of "
"container names, a feature absent in the default bridge network. This "
"simplifies quickstart example by avoiding the need to determine host IP "
"first."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:49
msgid "Step 2: Start the SuperLink"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:64
#: ../../source/docker/tutorial-quickstart-docker.rst:51
msgid "Open your terminal and run:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"``-p 9091:9091 -p 9092:9092 -p 9093:9093``: Map port ``9091``, ``9092`` "
"and ``9093`` of the"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"container to the same port of the host machine, allowing other services "
"to access the"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"ServerAppIO API on ``http://localhost:9091``, the Fleet API on "
"``http://localhost:9092`` and"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "the Exec API on ``http://localhost:9093``."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:74
#: ../../source/docker/tutorial-quickstart-docker.rst:114
#: ../../source/docker/tutorial-quickstart-docker.rst:223
#: ../../source/docker/tutorial-quickstart-docker.rst:305
msgid ""
"``--network flwr-network``: Make the container join the network named "
"``flwr-network``."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:75
msgid "``--name superlink``: Assign the name ``superlink`` to the container."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:76
#: ../../source/docker/tutorial-quickstart-docker.rst:116
#: ../../source/docker/tutorial-quickstart-docker.rst:225
#: ../../source/docker/tutorial-quickstart-docker.rst:306
msgid ""
"``--detach``: Run the container in the background, freeing up the "
"terminal."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"tag of the image. The tag :substitution-code:`|stable_flwr_version|` "
"represents a :doc:`specific version <pin-version>` of the image."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"``--insecure``: This flag tells the container to operate in an insecure "
"mode, allowing"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "unencrypted communication."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"independent process. The SuperLink does not attempt to create it. You can"
" learn more about"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "the different process modes here: :doc:`run-as-subprocess`."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:86
msgid "Step 3: Start the SuperNodes"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:88
msgid "Start two SuperNode containers."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:90
msgid "Start the first container:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "``-p 9094:9094``: Map port ``9094`` of the container to the same port of"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "the host machine, allowing other services to access the SuperNode API on"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "``http://localhost:9094``."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:115
msgid "``--name supernode-1``: Assign the name ``supernode-1`` to the container."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
":substitution-code:`flwr/supernode:|stable_flwr_version|`: This is the "
"name of the"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "image to be run and the specific tag of the image."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"``--superlink superlink:9092``: Connect to the SuperLink's Fleet API at "
"the address"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "``superlink:9092``."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"``--node-config \"partition-id=0 num-partitions=2\"``: Set the partition "
"ID to ``0`` and the"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "number of partitions to ``2`` for the SuperNode configuration."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"``--clientappio-api-address 0.0.0.0:9094``: Set the address and port "
"number that the"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "SuperNode is listening on to communicate with the ClientApp. If"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"two SuperNodes are started on the same machine, set two different port "
"numbers for each SuperNode."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"(E.g. In the next step, we set the second SuperNode container to listen "
"on port 9095)"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:132
msgid "Start the second container:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:150
msgid "Step 4: Start a ServerApp"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:152
msgid ""
"The ServerApp Docker image comes with a pre-installed version of Flower "
"and serves as a base for building your own ServerApp image. In order to "
"install the FAB dependencies, you will need to create a Dockerfile that "
"extends the ServerApp image and installs the required dependencies."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:157
msgid ""
"Create a ServerApp Dockerfile called ``serverapp.Dockerfile`` and paste "
"the following code in:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:160
#, fuzzy
msgid "serverapp.Dockerfile"
msgstr "Construindo a imagem do servidor"

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "Understand the Dockerfile"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
":substitution-code:`FROM flwr/serverapp:|stable_flwr_version|`: This line"
" specifies that the Docker image"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"to be built from is the ``flwr/serverapp`` image, version :substitution-"
"code:`|stable_flwr_version|`."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "``WORKDIR /app``: Set the working directory for the container to ``/app``."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"Any subsequent commands that reference a directory will be relative to "
"this directory."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "``COPY pyproject.toml .``: Copy the ``pyproject.toml`` file"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"from the current working directory into the container's ``/app`` "
"directory."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"``RUN sed -i 's/.*flwr\\[simulation\\].*//' pyproject.toml``: Remove the "
"``flwr`` dependency"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "from the ``pyproject.toml``."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"``python -m pip install -U --no-cache-dir .``: Run the ``pip`` install "
"command to"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "install the dependencies defined in the ``pyproject.toml`` file"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"The ``-U`` flag indicates that any existing packages should be upgraded, "
"and"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"``--no-cache-dir`` prevents pip from using the cache to speed up the "
"installation."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"``ENTRYPOINT [\"flwr-serverapp\"]``: Set the command ``flwr-serverapp`` "
"to be"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "the default command run when the container is started."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:194
msgid ""
"Note that `flwr <https://pypi.org/project/flwr/>`__ is already installed "
"in the ``flwr/clientapp`` base image, so only other package dependencies "
"such as ``flwr-datasets``, ``torch``, etc., need to be installed. As a "
"result, the ``flwr`` dependency is removed from the ``pyproject.toml`` "
"after it has been copied into the Docker image (see line 5)."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:200
msgid ""
"Afterward, in the directory that holds the Dockerfile, execute this "
"Docker command to build the ServerApp image:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:224
msgid "``--name serverapp``: Assign the name ``serverapp`` to the container."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"``flwr_serverapp:0.0.1``: This is the name of the image to be run and the"
" specific tag"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "of the image."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"``--serverappio-api-address superlink:9091``: Connect to the SuperLink's "
"ServerAppIO API"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "at the address ``superlink:9091``."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:234
msgid "Step 5: Start the ClientApp"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:236
msgid ""
"The procedure for building and running a ClientApp image is almost "
"identical to the ServerApp image."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:239
msgid ""
"Similar to the ServerApp image, you will need to create a Dockerfile that"
" extends the ClientApp image and installs the required FAB dependencies."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:242
msgid ""
"Create a ClientApp Dockerfile called ``clientapp.Dockerfile`` and paste "
"the following code into it:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:245
msgid "clientapp.Dockerfile"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
":substitution-code:`FROM flwr/clientapp:|stable_flwr_version|`: This line"
" specifies that the Docker image"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"to be built from is the ``flwr/clientapp`` image, version :substitution-"
"code:`|stable_flwr_version|`."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"``ENTRYPOINT [\"flwr-clientapp\"]``: Set the command ``flwr-clientapp`` "
"to be"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:277
msgid ""
"Next, build the ClientApp Docker image by running the following command "
"in the directory where the Dockerfile is located:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:286
msgid ""
"The image name was set as ``flwr_clientapp`` with the tag ``0.0.1``. "
"Remember that these values are merely examples, and you can customize "
"them according to your requirements."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:290
msgid "Start the first ClientApp container:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"``flwr_clientapp:0.0.1``: This is the name of the image to be run and the"
" specific tag"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"``--clientappio-api-address supernode-1:9094``: Connect to the "
"SuperNode's ClientAppIO"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "API at the address ``supernode-1:9094``."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:314
msgid "Start the second ClientApp container:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:326
msgid "Step 6: Run the Quickstart Project"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:328
msgid "Add the following lines to the ``pyproject.toml``:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:337
msgid ""
"Run the ``quickstart-docker`` project and follow the ServerApp logs to "
"track the execution of the run:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:345
msgid "Step 7: Update the Application"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:347
msgid ""
"Change the application code. For example, change the ``seed`` in "
"``quickstart_docker/task.py`` to ``43`` and save it:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:350
msgid "quickstart_docker/task.py"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:357
msgid "Stop the current ServerApp and ClientApp containers:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:125
#: ../../source/docker/tutorial-quickstart-docker.rst:361
msgid ""
"If you have modified the dependencies listed in your ``pyproject.toml`` "
"file, it is essential to rebuild images."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:364
msgid "If you haven’t made any changes, you can skip steps 2 through 4."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:370
#, fuzzy
msgid "Rebuild ServerApp and ClientApp images:"
msgstr "Construindo a imagem base"

#: ../../source/docker/tutorial-quickstart-docker.rst:377
msgid ""
"Launch one new ServerApp and two new ClientApp containers based on the "
"newly built image:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:402
msgid "Run the updated project:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:409
msgid "Step 8: Clean Up"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:411
msgid "Remove the containers and the bridge network:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:400
#: ../../source/docker/tutorial-quickstart-docker.rst:423
msgid "Where to Go Next"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:425
msgid ":doc:`enable-tls`"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:426
msgid ":doc:`persist-superlink-state`"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:427
msgid ":doc:`tutorial-quickstart-docker-compose`"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:2
msgid "Quickstart with Docker Compose"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:4
msgid ""
"This quickstart shows you how to set up Flower using Docker Compose in a "
"single command, allowing you to focus on developing your application "
"without worrying about the underlying infrastructure."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:8
msgid ""
"You will also learn how to easily enable TLS encryption and persist "
"application state locally, giving you the freedom to choose the "
"configuration that best suits your project's needs."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:24
msgid "Clone the Docker Compose ``complete`` directory:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:39
msgid ""
"Export the path of the newly created project. The path should be relative"
" to the location of the Docker Compose files:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:46
msgid ""
"Setting the ``PROJECT_DIR`` helps Docker Compose locate the "
"``pyproject.toml`` file, allowing it to install dependencies in the "
"``ServerApp`` and ``ClientApp`` images correctly."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:51
msgid "Step 2: Run Flower in Insecure Mode"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:53
msgid ""
"To begin, start Flower with the most basic configuration. In this setup, "
"Flower will run without TLS and without persisting the state."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:58
msgid ""
"Without TLS, the data sent between the services remains **unencrypted**. "
"Use it only for development purposes."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:61
msgid ""
"For production-oriented use cases, :ref:`enable TLS<TLS>` for secure data"
" transmission."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:72
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:175
msgid "``docker compose``: The Docker command to run the Docker Compose tool."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:73
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:181
msgid ""
"``--build``: Rebuild the images for each service if they don't already "
"exist."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:74
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:182
msgid ""
"``-d``: Detach the containers from the terminal and run them in the "
"background."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:77
msgid "Step 3: Run the Quickstart Project"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:79
msgid ""
"Now that the Flower services have been started via Docker Compose, it is "
"time to run the quickstart example."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:82
msgid ""
"To ensure the ``flwr`` CLI connects to the SuperLink, you need to specify"
" the SuperLink addresses in the ``pyproject.toml`` file."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:85
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:223
msgid "Add the following lines to the ``quickstart-compose/pyproject.toml``:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:87
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:225
msgid "quickstart-compose/pyproject.toml"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:94
msgid ""
"Run the quickstart example, monitor the ``ServerApp`` logs and wait for "
"the summary to appear:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:102
msgid "Step 4: Update the Application"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:104
msgid "In the next step, change the application code."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:106
msgid ""
"For example, go to the ``task.py`` file in the ``quickstart-"
"compose/quickstart_compose/`` directory and add a ``print`` call in the "
"``get_weights`` function:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:110
msgid "quickstart-compose/quickstart_compose/task.py"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:121
msgid "Rebuild and restart the services."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:128
msgid "If you haven't made any changes, you can skip this step."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:130
msgid "Run the following command to rebuild and restart the services:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:136
msgid "Run the updated quickstart example:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:142
msgid "In the ``ServerApp`` logs, you should find the ``Get weights`` line:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:155
msgid "Step 5: Persisting the SuperLink State"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:157
msgid ""
"In this step, Flower services are configured to persist the state of the "
"SuperLink service, ensuring that it maintains its state even after a "
"restart."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:162
msgid ""
"When working with Docker Compose on Linux, you may need to create the "
"``state`` directory first and change its ownership to ensure proper "
"access and permissions."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:167
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:217
msgid "Run the command:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:176
msgid ""
"``-f compose.yml``: Specify the YAML file that contains the basic Flower "
"service definitions."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst
msgid ""
"``-f with-state.yml``: Specifies the path to an additional Docker Compose"
" file that"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst
msgid "contains the configuration for persisting the SuperLink state."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst
msgid ""
"Docker merges Compose files according to `merging rules "
"<https://docs.docker.com/compose/multiple-compose-files/merge/#merging-"
"rules>`_."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:184
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:238
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:369
msgid "Rerun the ``quickstart-compose`` project:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:190
msgid "Check the content of the ``state`` directory:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:197
msgid ""
"You should see a ``state.db`` file in the ``state`` directory. If you "
"restart the service, the state file will be used to restore the state "
"from the previously saved data. This ensures that the data persists even "
"if the containers are stopped and started again."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:205
msgid "Step 6: Run Flower with TLS"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:207
msgid ""
"To demonstrate how to enable TLS, generate self-signed certificates using"
" the ``certs.yml`` Compose file."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:214
msgid ""
"For production environments, use a service like `Let's Encrypt "
"<https://letsencrypt.org/>`_ to obtain your certificates."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:232
msgid "Restart the services with TLS enabled:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:245
msgid "Step 7: Add another SuperNode and ClientApp"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:247
msgid ""
"You can add more SuperNodes and ClientApps by uncommenting their "
"definitions in the ``compose.yml`` file:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:250
msgid "compose.yml"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:302
msgid ""
"If you also want to enable TLS for the new SuperNode, uncomment the "
"definition in the ``with-tls.yml`` file:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:305
msgid "with-tls.yml"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:326
msgid "Restart the services with:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:335
msgid "Step 8: Persisting the SuperLink State and Enabling TLS"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:337
msgid ""
"To run Flower with persisted SuperLink state and enabled TLS, a slight "
"change in the ``with-state.yml`` file is required:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:340
msgid "Comment out the lines 2-6 and uncomment the lines 7-13:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:342
msgid "with-state.yml"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:363
msgid "Restart the services:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:376
msgid "Step 9: Merge Multiple Compose Files"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:378
msgid ""
"You can merge multiple Compose files into a single file. For instance, if"
" you wish to combine the basic configuration with the TLS configuration, "
"execute the following command:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:387
msgid ""
"This will merge the contents of ``compose.yml`` and ``with-tls.yml`` into"
" a new file called ``my_compose.yml``."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:391
msgid "Step 10: Clean Up"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:393
msgid "Remove all services and volumes:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:402
msgid ":doc:`run-quickstart-examples-docker-compose`"
msgstr ""

#: ../../source/docker/use-a-different-version.rst:2
msgid "Use a Different Flower Version"
msgstr ""

#: ../../source/docker/use-a-different-version.rst:4
msgid ""
"If you want to use a different version of Flower, for example Flower "
"nightly, you can do so by changing the tag. All available versions are on"
" `Docker Hub <https://hub.docker.com/u/flwr>`__."
msgstr ""

#: ../../source/docker/use-a-different-version.rst:10
msgid ""
"When using Flower nightly, the SuperLink nightly image must be paired "
"with the corresponding SuperNode and ServerApp nightly images released on"
" the same day. To ensure the versions are in sync, using the concrete "
"tag, e.g., ``1.10.0.dev20240610`` instead of ``nightly`` is recommended."
msgstr ""

#: ../../source/explanation-differential-privacy.rst:2
#: ../../source/explanation-differential-privacy.rst:14
#: ../../source/tutorial-series-what-is-federated-learning.ipynb:303
msgid "Differential Privacy"
msgstr ""

#: ../../source/explanation-differential-privacy.rst:4
msgid ""
"The information in datasets like healthcare, financial transactions, user"
" preferences, etc., is valuable and has the potential for scientific "
"breakthroughs and provides important business insights. However, such "
"data is also sensitive and there is a risk of compromising individual "
"privacy."
msgstr ""

#: ../../source/explanation-differential-privacy.rst:9
msgid ""
"Traditional methods like anonymization alone would not work because of "
"attacks like Re-identification and Data Linkage. That's where "
"differential privacy comes in. It provides the possibility of analyzing "
"data while ensuring the privacy of individuals."
msgstr ""

#: ../../source/explanation-differential-privacy.rst:16
msgid ""
"Imagine two datasets that are identical except for a single record (for "
"instance, Alice's data). Differential Privacy (DP) guarantees that any "
"analysis (M), like calculating the average income, will produce nearly "
"identical results for both datasets (O and O' would be similar). This "
"preserves group patterns while obscuring individual details, ensuring the"
" individual's information remains hidden in the crowd."
msgstr ""

#: ../../source/explanation-differential-privacy.rst:-1
msgid "DP Intro"
msgstr ""

#: ../../source/explanation-differential-privacy.rst:27
msgid ""
"One of the most commonly used mechanisms to achieve DP is adding enough "
"noise to the output of the analysis to mask the contribution of each "
"individual in the data while preserving the overall accuracy of the "
"analysis."
msgstr ""

#: ../../source/explanation-differential-privacy.rst:32
msgid "Formal Definition"
msgstr ""

#: ../../source/explanation-differential-privacy.rst:34
msgid ""
"Differential Privacy (DP) provides statistical guarantees against the "
"information an adversary can infer through the output of a randomized "
"algorithm. It provides an unconditional upper bound on the influence of a"
" single individual on the output of the algorithm by adding noise [1]. A "
"randomized mechanism M provides (:math:`\\epsilon`, "
":math:`\\delta`)-differential privacy if for any two neighboring "
"databases, D :sub:`1` and D :sub:`2`, that differ in only a single "
"record, and for all possible outputs S ⊆ Range(A):"
msgstr ""

#: ../../source/explanation-differential-privacy.rst:42
msgid ""
"\\small\n"
"P[M(D_{1} \\in A)] \\leq e^{\\epsilon} P[M(D_{2} \\in A)] + \\delta"
msgstr ""

#: ../../source/explanation-differential-privacy.rst:47
msgid ""
"The :math:`\\epsilon` parameter, also known as the privacy budget, is a "
"metric of privacy loss. It also controls the privacy-utility trade-off; "
"lower :math:`\\epsilon` values indicate higher levels of privacy but are "
"likely to reduce utility as well. The :math:`\\delta` parameter accounts "
"for a small probability on which the upper bound :math:`\\epsilon` does "
"not hold. The amount of noise needed to achieve differential privacy is "
"proportional to the sensitivity of the output, which measures the maximum"
" change in the output due to the inclusion or removal of a single record."
msgstr ""

#: ../../source/explanation-differential-privacy.rst:56
msgid "Differential Privacy in Machine Learning"
msgstr ""

#: ../../source/explanation-differential-privacy.rst:58
msgid ""
"DP can be utilized in machine learning to preserve the privacy of the "
"training data. Differentially private machine learning algorithms are "
"designed in a way to prevent the algorithm to learn any specific "
"information about any individual data points and subsequently prevent the"
" model from revealing sensitive information. Depending on the stage at "
"which noise is introduced, various methods exist for applying DP to "
"machine learning algorithms. One approach involves adding noise to the "
"training data (either to the features or labels), while another method "
"entails injecting noise into the gradients of the loss function during "
"model training. Additionally, such noise can be incorporated into the "
"model's output."
msgstr ""

#: ../../source/explanation-differential-privacy.rst:69
msgid "Differential Privacy in Federated Learning"
msgstr ""

#: ../../source/explanation-differential-privacy.rst:71
msgid ""
"Federated learning is a data minimization approach that allows multiple "
"parties to collaboratively train a model without sharing their raw data. "
"However, federated learning also introduces new privacy challenges. The "
"model updates between parties and the central server can leak information"
" about the local data. These leaks can be exploited by attacks such as "
"membership inference and property inference attacks, or model inversion "
"attacks."
msgstr ""

#: ../../source/explanation-differential-privacy.rst:78
msgid ""
"DP can play a crucial role in federated learning to provide privacy for "
"the clients' data."
msgstr ""

#: ../../source/explanation-differential-privacy.rst:81
msgid ""
"Depending on the granularity of privacy provision or the location of "
"noise addition, different forms of DP exist in federated learning. In "
"this explainer, we focus on two approaches of DP utilization in federated"
" learning based on where the noise is added: at the server (also known as"
" the center) or at the client (also known as the local)."
msgstr ""

#: ../../source/explanation-differential-privacy.rst:86
msgid ""
"**Central Differential Privacy**: DP is applied by the server and the "
"goal is to prevent the aggregated model from leaking information about "
"each client's data."
msgstr ""

#: ../../source/explanation-differential-privacy.rst:88
msgid ""
"**Local Differential Privacy**: DP is applied on the client side before "
"sending any information to the server and the goal is to prevent the "
"updates that are sent to the server from leaking any information about "
"the client's data."
msgstr ""

#: ../../source/explanation-differential-privacy.rst:-1
#: ../../source/explanation-differential-privacy.rst:93
#: ../../source/how-to-use-differential-privacy.rst:15
msgid "Central Differential Privacy"
msgstr ""

#: ../../source/explanation-differential-privacy.rst:95
msgid ""
"In this approach, which is also known as user-level DP, the central "
"server is responsible for adding noise to the globally aggregated "
"parameters. It should be noted that trust in the server is required."
msgstr ""

#: ../../source/explanation-differential-privacy.rst:104
msgid ""
"While there are various ways to implement central DP in federated "
"learning, we concentrate on the algorithms proposed by [2] and [3]. The "
"overall approach is to clip the model updates sent by the clients and add"
" some amount of noise to the aggregated model. In each iteration, a "
"random set of clients is chosen with a specific probability for training."
" Each client performs local training on its own data. The update of each "
"client is then clipped by some value `S` (sensitivity `S`). This would "
"limit the impact of any individual client which is crucial for privacy "
"and often beneficial for robustness. A common approach to achieve this is"
" by restricting the `L2` norm of the clients' model updates, ensuring "
"that larger updates are scaled down to fit within the norm `S`."
msgstr ""

#: ../../source/explanation-differential-privacy.rst:-1
msgid "clipping"
msgstr ""

#: ../../source/explanation-differential-privacy.rst:120
msgid ""
"Afterwards, the Gaussian mechanism is used to add noise in order to "
"distort the sum of all clients' updates. The amount of noise is scaled to"
" the sensitivity value to obtain a privacy guarantee. The Gaussian "
"mechanism is used with a noise sampled from `N (0, σ²)` where `σ = ( "
"noise_scale * S ) / (number of sampled clients)`."
msgstr ""

#: ../../source/explanation-differential-privacy.rst:126
msgid "Clipping"
msgstr ""

#: ../../source/explanation-differential-privacy.rst:128
msgid ""
"There are two forms of clipping commonly used in Central DP: Fixed "
"Clipping and Adaptive Clipping."
msgstr ""

#: ../../source/explanation-differential-privacy.rst:131
msgid ""
"**Fixed Clipping** : A predefined fix threshold is set for the magnitude "
"of clients' updates. Any update exceeding this threshold is clipped back "
"to the threshold value."
msgstr ""

#: ../../source/explanation-differential-privacy.rst:133
msgid ""
"**Adaptive Clipping** : The clipping threshold dynamically adjusts based "
"on the observed update distribution [4]. It means that the clipping value"
" is tuned during the rounds with respect to the quantile of the update "
"norm distribution."
msgstr ""

#: ../../source/explanation-differential-privacy.rst:137
msgid ""
"The choice between fixed and adaptive clipping depends on various factors"
" such as privacy requirements, data distribution, model complexity, and "
"others."
msgstr ""

#: ../../source/explanation-differential-privacy.rst:-1
#: ../../source/explanation-differential-privacy.rst:141
#: ../../source/how-to-use-differential-privacy.rst:114
msgid "Local Differential Privacy"
msgstr ""

#: ../../source/explanation-differential-privacy.rst:143
msgid ""
"In this approach, each client is responsible for performing DP. Local DP "
"avoids the need for a fully trusted aggregator, but it should be noted "
"that local DP leads to a decrease in accuracy but better privacy in "
"comparison to central DP."
msgstr ""

#: ../../source/explanation-differential-privacy.rst:152
msgid "In this explainer, we focus on two forms of achieving Local DP:"
msgstr ""

#: ../../source/explanation-differential-privacy.rst:154
msgid ""
"Each client adds noise to the local updates before sending them to the "
"server. To achieve (:math:`\\epsilon`, :math:`\\delta`)-DP, considering "
"the sensitivity of the local model to be ∆, Gaussian noise is applied "
"with a noise scale of σ where:"
msgstr ""

#: ../../source/explanation-differential-privacy.rst:158
msgid ""
"\\small\n"
"\\frac{∆ \\times \\sqrt{2 \\times "
"\\log\\left(\\frac{1.25}{\\delta}\\right)}}{\\epsilon}"
msgstr ""

#: ../../source/explanation-differential-privacy.rst:163
msgid ""
"Each client adds noise to the gradients of the model during the local "
"training (DP-SGD). More specifically, in this approach, gradients are "
"clipped and an amount of calibrated noise is injected into the gradients."
msgstr ""

#: ../../source/explanation-differential-privacy.rst:167
msgid ""
"Please note that these two approaches are providing privacy at different "
"levels."
msgstr ""

#: ../../source/explanation-differential-privacy.rst:169
msgid "**References:**"
msgstr ""

#: ../../source/explanation-differential-privacy.rst:171
msgid "[1] Dwork et al. The Algorithmic Foundations of Differential Privacy."
msgstr ""

#: ../../source/explanation-differential-privacy.rst:173
msgid ""
"[2] McMahan et al. Learning Differentially Private Recurrent Language "
"Models."
msgstr ""

#: ../../source/explanation-differential-privacy.rst:175
msgid ""
"[3] Geyer et al. Differentially Private Federated Learning: A Client "
"Level Perspective."
msgstr ""

#: ../../source/explanation-differential-privacy.rst:177
msgid "[4] Galen et al. Differentially Private Learning with Adaptive Clipping."
msgstr ""

#: ../../source/explanation-federated-evaluation.rst:2
msgid "Federated evaluation"
msgstr ""

#: ../../source/explanation-federated-evaluation.rst:4
msgid ""
"There are two main approaches to evaluating models in federated learning "
"systems: centralized (or server-side) evaluation and federated (or "
"client-side) evaluation."
msgstr ""

#: ../../source/explanation-federated-evaluation.rst:8
msgid "Centralized Evaluation"
msgstr ""

#: ../../source/explanation-federated-evaluation.rst:11
msgid "Built-In Strategies"
msgstr ""

#: ../../source/explanation-federated-evaluation.rst:13
msgid ""
"All built-in strategies support centralized evaluation by providing an "
"evaluation function during initialization. An evaluation function is any "
"function that can take the current global model parameters as input and "
"return evaluation results:"
msgstr ""

#: ../../source/explanation-federated-evaluation.rst:70
msgid "Custom Strategies"
msgstr ""

#: ../../source/explanation-federated-evaluation.rst:72
msgid ""
"The ``Strategy`` abstraction provides a method called ``evaluate`` that "
"can directly be used to evaluate the current global model parameters. The"
" current server implementation calls ``evaluate`` after parameter "
"aggregation and before federated evaluation (see next paragraph)."
msgstr ""

#: ../../source/explanation-federated-evaluation.rst:78
#: ../../source/tutorial-series-what-is-federated-learning.ipynb:292
msgid "Federated Evaluation"
msgstr ""

#: ../../source/explanation-federated-evaluation.rst:81
msgid "Implementing Federated Evaluation"
msgstr ""

#: ../../source/explanation-federated-evaluation.rst:83
msgid ""
"Client-side evaluation happens in the ``Client.evaluate`` method and can "
"be configured from the server side."
msgstr ""

#: ../../source/explanation-federated-evaluation.rst:116
msgid "Configuring Federated Evaluation"
msgstr ""

#: ../../source/explanation-federated-evaluation.rst:118
msgid ""
"Federated evaluation can be configured from the server side. Built-in "
"strategies support the following arguments:"
msgstr ""

#: ../../source/explanation-federated-evaluation.rst:121
msgid ""
"``fraction_evaluate``: a ``float`` defining the fraction of clients that "
"will be selected for evaluation. If ``fraction_evaluate`` is set to "
"``0.1`` and ``100`` clients are connected to the server, then ``10`` will"
" be randomly selected for evaluation. If ``fraction_evaluate`` is set to "
"``0.0``, federated evaluation will be disabled."
msgstr ""

#: ../../source/explanation-federated-evaluation.rst:126
msgid ""
"``min_evaluate_clients``: an ``int``: the minimum number of clients to be"
" selected for evaluation. If ``fraction_evaluate`` is set to ``0.1``, "
"``min_evaluate_clients`` is set to 20, and ``100`` clients are connected "
"to the server, then ``20`` clients will be selected for evaluation."
msgstr ""

#: ../../source/explanation-federated-evaluation.rst:130
msgid ""
"``min_available_clients``: an ``int`` that defines the minimum number of "
"clients which need to be connected to the server before a round of "
"federated evaluation can start. If fewer than ``min_available_clients`` "
"are connected to the server, the server will wait until more clients are "
"connected before it continues to sample clients for evaluation."
msgstr ""

#: ../../source/explanation-federated-evaluation.rst:135
msgid ""
"``on_evaluate_config_fn``: a function that returns a configuration "
"dictionary which will be sent to the selected clients. The function will "
"be called during each round and provides a convenient way to customize "
"client-side evaluation from the server side, for example, to configure "
"the number of validation steps performed."
msgstr ""

#: ../../source/explanation-federated-evaluation.rst:177
msgid "Evaluating Local Model Updates During Training"
msgstr ""

#: ../../source/explanation-federated-evaluation.rst:179
msgid ""
"Model parameters can also be evaluated during training. ``Client.fit`` "
"can return arbitrary evaluation results as a dictionary:"
msgstr ""

#: ../../source/explanation-federated-evaluation.rst:220
msgid "Full Code Example"
msgstr ""

#: ../../source/explanation-federated-evaluation.rst:222
msgid ""
"For a full code example that uses both centralized and federated "
"evaluation, see the `Advanced TensorFlow Example "
"<https://github.com/adap/flower/tree/main/examples/advanced-tensorflow>`_"
" (the same approach can be applied to workloads implemented in any other "
"framework)."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:-1
msgid ""
"Explore the federated learning architecture of the Flower framework, "
"featuring multi-run, concurrent execution, and scalable, secure machine "
"learning while preserving data privacy."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:2
msgid "Flower Architecture"
msgstr "Arquitetura do Flower"

#: ../../source/explanation-flower-architecture.rst:4
msgid ""
"This page explains the architecture of deployed Flower federated learning"
" system."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:6
msgid ""
"In federated learning (FL), there is typically one server and a number of"
" clients that are connected to the server. This is often called a "
"federation."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:9
msgid ""
"The role of the server is to coordinate the training process. The role of"
" each client is to receive tasks from the server, execute those tasks and"
" return the results back to the server."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:13
msgid "This is sometimes called a hub-and-spoke topology:"
msgstr ""

#: ../../source/explanation-flower-architecture.rst:21
msgid "Hub-and-spoke topology in federated learning"
msgstr ""

#: ../../source/explanation-flower-architecture.rst:21
msgid ""
"Hub-and-spoke topology in federated learning (one server, multiple "
"clients)."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:23
msgid ""
"In a real-world deployment, we typically want to run different projects "
"on such a federation. Each project could use different hyperparameters, "
"different model architectures, different aggregation strategies, or even "
"different machine learning frameworks like PyTorch and TensorFlow."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:28
msgid ""
"This is why, in Flower, both the server side and the client side are "
"split into two parts. One part is long-lived and responsible for "
"communicating across the network, the other part is short-lived and "
"executes task-specific code."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:32
msgid "A Flower `server` consists of **SuperLink** and ``ServerApp``:"
msgstr ""

#: ../../source/explanation-flower-architecture.rst:34
msgid ""
"**SuperLink**: a long-running process that forwards task instructions to "
"clients (SuperNodes) and receives task results back."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:36
msgid ""
"``ServerApp``: a short-lived process with project-spcific code that "
"customizes all server-side aspects of federated learning systems (client "
"selection, client configuration, result aggregation). This is what AI "
"researchers and AI engineers write when they build Flower apps."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:41
msgid "A Flower `client` consists of **SuperNode** and ``ClientApp``:"
msgstr ""

#: ../../source/explanation-flower-architecture.rst:43
msgid ""
"**SuperNode**: a long-running process that connects to the SuperLink, "
"asks for tasks, executes tasks (for example, \"train this model on your "
"local data\") and returns task results back to the SuperLink."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:46
msgid ""
"``ClientApp``: a short-lived process with project-specific code that "
"customizes all client-side aspects of federated learning systems (local "
"model training and evaluation, pre- and post-processing). This is what AI"
" researchers and AI engineers write when they build Flower apps."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:51
msgid ""
"Why SuperNode and SuperLink? Well, in federated learning, the clients are"
" the actual stars of the show. They hold the training data and they run "
"the actual training. This is why Flower decided to name them "
"**SuperNode**. The **SuperLink** is then responsible for acting as the "
"`missing link` between all those SuperNodes."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:62
#, fuzzy
msgid "Basic Flower architecture"
msgstr "Arquitetura do Flower"

#: ../../source/explanation-flower-architecture.rst:62
msgid "The basic Flower architecture for federated learning."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:64
msgid ""
"In a Flower app project, users will typically develop the ``ServerApp`` "
"and the ``ClientApp``. All the network communication between `server` and"
" `clients` is taken care of by the SuperLink and SuperNodes."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:70
msgid ""
"For more details, please refer to the |serverapp_link|_ and "
"|clientapp_link|_ documentation."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:73
msgid ""
"With *multi-run*, multiple ``ServerApp``\\s and ``ClientApp``\\s are now "
"capable of running on the same federation consisting of a single long-"
"running SuperLink and multiple long-running SuperNodes. This is sometimes"
" referred to as `multi-tenancy` or `multi-job`."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:78
msgid ""
"As shown in the figure below, two projects, each consisting of a "
"``ServerApp`` and a ``ClientApp``, could share the same SuperLink and "
"SuperNodes."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:87
msgid "Multi-tenancy federated learning architecture"
msgstr ""

#: ../../source/explanation-flower-architecture.rst:87
msgid "Multi-tenancy federated learning architecture with Flower"
msgstr ""

#: ../../source/explanation-flower-architecture.rst:89
msgid ""
"To illustrate how multi-run works, consider one federated learning "
"training run where a ``ServerApp`` and a ``ClientApp`` are participating "
"in ``[run 1]``. Note that a SuperNode will only run a ``ClientApp`` if it"
" is selected to participate in the training run."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:94
msgid ""
"In ``[run 1]`` below, all the SuperNodes are selected and therefore run "
"their corresponding ``ClientApp``\\s:"
msgstr ""

#: ../../source/explanation-flower-architecture.rst:103
msgid "Multi-tenancy federated learning architecture - Run 1"
msgstr ""

#: ../../source/explanation-flower-architecture.rst:103
msgid ""
"Run 1 in a multi-run federated learning architecture with Flower. All "
"SuperNodes participate in the training round."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:106
msgid ""
"However, in ``[run 2]``, only the first and third SuperNodes are selected"
" to participate in the training:"
msgstr ""

#: ../../source/explanation-flower-architecture.rst:115
msgid "Multi-tenancy federated learning architecture - Run 2"
msgstr ""

#: ../../source/explanation-flower-architecture.rst:115
msgid ""
"Run 2 in a multi-run federated learning architecture with Flower. Only "
"the first and third SuperNodes are selected to participate in the "
"training round."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:118
msgid ""
"Therefore, with Flower multi-run, different projects (each consisting of "
"a ``ServerApp`` and ``ClientApp``) can run on different sets of clients."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:123
msgid ""
"This explanation covers the Flower Deployment Engine. An explanation "
"covering the Flower Simulation Engine will follow."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:128
msgid ""
"As we continue to enhance Flower at a rapid pace, we'll periodically "
"update this explainer document. Feel free to share any feedback with us."
msgstr ""

#: ../../source/how-to-aggregate-evaluation-results.rst:2
msgid "Aggregate evaluation results"
msgstr ""

#: ../../source/how-to-aggregate-evaluation-results.rst:4
msgid ""
"The Flower server does not prescribe a way to aggregate evaluation "
"results, but it enables the user to fully customize result aggregation."
msgstr ""

#: ../../source/how-to-aggregate-evaluation-results.rst:8
msgid "Aggregate Custom Evaluation Results"
msgstr ""

#: ../../source/how-to-aggregate-evaluation-results.rst:10
msgid ""
"The same ``Strategy``-customization approach can be used to aggregate "
"custom evaluation results coming from individual clients. Clients can "
"return custom metrics to the server by returning a dictionary:"
msgstr ""

#: ../../source/how-to-aggregate-evaluation-results.rst:38
msgid ""
"The server can then use a customized strategy to aggregate the metrics "
"provided in these dictionaries:"
msgstr ""

#: ../../source/how-to-authenticate-supernodes.rst:2
msgid "Authenticate SuperNodes"
msgstr ""

#: ../../source/how-to-authenticate-supernodes.rst:4
msgid ""
"Flower has built-in support for authenticated SuperNodes that you can use"
" to verify the identities of each SuperNode connecting to a SuperLink. "
"Flower node authentication works similar to how GitHub SSH authentication"
" works:"
msgstr ""

#: ../../source/how-to-authenticate-supernodes.rst:8
msgid "SuperLink (server) stores a list of known (client) node public keys"
msgstr ""

#: ../../source/how-to-authenticate-supernodes.rst:9
msgid ""
"Using ECDH, both SuperNode and SuperLink independently derive a shared "
"secret"
msgstr ""

#: ../../source/how-to-authenticate-supernodes.rst:10
msgid ""
"Shared secret is used to compute the HMAC value of the message sent from "
"SuperNode to SuperLink as a token"
msgstr ""

#: ../../source/how-to-authenticate-supernodes.rst:12
msgid "SuperLink verifies the token"
msgstr ""

#: ../../source/how-to-authenticate-supernodes.rst:14
msgid ""
"We recommend you to check out the complete `code example "
"<https://github.com/adap/flower/tree/main/examples/flower-"
"authentication>`_ demonstrating federated learning with Flower in an "
"authenticated setting."
msgstr ""

#: ../../source/how-to-authenticate-supernodes.rst:20
msgid ""
"This guide covers a preview feature that might change in future versions "
"of Flower."
msgstr ""

#: ../../source/how-to-authenticate-supernodes.rst:24
msgid ""
"For increased security, node authentication can only be used when "
"encrypted connections (SSL/TLS) are enabled."
msgstr ""

#: ../../source/how-to-authenticate-supernodes.rst:28
msgid "Enable node authentication in ``SuperLink``"
msgstr ""

#: ../../source/how-to-authenticate-supernodes.rst:30
msgid ""
"To enable node authentication, first you need to configure SSL/TLS "
"connections to secure the SuperLink<>SuperNode communication. You can "
"find the complete guide `here <https://flower.ai/docs/framework/how-to-"
"enable-ssl-connections.html>`_. After configuring secure connections, you"
" can enable client authentication in a long-running Flower ``SuperLink``."
" Use the following terminal command to start a Flower ``SuperNode`` that "
"has both secure connections and node authentication enabled:"
msgstr ""

#: ../../source/how-to-authenticate-supernodes.rst:47
msgid "Let's break down the authentication flags:"
msgstr ""

#: ../../source/how-to-authenticate-supernodes.rst:49
msgid ""
"The first flag ``--auth-list-public-keys`` expects a path to a CSV file "
"storing all known node public keys. You need to store all known node "
"public keys that are allowed to participate in a federation in one CSV "
"file (``.csv``)."
msgstr ""

#: ../../source/how-to-authenticate-supernodes.rst:53
msgid ""
"A valid CSV file storing known node public keys should list the keys in "
"OpenSSH format, separated by commas and without any comments. For an "
"example, refer to our code sample, which contains a CSV file with two "
"known node public keys."
msgstr ""

#: ../../source/how-to-authenticate-supernodes.rst:57
msgid ""
"The second and third flags ``--auth-superlink-private-key`` and ``--auth-"
"superlink-public-key`` expect paths to the server's private and public "
"keys. For development purposes, you can generate a private and public key"
" pair using ``ssh-keygen -t ecdsa -b 384``."
msgstr ""

#: ../../source/how-to-authenticate-supernodes.rst:64
msgid ""
"In Flower 1.9, there is no support for dynamically removing, editing, or "
"adding known node public keys to the SuperLink. To change the set of "
"known nodes, you need to shut the server down, edit the CSV file, and "
"start the server again. Support for dynamically changing the set of known"
" nodes is on the roadmap to be released in Flower 1.10 (ETA: June)."
msgstr ""

#: ../../source/how-to-authenticate-supernodes.rst:71
msgid "Enable node authentication in ``SuperNode``"
msgstr ""

#: ../../source/how-to-authenticate-supernodes.rst:73
msgid ""
"Similar to the long-running Flower server (``SuperLink``), you can easily"
" enable node authentication in the long-running Flower client "
"(``SuperNode``). Use the following terminal command to start an "
"authenticated ``SuperNode``:"
msgstr ""

#: ../../source/how-to-authenticate-supernodes.rst:85
msgid ""
"The ``--auth-supernode-private-key`` flag expects a path to the node's "
"private key file and the ``--auth-supernode-public-key`` flag expects a "
"path to the node's public key file. For development purposes, you can "
"generate a private and public key pair using ``ssh-keygen -t ecdsa -b "
"384``."
msgstr ""

#: ../../source/how-to-authenticate-supernodes.rst:91
msgid "Security notice"
msgstr ""

#: ../../source/how-to-authenticate-supernodes.rst:93
msgid ""
"The system's security relies on the credentials of the SuperLink and each"
" SuperNode. Therefore, it is imperative to safeguard and safely store the"
" credentials to avoid security risks such as Public Key Infrastructure "
"(PKI) impersonation attacks. The node authentication mechanism also "
"involves human interaction, so please ensure that all of the "
"communication is done in a secure manner, using trusted communication "
"methods."
msgstr ""

#: ../../source/how-to-authenticate-supernodes.rst:100
#: ../../source/how-to-enable-tls-connections.rst:108
#: ../../source/how-to-use-built-in-mods.rst:95
#: ../../source/tutorial-series-what-is-federated-learning.ipynb:287
msgid "Conclusion"
msgstr ""

#: ../../source/how-to-authenticate-supernodes.rst:102
msgid ""
"You should now have learned how to start a long-running Flower server "
"(``SuperLink``) and client (``SuperNode``) with node authentication "
"enabled. You should also know the significance of the private key and "
"store it safely to minimize security risks."
msgstr ""

#: ../../source/how-to-configure-clients.rst:2
msgid "Configure Clients"
msgstr ""

#: ../../source/how-to-configure-clients.rst:4
msgid ""
"Flower provides the ability to send configuration values to clients, "
"allowing server-side control over client behavior. This feature enables "
"flexible and dynamic adjustment of client-side hyperparameters, improving"
" collaboration and experimentation."
msgstr ""

#: ../../source/how-to-configure-clients.rst:9
msgid "Configuration values"
msgstr ""

#: ../../source/how-to-configure-clients.rst:11
msgid ""
"``FitConfig`` and ``EvaluateConfig`` are dictionaries containing "
"configuration values that the server sends to clients during federated "
"learning rounds. These values must be of type ``Scalar``, which includes "
"``bool``, ``bytes``, ``float``, ``int``, or ``str`` (or equivalent types "
"in different languages). Scalar is the value type directly supported by "
"Flower for these configurations."
msgstr ""

#: ../../source/how-to-configure-clients.rst:17
msgid "For example, a ``FitConfig`` dictionary might look like this:"
msgstr ""

#: ../../source/how-to-configure-clients.rst:28
msgid ""
"Flower serializes these configuration dictionaries (or *config dicts* for"
" short) to their ProtoBuf representation, transports them to the client "
"using gRPC, and then deserializes them back to Python dictionaries."
msgstr ""

#: ../../source/how-to-configure-clients.rst:34
msgid ""
"Currently, there is no support for directly sending collection types "
"(e.g., ``Set``, ``List``, ``Map``) as values in configuration "
"dictionaries. To send collections, convert them to a supported type "
"(e.g., JSON string) and decode on the client side."
msgstr ""

#: ../../source/how-to-configure-clients.rst:38
#, fuzzy
msgid "Example:"
msgstr "Exemplo"

#: ../../source/how-to-configure-clients.rst:51
msgid "Configuration through Built-in Strategies"
msgstr ""

#: ../../source/how-to-configure-clients.rst:53
msgid ""
"Flower provides configuration options to control client behavior "
"dynamically through ``FitConfig`` and ``EvaluateConfig``. These "
"configurations allow server-side control over client-side parameters such"
" as batch size, number of local epochs, learning rate, and evaluation "
"settings, improving collaboration and experimentation."
msgstr ""

#: ../../source/how-to-configure-clients.rst:59
msgid "``FitConfig`` and ``EvaluateConfig``"
msgstr ""

#: ../../source/how-to-configure-clients.rst:61
msgid ""
"``FitConfig`` and ``EvaluateConfig`` are dictionaries containing "
"configuration values that the server sends to clients during federated "
"learning rounds. These dictionaries enable the server to adjust client-"
"side hyperparameters and monitor progress effectively."
msgstr ""

#: ../../source/how-to-configure-clients.rst:67
msgid "``FitConfig``"
msgstr ""

#: ../../source/how-to-configure-clients.rst:69
msgid ""
"``FitConfig`` specifies the hyperparameters for training rounds, such as "
"the batch size, number of local epochs, and other parameters that "
"influence training."
msgstr ""

#: ../../source/how-to-configure-clients.rst:72
msgid "For example, a ``fit_config`` callback might look like this:"
msgstr ""

#: ../../source/how-to-configure-clients.rst:90
msgid ""
"You can then pass this ``fit_config`` callback to a built-in strategy "
"such as ``FedAvg``:"
msgstr ""

#: ../../source/how-to-configure-clients.rst:101
msgid ""
"On the client side, the configuration is received in the ``fit`` method, "
"where it can be read and used:"
msgstr ""

#: ../../source/how-to-configure-clients.rst:124
msgid "``EvaluateConfig``"
msgstr ""

#: ../../source/how-to-configure-clients.rst:126
msgid ""
"``EvaluateConfig`` specifies hyperparameters for the evaluation process, "
"such as the batch size, evaluation frequency, or metrics to compute "
"during evaluation."
msgstr ""

#: ../../source/how-to-configure-clients.rst:129
msgid "For example, an ``evaluate_config`` callback might look like this:"
msgstr ""

#: ../../source/how-to-configure-clients.rst:143
msgid ""
"You can pass this ``evaluate_config`` callback to a built-in strategy "
"like ``FedAvg``:"
msgstr ""

#: ../../source/how-to-configure-clients.rst:151
msgid ""
"On the client side, the configuration is received in the ``evaluate`` "
"method, where it can be used during the evaluation process:"
msgstr ""

#: ../../source/how-to-configure-clients.rst:175
msgid "Example: Sending Training Configurations"
msgstr ""

#: ../../source/how-to-configure-clients.rst:177
msgid ""
"Imagine we want to send (a) the batch size, (b) the current global round,"
" and (c) the number of local epochs. Our configuration function could "
"look like this:"
msgstr ""

#: ../../source/how-to-configure-clients.rst:190
msgid ""
"To use this function with a built-in strategy like ``FedAvg``, pass it to"
" the ``FedAvg`` constructor (typically in your ``server_fn``):"
msgstr ""

#: ../../source/how-to-configure-clients.rst:211
msgid "Client-Side Configuration"
msgstr ""

#: ../../source/how-to-configure-clients.rst:213
msgid ""
"On the client side, configurations are received as input to the ``fit`` "
"and ``evaluate`` methods. For example:"
msgstr ""

#: ../../source/how-to-configure-clients.rst:230
msgid "Dynamic Configurations per Round"
msgstr ""

#: ../../source/how-to-configure-clients.rst:232
msgid ""
"Configuration functions are called at the beginning of every round. This "
"allows for dynamic adjustments based on progress. For example, you can "
"increase the number of local epochs in later rounds:"
msgstr ""

#: ../../source/how-to-configure-clients.rst:247
msgid "Customizing Client Configurations"
msgstr ""

#: ../../source/how-to-configure-clients.rst:249
msgid ""
"In some cases, it may be necessary to send different configurations to "
"individual clients. To achieve this, you can create a custom strategy by "
"extending a built-in one, such as ``FedAvg``:"
msgstr ""

#: ../../source/how-to-configure-clients.rst:254
msgid "Example: Client-Specific Configuration"
msgstr ""

#: ../../source/how-to-configure-clients.rst:273
msgid "Next, use this custom strategy as usual:"
msgstr ""

#: ../../source/how-to-configure-clients.rst:287
msgid "Summary of Enhancements"
msgstr ""

#: ../../source/how-to-configure-clients.rst:289
msgid "**Dynamic Configurations**: Enables per-round adjustments via functions."
msgstr ""

#: ../../source/how-to-configure-clients.rst:290
msgid "**Advanced Customization**: Supports client-specific strategies."
msgstr ""

#: ../../source/how-to-configure-clients.rst:291
msgid ""
"**Client-Side Integration**: Configurations accessible in ``fit`` and "
"``evaluate``."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:2
msgid "Design stateful ClientApps"
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:20
msgid ""
"By design, ClientApp_ objects are stateless. This means that the "
"``ClientApp`` object is recreated each time a new ``Message`` is to be "
"processed. This behaviour is identical with Flower's Simulation Engine "
"and Deployment Engine. For the former, it allows us to simulate the "
"running of a large number of nodes on a single machine or across multiple"
" machines. For the latter, it enables each ``SuperNode`` to be part of "
"multiple runs, each running a different ``ClientApp``."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:27
msgid ""
"When a ``ClientApp`` is executed it receives a Context_. This context is "
"unique for each ``ClientApp``, meaning that subsequent executions of the "
"same ``ClientApp`` from the same node will receive the same ``Context`` "
"object. In the ``Context``, the ``.state`` attribute can be used to store"
" information that you would like the ``ClientApp`` to have access to for "
"the duration of the run. This could be anything from intermediate results"
" such as the history of training losses (e.g. as a list of `float` values"
" with a new entry appended each time the ``ClientApp`` is executed), "
"certain parts of the model that should persist at the client side, or "
"some other arbitrary Python objects. These items would need to be "
"serialized before saving them into the context."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:38
msgid "Saving metrics to the context"
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:40
msgid ""
"This section will demonstrate how to save metrics such as accuracy/loss "
"values to the Context_ so they can be used in subsequent executions of "
"the ``ClientApp``. If your ``ClientApp`` makes use of NumPyClient_ then "
"entire object is also re-created for each call to methods like ``fit()`` "
"or ``evaluate()``."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:45
msgid ""
"Let's begin with a simple setting in which ``ClientApp`` is defined as "
"follows. The ``evaluate()`` method only generates a random number and "
"prints it."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:50
msgid ""
"You can create a PyTorch project with ready-to-use ``ClientApp`` and "
"other components by running ``flwr new``."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:81
msgid ""
"Let's say we want to save that randomly generated integer and append it "
"to a list that persists in the context. To do that, you'll need to do two"
" key things:"
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:84
msgid "Make the ``context.state`` reachable withing your client class"
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:85
msgid ""
"Initialise the appropiate record type (in this example we use "
"ConfigsRecord_) and save/read your entry when required."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:123
msgid ""
"If you run the app, you'll see an output similar to the one below. See "
"how after each round the `n_val` entry in the context gets one additional"
" integer ? Note that the order in which the `ClientApp` logs these "
"messages might differ slightly between rounds."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:146
msgid "Saving model parameters to the context"
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:148
msgid ""
"Using ConfigsRecord_ or MetricsRecord_ to save \"simple\" components is "
"fine (e.g., float, integer, boolean, string, bytes, and lists of these "
"types. Note that MetricsRecord_ only supports float, integer, and lists "
"of these types) Flower has a specific type of record, a "
"ParametersRecord_, for storing model parameters or more generally data "
"arrays."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:153
msgid ""
"Let's see a couple of examples of how to save NumPy arrays first and then"
" how to save parameters of PyTorch and TensorFlow models."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:158
msgid ""
"The examples below omit the definition of a ``ClientApp`` to keep the "
"code blocks concise. To make use of ``ParametersRecord`` objects in your "
"``ClientApp`` you can follow the same principles as outlined earlier."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:163
msgid "Saving NumPy arrays to the context"
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:165
msgid ""
"Elements stored in a `ParametersRecord` are of type Array_, which is a "
"data structure that holds ``bytes`` and metadata that can be used for "
"deserialization. Let's see how to create an ``Array`` from a NumPy array "
"and insert it into a ``ParametersRecord``. Here we will make use of the "
"built-in serialization and deserialization mechanisms in Flower, namely "
"the ``flwr.common.array_from_numpy`` function and the `numpy()` method of"
" an Array_ object."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:174
msgid ""
"Array_ objects carry bytes as their main payload and additional metadata "
"to use for deserialization. You can implement your own "
"serialization/deserialization if the provided ``array_from_numpy`` "
"doesn't fit your usecase."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:178
msgid ""
"Let's see how to use those functions to store a NumPy array into the "
"context."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:206
msgid ""
"To extract the data in a ``ParametersRecord``, you just need to "
"deserialize the array if interest. For example, following the example "
"above:"
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:223
msgid "Saving PyTorch parameters to the context"
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:225
msgid ""
"Following the NumPy example above, to save parameters of a PyTorch model "
"a straightforward way of doing so is to transform the parameters into "
"their NumPy representation and then proceed as shown earlier. Below is a "
"simple self-contained example for how to do this."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:263
msgid ""
"Let say now you want to apply the parameters stored in your context to a "
"new instance of the model (as it happens each time a ``ClientApp`` is "
"executed). You will need to:"
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:266
msgid "Deserialize each element in your specific ``ParametersRecord``"
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:267
msgid "Construct a ``state_dict`` and load it"
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:287
msgid ""
"And that's it! Recall that even though this example shows how to store "
"the entire ``state_dict`` in a ``ParametersRecord``, you can just save "
"part of it. The process would be identical, but you might need to adjust "
"how it is loaded into an existing model using PyTorch APIs."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:293
msgid "Saving Tensorflow/Keras parameters to the context"
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:295
msgid ""
"Follow the same steps as done above but replace the ``state_dict`` logic "
"with simply `get_weights() "
"<https://www.tensorflow.org/api_docs/python/tf/keras/Layer#get_weights>`_"
" to convert the model parameters to a list of NumPy arrays that can then "
"be serialized into an ``Array``. Then, after deserialization, use "
"`set_weights() "
"<https://www.tensorflow.org/api_docs/python/tf/keras/Layer#set_weights>`_"
" to apply the new parameters to a model."
msgstr ""

#: ../../source/how-to-enable-tls-connections.rst:2
msgid "Enable TLS connections"
msgstr ""

#: ../../source/how-to-enable-tls-connections.rst:4
msgid ""
"This guide describes how to a TLS-enabled secure Flower server "
"(``SuperLink``) can be started and how a Flower client (``SuperNode``) "
"can establish a secure connections to it."
msgstr ""

#: ../../source/how-to-enable-tls-connections.rst:8
msgid ""
"A complete code example demonstrating a secure connection can be found "
"`here <https://github.com/adap/flower/tree/main/examples/advanced-"
"tensorflow>`_."
msgstr ""

#: ../../source/how-to-enable-tls-connections.rst:11
msgid ""
"The code example comes with a ``README.md`` file which explains how to "
"start it. Although it is already TLS-enabled, it might be less "
"descriptive on how it does so. Stick to this guide for a deeper "
"introduction to the topic."
msgstr ""

#: ../../source/how-to-enable-tls-connections.rst:16
msgid "Certificates"
msgstr ""

#: ../../source/how-to-enable-tls-connections.rst:18
msgid ""
"Using TLS-enabled connections requires certificates to be passed to the "
"server and client. For the purpose of this guide we are going to generate"
" self-signed certificates. As this can become quite complex we are going "
"to ask you to run the script in ``examples/advanced-"
"tensorflow/certificates/generate.sh`` with the following command "
"sequence:"
msgstr ""

#: ../../source/how-to-enable-tls-connections.rst:29
msgid ""
"This will generate the certificates in ``examples/advanced-"
"tensorflow/.cache/certificates``."
msgstr ""

#: ../../source/how-to-enable-tls-connections.rst:32
msgid ""
"The approach for generating TLS certificates in the context of this "
"example can serve as an inspiration and starting point, but it should not"
" be used as a reference for production environments. Please refer to "
"other sources regarding the issue of correctly generating certificates "
"for production environments. For non-critical prototyping or research "
"projects, it might be sufficient to use the self-signed certificates "
"generated using the scripts mentioned in this guide."
msgstr ""

#: ../../source/how-to-enable-tls-connections.rst:40
msgid "Server (SuperLink)"
msgstr ""

#: ../../source/how-to-enable-tls-connections.rst:42
msgid ""
"Navigate to the ``examples/advanced-tensorflow`` folder (`here "
"<https://github.com/adap/flower/tree/main/examples/advanced-"
"tensorflow>`_) and use the following terminal command to start a server "
"(SuperLink) that uses the previously generated certificates:"
msgstr ""

#: ../../source/how-to-enable-tls-connections.rst:54
msgid ""
"When providing certificates, the server expects a tuple of three "
"certificates paths: CA certificate, server certificate and server private"
" key."
msgstr ""

#: ../../source/how-to-enable-tls-connections.rst:58
msgid "Clients (SuperNode)"
msgstr ""

#: ../../source/how-to-enable-tls-connections.rst:60
msgid ""
"Use the following terminal command to start a client (SuperNode) that "
"uses the previously generated certificates:"
msgstr ""

#: ../../source/how-to-enable-tls-connections.rst:71
msgid ""
"When setting ``root_certificates``, the client expects a file path to "
"PEM-encoded root certificates."
msgstr ""

#: ../../source/how-to-enable-tls-connections.rst:74
msgid ""
"In another terminal, start a second SuperNode that uses the same "
"certificates:"
msgstr ""

#: ../../source/how-to-enable-tls-connections.rst:84
msgid ""
"Note that in the second SuperNode, if you run both on the same machine, "
"you must specify a different port for the ``ClientAppIO`` API address to "
"avoid clashing with the first SuperNode."
msgstr ""

#: ../../source/how-to-enable-tls-connections.rst:89
msgid "Executing ``flwr run`` with TLS"
msgstr ""

#: ../../source/how-to-enable-tls-connections.rst:91
msgid ""
"The root certificates used for executing ``flwr run`` is specified in the"
" ``pyproject.toml`` of your app."
msgstr ""

#: ../../source/how-to-enable-tls-connections.rst:100
msgid ""
"Note that the path to the ``root-certificates`` is relative to the root "
"of the project. Now, you can run the example by executing the following:"
msgstr ""

#: ../../source/how-to-enable-tls-connections.rst:110
msgid ""
"You should now have learned how to generate self-signed certificates "
"using the given script, start an TLS-enabled server and have two clients "
"establish secure connections to it. You should also have learned how to "
"run your Flower project using ``flwr run`` with TLS enabled."
msgstr ""

#: ../../source/how-to-enable-tls-connections.rst:117
msgid ""
"For running a Docker setup with TLS enabled, please refer to :doc:`docker"
"/enable-tls`."
msgstr ""

#: ../../source/how-to-enable-tls-connections.rst:121
msgid "Additional resources"
msgstr ""

#: ../../source/how-to-enable-tls-connections.rst:123
msgid ""
"These additional sources might be relevant if you would like to dive "
"deeper into the topic of certificates:"
msgstr ""

#: ../../source/how-to-enable-tls-connections.rst:126
msgid "`Let's Encrypt <https://letsencrypt.org/docs/>`_"
msgstr ""

#: ../../source/how-to-enable-tls-connections.rst:127
msgid "`certbot <https://certbot.eff.org/>`_"
msgstr ""

#: ../../source/how-to-implement-fedbn.rst:2
msgid "Implement FedBN"
msgstr ""

#: ../../source/how-to-implement-fedbn.rst:4
msgid ""
"This tutorial will show you how to use Flower to build a federated "
"version of an existing machine learning workload with `FedBN "
"<https://github.com/med-air/FedBN>`_, a federated training method "
"designed for non-IID data. We are using PyTorch to train a Convolutional "
"Neural Network (with Batch Normalization layers) on the CIFAR-10 dataset."
" When applying FedBN, only minor changes are needed compared to "
":doc:`Quickstart PyTorch <tutorial-quickstart-pytorch>`."
msgstr ""

#: ../../source/how-to-implement-fedbn.rst:12
msgid "Model"
msgstr ""

#: ../../source/how-to-implement-fedbn.rst:14
msgid ""
"A full introduction to federated learning with PyTorch and Flower can be "
"found in :doc:`Quickstart PyTorch <tutorial-quickstart-pytorch>`. This "
"how-to guide varies only a few details in ``task.py``. FedBN requires a "
"model architecture (defined in class ``Net()``) that uses Batch "
"Normalization layers:"
msgstr ""

#: ../../source/how-to-implement-fedbn.rst:45
msgid ""
"Try editing the model architecture, then run the project to ensure "
"everything still works:"
msgstr ""

#: ../../source/how-to-implement-fedbn.rst:52
msgid ""
"So far this should all look fairly familiar if you've used Flower with "
"PyTorch before."
msgstr ""

#: ../../source/how-to-implement-fedbn.rst:55
msgid "FedBN"
msgstr ""

#: ../../source/how-to-implement-fedbn.rst:57
msgid ""
"To adopt FedBN, only the ``get_parameters`` and ``set_parameters`` "
"functions in ``task.py`` need to be revised. FedBN only changes the "
"client-side by excluding batch normalization parameters from being "
"exchanged with the server."
msgstr ""

#: ../../source/how-to-implement-fedbn.rst:61
msgid ""
"We revise the *client* logic by changing ``get_parameters`` and "
"``set_parameters`` in ``task.py``. The batch normalization parameters are"
" excluded from model parameter list when sending to or receiving from the"
" server:"
msgstr ""

#: ../../source/how-to-implement-fedbn.rst:90
msgid "To test the new appraoch, run the project again:"
msgstr ""

#: ../../source/how-to-implement-fedbn.rst:96
msgid ""
"Your PyTorch project now runs federated learning with FedBN. "
"Congratulations!"
msgstr ""

#: ../../source/how-to-implement-fedbn.rst:99
#: ../../source/how-to-run-flower-on-azure.rst:217
msgid "Next Steps"
msgstr ""

#: ../../source/how-to-implement-fedbn.rst:101
msgid ""
"The example is of course over-simplified since all clients load the exact"
" same dataset. This isn't realistic. You now have the tools to explore "
"this topic further. How about using different subsets of CIFAR-10 on each"
" client? How about adding more clients?"
msgstr ""

#: ../../source/how-to-implement-strategies.rst:2
msgid "Implement strategies"
msgstr ""

#: ../../source/how-to-implement-strategies.rst:4
msgid ""
"The strategy abstraction enables implementation of fully custom "
"strategies. A strategy is basically the federated learning algorithm that"
" runs on the server. Strategies decide how to sample clients, how to "
"configure clients for training, how to aggregate updates, and how to "
"evaluate models. Flower provides a few built-in strategies which are "
"based on the same API described below."
msgstr ""

#: ../../source/how-to-implement-strategies.rst:11
msgid "The ``Strategy`` abstraction"
msgstr ""

#: ../../source/how-to-implement-strategies.rst:13
msgid ""
"All strategy implementation are derived from the abstract base class "
"``flwr.server.strategy.Strategy``, both built-in implementations and "
"third party implementations. This means that custom strategy "
"implementations have the exact same capabilities at their disposal as "
"built-in ones."
msgstr ""

#: ../../source/how-to-implement-strategies.rst:18
msgid ""
"The strategy abstraction defines a few abstract methods that need to be "
"implemented:"
msgstr ""

#: ../../source/how-to-implement-strategies.rst:67
msgid ""
"Creating a new strategy means implementing a new ``class`` (derived from "
"the abstract base class ``Strategy``) that implements for the previously "
"shown abstract methods:"
msgstr ""

#: ../../source/how-to-implement-strategies.rst:97
msgid "The Flower server calls these methods in the following order:"
msgstr ""

#: ../../source/how-to-implement-strategies.rst:174
msgid "The following sections describe each of those methods in more detail."
msgstr ""

#: ../../source/how-to-implement-strategies.rst:177
msgid "The ``initialize_parameters`` method"
msgstr ""

#: ../../source/how-to-implement-strategies.rst:179
msgid ""
"``initialize_parameters`` is called only once, at the very beginning of "
"an execution. It is responsible for providing the initial global model "
"parameters in a serialized form (i.e., as a ``Parameters`` object)."
msgstr ""

#: ../../source/how-to-implement-strategies.rst:183
msgid ""
"Built-in strategies return user-provided initial parameters. The "
"following example shows how initial parameters can be passed to "
"``FedAvg``:"
msgstr ""

#: ../../source/how-to-implement-strategies.rst:209
msgid ""
"The Flower server will call ``initialize_parameters``, which either "
"returns the parameters that were passed to ``initial_parameters``, or "
"``None``. If no parameters are returned from ``initialize_parameters`` "
"(i.e., ``None``), the server will randomly select one client and ask it "
"to provide its parameters. This is a convenience feature and not "
"recommended in practice, but it can be useful for prototyping. In "
"practice, it is recommended to always use server-side parameter "
"initialization."
msgstr ""

#: ../../source/how-to-implement-strategies.rst:218
msgid ""
"Server-side parameter initialization is a powerful mechanism. It can be "
"used, for example, to resume training from a previously saved checkpoint."
" It is also the fundamental capability needed to implement hybrid "
"approaches, for example, to fine-tune a pre-trained model using federated"
" learning."
msgstr ""

#: ../../source/how-to-implement-strategies.rst:224
msgid "The ``configure_fit`` method"
msgstr ""

#: ../../source/how-to-implement-strategies.rst:226
msgid ""
"``configure_fit`` is responsible for configuring the upcoming round of "
"training. What does *configure* mean in this context? Configuring a round"
" means selecting clients and deciding what instructions to send to these "
"clients. The signature of ``configure_fit`` makes this clear:"
msgstr ""

#: ../../source/how-to-implement-strategies.rst:239
msgid ""
"The return value is a list of tuples, each representing the instructions "
"that will be sent to a particular client. Strategy implementations "
"usually perform the following steps in ``configure_fit``:"
msgstr ""

#: ../../source/how-to-implement-strategies.rst:243
#: ../../source/how-to-implement-strategies.rst:307
msgid ""
"Use the ``client_manager`` to randomly sample all (or a subset of) "
"available clients (each represented as a ``ClientProxy`` object)"
msgstr ""

#: ../../source/how-to-implement-strategies.rst:245
msgid ""
"Pair each ``ClientProxy`` with the same ``FitIns`` holding the current "
"global model ``parameters`` and ``config`` dict"
msgstr ""

#: ../../source/how-to-implement-strategies.rst:248
msgid ""
"More sophisticated implementations can use ``configure_fit`` to implement"
" custom client selection logic. A client will only participate in a round"
" if the corresponding ``ClientProxy`` is included in the list returned "
"from ``configure_fit``."
msgstr ""

#: ../../source/how-to-implement-strategies.rst:254
msgid ""
"The structure of this return value provides a lot of flexibility to the "
"user. Since instructions are defined on a per-client basis, different "
"instructions can be sent to each client. This enables custom strategies "
"to train, for example, different models on different clients, or use "
"different hyperparameters on different clients (via the ``config`` dict)."
msgstr ""

#: ../../source/how-to-implement-strategies.rst:261
msgid "The ``aggregate_fit`` method"
msgstr ""

#: ../../source/how-to-implement-strategies.rst:263
msgid ""
"``aggregate_fit`` is responsible for aggregating the results returned by "
"the clients that were selected and asked to train in ``configure_fit``."
msgstr ""

#: ../../source/how-to-implement-strategies.rst:277
msgid ""
"Of course, failures can happen, so there is no guarantee that the server "
"will get results from all the clients it sent instructions to (via "
"``configure_fit``). ``aggregate_fit`` therefore receives a list of "
"``results``, but also a list of ``failures``."
msgstr ""

#: ../../source/how-to-implement-strategies.rst:282
msgid ""
"``aggregate_fit`` returns an optional ``Parameters`` object and a "
"dictionary of aggregated metrics. The ``Parameters`` return value is "
"optional because ``aggregate_fit`` might decide that the results provided"
" are not sufficient for aggregation (e.g., too many failures)."
msgstr ""

#: ../../source/how-to-implement-strategies.rst:288
msgid "The ``configure_evaluate`` method"
msgstr ""

#: ../../source/how-to-implement-strategies.rst:290
msgid ""
"``configure_evaluate`` is responsible for configuring the upcoming round "
"of evaluation. What does *configure* mean in this context? Configuring a "
"round means selecting clients and deciding what instructions to send to "
"these clients. The signature of ``configure_evaluate`` makes this clear:"
msgstr ""

#: ../../source/how-to-implement-strategies.rst:303
msgid ""
"The return value is a list of tuples, each representing the instructions "
"that will be sent to a particular client. Strategy implementations "
"usually perform the following steps in ``configure_evaluate``:"
msgstr ""

#: ../../source/how-to-implement-strategies.rst:309
msgid ""
"Pair each ``ClientProxy`` with the same ``EvaluateIns`` holding the "
"current global model ``parameters`` and ``config`` dict"
msgstr ""

#: ../../source/how-to-implement-strategies.rst:312
msgid ""
"More sophisticated implementations can use ``configure_evaluate`` to "
"implement custom client selection logic. A client will only participate "
"in a round if the corresponding ``ClientProxy`` is included in the list "
"returned from ``configure_evaluate``."
msgstr ""

#: ../../source/how-to-implement-strategies.rst:318
msgid ""
"The structure of this return value provides a lot of flexibility to the "
"user. Since instructions are defined on a per-client basis, different "
"instructions can be sent to each client. This enables custom strategies "
"to evaluate, for example, different models on different clients, or use "
"different hyperparameters on different clients (via the ``config`` dict)."
msgstr ""

#: ../../source/how-to-implement-strategies.rst:325
msgid "The ``aggregate_evaluate`` method"
msgstr ""

#: ../../source/how-to-implement-strategies.rst:327
msgid ""
"``aggregate_evaluate`` is responsible for aggregating the results "
"returned by the clients that were selected and asked to evaluate in "
"``configure_evaluate``."
msgstr ""

#: ../../source/how-to-implement-strategies.rst:341
msgid ""
"Of course, failures can happen, so there is no guarantee that the server "
"will get results from all the clients it sent instructions to (via "
"``configure_evaluate``). ``aggregate_evaluate`` therefore receives a list"
" of ``results``, but also a list of ``failures``."
msgstr ""

#: ../../source/how-to-implement-strategies.rst:346
msgid ""
"``aggregate_evaluate`` returns an optional ``float`` (loss) and a "
"dictionary of aggregated metrics. The ``float`` return value is optional "
"because ``aggregate_evaluate`` might decide that the results provided are"
" not sufficient for aggregation (e.g., too many failures)."
msgstr ""

#: ../../source/how-to-implement-strategies.rst:352
msgid "The ``evaluate`` method"
msgstr ""

#: ../../source/how-to-implement-strategies.rst:354
msgid ""
"``evaluate`` is responsible for evaluating model parameters on the "
"server-side. Having ``evaluate`` in addition to "
"``configure_evaluate``/``aggregate_evaluate`` enables strategies to "
"perform both servers-side and client-side (federated) evaluation."
msgstr ""

#: ../../source/how-to-implement-strategies.rst:364
msgid ""
"The return value is again optional because the strategy might not need to"
" implement server-side evaluation or because the user-defined "
"``evaluate`` method might not complete successfully (e.g., it might fail "
"to load the server-side evaluation data)."
msgstr ""

#: ../../source/how-to-install-flower.rst:2
msgid "Install Flower"
msgstr ""

#: ../../source/how-to-install-flower.rst:5
msgid "Python version"
msgstr ""

#: ../../source/how-to-install-flower.rst:11
msgid "Install stable release"
msgstr ""

#: ../../source/how-to-install-flower.rst:14
msgid "Using pip"
msgstr ""

#: ../../source/how-to-install-flower.rst:16
msgid "Stable releases are available on `PyPI <https://pypi.org/project/flwr/>`_:"
msgstr ""

#: ../../source/how-to-install-flower.rst:22
msgid ""
"For simulations that use the Virtual Client Engine, ``flwr`` should be "
"installed with the ``simulation`` extra:"
msgstr ""

#: ../../source/how-to-install-flower.rst:30
msgid "Using conda (or mamba)"
msgstr ""

#: ../../source/how-to-install-flower.rst:32
msgid "Flower can also be installed from the ``conda-forge`` channel."
msgstr ""

#: ../../source/how-to-install-flower.rst:34
msgid ""
"If you have not added ``conda-forge`` to your channels, you will first "
"need to run the following:"
msgstr ""

#: ../../source/how-to-install-flower.rst:42
msgid ""
"Once the ``conda-forge`` channel has been enabled, ``flwr`` can be "
"installed with ``conda``:"
msgstr ""

#: ../../source/how-to-install-flower.rst:49
msgid "or with ``mamba``:"
msgstr ""

#: ../../source/how-to-install-flower.rst:56
msgid "Verify installation"
msgstr ""

#: ../../source/how-to-install-flower.rst:58
msgid ""
"The following command can be used to verify if Flower was successfully "
"installed. If everything worked, it should print the version of Flower to"
" the command line:"
msgstr ""

#: ../../source/how-to-install-flower.rst:68
msgid "Advanced installation options"
msgstr ""

#: ../../source/how-to-install-flower.rst:71
msgid "Install via Docker"
msgstr ""

#: ../../source/how-to-install-flower.rst:73
msgid ":doc:`Run Flower using Docker <docker/index>`"
msgstr ""

#: ../../source/how-to-install-flower.rst:76
msgid "Install pre-release"
msgstr ""

#: ../../source/how-to-install-flower.rst:78
msgid ""
"New (possibly unstable) versions of Flower are sometimes available as "
"pre-release versions (alpha, beta, release candidate) before the stable "
"release happens:"
msgstr ""

#: ../../source/how-to-install-flower.rst:85
msgid ""
"For simulations that use the Virtual Client Engine, ``flwr`` pre-releases"
" should be installed with the ``simulation`` extra:"
msgstr ""

#: ../../source/how-to-install-flower.rst:93
msgid "Install nightly release"
msgstr ""

#: ../../source/how-to-install-flower.rst:95
msgid ""
"The latest (potentially unstable) changes in Flower are available as "
"nightly releases:"
msgstr ""

#: ../../source/how-to-install-flower.rst:101
msgid ""
"For simulations that use the Virtual Client Engine, ``flwr-nightly`` "
"should be installed with the ``simulation`` extra:"
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:18
msgid "Run Flower on Azure"
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:22
msgid ""
"There are many ways to deploy Flower on Microst Azure. The instructions "
"provided in this guide is just a basic walkthrough, step-by-step guide on"
" how to quickly setup and run a Flower application on a Federated "
"Learning environment on Microst Azure."
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:26
msgid ""
"In this how-to guide, we want to create a Federated Learning environment "
"on Microst Azure using three Virtual Machines (VMs). From the three "
"machines, one machine will be used as the Federation server and two as "
"the Federation clients. Our goal is to create a Flower federation on "
"Microst Azure where we can run Flower apps from our local machine, e.g., "
"laptop."
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:32
msgid ""
"On the Federation server VM we will deploy the long-running Flower server"
" (``SuperLink``) and on the two Federation client VMs we will deploy the "
"long-running Flower client (``SuperNode``). For more details For more "
"details regarding the ``SuperLink`` and ``SuperNode`` concepts, please "
"see the |flower_architecture_link|_ ."
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:38
msgid "Azure VMs"
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:40
msgid ""
"First we need to create the three VMs configure their Python "
"environments, and inbound networking rules to allow cross-VM "
"communication."
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:44
msgid "VM Create"
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:46
msgid ""
"Assuming we are already inside the Microst Azure portal, we navigate to "
"the ``Create`` page and we select ``Azure virtual machine``. In the new "
"page, for each VM we edit the properties as follows:"
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:55
msgid "**Virtual machine name**"
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:56
msgid ""
"for server machine we can use ``flower-server`` and for clients, "
"``flower-client-1`` and ``flower-client-2``"
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:58
msgid "**Image**"
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:59
msgid "in this guide, we use ``Ubuntu Server 24.04 - x64 Gen2 LTS``"
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:60
msgid "**Size**"
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:61
msgid "in this guide, we use ``Standard_D2s_v3 - 2 vcpus, 8GiB memory``"
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:65
msgid "For resource group, we can create a new group and assign it to all VMs."
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:67
msgid ""
"When each VM instance has been created the portal will allow you to "
"download the public key (.pem) of each instance. Make sure you save this "
"key in safe place and change its permissions to user read only, i.e., run"
" the ``chmod 400 <PATH_TO_PEM_FILE>`` command for every .pem file."
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:72
msgid ""
"Once all three VMs are created then navigate to the overview page where "
"all three VMs are listed and open every other VM, and copy its Public IP "
"address. Using the Public IP address and the public key (after changing "
"the permissions), login to the instances from our local machine by "
"running the following command (by default Azure creates the "
"``azureuser``):"
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:83
msgid "VM Networking"
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:85
msgid ""
"During the execution of the Flower application, the server VM "
"(``SuperLink``) will be responsible to orchestrate the execution of the "
"application across the client VMs (``SuperNode``). When the SuperLink "
"server starts, by default, it listens to the following ports: ``{9092, "
"9093}``. Port `9092` is used to communicate with the Federation clients "
"(``SuperNode``) and port ``9093`` to receive and execute Flower "
"applications."
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:92
msgid ""
"Therefore, to enable this communication we need to allow inbound traffic "
"to the server VM instance. To achieve this, we need to navigate to the "
"Networking page of the server VM in the Microsoft Azure portal. There, we"
" will click the ``Add inbound port rule``. In the new window that "
"appears, we edit the rule properties as follows:"
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:97
msgid "The rest of the fields can be left at their default values."
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:104
#: ../../source/how-to-run-flower-on-azure.rst:145
msgid "**Source**"
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:105
msgid "``IP Addresses``"
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:106
#: ../../source/how-to-run-flower-on-azure.rst:133
msgid "**Source IP addresses/CIDR ranges**"
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:107
msgid "add client VMs' Public IP (separated by comma)"
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:108
#, fuzzy
msgid "**Destination**"
msgstr "Descrição"

#: ../../source/how-to-run-flower-on-azure.rst:109
#: ../../source/how-to-run-flower-on-azure.rst:146
#, fuzzy
msgid "``Any``"
msgstr "``FLWR_VERSION``"

#: ../../source/how-to-run-flower-on-azure.rst:110
msgid "**Service**"
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:111
#, fuzzy
msgid "``custom``"
msgstr "``UBUNTU_VERSION``"

#: ../../source/how-to-run-flower-on-azure.rst:112
#: ../../source/how-to-run-flower-on-azure.rst:135
#: ../../source/how-to-run-flower-on-azure.rst:147
msgid "**Destination port ranges**"
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:113
msgid "``9092``"
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:114
msgid "**Protocol**"
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:115
msgid "``TCP``"
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:117
msgid ""
"Finally, we need to also open port 9093 to allow receiving and executing "
"incoming application requests. To enable this we just need to repeat the "
"steps above, i.e., create a new inbound rule, where for port range we "
"assign port 9093. If we already know the Public IP from which our local "
"machine (e.g., laptop) will be submitting applications to the Azure "
"cluster, then we just need to specify the Source IP address/CIDR range. "
"However, if we want to keep the port widely open we simply need to change"
" source to ``Any``."
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:125
msgid ""
"To be more precise, if we know the Public IP of our machine, then we make"
" the following changes:"
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:134
msgid "add machine's Public IP"
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:136
#: ../../source/how-to-run-flower-on-azure.rst:148
msgid "``9093``"
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:138
msgid "Otherwise, we change the properties as follows:"
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:151
#, fuzzy
msgid "Flower Environment"
msgstr "``FLWR_VERSION``"

#: ../../source/how-to-run-flower-on-azure.rst:153
msgid ""
"Assuming we have been able to login to each VM, and create a Python "
"environment with Flower and all its dependencies installed (``pip install"
" flwr``), we can create a Flower application by running the ``flwr new`` "
"command. The console will then prompt us to give a name to the project, "
"e.g., ``flwr_azure_test``, the name of the author and select the type of "
"the Flower Framework we want to run, e.g., ``numpy``."
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:161
msgid ""
"An alternative approach would be to use Docker in each VM, with each "
"image containing the necessary environment and dependencies. For more "
"details please refer to the |flower_docker_index|_ guide."
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:166
msgid "Server Initialization"
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:168
msgid ""
"After configuring the Flower application environment, we proceed by "
"starting the Flower long-running processes (i.e., ``SuperLink`` and "
"``SuperNode``) at each VM instance. In particular, we need to run the "
"following commands, first in the server (``SuperLink``) and then at each "
"client (``SuperNode``)."
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:175
msgid ""
"To enable authentication and encrypted communication during the execution"
" lifecycle of the Flower application, please have a look at the following"
" resources: |authenticate_supernodes|_, |enable_tls_connections|_"
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:197
#, fuzzy
msgid "Run Flower App"
msgstr "O nome do repositório da imagem base."

#: ../../source/how-to-run-flower-on-azure.rst:199
msgid ""
"Finally, after all running Flower processes have been initialized on the "
"Microsoft Azure cluster, in our local machine, we first need to install "
"Flower and can create a project with a similar structure as the one we "
"have in the server and the clients, or copy the project structure from "
"one of them. Once we have the project locally, we can open the "
"``pyproject.toml`` file, and then add the following sections:"
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:214
msgid "Then from our local machine we need to run ``flwr run . my-federation``."
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:221
msgid ""
"This guide is not suitable for production environments due to missing "
"authentication and TLS security."
msgstr ""

#: ../../source/how-to-run-flower-on-azure.rst:224
msgid ""
"To enable authentication and establish secure connections, please refer "
"to the following resources: |authenticate_supernodes|_, "
"|enable_tls_connections|_"
msgstr ""

#: ../../source/how-to-run-simulations.rst:22
msgid "Run simulations"
msgstr ""

#: ../../source/how-to-run-simulations.rst:24
msgid ""
"Simulating Federated Learning workloads is useful for a multitude of use "
"cases: you might want to run your workload on a large cohort of clients "
"without having to source, configure, and manage a large number of "
"physical devices; you might want to run your FL workloads as fast as "
"possible on the compute systems you have access to without going through "
"a complex setup process; you might want to validate your algorithm in "
"different scenarios at varying levels of data and system heterogeneity, "
"client availability, privacy budgets, etc. These are among some of the "
"use cases where simulating FL workloads makes sense."
msgstr ""

#: ../../source/how-to-run-simulations.rst:33
msgid ""
"Flower's ``Simulation Engine`` schedules, launches, and manages "
"|clientapp_link|_ instances. It does so through a ``Backend``, which "
"contains several workers (i.e., Python processes) that can execute a "
"``ClientApp`` by passing it a |context_link|_ and a |message_link|_. "
"These ``ClientApp`` objects are identical to those used by Flower's "
"`Deployment Engine <contributor-explanation-architecture.html>`_, making "
"alternating between *simulation* and *deployment* an effortless process. "
"The execution of ``ClientApp`` objects through Flower's ``Simulation "
"Engine`` is:"
msgstr ""

#: ../../source/how-to-run-simulations.rst:41
msgid ""
"**Resource-aware**: Each backend worker executing ``ClientApp``\\s gets "
"assigned a portion of the compute and memory on your system. You can "
"define these at the beginning of the simulation, allowing you to control "
"the degree of parallelism of your simulation. For a fixed total pool of "
"resources, the fewer the resources per backend worker, the more "
"``ClientApps`` can run concurrently on the same hardware."
msgstr ""

#: ../../source/how-to-run-simulations.rst:46
msgid ""
"**Batchable**: When there are more ``ClientApps`` to execute than backend"
" workers, ``ClientApps`` are queued and executed as soon as resources are"
" freed. This means that ``ClientApps`` are typically executed in batches "
"of N, where N is the number of backend workers."
msgstr ""

#: ../../source/how-to-run-simulations.rst:50
msgid ""
"**Self-managed**: This means that you, as a user, do not need to launch "
"``ClientApps`` manually; instead, the ``Simulation Engine``'s internals "
"orchestrates the execution of all ``ClientApp``\\s."
msgstr ""

#: ../../source/how-to-run-simulations.rst:53
msgid ""
"**Ephemeral**: This means that a ``ClientApp`` is only materialized when "
"it is required by the application (e.g., to do `fit() <ref-api-"
"flwr.html#flwr.client.Client.fit>`_). The object is destroyed afterward, "
"releasing the resources it was assigned and allowing other clients to "
"participate."
msgstr ""

#: ../../source/how-to-run-simulations.rst:60
msgid ""
"You can preserve the state (e.g., internal variables, parts of an ML "
"model, intermediate results) of a ``ClientApp`` by saving it to its "
"``Context``. Check the `Designing Stateful Clients <how-to-design-"
"stateful-clients.rst>`_ guide for a complete walkthrough."
msgstr ""

#: ../../source/how-to-run-simulations.rst:65
msgid ""
"The ``Simulation Engine`` delegates to a ``Backend`` the role of spawning"
" and managing ``ClientApps``. The default backend is the ``RayBackend``, "
"which uses `Ray <https://www.ray.io/>`_, an open-source framework for "
"scalable Python workloads. In particular, each worker is an `Actor "
"<https://docs.ray.io/en/latest/ray-core/actors.html>`_ capable of "
"spawning a ``ClientApp`` given its ``Context`` and a ``Message`` to "
"process."
msgstr ""

#: ../../source/how-to-run-simulations.rst:73
msgid "Launch your Flower simulation"
msgstr ""

#: ../../source/how-to-run-simulations.rst:75
msgid ""
"Running a simulation is straightforward; in fact, it is the default mode "
"of operation for |flwr_run_link|_. Therefore, running Flower simulations "
"primarily requires you to first define a ``ClientApp`` and a "
"``ServerApp``. A convenient way to generate a minimal but fully "
"functional Flower app is by means of the |flwr_new_link|_ command. There "
"are multiple templates to choose from. The example below uses the "
"``PyTorch`` template."
msgstr ""

#: ../../source/how-to-run-simulations.rst:83
msgid ""
"If you haven't already, install Flower via ``pip install -U flwr`` in a "
"Python environment."
msgstr ""

#: ../../source/how-to-run-simulations.rst:91
msgid ""
"Then, follow the instructions shown after completing the |flwr_new_link|_"
" command. When you execute |flwr_run_link|_, you'll be using the "
"``Simulation Engine``."
msgstr ""

#: ../../source/how-to-run-simulations.rst:94
msgid ""
"If we take a look at the ``pyproject.toml`` that was generated from the "
"|flwr_new_link|_ command (and loaded upon |flwr_run_link|_ execution), we"
" see that a *default* federation is defined. It sets the number of "
"supernodes to 10."
msgstr ""

#: ../../source/how-to-run-simulations.rst:106
msgid ""
"You can modify the size of your simulations by adjusting ``options.num-"
"supernodes``."
msgstr ""

#: ../../source/how-to-run-simulations.rst:109
msgid "Simulation examples"
msgstr ""

#: ../../source/how-to-run-simulations.rst:111
msgid ""
"In addition to the quickstart tutorials in the documentation (e.g., "
"`quickstart PyTorch Tutorial <tutorial-quickstart-pytorch.html>`_, "
"`quickstart JAX Tutorial <tutorial-quickstart-jax.html>`_), most examples"
" in the Flower repository are simulation-ready."
msgstr ""

#: ../../source/how-to-run-simulations.rst:116
msgid ""
"`Quickstart TensorFlow/Keras "
"<https://github.com/adap/flower/tree/main/examples/quickstart-"
"tensorflow>`_."
msgstr ""

#: ../../source/how-to-run-simulations.rst:118
msgid ""
"`Quickstart PyTorch <https://github.com/adap/flower/tree/main/examples"
"/quickstart-pytorch>`_"
msgstr ""

#: ../../source/how-to-run-simulations.rst:120
msgid ""
"`Advanced PyTorch <https://github.com/adap/flower/tree/main/examples"
"/advanced-pytorch>`_"
msgstr ""

#: ../../source/how-to-run-simulations.rst:122
msgid ""
"`Quickstart MLX <https://github.com/adap/flower/tree/main/examples"
"/quickstart-mlx>`_"
msgstr ""

#: ../../source/how-to-run-simulations.rst:123
msgid ""
"`ViT fine-tuning <https://github.com/adap/flower/tree/main/examples"
"/flowertune-vit>`_"
msgstr ""

#: ../../source/how-to-run-simulations.rst:125
msgid ""
"The complete list of examples can be found in `the Flower GitHub "
"<https://github.com/adap/flower/tree/main/examples>`_."
msgstr ""

#: ../../source/how-to-run-simulations.rst:131
msgid "Defining ``ClientApp`` resources"
msgstr ""

#: ../../source/how-to-run-simulations.rst:133
msgid ""
"By default, the ``Simulation Engine`` assigns two CPU cores to each "
"backend worker. This means that if your system has 10 CPU cores, five "
"backend workers can be running in parallel, each executing a different "
"``ClientApp`` instance."
msgstr ""

#: ../../source/how-to-run-simulations.rst:137
msgid ""
"More often than not, you would probably like to adjust the resources your"
" ``ClientApp`` gets assigned based on the complexity (i.e., compute and "
"memory footprint) of your workload. You can do so by adjusting the "
"backend resources for your federation."
msgstr ""

#: ../../source/how-to-run-simulations.rst:143
#, python-format
msgid ""
"Note that the resources the backend assigns to each worker (and hence to "
"each ``ClientApp`` being executed) are assigned in a *soft* manner. This "
"means that the resources are primarily taken into account in order to "
"control the degree of parallelism at which ``ClientApp`` instances should"
" be executed. Resource assignment is **not strict**, meaning that if you "
"specified your ``ClientApp`` is assumed to make use of 25% of the "
"available VRAM but it ends up using 50%, it might cause other "
"``ClientApp`` instances to crash throwing an out-of-memory (OOM) error."
msgstr ""

#: ../../source/how-to-run-simulations.rst:151
msgid ""
"Customizing resources can be done directly in the ``pyproject.toml`` of "
"your app."
msgstr ""

#: ../../source/how-to-run-simulations.rst:160
msgid ""
"With the above backend settings, your simulation will run as many "
"``ClientApps`` in parallel as CPUs you have in your system. GPU resources"
" for your ``ClientApp`` can be assigned by specifying the **ratio** of "
"VRAM each should make use of."
msgstr ""

#: ../../source/how-to-run-simulations.rst:173
msgid ""
"If you are using TensorFlow, you need to `enable memory growth "
"<https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth>`_ so "
"multiple ``ClientApp`` instances can share a GPU. This needs to be done "
"before launching the simulation. To do so, set the environment variable "
"``TF_FORCE_GPU_ALLOW_GROWTH=\"1\"``."
msgstr ""

#: ../../source/how-to-run-simulations.rst:179
msgid ""
"Let's see how the above configuration results in a different number of "
"``ClientApps`` running in parallel depending on the resources available "
"in your system. If your system has:"
msgstr ""

#: ../../source/how-to-run-simulations.rst:183
#, python-format
msgid ""
"10x CPUs and 1x GPU: at most 4 ``ClientApps`` will run in parallel since "
"each requires 25% of the available VRAM."
msgstr ""

#: ../../source/how-to-run-simulations.rst:185
msgid ""
"10x CPUs and 2x GPUs: at most 8 ``ClientApps`` will run in parallel "
"(VRAM-limited)."
msgstr ""

#: ../../source/how-to-run-simulations.rst:186
msgid ""
"6x CPUs and 4x GPUs: at most 6 ``ClientApps`` will run in parallel (CPU-"
"limited)."
msgstr ""

#: ../../source/how-to-run-simulations.rst:187
msgid ""
"10x CPUs but 0x GPUs: you won't be able to run the simulation since not "
"even the resources for a single ``ClientApp`` can be met."
msgstr ""

#: ../../source/how-to-run-simulations.rst:190
msgid ""
"A generalization of this is given by the following equation. It gives the"
" maximum number of ``ClientApps`` that can be executed in parallel on "
"available CPU cores (SYS_CPUS) and VRAM (SYS_GPUS)."
msgstr ""

#: ../../source/how-to-run-simulations.rst:194
msgid ""
"N = \\min\\left(\\left\\lfloor \\frac{\\text{SYS_CPUS}}{\\text{num_cpus}}"
" \\right\\rfloor, \\left\\lfloor "
"\\frac{\\text{SYS_GPUS}}{\\text{num_gpus}} \\right\\rfloor\\right)"
msgstr ""

#: ../../source/how-to-run-simulations.rst:198
msgid ""
"Both ``num_cpus`` (an integer higher than 1) and ``num_gpus`` (a non-"
"negative real number) should be set on a per ``ClientApp`` basis. If, for"
" example, you want only a single ``ClientApp`` to run on each GPU, then "
"set ``num_gpus=1.0``. If, for example, a ``ClientApp`` requires access to"
" two whole GPUs, you'd set ``num_gpus=2``."
msgstr ""

#: ../../source/how-to-run-simulations.rst:203
msgid ""
"While the ``options.backend.client-resources`` can be used to control the"
" degree of concurrency in your simulations, this does not stop you from "
"running hundreds or even thousands of clients in the same round and "
"having orders of magnitude more *dormant* (i.e., not participating in a "
"round) clients. Let's say you want to have 100 clients per round but your"
" system can only accommodate 8 clients concurrently. The ``Simulation "
"Engine`` will schedule 100 ``ClientApps`` to run and then will execute "
"them in a resource-aware manner in batches of 8."
msgstr ""

#: ../../source/how-to-run-simulations.rst:212
msgid "Simulation Engine resources"
msgstr ""

#: ../../source/how-to-run-simulations.rst:214
msgid ""
"By default, the ``Simulation Engine`` has **access to all system "
"resources** (i.e., all CPUs, all GPUs). However, in some settings, you "
"might want to limit how many of your system resources are used for "
"simulation. You can do this in the ``pyproject.toml`` of your app by "
"setting the ``options.backend.init_args`` variable."
msgstr ""

#: ../../source/how-to-run-simulations.rst:228
msgid ""
"With the above setup, the Backend will be initialized with a single CPU "
"and GPU. Therefore, even if more CPUs and GPUs are available in your "
"system, they will not be used for the simulation. The example above "
"results in a single ``ClientApp`` running at any given point."
msgstr ""

#: ../../source/how-to-run-simulations.rst:233
msgid ""
"For a complete list of settings you can configure, check the `ray.init "
"<https://docs.ray.io/en/latest/ray-core/api/doc/ray.init.html#ray-init>`_"
" documentation."
msgstr ""

#: ../../source/how-to-run-simulations.rst:236
msgid "For the highest performance, do not set ``options.backend.init_args``."
msgstr ""

#: ../../source/how-to-run-simulations.rst:239
msgid "Simulation in Colab/Jupyter"
msgstr ""

#: ../../source/how-to-run-simulations.rst:241
msgid ""
"The preferred way of running simulations should always be "
"|flwr_run_link|_. However, the core functionality of the ``Simulation "
"Engine`` can be used from within a Google Colab or Jupyter environment by"
" means of `run_simulation <ref-api-"
"flwr.html#flwr.simulation.run_simulation>`_."
msgstr ""

#: ../../source/how-to-run-simulations.rst:262
msgid ""
"With ``run_simulation``, you can also control the amount of resources for"
" your ``ClientApp`` instances. Do so by setting ``backend_config``. If "
"unset, the default resources are assigned (i.e., 2xCPUs per ``ClientApp``"
" and no GPU)."
msgstr ""

#: ../../source/how-to-run-simulations.rst:273
msgid ""
"Refer to the `30 minutes Federated AI Tutorial "
"<https://colab.research.google.com/github/adap/flower/blob/main/examples"
"/flower-in-30-minutes/tutorial.ipynb>`_ for a complete example on how to "
"run Flower Simulations in Colab."
msgstr ""

#: ../../source/how-to-run-simulations.rst:280
msgid "Multi-node Flower simulations"
msgstr ""

#: ../../source/how-to-run-simulations.rst:282
msgid ""
"Flower's ``Simulation Engine`` allows you to run FL simulations across "
"multiple compute nodes so that you're not restricted to running "
"simulations on a _single_ machine. Before starting your multi-node "
"simulation, ensure that you:"
msgstr ""

#: ../../source/how-to-run-simulations.rst:286
msgid "Have the same Python environment on all nodes."
msgstr ""

#: ../../source/how-to-run-simulations.rst:287
msgid "Have a copy of your code on all nodes."
msgstr ""

#: ../../source/how-to-run-simulations.rst:288
msgid ""
"Have a copy of your dataset on all nodes. If you are using partitions "
"from `Flower Datasets <https://flower.ai/docs/datasets>`_, ensure the "
"partitioning strategy its parameterization are the same. The expectation "
"is that the i-th dataset partition is identical in all nodes."
msgstr ""

#: ../../source/how-to-run-simulations.rst:292
msgid ""
"Start Ray on your head node: on the terminal, type ``ray start --head``. "
"This command will print a few lines, one of which indicates how to attach"
" other nodes to the head node."
msgstr ""

#: ../../source/how-to-run-simulations.rst:295
msgid ""
"Attach other nodes to the head node: copy the command shown after "
"starting the head and execute it on the terminal of a new node (before "
"executing |flwr_run_link|_). For example: ``ray start "
"--address='192.168.1.132:6379'``. Note that to be able to attach nodes to"
" the head node they should be discoverable by each other."
msgstr ""

#: ../../source/how-to-run-simulations.rst:300
msgid ""
"With all the above done, you can run your code from the head node as you "
"would if the simulation were running on a single node. In other words:"
msgstr ""

#: ../../source/how-to-run-simulations.rst:308
msgid ""
"Once your simulation is finished, if you'd like to dismantle your "
"cluster, you simply need to run the command ``ray stop`` in each node's "
"terminal (including the head node)."
msgstr ""

#: ../../source/how-to-run-simulations.rst:313
msgid ""
"When attaching a new node to the head, all its resources (i.e., all CPUs,"
" all GPUs) will be visible by the head node. This means that the "
"``Simulation Engine`` can schedule as many ``ClientApp`` instances as "
"that node can possibly run. In some settings, you might want to exclude "
"certain resources from the simulation. You can do this by appending "
"``--num-cpus=<NUM_CPUS_FROM_NODE>`` and/or ``--num-"
"gpus=<NUM_GPUS_FROM_NODE>`` in any ``ray start`` command (including when "
"starting the head)."
msgstr ""

#: ../../source/how-to-run-simulations.rst:322
msgid "FAQ for Simulations"
msgstr ""

#: ../../source/how-to-run-simulations.rst
msgid "Can I make my ``ClientApp`` instances stateful?"
msgstr ""

#: ../../source/how-to-run-simulations.rst:326
msgid ""
"Yes. Use the ``state`` attribute of the |context_link|_ object that is "
"passed to the ``ClientApp`` to save variables, parameters, or results to "
"it. Read the `Designing Stateful Clients <how-to-design-stateful-"
"clients.rst>`_ guide for a complete walkthrough."
msgstr ""

#: ../../source/how-to-run-simulations.rst
msgid "Can I run multiple simulations on the same machine?"
msgstr ""

#: ../../source/how-to-run-simulations.rst:330
msgid ""
"Yes, but bear in mind that each simulation isn't aware of the resource "
"usage of the other. If your simulations make use of GPUs, consider "
"setting the ``CUDA_VISIBLE_DEVICES`` environment variable to make each "
"simulation use a different set of the available GPUs. Export such an "
"environment variable before starting |flwr_run_link|_."
msgstr ""

#: ../../source/how-to-run-simulations.rst
msgid ""
"Do the CPU/GPU resources set for each ``ClientApp`` restrict how much "
"compute/memory these make use of?"
msgstr ""

#: ../../source/how-to-run-simulations.rst:334
msgid ""
"No. These resources are exclusively used by the simulation backend to "
"control how many workers can be created on startup. Let's say N backend "
"workers are launched, then at most N ``ClientApp`` instances will be "
"running in parallel. It is your responsibility to ensure ``ClientApp`` "
"instances have enough resources to execute their workload (e.g., fine-"
"tune a transformer model)."
msgstr ""

#: ../../source/how-to-run-simulations.rst
msgid "My ``ClientApp`` is triggering OOM on my GPU. What should I do?"
msgstr ""

#: ../../source/how-to-run-simulations.rst:338
msgid ""
"It is likely that your `num_gpus` setting, which controls the number of "
"``ClientApp`` instances that can share a GPU, is too low (meaning too "
"many ``ClientApps`` share the same GPU). Try the following:"
msgstr ""

#: ../../source/how-to-run-simulations.rst:340
msgid ""
"Set your ``num_gpus=1``. This will make a single ``ClientApp`` run on a "
"GPU."
msgstr ""

#: ../../source/how-to-run-simulations.rst:341
msgid "Inspect how much VRAM is being used (use ``nvidia-smi`` for this)."
msgstr ""

#: ../../source/how-to-run-simulations.rst:342
msgid ""
"Based on the VRAM you see your single ``ClientApp`` using, calculate how "
"many more would fit within the remaining VRAM. One divided by the total "
"number of ``ClientApps`` is the ``num_gpus`` value you should set."
msgstr ""

#: ../../source/how-to-run-simulations.rst:344
msgid "Refer to :ref:`clientappresources` for more details."
msgstr ""

#: ../../source/how-to-run-simulations.rst:346
msgid ""
"If your ``ClientApp`` is using TensorFlow, make sure you are exporting "
"``TF_FORCE_GPU_ALLOW_GROWTH=\"1\"`` before starting your simulation. For "
"more details, check."
msgstr ""

#: ../../source/how-to-run-simulations.rst
msgid ""
"How do I know what's the right ``num_cpus`` and ``num_gpus`` for my "
"``ClientApp``?"
msgstr ""

#: ../../source/how-to-run-simulations.rst:350
msgid ""
"A good practice is to start by running the simulation for a few rounds "
"with higher ``num_cpus`` and ``num_gpus`` than what is really needed "
"(e.g., ``num_cpus=8`` and, if you have a GPU, ``num_gpus=1``). Then "
"monitor your CPU and GPU utilization. For this, you can make use of tools"
" such as ``htop`` and ``nvidia-smi``. If you see overall resource "
"utilization remains low, try lowering ``num_cpus`` and ``num_gpus`` "
"(recall this will make more ``ClientApp`` instances run in parallel) "
"until you see a satisfactory system resource utilization."
msgstr ""

#: ../../source/how-to-run-simulations.rst:352
msgid ""
"Note that if the workload on your ``ClientApp`` instances is not "
"homogeneous (i.e., some come with a larger compute or memory footprint), "
"you'd probably want to focus on those when coming up with a good value "
"for ``num_gpus`` and ``num_cpus``."
msgstr ""

#: ../../source/how-to-run-simulations.rst
msgid "Can I assign different resources to each ``ClientApp`` instance?"
msgstr ""

#: ../../source/how-to-run-simulations.rst:356
msgid ""
"No. All ``ClientApp`` objects are assumed to make use of the same "
"``num_cpus`` and ``num_gpus``. When setting these values (refer to "
":ref:`clientappresources` for more details), ensure the ``ClientApp`` "
"with the largest memory footprint (either RAM or VRAM) can run in your "
"system with others like it in parallel."
msgstr ""

#: ../../source/how-to-run-simulations.rst
msgid ""
"Can I run single simulation accross multiple compute nodes (e.g. GPU "
"servers)?"
msgstr ""

#: ../../source/how-to-run-simulations.rst:360
msgid ""
"Yes. If you are using the ``RayBackend`` (the *default* backend) you can "
"first interconnect your nodes through Ray's cli and then launch the "
"simulation. Refer to :ref:`multinodesimulations` for a step-by-step "
"guide."
msgstr ""

#: ../../source/how-to-run-simulations.rst
msgid ""
"My ``ServerApp`` also needs to make use of the GPU (e.g., to do "
"evaluation of the *global model* after aggregation). Is this GPU usage "
"taken into account by the ``Simulation Engine``?"
msgstr ""

#: ../../source/how-to-run-simulations.rst:364
msgid ""
"No. The ``Simulation Engine`` only manages ``ClientApps`` and therefore "
"is only aware of the system resources they require. If your ``ServerApp``"
" makes use of substantial compute or memory resources, factor that into "
"account when setting ``num_cpus`` and ``num_gpus``."
msgstr ""

#: ../../source/how-to-run-simulations.rst
msgid ""
"Can I indicate on what resource a specific instance of a ``ClientApp`` "
"should run? Can I do resource placement?"
msgstr ""

#: ../../source/how-to-run-simulations.rst:368
msgid ""
"Currently, the placement of ``ClientApp`` instances is managed by the "
"``RayBackend`` (the only backend available as of ``flwr==1.13.0``) and "
"cannot be customized. Implementing a *custom* backend would be a way of "
"achieving resource placement."
msgstr ""

#: ../../source/how-to-save-and-load-model-checkpoints.rst:2
msgid "Save and Load Model Checkpoints"
msgstr ""

#: ../../source/how-to-save-and-load-model-checkpoints.rst:4
msgid ""
"Flower does not automatically save model updates on the server-side. This"
" how-to guide describes the steps to save (and load) model checkpoints in"
" Flower."
msgstr ""

#: ../../source/how-to-save-and-load-model-checkpoints.rst:8
msgid "Model Checkpointing"
msgstr ""

#: ../../source/how-to-save-and-load-model-checkpoints.rst:10
msgid ""
"Model updates can be persisted on the server-side by customizing "
"``Strategy`` methods. Implementing custom strategies is always an option,"
" but for many cases it may be more convenient to simply customize an "
"existing strategy. The following code example defines a new "
"``SaveModelStrategy`` which customized the existing built-in ``FedAvg`` "
"strategy. In particular, it customizes ``aggregate_fit`` by calling "
"``aggregate_fit`` in the base class (``FedAvg``). It then continues to "
"save returned (aggregated) weights before it returns those aggregated "
"weights to the caller (i.e., the server):"
msgstr ""

#: ../../source/how-to-save-and-load-model-checkpoints.rst:58
msgid "Save and Load PyTorch Checkpoints"
msgstr ""

#: ../../source/how-to-save-and-load-model-checkpoints.rst:60
msgid ""
"Similar to the previous example but with a few extra steps, we'll show "
"how to store a PyTorch checkpoint we'll use the ``torch.save`` function. "
"Firstly, ``aggregate_fit`` returns a ``Parameters`` object that has to be"
" transformed into a list of NumPy ``ndarray``'s, then those are "
"transformed into the PyTorch ``state_dict`` following the ``OrderedDict``"
" class structure."
msgstr ""

#: ../../source/how-to-save-and-load-model-checkpoints.rst:103
msgid ""
"To load your progress, you simply append the following lines to your "
"code. Note that this will iterate over all saved checkpoints and load the"
" latest one:"
msgstr ""

#: ../../source/how-to-save-and-load-model-checkpoints.rst:116
msgid ""
"Return/use this object of type ``Parameters`` wherever necessary, such as"
" in the ``initial_parameters`` when defining a ``Strategy``."
msgstr ""

#: ../../source/how-to-save-and-load-model-checkpoints.rst:119
msgid ""
"Alternatively, we can save and load the model updates during evaluation "
"phase by overriding ``evaluate()`` or ``aggregate_evaluate()`` method of "
"the strategy (``FedAvg``). Checkout the details in `Advanced PyTorch "
"Example <https://github.com/adap/flower/tree/main/examples/advanced-"
"pytorch>`_ and `Advanced TensorFlow Example "
"<https://github.com/adap/flower/tree/main/examples/advanced-"
"tensorflow>`_."
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:2
msgid "Upgrade to Flower 1.0"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:6
msgid ""
"This guide is for users who have already worked with Flower 0.x and want "
"to upgrade to Flower 1.0. Newer versions of Flower (1.13 and later) are "
"based on a new architecture and not covered in this guide. After "
"upgrading Flower 0.x projects to Flower 1.0, please refer to "
":doc:`Upgrade to Flower 1.13 <how-to-upgrade-to-flower-1.13>` to make "
"your project compatible with the lastest version of Flower."
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:13
msgid ""
"Flower 1.0 is here. Along with new features, Flower 1.0 provides a stable"
" foundation for future growth. Compared to Flower 0.19 (and other 0.x "
"series releases), there are a few breaking changes that make it necessary"
" to change the code of existing 0.x-series projects."
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:19
#: ../../source/how-to-upgrade-to-flower-1.13.rst:49
msgid "Install update"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:21
msgid ""
"Here's how to update an existing installation to Flower 1.0 using either "
"pip or Poetry:"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:23
msgid "pip: add ``-U`` when installing."
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:25
msgid ""
"``python -m pip install -U flwr`` (when using ``start_server`` and "
"``start_client``)"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:26
msgid ""
"``python -m pip install -U 'flwr[simulation]'`` (when using "
"``start_simulation``)"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:28
msgid ""
"Poetry: update the ``flwr`` dependency in ``pyproject.toml`` and then "
"reinstall (don't forget to delete ``poetry.lock`` via ``rm poetry.lock`` "
"before running ``poetry install``)."
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:32
msgid "``flwr = \"^1.0.0\"`` (when using ``start_server`` and ``start_client``)"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:33
msgid ""
"``flwr = { version = \"^1.0.0\", extras = [\"simulation\"] }`` (when "
"using ``start_simulation``)"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:37
#: ../../source/how-to-upgrade-to-flower-1.13.rst:88
msgid "Required changes"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:39
msgid "The following breaking changes require manual updates."
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:42
msgid "General"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:44
msgid ""
"Pass all arguments as keyword arguments (not as positional arguments). "
"Here's an example:"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:47
msgid ""
"Flower 0.19 (positional arguments): ``start_client(\"127.0.0.1:8080\", "
"FlowerClient())``"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:48
msgid ""
"Flower 1.0 (keyword arguments): "
"``start_client(server_address=\"127.0.0.1:8080\", "
"client=FlowerClient())``"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:52
#: ../../source/ref-api/flwr.client.Client.rst:2
msgid "Client"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:54
msgid ""
"Subclasses of ``NumPyClient``: change ``def get_parameters(self):``` to "
"``def get_parameters(self, config):``"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:56
msgid ""
"Subclasses of ``Client``: change ``def get_parameters(self):``` to ``def "
"get_parameters(self, ins: GetParametersIns):``"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:60
msgid "Strategies / ``start_server`` / ``start_simulation``"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:62
msgid ""
"Pass ``ServerConfig`` (instead of a dictionary) to ``start_server`` and "
"``start_simulation``. Here's an example:"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:65
msgid ""
"Flower 0.19: ``start_server(..., config={\"num_rounds\": 3, "
"\"round_timeout\": 600.0}, ...)``"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:67
msgid ""
"Flower 1.0: ``start_server(..., "
"config=flwr.server.ServerConfig(num_rounds=3, round_timeout=600.0), "
"...)``"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:70
msgid ""
"Replace ``num_rounds=1`` in ``start_simulation`` with the new "
"``config=ServerConfig(...)`` (see previous item)"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:72
msgid ""
"Remove ``force_final_distributed_eval`` parameter from calls to "
"``start_server``. Distributed evaluation on all clients can be enabled by"
" configuring the strategy to sample all clients for evaluation after the "
"last round of training."
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:75
msgid "Rename parameter/ndarray conversion functions:"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:77
msgid "``parameters_to_weights`` --> ``parameters_to_ndarrays``"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:78
msgid "``weights_to_parameters`` --> ``ndarrays_to_parameters``"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:80
msgid ""
"Strategy initialization: if the strategy relies on the default values for"
" ``fraction_fit`` and ``fraction_evaluate``, set ``fraction_fit`` and "
"``fraction_evaluate`` manually to ``0.1``. Projects that do not manually "
"create a strategy (by calling ``start_server`` or ``start_simulation`` "
"without passing a strategy instance) should now manually initialize "
"FedAvg with ``fraction_fit`` and ``fraction_evaluate`` set to ``0.1``."
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:86
msgid "Rename built-in strategy parameters (e.g., ``FedAvg``):"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:88
msgid "``fraction_eval`` --> ``fraction_evaluate``"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:89
msgid "``min_eval_clients`` --> ``min_evaluate_clients``"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:90
msgid "``eval_fn`` --> ``evaluate_fn``"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:92
msgid ""
"Rename ``rnd`` to ``server_round``. This impacts multiple methods and "
"functions, for example, ``configure_fit``, ``aggregate_fit``, "
"``configure_evaluate``, ``aggregate_evaluate``, and ``evaluate_fn``."
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:95
msgid "Add ``server_round`` and ``config`` to ``evaluate_fn``:"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:97
msgid ""
"Flower 0.19: ``def evaluate(parameters: NDArrays) -> "
"Optional[Tuple[float, Dict[str, Scalar]]]:``"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:99
msgid ""
"Flower 1.0: ``def evaluate(server_round: int, parameters: NDArrays, "
"config: Dict[str, Scalar]) -> Optional[Tuple[float, Dict[str, "
"Scalar]]]:``"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:103
msgid "Custom strategies"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:105
msgid ""
"The type of parameter ``failures`` has changed from "
"``List[BaseException]`` to ``List[Union[Tuple[ClientProxy, FitRes], "
"BaseException]]`` (in ``aggregate_fit``) and "
"``List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]]`` (in "
"``aggregate_evaluate``)"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:109
msgid ""
"The ``Strategy`` method ``evaluate`` now receives the current round of "
"federated learning/evaluation as the first parameter:"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:112
msgid ""
"Flower 0.19: ``def evaluate(self, parameters: Parameters) -> "
"Optional[Tuple[float, Dict[str, Scalar]]]:``"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:114
msgid ""
"Flower 1.0: ``def evaluate(self, server_round: int, parameters: "
"Parameters) -> Optional[Tuple[float, Dict[str, Scalar]]]:``"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:118
msgid "Optional improvements"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:120
msgid ""
"Along with the necessary changes above, there are a number of potential "
"improvements that just became possible:"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:123
msgid ""
"Remove \"placeholder\" methods from subclasses of ``Client`` or "
"``NumPyClient``. If you, for example, use server-side evaluation, then "
"empty placeholder implementations of ``evaluate`` are no longer "
"necessary."
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:126
msgid ""
"Configure the round timeout via ``start_simulation``: "
"``start_simulation(..., config=flwr.server.ServerConfig(num_rounds=3, "
"round_timeout=600.0), ...)``"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:130
#: ../../source/how-to-upgrade-to-flower-1.13.rst:451
msgid "Further help"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:132
msgid ""
"Most official `Flower code examples "
"<https://github.com/adap/flower/tree/main/examples>`_ are already updated"
" to Flower 1.0, they can serve as a reference for using the Flower 1.0 "
"API. If there are further questions, `join the Flower Slack "
"<https://flower.ai/join-slack/>`_ and use the channel ``#questions``."
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:2
msgid "Upgrade to Flower 1.13"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:4
msgid ""
"Welcome to the migration guide for updating Flower to Flower 1.13! "
"Whether you're a seasoned user or just getting started, this guide will "
"help you smoothly transition your existing setup to take advantage of the"
" latest features and improvements in Flower 1.13."
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:10
msgid ""
"This guide shows how to make pre-``1.13`` Flower code compatible with "
"Flower 1.13 (and later) with only minimal code changes."
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:13
msgid "Let's dive in!"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:51
msgid ""
"Here's how to update an existing installation of Flower to Flower 1.13 "
"with ``pip``:"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:57
msgid "or if you need Flower 1.13 with simulation:"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:63
msgid ""
"Ensure you set the following version constraint in your "
"``requirements.txt``"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:73
msgid "or ``pyproject.toml``:"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:90
msgid ""
"Starting with Flower 1.8, the *infrastructure* and *application layers* "
"have been decoupled. Flower 1.13 enforces this separation further. Among "
"other things, this allows you to run the exact same code in a simulation "
"as in a real deployment."
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:94
msgid ""
"Instead of starting a client in code via ``start_client()``, you create a"
" |clientapp_link|_. Instead of starting a server in code via "
"``start_server()``, you create a |serverapp_link|_. Both ``ClientApp`` "
"and ``ServerApp`` are started by the long-running components of the "
"server and client: the `SuperLink` and `SuperNode`, respectively."
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:102
msgid ""
"For more details on SuperLink and SuperNode, please see the "
"|flower_architecture_link|_ ."
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:105
msgid ""
"The following non-breaking changes require manual updates and allow you "
"to run your project both in the traditional (now deprecated) way and in "
"the new (recommended) Flower 1.13 way:"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:110
msgid "|clientapp_link|_"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:112
msgid ""
"Wrap your existing client with |clientapp_link|_ instead of launching it "
"via ``start_client()``. Here's an example:"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:146
msgid "|serverapp_link|_"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:148
msgid ""
"Wrap your existing strategy with |serverapp_link|_ instead of starting "
"the server via ``start_server()``. Here's an example:"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:185
msgid "Deployment"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:187
msgid ""
"In a terminal window, start the SuperLink using |flower_superlink_link|_."
" Then, in two additional terminal windows, start two SuperNodes using "
"|flower_supernode_link|_ (2x). There is no need to directly run "
"``client.py`` and ``server.py`` as Python scripts."
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:190
msgid ""
"Here's an example to start the server without HTTPS (insecure mode, only "
"for prototyping):"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:195
msgid ""
"For a comprehensive walk-through on how to deploy Flower using Docker, "
"please refer to the :doc:`docker/index` guide."
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:218
msgid ""
"Here's another example to start both SuperLink and SuperNodes with HTTPS."
" Use the ``--ssl-ca-certfile``, ``--ssl-certfile``, and ``--ssl-keyfile``"
" command line options to pass paths to (CA certificate, server "
"certificate, and server private key)."
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:246
msgid "Simulation (CLI)"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:248
msgid ""
"Wrap your existing client and strategy with |clientapp_link|_ and "
"|serverapp_link|_, respectively. There is no need to use "
"``start_simulation()`` anymore. Here's an example:"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:253
#: ../../source/how-to-upgrade-to-flower-1.13.rst:389
msgid ""
"For a comprehensive guide on how to setup and run Flower simulations "
"please read the |flower_how_to_run_simulations_link|_ guide."
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:310
msgid "Depending on your Flower version, you can run your simulation as follows:"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:312
msgid ""
"For Flower 1.11 and later, run ``flwr run`` in the terminal. This is the "
"recommended way to start simulations, other ways are deprecated and no "
"longer recommended."
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:314
msgid ""
"DEPRECATED For Flower versions between 1.8 and 1.10, run ``flower-"
"simulation`` in the terminal and point to the ``server_app`` / "
"``client_app`` object in the code instead of executing the Python script."
" In the code snippet below, there is an example (assuming the "
"``server_app`` and ``client_app`` objects are in a ``sim.py`` module)."
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:318
msgid "DEPRECATED For Flower versions before 1.8, run the Python script directly."
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:337
msgid ""
"Depending on your Flower version, you can also define the default "
"resources as follows:"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:339
msgid ""
"For Flower 1.11 and later, you can edit your ``pyproject.toml`` file and "
"then run ``flwr run`` in the terminal as shown in the example below."
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:341
msgid ""
"DEPRECATED For Flower versions between 1.8 and 1.10, you can adjust the "
"resources for each |clientapp_link|_ using the ``--backend-config`` "
"command line argument instead of setting the ``client_resources`` "
"argument in ``start_simulation()``."
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:344
#: ../../source/how-to-upgrade-to-flower-1.13.rst:384
msgid ""
"DEPRECATED For Flower versions before 1.8, you need to run "
"``start_simulation()`` and pass a dictionary of the required resources to"
" the ``client_resources`` argument."
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:375
msgid "Simulation (Notebook)"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:377
msgid ""
"To run your simulation from within a notebook, please consider the "
"following examples depending on your Flower version:"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:380
msgid ""
"For Flower 1.11 and later, you need to run |runsim_link|_ in your "
"notebook instead of ``start_simulation()``."
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:382
msgid ""
"DEPRECATED For Flower versions between 1.8 and 1.10, you need to run "
"|runsim_link|_ in your notebook instead of ``start_simulation()`` and "
"configure the resources."
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:453
msgid ""
"Most official `Flower code examples <https://flower.ai/docs/examples/>`_ "
"are already updated to Flower 1.13 so they can serve as a reference for "
"using the Flower 1.13 API. If there are further questions, `join the "
"Flower Slack <https://flower.ai/join-slack/>`_ (and use the channel "
"``#questions``) or post them on `Flower Discuss "
"<https://discuss.flower.ai/>`_ where you can find the community posting "
"and answering questions."
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:460
msgid "Important"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:462
msgid ""
"As we continuously enhance Flower at a rapid pace, we'll be periodically "
"updating this guide. Please feel free to share any feedback with us!"
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.13.rst:465
msgid "Happy migrating! 🚀"
msgstr ""

#: ../../source/how-to-use-built-in-mods.rst:2
msgid "Use Built-in Mods"
msgstr ""

#: ../../source/how-to-use-built-in-mods.rst:4
msgid ""
"**Note: This tutorial covers experimental features. The functionality and"
" interfaces may change in future versions.**"
msgstr ""

#: ../../source/how-to-use-built-in-mods.rst:7
msgid ""
"In this tutorial, we will learn how to utilize built-in mods to augment "
"the behavior of a ``ClientApp``. Mods (sometimes also called Modifiers) "
"allow us to perform operations before and after a task is processed in "
"the ``ClientApp``."
msgstr ""

#: ../../source/how-to-use-built-in-mods.rst:12
msgid "What are Mods?"
msgstr ""

#: ../../source/how-to-use-built-in-mods.rst:14
msgid ""
"A Mod is a callable that wraps around a ``ClientApp``. It can manipulate "
"or inspect the incoming ``Message`` and the resulting outgoing "
"``Message``. The signature for a ``Mod`` is as follows:"
msgstr ""

#: ../../source/how-to-use-built-in-mods.rst:23
msgid "A typical mod function might look something like this:"
msgstr ""

#: ../../source/how-to-use-built-in-mods.rst:36
msgid "Using Mods"
msgstr ""

#: ../../source/how-to-use-built-in-mods.rst:38
msgid "To use mods in your ``ClientApp``, you can follow these steps:"
msgstr ""

#: ../../source/how-to-use-built-in-mods.rst:41
msgid "1. Import the required mods"
msgstr ""

#: ../../source/how-to-use-built-in-mods.rst:43
msgid "First, import the built-in mod you intend to use:"
msgstr ""

#: ../../source/how-to-use-built-in-mods.rst:51
msgid "2. Define your client function"
msgstr ""

#: ../../source/how-to-use-built-in-mods.rst:53
msgid ""
"Define your client function (``client_fn``) that will be wrapped by the "
"mod(s):"
msgstr ""

#: ../../source/how-to-use-built-in-mods.rst:62
msgid "3. Create the ``ClientApp`` with mods"
msgstr ""

#: ../../source/how-to-use-built-in-mods.rst:64
msgid ""
"Create your ``ClientApp`` and pass the mods as a list to the ``mods`` "
"argument. The order in which you provide the mods matters:"
msgstr ""

#: ../../source/how-to-use-built-in-mods.rst:78
msgid "Order of execution"
msgstr ""

#: ../../source/how-to-use-built-in-mods.rst:80
msgid ""
"When the ``ClientApp`` runs, the mods are executed in the order they are "
"provided in the list:"
msgstr ""

#: ../../source/how-to-use-built-in-mods.rst:83
msgid "``example_mod_1`` (outermost mod)"
msgstr ""

#: ../../source/how-to-use-built-in-mods.rst:84
msgid "``example_mod_2`` (next mod)"
msgstr ""

#: ../../source/how-to-use-built-in-mods.rst:85
msgid ""
"Message handler (core function that handles the incoming ``Message`` and "
"returns the outgoing ``Message``)"
msgstr ""

#: ../../source/how-to-use-built-in-mods.rst:87
msgid "``example_mod_2`` (on the way back)"
msgstr ""

#: ../../source/how-to-use-built-in-mods.rst:88
msgid "``example_mod_1`` (outermost mod on the way back)"
msgstr ""

#: ../../source/how-to-use-built-in-mods.rst:90
msgid ""
"Each mod has a chance to inspect and modify the incoming ``Message`` "
"before passing it to the next mod, and likewise with the outgoing "
"``Message`` before returning it up the stack."
msgstr ""

#: ../../source/how-to-use-built-in-mods.rst:97
msgid ""
"By following this guide, you have learned how to effectively use mods to "
"enhance your ``ClientApp``'s functionality. Remember that the order of "
"mods is crucial and affects how the input and output are processed."
msgstr ""

#: ../../source/how-to-use-built-in-mods.rst:101
msgid "Enjoy building a more robust and flexible ``ClientApp`` with mods!"
msgstr ""

#: ../../source/how-to-use-differential-privacy.rst:2
msgid "Use Differential Privacy"
msgstr ""

#: ../../source/how-to-use-differential-privacy.rst:4
msgid ""
"This guide explains how you can utilize differential privacy in the "
"Flower framework. If you are not yet familiar with differential privacy, "
"you can refer to :doc:`explanation-differential-privacy`."
msgstr ""

#: ../../source/how-to-use-differential-privacy.rst:10
msgid ""
"Differential Privacy in Flower is in a preview phase. If you plan to use "
"these features in a production environment with sensitive data, feel free"
" contact us to discuss your requirements and to receive guidance on how "
"to best use these features."
msgstr ""

#: ../../source/how-to-use-differential-privacy.rst:17
msgid ""
"This approach consists of two separate phases: clipping of the updates "
"and adding noise to the aggregated model. For the clipping phase, Flower "
"framework has made it possible to decide whether to perform clipping on "
"the server side or the client side."
msgstr ""

#: ../../source/how-to-use-differential-privacy.rst:21
msgid ""
"**Server-side Clipping**: This approach has the advantage of the server "
"enforcing uniform clipping across all clients' updates and reducing the "
"communication overhead for clipping values. However, it also has the "
"disadvantage of increasing the computational load on the server due to "
"the need to perform the clipping operation for all clients."
msgstr ""

#: ../../source/how-to-use-differential-privacy.rst:26
msgid ""
"**Client-side Clipping**: This approach has the advantage of reducing the"
" computational overhead on the server. However, it also has the "
"disadvantage of lacking centralized control, as the server has less "
"control over the clipping process."
msgstr ""

#: ../../source/how-to-use-differential-privacy.rst:31
msgid "Server-side Clipping"
msgstr ""

#: ../../source/how-to-use-differential-privacy.rst:33
msgid ""
"For central DP with server-side clipping, there are two ``Strategy`` "
"classes that act as wrappers around the actual ``Strategy`` instance (for"
" example, ``FedAvg``). The two wrapper classes are "
"``DifferentialPrivacyServerSideFixedClipping`` and "
"``DifferentialPrivacyServerSideAdaptiveClipping`` for fixed and adaptive "
"clipping."
msgstr ""

#: ../../source/how-to-use-differential-privacy.rst:-1
msgid "server side clipping"
msgstr ""

#: ../../source/how-to-use-differential-privacy.rst:43
msgid ""
"The code sample below enables the ``FedAvg`` strategy to use server-side "
"fixed clipping using the ``DifferentialPrivacyServerSideFixedClipping`` "
"wrapper class. The same approach can be used with "
"``DifferentialPrivacyServerSideAdaptiveClipping`` by adjusting the "
"corresponding input parameters."
msgstr ""

#: ../../source/how-to-use-differential-privacy.rst:64
msgid "Client-side Clipping"
msgstr ""

#: ../../source/how-to-use-differential-privacy.rst:66
msgid ""
"For central DP with client-side clipping, the server sends the clipping "
"value to selected clients on each round. Clients can use existing Flower "
"``Mods`` to perform the clipping. Two mods are available for fixed and "
"adaptive client-side clipping: ``fixedclipping_mod`` and "
"``adaptiveclipping_mod`` with corresponding server-side wrappers "
"``DifferentialPrivacyClientSideFixedClipping`` and "
"``DifferentialPrivacyClientSideAdaptiveClipping``."
msgstr ""

#: ../../source/how-to-use-differential-privacy.rst:-1
msgid "client side clipping"
msgstr ""

#: ../../source/how-to-use-differential-privacy.rst:78
msgid ""
"The code sample below enables the ``FedAvg`` strategy to use differential"
" privacy with client-side fixed clipping using both the "
"``DifferentialPrivacyClientSideFixedClipping`` wrapper class and, on the "
"client, ``fixedclipping_mod``:"
msgstr ""

#: ../../source/how-to-use-differential-privacy.rst:97
msgid ""
"In addition to the server-side strategy wrapper, the ``ClientApp`` needs "
"to configure the matching ``fixedclipping_mod`` to perform the client-"
"side clipping:"
msgstr ""

#: ../../source/how-to-use-differential-privacy.rst:116
msgid ""
"To utilize local differential privacy (DP) and add noise to the client "
"model parameters before transmitting them to the server in Flower, you "
"can use the `LocalDpMod`. The following hyperparameters need to be set: "
"clipping norm value, sensitivity, epsilon, and delta."
msgstr ""

#: ../../source/how-to-use-differential-privacy.rst:-1
msgid "local DP mod"
msgstr ""

#: ../../source/how-to-use-differential-privacy.rst:126
msgid "Below is a code example that shows how to use ``LocalDpMod``:"
msgstr ""

#: ../../source/how-to-use-differential-privacy.rst:144
msgid ""
"Please note that the order of mods, especially those that modify "
"parameters, is important when using multiple modifiers. Typically, "
"differential privacy (DP) modifiers should be the last to operate on "
"parameters."
msgstr ""

#: ../../source/how-to-use-differential-privacy.rst:149
msgid "Local Training using Privacy Engines"
msgstr ""

#: ../../source/how-to-use-differential-privacy.rst:151
msgid ""
"For ensuring data instance-level privacy during local model training on "
"the client side, consider leveraging privacy engines such as Opacus and "
"TensorFlow Privacy. For examples of using Flower with these engines, "
"please refer to the Flower examples directory (`Opacus "
"<https://github.com/adap/flower/tree/main/examples/opacus>`_, `Tensorflow"
" Privacy <https://github.com/adap/flower/tree/main/examples/tensorflow-"
"privacy>`_)."
msgstr ""

#: ../../source/how-to-use-strategies.rst:2
msgid "Use strategies"
msgstr ""

#: ../../source/how-to-use-strategies.rst:4
msgid ""
"Flower allows full customization of the learning process through the "
"``Strategy`` abstraction. A number of built-in strategies are provided in"
" the core framework."
msgstr ""

#: ../../source/how-to-use-strategies.rst:7
msgid ""
"There are three ways to customize the way Flower orchestrates the "
"learning process on the server side:"
msgstr ""

#: ../../source/how-to-use-strategies.rst:10
msgid "Use an existing strategy, for example, ``FedAvg``"
msgstr ""

#: ../../source/how-to-use-strategies.rst:11
#: ../../source/how-to-use-strategies.rst:66
msgid "Customize an existing strategy with callback functions"
msgstr ""

#: ../../source/how-to-use-strategies.rst:12
#: ../../source/how-to-use-strategies.rst:139
msgid "Implement a novel strategy"
msgstr ""

#: ../../source/how-to-use-strategies.rst:15
msgid "Use an existing strategy"
msgstr ""

#: ../../source/how-to-use-strategies.rst:17
msgid ""
"Flower comes with a number of popular federated learning Strategies which"
" can be instantiated as follows:"
msgstr ""

#: ../../source/how-to-use-strategies.rst:45
msgid ""
"To make the ``ServerApp`` use this strategy, pass a ``server_fn`` "
"function to the ``ServerApp`` constructor. The ``server_fn`` function "
"should return a ``ServerAppComponents`` object that contains the strategy"
" instance and a ``ServerConfig`` instance."
msgstr ""

#: ../../source/how-to-use-strategies.rst:50
msgid ""
"Both ``Strategy`` and ``ServerConfig`` classes can be configured with "
"parameters. The ``Context`` object passed to ``server_fn`` contains the "
"values specified in the ``[tool.flwr.app.config]`` table in your "
"``pyproject.toml`` (a snippet is shown below). To access these values, "
"use ``context.run_config``."
msgstr ""

#: ../../source/how-to-use-strategies.rst:68
msgid ""
"Existing strategies provide several ways to customize their behavior. "
"Callback functions allow strategies to call user-provided code during "
"execution. This approach enables you to modify the strategy's partial "
"behavior without rewriting the whole class from zero."
msgstr ""

#: ../../source/how-to-use-strategies.rst:73
msgid "Configuring client fit and client evaluate"
msgstr ""

#: ../../source/how-to-use-strategies.rst:75
msgid ""
"The server can pass new configuration values to the client each round by "
"providing a function to ``on_fit_config_fn``. The provided function will "
"be called by the strategy and must return a dictionary of configuration "
"key value pairs that will be sent to the client. It must return a "
"dictionary of arbitrary configuration values ``client.fit`` and "
"``client.evaluate`` functions during each round of federated learning."
msgstr ""

#: ../../source/how-to-use-strategies.rst:121
msgid ""
"The ``on_fit_config_fn`` can be used to pass arbitrary configuration "
"values from server to client and potentially change these values each "
"round, for example, to adjust the learning rate. The client will receive "
"the dictionary returned by the ``on_fit_config_fn`` in its own "
"``client.fit()`` function. And while the values can be also passed "
"directly via the context this function can be a place to implement finer "
"control over the `fit` behaviour that may not be achieved by the context,"
" which sets fixed values."
msgstr ""

#: ../../source/how-to-use-strategies.rst:129
msgid ""
"Similar to ``on_fit_config_fn``, there is also ``on_evaluate_config_fn`` "
"to customize the configuration sent to ``client.evaluate()``"
msgstr ""

#: ../../source/how-to-use-strategies.rst:133
msgid "Configuring server-side evaluation"
msgstr ""

#: ../../source/how-to-use-strategies.rst:135
msgid ""
"Server-side evaluation can be enabled by passing an evaluation function "
"to ``evaluate_fn``."
msgstr ""

#: ../../source/how-to-use-strategies.rst:141
msgid ""
"Writing a fully custom strategy is a bit more involved, but it provides "
"the most flexibility. Read the `Implementing Strategies <how-to-"
"implement-strategies.html>`_ guide to learn more."
msgstr ""

#: ../../source/index.rst:34
msgid "Tutorial"
msgstr ""

#: ../../source/index.rst:44
msgid "Quickstart tutorials"
msgstr ""

#: ../../source/index.rst:81 ../../source/index.rst:85
msgid "How-to guides"
msgstr ""

#: ../../source/index.rst:108 ../../source/index.rst:113
msgid "Explanations"
msgstr ""

#: None:-1
msgid "API reference"
msgstr ""

#: ../../source/index.rst:139
msgid "Reference docs"
msgstr ""

#: ../../source/index.rst:154
msgid "Contributor tutorials"
msgstr ""

#: ../../source/index.rst:161
msgid "Contributor how-to guides"
msgstr ""

#: ../../source/index.rst:173
msgid "Contributor explanations"
msgstr ""

#: ../../source/index.rst:179
msgid "Contributor references"
msgstr ""

#: ../../source/index.rst:-1
msgid ""
"Check out the documentation of the main Flower Framework enabling easy "
"Python development for Federated Learning."
msgstr ""

#: ../../source/index.rst:2
msgid "Flower Framework Documentation"
msgstr ""

#: ../../source/index.rst:7
msgid ""
"Welcome to Flower's documentation. `Flower <https://flower.ai>`_ is a "
"friendly federated learning framework."
msgstr ""

#: ../../source/index.rst:11
msgid "Join the Flower Community"
msgstr ""

#: ../../source/index.rst:13
msgid ""
"The Flower Community is growing quickly - we're a friendly group of "
"researchers, engineers, students, professionals, academics, and other "
"enthusiasts."
msgstr ""

#: ../../source/index.rst:16
msgid "Join us on Slack"
msgstr ""

#: ../../source/index.rst:23
msgid "Flower Framework"
msgstr ""

#: ../../source/index.rst:25
msgid ""
"The user guide is targeted at researchers and developers who want to use "
"Flower to bring existing machine learning workloads into a federated "
"setting. One of Flower's design goals was to make this simple. Read on to"
" learn more."
msgstr ""

#: ../../source/index.rst:30
msgid "Tutorials"
msgstr ""

#: ../../source/index.rst:32
msgid ""
"A learning-oriented series of federated learning tutorials, the best "
"place to start."
msgstr ""

#: ../../source/index.rst:62
msgid ""
"QUICKSTART TUTORIALS: :doc:`PyTorch <tutorial-quickstart-pytorch>` | "
":doc:`TensorFlow <tutorial-quickstart-tensorflow>` | :doc:`MLX <tutorial-"
"quickstart-mlx>` | :doc:`🤗 Transformers <tutorial-quickstart-"
"huggingface>` | :doc:`JAX <tutorial-quickstart-jax>` | :doc:`Pandas "
"<tutorial-quickstart-pandas>` | :doc:`fastai <tutorial-quickstart-"
"fastai>` | :doc:`PyTorch Lightning <tutorial-quickstart-pytorch-"
"lightning>` | :doc:`scikit-learn <tutorial-quickstart-scikitlearn>` | "
":doc:`XGBoost <tutorial-quickstart-xgboost>` | :doc:`Android <tutorial-"
"quickstart-android>` | :doc:`iOS <tutorial-quickstart-ios>`"
msgstr ""

#: ../../source/index.rst:70
msgid "We also made video tutorials for PyTorch:"
msgstr ""

#: ../../source/index.rst:75
msgid "And TensorFlow:"
msgstr ""

#: ../../source/index.rst:83
msgid ""
"Problem-oriented how-to guides show step-by-step how to achieve a "
"specific goal."
msgstr ""

#: ../../source/index.rst:110
msgid ""
"Understanding-oriented concept guides explain and discuss key topics and "
"underlying ideas behind Flower and collaborative AI."
msgstr ""

#: ../../source/index.rst:122
msgid "References"
msgstr ""

#: ../../source/index.rst:124
msgid "Information-oriented API reference and other reference material."
msgstr ""

#: ../../source/index.rst:133:<autosummary>:1
msgid ":py:obj:`flwr <flwr>`\\"
msgstr ""

#: ../../source/index.rst:133:<autosummary>:1 flwr:1 of
msgid "Flower main package."
msgstr ""

#: ../../source/index.rst:149
msgid "Contributor docs"
msgstr ""

#: ../../source/index.rst:151
msgid ""
"The Flower community welcomes contributions. The following docs are "
"intended to help along the way."
msgstr ""

#: ../../source/ref-api-cli.rst:2
msgid "Flower CLI reference"
msgstr ""

#: ../../source/ref-api-cli.rst:5
msgid "Basic Commands"
msgstr ""

#: ../../source/ref-api-cli.rst:10
#, fuzzy
msgid "``flwr`` CLI"
msgstr "``FLWR_VERSION``"

#: ../../flwr:1
msgid "flwr is the Flower command line interface."
msgstr ""

#: ../../source/ref-api-cli.rst
msgid "Options"
msgstr ""

#: ../../flwr:1
msgid "Install completion for the current shell."
msgstr ""

#: ../../flwr:1
msgid ""
"Show completion for the current shell, to copy it or customize the "
"installation."
msgstr ""

#: ../../flwr build:1
msgid "Build a Flower App into a Flower App Bundle (FAB)."
msgstr ""

#: ../../flwr build:1
msgid ""
"You can run ``flwr build`` without any arguments to bundle the app "
"located in the current directory. Alternatively, you can you can specify "
"a path using the ``--app`` option to bundle an app located at the "
"provided path. For example:"
msgstr ""

#: ../../flwr build:1
msgid "``flwr build --app ./apps/flower-hello-world``."
msgstr ""

#: ../../flwr build:1
msgid "Path of the Flower App to bundle into a FAB"
msgstr ""

#: ../../flwr install:1
msgid "Install a Flower App Bundle."
msgstr ""

#: ../../flwr install:1
msgid "It can be ran with a single FAB file argument:"
msgstr ""

#: ../../flwr install:1
msgid "``flwr install ./target_project.fab``"
msgstr ""

#: ../../flwr install:1
msgid "The target install directory can be specified with ``--flwr-dir``:"
msgstr ""

#: ../../flwr install:1
msgid "``flwr install ./target_project.fab --flwr-dir ./docs/flwr``"
msgstr ""

#: ../../flwr install:1
msgid ""
"This will install ``target_project`` to ``./docs/flwr/``. By default, "
"``flwr-dir`` is equal to:"
msgstr ""

#: ../../flwr install:1
msgid "``$FLWR_HOME/`` if ``$FLWR_HOME`` is defined"
msgstr ""

#: ../../flwr install:1
msgid "``$XDG_DATA_HOME/.flwr/`` if ``$XDG_DATA_HOME`` is defined"
msgstr ""

#: ../../flwr install:1
msgid "``$HOME/.flwr/`` in all other cases"
msgstr ""

#: ../../flwr install:1
msgid "The desired install path."
msgstr ""

#: ../../source/ref-api-cli.rst
#, fuzzy
msgid "Arguments"
msgstr "Argumento de compilação"

#: ../../flwr install:1 log:1 ls:1 new:1 run:1
#, fuzzy
msgid "Optional argument"
msgstr "Argumento de compilação"

#: ../../flwr install:1
msgid "The source FAB file to install."
msgstr ""

#: ../../flwr log:1
msgid "Get logs from a Flower project run."
msgstr ""

#: ../../flwr log:1
msgid "Flag to stream or print logs from the Flower run"
msgstr ""

#: ../../flwr log ls run
msgid "default"
msgstr ""

#: ../../flwr log:1
msgid "``True``"
msgstr ""

#: ../../flwr log:1
#, fuzzy
msgid "Required argument"
msgstr "Argumento de compilação"

#: ../../flwr log:1
msgid "The Flower run ID to query"
msgstr ""

#: ../../flwr log:1
msgid "Path of the Flower project to run"
msgstr ""

#: ../../flwr log:1
msgid "Name of the federation to run the app on"
msgstr ""

#: ../../flwr ls:1
msgid "List runs."
msgstr ""

#: ../../flwr ls:1
msgid "List all runs"
msgstr ""

#: ../../flwr ls:1 run:1
#, fuzzy
msgid "``False``"
msgstr "``FLWR_VERSION``"

#: ../../flwr ls:1
msgid "Specific run ID to display"
msgstr ""

#: ../../flwr ls:1 run:1
msgid "Format output using 'default' view or 'json'"
msgstr ""

#: ../../flwr ls:1 run:1
#, fuzzy
msgid "``'default'``"
msgstr "``FLWR_VERSION``"

#: ../../flwr ls:1
#, fuzzy
msgid "Path of the Flower project"
msgstr "O nome do repositório da imagem base."

#: ../../flwr ls:1
msgid "Name of the federation"
msgstr ""

#: ../../flwr new:1
msgid "Create new Flower App."
msgstr ""

#: ../../flwr new:1
msgid "The ML framework to use"
msgstr ""

#: ../../flwr new
msgid "options"
msgstr ""

#: ../../flwr new:1
msgid ""
"PyTorch | TensorFlow | sklearn | HuggingFace | JAX | MLX | NumPy | "
"FlowerTune | Flower Baseline"
msgstr ""

#: ../../flwr new:1
msgid "The Flower username of the author"
msgstr ""

#: ../../flwr new:1
#, fuzzy
msgid "The name of the Flower App"
msgstr "O nome do repositório da imagem base."

#: ../../flwr run:1
msgid "Run Flower App."
msgstr ""

#: ../../flwr run:1
msgid "Override configuration key-value pairs, should be of the format:"
msgstr ""

#: ../../flwr run:1
msgid ""
"`--run-config 'key1=\"value1\" key2=\"value2\"' --run-config "
"'key3=\"value3\"'`"
msgstr ""

#: ../../flwr run:1
msgid ""
"Note that `key1`, `key2`, and `key3` in this example need to exist inside"
" the `pyproject.toml` in order to be properly overriden."
msgstr ""

#: ../../flwr run:1
msgid ""
"Use `--stream` with `flwr run` to display logs; logs are not streamed by "
"default."
msgstr ""

#: ../../flwr run:1
#, fuzzy
msgid "Path of the Flower App to run."
msgstr "O nome do repositório da imagem base."

#: ../../flwr run:1
msgid "Name of the federation to run the app on."
msgstr ""

#: ../../source/ref-api-cli.rst:19
#, fuzzy
msgid "``flower-superlink``"
msgstr "``FLWR_VERSION``"

#: ../../source/ref-api-cli.rst:29
#, fuzzy
msgid "``flower-supernode``"
msgstr "``FLWR_VERSION``"

#: ../../source/ref-api-cli.rst:37
msgid "Advanced Commands"
msgstr ""

#: ../../source/ref-api-cli.rst:42
#, fuzzy
msgid "``flwr-serverapp``"
msgstr "``FLWR_VERSION``"

#: ../../source/ref-api-cli.rst:52
msgid "``flwr-clientapp``"
msgstr ""

#: ../../source/ref-api-cli.rst:60
msgid "Technical Commands"
msgstr ""

#: ../../source/ref-api-cli.rst:65
#, fuzzy
msgid "``flower-simulation``"
msgstr "``FLWR_VERSION``"

#: ../../source/ref-api-cli.rst:73
msgid "Deprecated Commands"
msgstr ""

#: ../../source/ref-api-cli.rst:78
#, fuzzy
msgid "``flower-server-app``"
msgstr "Clone o repositório do flower."

#: ../../source/ref-api-cli.rst:82
msgid ""
"Note that from version ``1.13.0``, ``flower-server-app`` is deprecated. "
"Instead, you only need to execute |flwr_run_link|_ to start the run."
msgstr ""

#: ../../source/ref-api-cli.rst:88
#, fuzzy
msgid "``flower-superexec``"
msgstr "``FLWR_VERSION``"

#: ../../source/ref-api-cli.rst:92
msgid ""
"Note that from version ``1.13.0``, ``flower-superexec`` is deprecated. "
"Instead, you only need to execute |flower_superlink_link|_."
msgstr ""

#: ../../source/ref-api/flwr.rst:2
msgid "flwr"
msgstr ""

#: ../../source/ref-api/flwr.client.rst:43 ../../source/ref-api/flwr.rst:25
#: ../../source/ref-api/flwr.server.rst:48
msgid "Modules"
msgstr ""

#: ../../source/ref-api/flwr.rst:35:<autosummary>:1
msgid ":py:obj:`flwr.client <flwr.client>`\\"
msgstr ""

#: ../../source/ref-api/flwr.rst:35:<autosummary>:1 flwr.client:1 of
msgid "Flower client."
msgstr ""

#: ../../source/ref-api/flwr.rst:35:<autosummary>:1
msgid ":py:obj:`flwr.common <flwr.common>`\\"
msgstr ""

#: ../../source/ref-api/flwr.rst:35:<autosummary>:1 flwr.common:1 of
msgid "Common components shared between server and client."
msgstr ""

#: ../../source/ref-api/flwr.rst:35:<autosummary>:1
msgid ":py:obj:`flwr.server <flwr.server>`\\"
msgstr ""

#: ../../source/ref-api/flwr.rst:35:<autosummary>:1
#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1 flwr.server:1
#: flwr.server.server.Server:1 of
msgid "Flower server."
msgstr ""

#: ../../source/ref-api/flwr.rst:35:<autosummary>:1
msgid ":py:obj:`flwr.simulation <flwr.simulation>`\\"
msgstr ""

#: ../../source/ref-api/flwr.rst:35:<autosummary>:1 flwr.simulation:1 of
msgid "Flower simulation."
msgstr ""

#: ../../source/ref-api/flwr.client.rst:2
msgid "client"
msgstr ""

#: ../../source/ref-api/flwr.client.mod.rst:13
#: ../../source/ref-api/flwr.client.rst:13
#: ../../source/ref-api/flwr.common.rst:13
#: ../../source/ref-api/flwr.server.rst:13
#: ../../source/ref-api/flwr.simulation.rst:13
msgid "Functions"
msgstr ""

#: ../../source/ref-api/flwr.client.rst:23:<autosummary>:1
msgid ""
":py:obj:`start_client <flwr.client.start_client>`\\ \\(\\*\\, "
"server\\_address\\[\\, client\\_fn\\, ...\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.client.rst:23:<autosummary>:1
#: flwr.client.app.start_client:1 of
msgid "Start a Flower client node which connects to a Flower server."
msgstr ""

#: ../../source/ref-api/flwr.client.rst:23:<autosummary>:1
msgid ""
":py:obj:`start_numpy_client <flwr.client.start_numpy_client>`\\ \\(\\*\\,"
" server\\_address\\, client\\)"
msgstr ""

#: ../../source/ref-api/flwr.client.rst:23:<autosummary>:1
#: flwr.client.app.start_numpy_client:1 of
msgid "Start a Flower NumPyClient which connects to a gRPC server."
msgstr ""

#: ../../source/ref-api/flwr.client.mod.rst:30
#: ../../source/ref-api/flwr.client.rst:25
#: ../../source/ref-api/flwr.common.rst:32
#: ../../source/ref-api/flwr.server.rst:24
#: ../../source/ref-api/flwr.server.strategy.rst:17
#: ../../source/ref-api/flwr.server.workflow.rst:17
#: ../../source/ref-api/flwr.simulation.rst:26
msgid "Classes"
msgstr ""

#: ../../source/ref-api/flwr.client.rst:32:<autosummary>:1
msgid ":py:obj:`Client <flwr.client.Client>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.client.rst:32:<autosummary>:1
#: flwr.client.client.Client:1 of
msgid "Abstract base class for Flower clients."
msgstr ""

#: ../../source/ref-api/flwr.client.rst:32:<autosummary>:1
msgid ""
":py:obj:`ClientApp <flwr.client.ClientApp>`\\ \\(\\[client\\_fn\\, "
"mods\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.client.rst:32:<autosummary>:1
#: flwr.client.client_app.ClientApp:1 of
msgid "Flower ClientApp."
msgstr ""

#: ../../source/ref-api/flwr.client.rst:32:<autosummary>:1
msgid ":py:obj:`NumPyClient <flwr.client.NumPyClient>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.client.rst:32:<autosummary>:1
#: flwr.client.numpy_client.NumPyClient:1 of
msgid "Abstract base class for Flower clients using NumPy."
msgstr ""

#: ../../source/ref-api/flwr.client.rst:50:<autosummary>:1
msgid ":py:obj:`flwr.client.mod <flwr.client.mod>`\\"
msgstr ""

#: ../../source/ref-api/flwr.client.rst:50:<autosummary>:1 flwr.client.mod:1 of
msgid "Flower Built-in Mods."
msgstr ""

#: flwr.client.client.Client:1 flwr.client.numpy_client.NumPyClient:1
#: flwr.server.client_manager.ClientManager:1
#: flwr.server.driver.driver.Driver:1 flwr.server.strategy.strategy.Strategy:1
#: of
msgid "Bases: :py:class:`~abc.ABC`"
msgstr ""

#: ../../source/ref-api/flwr.client.Client.rst:15
#: ../../source/ref-api/flwr.client.ClientApp.rst:15
#: ../../source/ref-api/flwr.client.NumPyClient.rst:15
#: ../../source/ref-api/flwr.client.mod.LocalDpMod.rst:15
#: ../../source/ref-api/flwr.common.Array.rst:15
#: ../../source/ref-api/flwr.common.ClientMessage.rst:15
#: ../../source/ref-api/flwr.common.ConfigsRecord.rst:15
#: ../../source/ref-api/flwr.common.Context.rst:15
#: ../../source/ref-api/flwr.common.DisconnectRes.rst:15
#: ../../source/ref-api/flwr.common.Error.rst:15
#: ../../source/ref-api/flwr.common.EvaluateIns.rst:15
#: ../../source/ref-api/flwr.common.EvaluateRes.rst:15
#: ../../source/ref-api/flwr.common.EventType.rst:15
#: ../../source/ref-api/flwr.common.FitIns.rst:15
#: ../../source/ref-api/flwr.common.FitRes.rst:15
#: ../../source/ref-api/flwr.common.GetParametersIns.rst:15
#: ../../source/ref-api/flwr.common.GetParametersRes.rst:15
#: ../../source/ref-api/flwr.common.GetPropertiesIns.rst:15
#: ../../source/ref-api/flwr.common.GetPropertiesRes.rst:15
#: ../../source/ref-api/flwr.common.Message.rst:15
#: ../../source/ref-api/flwr.common.MessageType.rst:15
#: ../../source/ref-api/flwr.common.MessageTypeLegacy.rst:15
#: ../../source/ref-api/flwr.common.Metadata.rst:15
#: ../../source/ref-api/flwr.common.MetricsRecord.rst:15
#: ../../source/ref-api/flwr.common.Parameters.rst:15
#: ../../source/ref-api/flwr.common.ParametersRecord.rst:15
#: ../../source/ref-api/flwr.common.ReconnectIns.rst:15
#: ../../source/ref-api/flwr.common.RecordSet.rst:15
#: ../../source/ref-api/flwr.common.ServerMessage.rst:15
#: ../../source/ref-api/flwr.common.Status.rst:15
#: ../../source/ref-api/flwr.server.ClientManager.rst:15
#: ../../source/ref-api/flwr.server.Driver.rst:15
#: ../../source/ref-api/flwr.server.History.rst:15
#: ../../source/ref-api/flwr.server.LegacyContext.rst:15
#: ../../source/ref-api/flwr.server.Server.rst:15
#: ../../source/ref-api/flwr.server.ServerApp.rst:15
#: ../../source/ref-api/flwr.server.ServerAppComponents.rst:15
#: ../../source/ref-api/flwr.server.ServerConfig.rst:15
#: ../../source/ref-api/flwr.server.SimpleClientManager.rst:15
#: ../../source/ref-api/flwr.server.strategy.Bulyan.rst:15
#: ../../source/ref-api/flwr.server.strategy.DPFedAvgAdaptive.rst:15
#: ../../source/ref-api/flwr.server.strategy.DPFedAvgFixed.rst:15
#: ../../source/ref-api/flwr.server.strategy.DifferentialPrivacyClientSideAdaptiveClipping.rst:15
#: ../../source/ref-api/flwr.server.strategy.DifferentialPrivacyClientSideFixedClipping.rst:15
#: ../../source/ref-api/flwr.server.strategy.DifferentialPrivacyServerSideAdaptiveClipping.rst:15
#: ../../source/ref-api/flwr.server.strategy.DifferentialPrivacyServerSideFixedClipping.rst:15
#: ../../source/ref-api/flwr.server.strategy.FaultTolerantFedAvg.rst:15
#: ../../source/ref-api/flwr.server.strategy.FedAdagrad.rst:15
#: ../../source/ref-api/flwr.server.strategy.FedAdam.rst:15
#: ../../source/ref-api/flwr.server.strategy.FedAvg.rst:15
#: ../../source/ref-api/flwr.server.strategy.FedAvgAndroid.rst:15
#: ../../source/ref-api/flwr.server.strategy.FedAvgM.rst:15
#: ../../source/ref-api/flwr.server.strategy.FedMedian.rst:15
#: ../../source/ref-api/flwr.server.strategy.FedOpt.rst:15
#: ../../source/ref-api/flwr.server.strategy.FedProx.rst:15
#: ../../source/ref-api/flwr.server.strategy.FedTrimmedAvg.rst:15
#: ../../source/ref-api/flwr.server.strategy.FedXgbBagging.rst:15
#: ../../source/ref-api/flwr.server.strategy.FedXgbCyclic.rst:15
#: ../../source/ref-api/flwr.server.strategy.FedXgbNnAvg.rst:15
#: ../../source/ref-api/flwr.server.strategy.FedYogi.rst:15
#: ../../source/ref-api/flwr.server.strategy.Krum.rst:15
#: ../../source/ref-api/flwr.server.strategy.QFedAvg.rst:15
#: ../../source/ref-api/flwr.server.strategy.Strategy.rst:15
#: ../../source/ref-api/flwr.server.workflow.DefaultWorkflow.rst:15
#: ../../source/ref-api/flwr.server.workflow.SecAggPlusWorkflow.rst:15
#: ../../source/ref-api/flwr.server.workflow.SecAggWorkflow.rst:15
#: ../../source/ref-api/flwr.simulation.SimulationIoConnection.rst:15
msgid "Methods"
msgstr ""

#: ../../source/ref-api/flwr.client.Client.rst:44:<autosummary>:1
msgid ":py:obj:`evaluate <flwr.client.Client.evaluate>`\\ \\(ins\\)"
msgstr ""

#: ../../source/ref-api/flwr.client.Client.rst:44:<autosummary>:1
#: ../../source/ref-api/flwr.client.NumPyClient.rst:44:<autosummary>:1
#: flwr.client.client.Client.evaluate:1
#: flwr.client.numpy_client.NumPyClient.evaluate:1 of
msgid "Evaluate the provided parameters using the locally held dataset."
msgstr ""

#: ../../source/ref-api/flwr.client.Client.rst:44:<autosummary>:1
msgid ":py:obj:`fit <flwr.client.Client.fit>`\\ \\(ins\\)"
msgstr ""

#: ../../source/ref-api/flwr.client.Client.rst:44:<autosummary>:1
#: flwr.client.client.Client.fit:1 of
msgid "Refine the provided parameters using the locally held dataset."
msgstr ""

#: ../../source/ref-api/flwr.client.Client.rst:44:<autosummary>:1
msgid ":py:obj:`get_context <flwr.client.Client.get_context>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.client.Client.rst:44:<autosummary>:1
#: ../../source/ref-api/flwr.client.NumPyClient.rst:44:<autosummary>:1
#: flwr.client.client.Client.get_context:1
#: flwr.client.numpy_client.NumPyClient.get_context:1 of
msgid "Get the run context from this client."
msgstr ""

#: ../../source/ref-api/flwr.client.Client.rst:44:<autosummary>:1
msgid ":py:obj:`get_parameters <flwr.client.Client.get_parameters>`\\ \\(ins\\)"
msgstr ""

#: ../../source/ref-api/flwr.client.Client.rst:44:<autosummary>:1
#: ../../source/ref-api/flwr.client.NumPyClient.rst:44:<autosummary>:1
#: flwr.client.client.Client.get_parameters:1
#: flwr.client.numpy_client.NumPyClient.get_parameters:1 of
msgid "Return the current local model parameters."
msgstr ""

#: ../../source/ref-api/flwr.client.Client.rst:44:<autosummary>:1
msgid ":py:obj:`get_properties <flwr.client.Client.get_properties>`\\ \\(ins\\)"
msgstr ""

#: ../../source/ref-api/flwr.client.Client.rst:44:<autosummary>:1
#: flwr.client.client.Client.get_properties:1 of
msgid "Return set of client's properties."
msgstr ""

#: ../../source/ref-api/flwr.client.Client.rst:44:<autosummary>:1
msgid ":py:obj:`set_context <flwr.client.Client.set_context>`\\ \\(context\\)"
msgstr ""

#: ../../source/ref-api/flwr.client.Client.rst:44:<autosummary>:1
#: ../../source/ref-api/flwr.client.NumPyClient.rst:44:<autosummary>:1
#: flwr.client.client.Client.set_context:1
#: flwr.client.numpy_client.NumPyClient.set_context:1 of
msgid "Apply a run context to this client."
msgstr ""

#: ../../source/ref-api/flwr.client.Client.rst:44:<autosummary>:1
msgid ":py:obj:`to_client <flwr.client.Client.to_client>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.client.Client.rst:44:<autosummary>:1
#: flwr.client.client.Client.to_client:1 of
msgid "Return client (itself)."
msgstr ""

#: ../../source/ref-api/flwr.client.Client.rst:46
#: ../../source/ref-api/flwr.client.NumPyClient.rst:46
#: ../../source/ref-api/flwr.common.Array.rst:28
#: ../../source/ref-api/flwr.common.ClientMessage.rst:25
#: ../../source/ref-api/flwr.common.Code.rst:19
#: ../../source/ref-api/flwr.common.Context.rst:25
#: ../../source/ref-api/flwr.common.DisconnectRes.rst:25
#: ../../source/ref-api/flwr.common.Error.rst:25
#: ../../source/ref-api/flwr.common.EvaluateIns.rst:25
#: ../../source/ref-api/flwr.common.EvaluateRes.rst:25
#: ../../source/ref-api/flwr.common.EventType.rst:165
#: ../../source/ref-api/flwr.common.FitIns.rst:25
#: ../../source/ref-api/flwr.common.FitRes.rst:25
#: ../../source/ref-api/flwr.common.GetParametersIns.rst:25
#: ../../source/ref-api/flwr.common.GetParametersRes.rst:25
#: ../../source/ref-api/flwr.common.GetPropertiesIns.rst:25
#: ../../source/ref-api/flwr.common.GetPropertiesRes.rst:25
#: ../../source/ref-api/flwr.common.Message.rst:37
#: ../../source/ref-api/flwr.common.MessageType.rst:25
#: ../../source/ref-api/flwr.common.MessageTypeLegacy.rst:25
#: ../../source/ref-api/flwr.common.Metadata.rst:25
#: ../../source/ref-api/flwr.common.Parameters.rst:25
#: ../../source/ref-api/flwr.common.ReconnectIns.rst:25
#: ../../source/ref-api/flwr.common.RecordSet.rst:25
#: ../../source/ref-api/flwr.common.ServerMessage.rst:25
#: ../../source/ref-api/flwr.common.Status.rst:25
#: ../../source/ref-api/flwr.server.Driver.rst:43
#: ../../source/ref-api/flwr.server.LegacyContext.rst:25
#: ../../source/ref-api/flwr.server.ServerAppComponents.rst:25
#: ../../source/ref-api/flwr.server.ServerConfig.rst:25
msgid "Attributes"
msgstr ""

#: flwr.client.Client.context:1:<autosummary>:1 of
msgid ":py:obj:`context <flwr.client.Client.context>`\\"
msgstr ""

#: flwr.client.Client.context:1 flwr.client.Client.context:1:<autosummary>:1
#: flwr.client.NumPyClient.context:1
#: flwr.client.NumPyClient.context:1:<autosummary>:1 of
msgid "Getter for `Context` client attribute."
msgstr ""

#: ../../source/ref-api/flwr.common.Parameters.rst:2
#: flwr.client.app.start_client flwr.client.app.start_numpy_client
#: flwr.client.client.Client.evaluate flwr.client.client.Client.fit
#: flwr.client.client.Client.get_parameters
#: flwr.client.client.Client.get_properties
#: flwr.client.mod.localdp_mod.LocalDpMod
#: flwr.client.numpy_client.NumPyClient.evaluate
#: flwr.client.numpy_client.NumPyClient.fit
#: flwr.client.numpy_client.NumPyClient.get_parameters
#: flwr.client.numpy_client.NumPyClient.get_properties
#: flwr.common.context.Context flwr.common.message.Error
#: flwr.common.message.Message flwr.common.message.Message.create_error_reply
#: flwr.common.message.Message.create_reply flwr.common.message.Metadata
#: flwr.common.record.configsrecord.ConfigsRecord
#: flwr.common.record.metricsrecord.MetricsRecord
#: flwr.common.record.parametersrecord.Array
#: flwr.common.record.parametersrecord.ParametersRecord
#: flwr.common.record.recordset.RecordSet flwr.server.app.start_server
#: flwr.server.client_manager.ClientManager.register
#: flwr.server.client_manager.ClientManager.unregister
#: flwr.server.client_manager.SimpleClientManager.register
#: flwr.server.client_manager.SimpleClientManager.unregister
#: flwr.server.client_manager.SimpleClientManager.wait_for
#: flwr.server.driver.driver.Driver.create_message
#: flwr.server.driver.driver.Driver.pull_messages
#: flwr.server.driver.driver.Driver.push_messages
#: flwr.server.driver.driver.Driver.send_and_receive
#: flwr.server.driver.driver.Driver.set_run
#: flwr.server.serverapp_components.ServerAppComponents
#: flwr.server.strategy.bulyan.Bulyan
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_evaluate
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_fit
#: flwr.server.strategy.fedadagrad.FedAdagrad
#: flwr.server.strategy.fedadam.FedAdam flwr.server.strategy.fedavg.FedAvg
#: flwr.server.strategy.fedavg_android.FedAvgAndroid
#: flwr.server.strategy.fedavgm.FedAvgM flwr.server.strategy.fedopt.FedOpt
#: flwr.server.strategy.fedprox.FedProx
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg
#: flwr.server.strategy.fedyogi.FedYogi flwr.server.strategy.krum.Krum
#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate
#: flwr.server.strategy.strategy.Strategy.aggregate_fit
#: flwr.server.strategy.strategy.Strategy.configure_evaluate
#: flwr.server.strategy.strategy.Strategy.configure_fit
#: flwr.server.strategy.strategy.Strategy.evaluate
#: flwr.server.strategy.strategy.Strategy.initialize_parameters
#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow
#: flwr.simulation.run_simulation.run_simulation
#: flwr.simulation.simulationio_connection.SimulationIoConnection of
msgid "Parameters"
msgstr ""

#: flwr.client.client.Client.evaluate:3 of
msgid ""
"The evaluation instructions containing (global) model parameters received"
" from the server and a dictionary of configuration values used to "
"customize the local evaluation process."
msgstr ""

#: flwr.client.client.Client.evaluate flwr.client.client.Client.fit
#: flwr.client.client.Client.get_parameters
#: flwr.client.client.Client.get_properties
#: flwr.client.numpy_client.NumPyClient.evaluate
#: flwr.client.numpy_client.NumPyClient.fit
#: flwr.client.numpy_client.NumPyClient.get_parameters
#: flwr.client.numpy_client.NumPyClient.get_properties
#: flwr.common.message.Message.create_error_reply
#: flwr.common.message.Message.create_reply flwr.server.app.start_server
#: flwr.server.client_manager.ClientManager.num_available
#: flwr.server.client_manager.ClientManager.register
#: flwr.server.client_manager.SimpleClientManager.num_available
#: flwr.server.client_manager.SimpleClientManager.register
#: flwr.server.client_manager.SimpleClientManager.wait_for
#: flwr.server.driver.driver.Driver.create_message
#: flwr.server.driver.driver.Driver.pull_messages
#: flwr.server.driver.driver.Driver.push_messages
#: flwr.server.driver.driver.Driver.send_and_receive
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_evaluate
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_fit
#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate
#: flwr.server.strategy.strategy.Strategy.aggregate_fit
#: flwr.server.strategy.strategy.Strategy.configure_evaluate
#: flwr.server.strategy.strategy.Strategy.configure_fit
#: flwr.server.strategy.strategy.Strategy.evaluate
#: flwr.server.strategy.strategy.Strategy.initialize_parameters of
msgid "Returns"
msgstr ""

#: flwr.client.client.Client.evaluate:8 of
msgid ""
"The evaluation result containing the loss on the local dataset and other "
"details such as the number of local data examples used for evaluation."
msgstr ""

#: flwr.client.client.Client.evaluate flwr.client.client.Client.fit
#: flwr.client.client.Client.get_parameters
#: flwr.client.client.Client.get_properties
#: flwr.client.numpy_client.NumPyClient.get_parameters
#: flwr.client.numpy_client.NumPyClient.get_properties
#: flwr.common.message.Message.create_error_reply
#: flwr.common.message.Message.create_reply flwr.server.app.start_server
#: flwr.server.client_manager.ClientManager.num_available
#: flwr.server.client_manager.ClientManager.register
#: flwr.server.client_manager.SimpleClientManager.num_available
#: flwr.server.client_manager.SimpleClientManager.register
#: flwr.server.client_manager.SimpleClientManager.wait_for
#: flwr.server.driver.driver.Driver.create_message
#: flwr.server.driver.driver.Driver.pull_messages
#: flwr.server.driver.driver.Driver.push_messages
#: flwr.server.driver.driver.Driver.send_and_receive
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_evaluate
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_fit
#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate
#: flwr.server.strategy.strategy.Strategy.aggregate_fit
#: flwr.server.strategy.strategy.Strategy.configure_evaluate
#: flwr.server.strategy.strategy.Strategy.configure_fit
#: flwr.server.strategy.strategy.Strategy.evaluate
#: flwr.server.strategy.strategy.Strategy.initialize_parameters of
msgid "Return type"
msgstr ""

#: flwr.client.client.Client.fit:3 of
msgid ""
"The training instructions containing (global) model parameters received "
"from the server and a dictionary of configuration values used to "
"customize the local training process."
msgstr ""

#: flwr.client.client.Client.fit:8 of
msgid ""
"The training result containing updated parameters and other details such "
"as the number of local training examples used for training."
msgstr ""

#: flwr.client.client.Client.get_parameters:3 of
msgid ""
"The get parameters instructions received from the server containing a "
"dictionary of configuration values."
msgstr ""

#: flwr.client.client.Client.get_parameters:7 of
msgid "The current local model parameters."
msgstr ""

#: flwr.client.client.Client.get_properties:3 of
msgid ""
"The get properties instructions received from the server containing a "
"dictionary of configuration values."
msgstr ""

#: flwr.client.client.Client.get_properties:7 of
msgid "The current client properties."
msgstr ""

#: flwr.client.client_app.ClientApp:1 flwr.client.mod.localdp_mod.LocalDpMod:1
#: flwr.common.constant.MessageType:1 flwr.common.constant.MessageTypeLegacy:1
#: flwr.common.context.Context:1 flwr.common.message.Error:1
#: flwr.common.message.Message:1 flwr.common.message.Metadata:1
#: flwr.common.record.parametersrecord.Array:1
#: flwr.common.record.recordset.RecordSet:1 flwr.common.typing.ClientMessage:1
#: flwr.common.typing.DisconnectRes:1 flwr.common.typing.EvaluateIns:1
#: flwr.common.typing.EvaluateRes:1 flwr.common.typing.FitIns:1
#: flwr.common.typing.FitRes:1 flwr.common.typing.GetParametersIns:1
#: flwr.common.typing.GetParametersRes:1 flwr.common.typing.GetPropertiesIns:1
#: flwr.common.typing.GetPropertiesRes:1 flwr.common.typing.Parameters:1
#: flwr.common.typing.ReconnectIns:1 flwr.common.typing.ServerMessage:1
#: flwr.common.typing.Status:1 flwr.server.history.History:1
#: flwr.server.server.Server:1 flwr.server.server_app.ServerApp:1
#: flwr.server.server_config.ServerConfig:1
#: flwr.server.serverapp_components.ServerAppComponents:1
#: flwr.server.workflow.default_workflows.DefaultWorkflow:1
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:1
#: flwr.simulation.simulationio_connection.SimulationIoConnection:1 of
msgid "Bases: :py:class:`object`"
msgstr ""

#: flwr.client.app.start_client:51 flwr.client.app.start_numpy_client:36
#: flwr.client.client_app.ClientApp:4
#: flwr.client.client_app.ClientApp.evaluate:4
#: flwr.client.client_app.ClientApp.query:4
#: flwr.client.client_app.ClientApp.train:4
#: flwr.client.mod.localdp_mod.LocalDpMod:22
#: flwr.common.record.configsrecord.ConfigsRecord:20
#: flwr.common.record.metricsrecord.MetricsRecord:19
#: flwr.common.record.parametersrecord.ParametersRecord:22
#: flwr.common.record.recordset.RecordSet:23 flwr.server.app.start_server:46
#: flwr.server.server_app.ServerApp:4 flwr.server.server_app.ServerApp.main:4
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping:29
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping:22
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping:21
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping:14
#: of
msgid "Examples"
msgstr ""

#: flwr.client.client_app.ClientApp:5 of
msgid ""
"Assuming a typical `Client` implementation named `FlowerClient`, you can "
"wrap it in a `ClientApp` as follows:"
msgstr ""

#: flwr.client.client_app.ClientApp:16 of
msgid ""
"If the above code is in a Python module called `client`, it can be "
"started as follows:"
msgstr ""

#: flwr.client.client_app.ClientApp:21 of
msgid ""
"In this `client:app` example, `client` refers to the Python module "
"`client.py` in which the previous code lives in and `app` refers to the "
"global attribute `app` that points to an object of type `ClientApp`."
msgstr ""

#: flwr.client.client_app.ClientApp.evaluate:1:<autosummary>:1 of
msgid ":py:obj:`evaluate <flwr.client.ClientApp.evaluate>`\\ \\(\\)"
msgstr ""

#: flwr.client.client_app.ClientApp.evaluate:1
#: flwr.client.client_app.ClientApp.evaluate:1:<autosummary>:1 of
msgid "Return a decorator that registers the evaluate fn with the client app."
msgstr ""

#: flwr.client.client_app.ClientApp.evaluate:1:<autosummary>:1 of
msgid ":py:obj:`query <flwr.client.ClientApp.query>`\\ \\(\\)"
msgstr ""

#: flwr.client.client_app.ClientApp.evaluate:1:<autosummary>:1
#: flwr.client.client_app.ClientApp.query:1 of
msgid "Return a decorator that registers the query fn with the client app."
msgstr ""

#: flwr.client.client_app.ClientApp.evaluate:1:<autosummary>:1 of
msgid ":py:obj:`train <flwr.client.ClientApp.train>`\\ \\(\\)"
msgstr ""

#: flwr.client.client_app.ClientApp.evaluate:1:<autosummary>:1
#: flwr.client.client_app.ClientApp.train:1 of
msgid "Return a decorator that registers the train fn with the client app."
msgstr ""

#: ../../source/ref-api/flwr.client.NumPyClient.rst:2
msgid "NumPyClient"
msgstr ""

#: ../../source/ref-api/flwr.client.NumPyClient.rst:44:<autosummary>:1
msgid ""
":py:obj:`evaluate <flwr.client.NumPyClient.evaluate>`\\ \\(parameters\\, "
"config\\)"
msgstr ""

#: ../../source/ref-api/flwr.client.NumPyClient.rst:44:<autosummary>:1
msgid ":py:obj:`fit <flwr.client.NumPyClient.fit>`\\ \\(parameters\\, config\\)"
msgstr ""

#: ../../source/ref-api/flwr.client.NumPyClient.rst:44:<autosummary>:1
#: flwr.client.numpy_client.NumPyClient.fit:1 of
msgid "Train the provided parameters using the locally held dataset."
msgstr ""

#: ../../source/ref-api/flwr.client.NumPyClient.rst:44:<autosummary>:1
msgid ":py:obj:`get_context <flwr.client.NumPyClient.get_context>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.client.NumPyClient.rst:44:<autosummary>:1
msgid ""
":py:obj:`get_parameters <flwr.client.NumPyClient.get_parameters>`\\ "
"\\(config\\)"
msgstr ""

#: ../../source/ref-api/flwr.client.NumPyClient.rst:44:<autosummary>:1
msgid ""
":py:obj:`get_properties <flwr.client.NumPyClient.get_properties>`\\ "
"\\(config\\)"
msgstr ""

#: ../../source/ref-api/flwr.client.NumPyClient.rst:44:<autosummary>:1
#: flwr.client.numpy_client.NumPyClient.get_properties:1 of
msgid "Return a client's set of properties."
msgstr ""

#: ../../source/ref-api/flwr.client.NumPyClient.rst:44:<autosummary>:1
msgid ""
":py:obj:`set_context <flwr.client.NumPyClient.set_context>`\\ "
"\\(context\\)"
msgstr ""

#: ../../source/ref-api/flwr.client.NumPyClient.rst:44:<autosummary>:1
msgid ":py:obj:`to_client <flwr.client.NumPyClient.to_client>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.client.NumPyClient.rst:44:<autosummary>:1
#: flwr.client.numpy_client.NumPyClient.to_client:1 of
msgid "Convert to object to Client type and return it."
msgstr ""

#: flwr.client.NumPyClient.context:1:<autosummary>:1 of
msgid ":py:obj:`context <flwr.client.NumPyClient.context>`\\"
msgstr ""

#: flwr.client.numpy_client.NumPyClient.evaluate:3
#: flwr.client.numpy_client.NumPyClient.fit:3
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_evaluate:5
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_fit:8
#: flwr.server.strategy.strategy.Strategy.configure_evaluate:5
#: flwr.server.strategy.strategy.Strategy.configure_fit:5
#: flwr.server.strategy.strategy.Strategy.evaluate:8 of
msgid "The current (global) model parameters."
msgstr ""

#: flwr.client.numpy_client.NumPyClient.evaluate:5 of
msgid ""
"Configuration parameters which allow the server to influence evaluation "
"on the client. It can be used to communicate arbitrary values from the "
"server to the client, for example, to influence the number of examples "
"used for evaluation."
msgstr ""

#: flwr.client.numpy_client.NumPyClient.evaluate:11 of
msgid ""
"* **loss** (*float*) -- The evaluation loss of the model on the local "
"dataset. * **num_examples** (*int*) -- The number of examples used for "
"evaluation. * **metrics** (*Dict[str, Scalar]*) -- A dictionary mapping "
"arbitrary string keys to values of   type bool, bytes, float, int, or "
"str. It can be used to   communicate arbitrary values back to the server."
msgstr ""

#: flwr.client.numpy_client.NumPyClient.evaluate:11 of
msgid ""
"**loss** (*float*) -- The evaluation loss of the model on the local "
"dataset."
msgstr ""

#: flwr.client.numpy_client.NumPyClient.evaluate:12 of
msgid "**num_examples** (*int*) -- The number of examples used for evaluation."
msgstr ""

#: flwr.client.numpy_client.NumPyClient.evaluate:13
#: flwr.client.numpy_client.NumPyClient.fit:13 of
msgid ""
"**metrics** (*Dict[str, Scalar]*) -- A dictionary mapping arbitrary "
"string keys to values of type bool, bytes, float, int, or str. It can be "
"used to communicate arbitrary values back to the server."
msgstr ""

#: flwr.client.numpy_client.NumPyClient.evaluate:19 of
msgid ""
"The previous return type format (int, float, float) and the extended "
"format (int, float, float, Dict[str, Scalar]) have been deprecated and "
"removed since Flower 0.19."
msgstr ""

#: flwr.client.numpy_client.NumPyClient.fit:5 of
msgid ""
"Configuration parameters which allow the server to influence training on "
"the client. It can be used to communicate arbitrary values from the "
"server to the client, for example, to set the number of (local) training "
"epochs."
msgstr ""

#: flwr.client.numpy_client.NumPyClient.fit:11 of
msgid ""
"* **parameters** (*NDArrays*) -- The locally updated model parameters. * "
"**num_examples** (*int*) -- The number of examples used for training. * "
"**metrics** (*Dict[str, Scalar]*) -- A dictionary mapping arbitrary "
"string keys to values of type   bool, bytes, float, int, or str. It can "
"be used to communicate   arbitrary values back to the server."
msgstr ""

#: flwr.client.numpy_client.NumPyClient.fit:11 of
msgid "**parameters** (*NDArrays*) -- The locally updated model parameters."
msgstr ""

#: flwr.client.numpy_client.NumPyClient.fit:12 of
msgid "**num_examples** (*int*) -- The number of examples used for training."
msgstr ""

#: flwr.client.numpy_client.NumPyClient.get_parameters:3 of
msgid ""
"Configuration parameters requested by the server. This can be used to "
"tell the client which parameters are needed along with some Scalar "
"attributes."
msgstr ""

#: flwr.client.numpy_client.NumPyClient.get_parameters:8 of
msgid "**parameters** -- The local model parameters as a list of NumPy ndarrays."
msgstr ""

#: flwr.client.numpy_client.NumPyClient.get_properties:3 of
msgid ""
"Configuration parameters requested by the server. This can be used to "
"tell the client which properties are needed along with some Scalar "
"attributes."
msgstr ""

#: flwr.client.numpy_client.NumPyClient.get_properties:8 of
msgid ""
"**properties** -- A dictionary mapping arbitrary string keys to values of"
" type bool, bytes, float, int, or str. It can be used to communicate "
"arbitrary property values back to the server."
msgstr ""

#: ../../source/ref-api/flwr.client.mod.rst:2
msgid "mod"
msgstr ""

#: ../../source/ref-api/flwr.client.mod.rst:28:<autosummary>:1
msgid ""
":py:obj:`adaptiveclipping_mod <flwr.client.mod.adaptiveclipping_mod>`\\ "
"\\(msg\\, ctxt\\, call\\_next\\)"
msgstr ""

#: ../../source/ref-api/flwr.client.mod.rst:28:<autosummary>:1
#: flwr.client.mod.centraldp_mods.adaptiveclipping_mod:1 of
msgid "Client-side adaptive clipping modifier."
msgstr ""

#: ../../source/ref-api/flwr.client.mod.rst:28:<autosummary>:1
msgid ""
":py:obj:`fixedclipping_mod <flwr.client.mod.fixedclipping_mod>`\\ "
"\\(msg\\, ctxt\\, call\\_next\\)"
msgstr ""

#: ../../source/ref-api/flwr.client.mod.rst:28:<autosummary>:1
#: flwr.client.mod.centraldp_mods.fixedclipping_mod:1 of
msgid "Client-side fixed clipping modifier."
msgstr ""

#: ../../source/ref-api/flwr.client.mod.rst:28:<autosummary>:1
msgid ":py:obj:`make_ffn <flwr.client.mod.make_ffn>`\\ \\(ffn\\, mods\\)"
msgstr ""

#: ../../source/ref-api/flwr.client.mod.rst:28:<autosummary>:1
#: flwr.client.mod.utils.make_ffn:1 of
msgid "."
msgstr ""

#: ../../source/ref-api/flwr.client.mod.rst:28:<autosummary>:1
msgid ""
":py:obj:`message_size_mod <flwr.client.mod.message_size_mod>`\\ \\(msg\\,"
" ctxt\\, call\\_next\\)"
msgstr ""

#: ../../source/ref-api/flwr.client.mod.rst:28:<autosummary>:1
#: flwr.client.mod.comms_mods.message_size_mod:1 of
msgid "Message size mod."
msgstr ""

#: ../../source/ref-api/flwr.client.mod.rst:28:<autosummary>:1
msgid ""
":py:obj:`parameters_size_mod <flwr.client.mod.parameters_size_mod>`\\ "
"\\(msg\\, ctxt\\, call\\_next\\)"
msgstr ""

#: ../../source/ref-api/flwr.client.mod.rst:28:<autosummary>:1
#: flwr.client.mod.comms_mods.parameters_size_mod:1 of
msgid "Parameters size mod."
msgstr ""

#: ../../source/ref-api/flwr.client.mod.rst:28:<autosummary>:1
msgid ""
":py:obj:`secagg_mod <flwr.client.mod.secagg_mod>`\\ \\(msg\\, ctxt\\, "
"call\\_next\\)"
msgstr ""

#: ../../source/ref-api/flwr.client.mod.rst:28:<autosummary>:1
#: flwr.client.mod.secure_aggregation.secagg_mod.secagg_mod:1 of
msgid "Handle incoming message and return results, following the SecAgg protocol."
msgstr ""

#: ../../source/ref-api/flwr.client.mod.rst:28:<autosummary>:1
msgid ""
":py:obj:`secaggplus_mod <flwr.client.mod.secaggplus_mod>`\\ \\(msg\\, "
"ctxt\\, call\\_next\\)"
msgstr ""

#: ../../source/ref-api/flwr.client.mod.rst:28:<autosummary>:1
#: flwr.client.mod.secure_aggregation.secaggplus_mod.secaggplus_mod:1 of
msgid ""
"Handle incoming message and return results, following the SecAgg+ "
"protocol."
msgstr ""

#: ../../source/ref-api/flwr.client.mod.rst:35:<autosummary>:1
msgid ""
":py:obj:`LocalDpMod <flwr.client.mod.LocalDpMod>`\\ \\(clipping\\_norm\\,"
" sensitivity\\, ...\\)"
msgstr ""

#: ../../source/ref-api/flwr.client.mod.rst:35:<autosummary>:1
#: flwr.client.mod.localdp_mod.LocalDpMod:1 of
msgid "Modifier for local differential privacy."
msgstr ""

#: ../../source/ref-api/flwr.client.mod.LocalDpMod.rst:2
msgid "LocalDpMod"
msgstr ""

#: flwr.client.mod.localdp_mod.LocalDpMod:3 of
msgid ""
"This mod clips the client model updates and adds noise to the params "
"before sending them to the server."
msgstr ""

#: flwr.client.mod.centraldp_mods.adaptiveclipping_mod:12
#: flwr.client.mod.centraldp_mods.fixedclipping_mod:10
#: flwr.client.mod.localdp_mod.LocalDpMod:6 of
msgid "It operates on messages of type `MessageType.TRAIN`."
msgstr ""

#: flwr.client.mod.localdp_mod.LocalDpMod:8
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping:15
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping:8
#: of
msgid "The value of the clipping norm."
msgstr ""

#: flwr.client.mod.localdp_mod.LocalDpMod:10 of
msgid "The sensitivity of the client model."
msgstr ""

#: flwr.client.mod.localdp_mod.LocalDpMod:12 of
msgid ""
"The privacy budget. Smaller value of epsilon indicates a higher level of "
"privacy protection."
msgstr ""

#: flwr.client.mod.localdp_mod.LocalDpMod:15 of
msgid ""
"The failure probability. The probability that the privacy mechanism fails"
" to provide the desired level of privacy. A smaller value of delta "
"indicates a stricter privacy guarantee."
msgstr ""

#: flwr.client.mod.localdp_mod.LocalDpMod:23 of
msgid "Create an instance of the local DP mod and add it to the client-side mods:"
msgstr ""

#: ../../source/ref-api/flwr.client.mod.adaptiveclipping_mod.rst:2
msgid "adaptiveclipping\\_mod"
msgstr ""

#: flwr.client.mod.centraldp_mods.adaptiveclipping_mod:3 of
msgid ""
"This mod needs to be used with the "
"DifferentialPrivacyClientSideAdaptiveClipping server-side strategy "
"wrapper."
msgstr ""

#: flwr.client.mod.centraldp_mods.adaptiveclipping_mod:6
#: flwr.client.mod.centraldp_mods.fixedclipping_mod:6 of
msgid "The wrapper sends the clipping_norm value to the client."
msgstr ""

#: flwr.client.mod.centraldp_mods.adaptiveclipping_mod:8
#: flwr.client.mod.centraldp_mods.fixedclipping_mod:8 of
msgid "This mod clips the client model updates before sending them to the server."
msgstr ""

#: flwr.client.mod.centraldp_mods.adaptiveclipping_mod:10 of
msgid ""
"It also sends KEY_NORM_BIT to the server for computing the new clipping "
"value."
msgstr ""

#: flwr.client.mod.centraldp_mods.adaptiveclipping_mod:15
#: flwr.client.mod.centraldp_mods.fixedclipping_mod:13
#: flwr.server.driver.driver.Driver.send_and_receive:18
#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:54
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:61
#: of
msgid "Notes"
msgstr ""

#: flwr.client.mod.centraldp_mods.adaptiveclipping_mod:16
#: flwr.client.mod.centraldp_mods.fixedclipping_mod:14 of
msgid "Consider the order of mods when using multiple."
msgstr ""

#: flwr.client.mod.centraldp_mods.adaptiveclipping_mod:18 of
msgid "Typically, adaptiveclipping_mod should be the last to operate on params."
msgstr ""

#: ../../source/ref-api/flwr.client.mod.fixedclipping_mod.rst:2
msgid "fixedclipping\\_mod"
msgstr ""

#: flwr.client.mod.centraldp_mods.fixedclipping_mod:3 of
msgid ""
"This mod needs to be used with the "
"DifferentialPrivacyClientSideFixedClipping server-side strategy wrapper."
msgstr ""

#: flwr.client.mod.centraldp_mods.fixedclipping_mod:16 of
msgid "Typically, fixedclipping_mod should be the last to operate on params."
msgstr ""

#: ../../source/ref-api/flwr.client.mod.make_ffn.rst:2
msgid "make\\_ffn"
msgstr ""

#: ../../source/ref-api/flwr.client.mod.message_size_mod.rst:2
msgid "message\\_size\\_mod"
msgstr ""

#: flwr.client.mod.comms_mods.message_size_mod:3 of
msgid "This mod logs the size in bytes of the message being transmited."
msgstr ""

#: ../../source/ref-api/flwr.client.mod.parameters_size_mod.rst:2
msgid "parameters\\_size\\_mod"
msgstr ""

#: flwr.client.mod.comms_mods.parameters_size_mod:3 of
msgid ""
"This mod logs the number of parameters transmitted in the message as well"
" as their size in bytes."
msgstr ""

#: ../../source/ref-api/flwr.client.mod.secagg_mod.rst:2
msgid "secagg\\_mod"
msgstr ""

#: ../../source/ref-api/flwr.client.mod.secaggplus_mod.rst:2
msgid "secaggplus\\_mod"
msgstr ""

#: ../../source/ref-api/flwr.client.start_client.rst:2
msgid "start\\_client"
msgstr ""

#: flwr.client.app.start_client:5 of
msgid ""
"This function is deprecated since 1.13.0. Use :code:`flower-supernode` "
"command instead to start a SuperNode."
msgstr ""

#: flwr.client.app.start_client:8 flwr.client.app.start_numpy_client:9 of
msgid ""
"The IPv4 or IPv6 address of the server. If the Flower server runs on the "
"same machine on port 8080, then `server_address` would be "
"`\"[::]:8080\"`."
msgstr ""

#: flwr.client.app.start_client:12 of
msgid "A callable that instantiates a Client. (default: None)"
msgstr ""

#: flwr.client.app.start_client:14 of
msgid ""
"An implementation of the abstract base class `flwr.client.Client` "
"(default: None)"
msgstr ""

#: flwr.client.app.start_client:17 flwr.client.app.start_numpy_client:15 of
msgid ""
"The maximum length of gRPC messages that can be exchanged with the Flower"
" server. The default should be sufficient for most models. Users who "
"train very large models might need to increase this value. Note that the "
"Flower server needs to be started with the same value (see "
"`flwr.server.start_server`), otherwise it will not know about the "
"increased limit and block larger messages."
msgstr ""

#: flwr.client.app.start_client:24 flwr.client.app.start_numpy_client:22 of
msgid ""
"The PEM-encoded root certificates as a byte string or a path string. If "
"provided, a secure connection using the certificates will be established "
"to an SSL-enabled Flower server."
msgstr ""

#: flwr.client.app.start_client:28 flwr.client.app.start_numpy_client:26 of
msgid ""
"Starts an insecure gRPC connection when True. Enables HTTPS connection "
"when False, using system certificates if `root_certificates` is None."
msgstr ""

#: flwr.client.app.start_client:31 flwr.client.app.start_numpy_client:29 of
msgid ""
"Configure the transport layer. Allowed values: - 'grpc-bidi': gRPC, "
"bidirectional streaming - 'grpc-rere': gRPC, request-response "
"(experimental) - 'rest': HTTP (experimental)"
msgstr ""

#: flwr.client.app.start_client:36 of
msgid ""
"Tuple containing the elliptic curve private key and public key for "
"authentication from the cryptography library. Source: "
"https://cryptography.io/en/latest/hazmat/primitives/asymmetric/ec/ Used "
"to establish an authenticated connection with the server."
msgstr ""

#: flwr.client.app.start_client:41 of
msgid ""
"The maximum number of times the client will try to connect to the server "
"before giving up in case of a connection error. If set to None, there is "
"no limit to the number of tries."
msgstr ""

#: flwr.client.app.start_client:45 of
msgid ""
"The maximum duration before the client stops trying to connect to the "
"server in case of connection error. If set to None, there is no limit to "
"the total time."
msgstr ""

#: flwr.client.app.start_client:52 flwr.client.app.start_numpy_client:37 of
msgid "Starting a gRPC client with an insecure server connection:"
msgstr ""

#: flwr.client.app.start_client:59 flwr.client.app.start_numpy_client:44 of
msgid "Starting an SSL-enabled gRPC client using system certificates:"
msgstr ""

#: flwr.client.app.start_client:70 flwr.client.app.start_numpy_client:52 of
msgid "Starting an SSL-enabled gRPC client using provided certificates:"
msgstr ""

#: ../../source/ref-api/flwr.client.start_numpy_client.rst:2
msgid "start\\_numpy\\_client"
msgstr ""

#: flwr.client.app.start_numpy_client:5 of
msgid ""
"This function is deprecated since 1.7.0. Use "
":code:`flwr.client.start_client` instead and first convert your "
":code:`NumPyClient` to type :code:`flwr.client.Client` by executing its "
":code:`to_client()` method."
msgstr ""

#: flwr.client.app.start_numpy_client:13 of
msgid "An implementation of the abstract base class `flwr.client.NumPyClient`."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:2
msgid "common"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
msgid ":py:obj:`array_from_numpy <flwr.common.array_from_numpy>`\\ \\(ndarray\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
#: flwr.common.record.conversion_utils.array_from_numpy:1 of
msgid "Create Array from NumPy ndarray."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
msgid ":py:obj:`bytes_to_ndarray <flwr.common.bytes_to_ndarray>`\\ \\(tensor\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
#: flwr.common.parameter.bytes_to_ndarray:1 of
msgid "Deserialize NumPy ndarray from bytes."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
msgid ""
":py:obj:`configure <flwr.common.configure>`\\ \\(identifier\\[\\, "
"filename\\, host\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
#: flwr.common.logger.configure:1 of
msgid "Configure logging to file and/or remote log server."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
msgid ""
":py:obj:`event <flwr.common.event>`\\ \\(event\\_type\\[\\, "
"event\\_details\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
#: flwr.common.telemetry.event:1 of
msgid "Submit create_event to ThreadPoolExecutor to avoid blocking."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
msgid ""
":py:obj:`log <flwr.common.log>`\\ \\(level\\, msg\\, \\*args\\, "
"\\*\\*kwargs\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1 logging.Logger.log:1
#: of
msgid "Log 'msg % args' with the integer severity 'level'."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
msgid ":py:obj:`ndarray_to_bytes <flwr.common.ndarray_to_bytes>`\\ \\(ndarray\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
#: flwr.common.parameter.ndarray_to_bytes:1 of
msgid "Serialize NumPy ndarray to bytes."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
msgid ""
":py:obj:`ndarrays_to_parameters <flwr.common.ndarrays_to_parameters>`\\ "
"\\(ndarrays\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
#: flwr.common.parameter.ndarrays_to_parameters:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.ndarrays_to_parameters:1
#: of
msgid "Convert NumPy ndarrays to parameters object."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
msgid ":py:obj:`now <flwr.common.now>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
#: flwr.common.date.now:1 of
msgid "Construct a datetime from time.time() with time zone set to UTC."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
msgid ""
":py:obj:`parameters_to_ndarrays <flwr.common.parameters_to_ndarrays>`\\ "
"\\(parameters\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
#: flwr.common.parameter.parameters_to_ndarrays:1 of
msgid "Convert parameters object to NumPy ndarrays."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ""
":py:obj:`Array <flwr.common.Array>`\\ \\(dtype\\, shape\\, stype\\, "
"data\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.record.parametersrecord.Array:1 of
msgid "Array type."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ""
":py:obj:`ClientMessage <flwr.common.ClientMessage>`\\ "
"\\(\\[get\\_properties\\_res\\, ...\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.typing.ClientMessage:1 of
msgid "ClientMessage is a container used to hold one result message."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ":py:obj:`Code <flwr.common.Code>`\\ \\(value\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.typing.Code:1 of
msgid "Client status codes."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ":py:obj:`Config <flwr.common.Config>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ""
"alias of :py:class:`dict`\\ [:py:class:`str`, :py:class:`bool` | "
":py:class:`bytes` | :py:class:`float` | :py:class:`int` | "
":py:class:`str`]"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ""
":py:obj:`ConfigsRecord <flwr.common.ConfigsRecord>`\\ "
"\\(\\[configs\\_dict\\, keep\\_input\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.record.configsrecord.ConfigsRecord:1 of
msgid "Configs record."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ""
":py:obj:`Context <flwr.common.Context>`\\ \\(run\\_id\\, node\\_id\\, "
"node\\_config\\, state\\, ...\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.context.Context:1 of
msgid "Context of your run."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ":py:obj:`DisconnectRes <flwr.common.DisconnectRes>`\\ \\(reason\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.typing.DisconnectRes:1 of
msgid "DisconnectRes message from client to server."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ":py:obj:`Error <flwr.common.Error>`\\ \\(code\\[\\, reason\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.message.Error:1 of
msgid "A dataclass that stores information about an error that occurred."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ""
":py:obj:`EvaluateIns <flwr.common.EvaluateIns>`\\ \\(parameters\\, "
"config\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.typing.EvaluateIns:1 of
msgid "Evaluate instructions for a client."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ""
":py:obj:`EvaluateRes <flwr.common.EvaluateRes>`\\ \\(status\\, loss\\, "
"num\\_examples\\, metrics\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.typing.EvaluateRes:1 of
msgid "Evaluate response from a client."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ":py:obj:`EventType <flwr.common.EventType>`\\ \\(value\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.telemetry.EventType:1 of
msgid "Types of telemetry events."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ":py:obj:`FitIns <flwr.common.FitIns>`\\ \\(parameters\\, config\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.typing.FitIns:1 of
msgid "Fit instructions for a client."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ""
":py:obj:`FitRes <flwr.common.FitRes>`\\ \\(status\\, parameters\\, "
"num\\_examples\\, metrics\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.typing.FitRes:1 of
msgid "Fit response from a client."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ":py:obj:`GetParametersIns <flwr.common.GetParametersIns>`\\ \\(config\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.typing.GetParametersIns:1 of
msgid "Parameters request for a client."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ""
":py:obj:`GetParametersRes <flwr.common.GetParametersRes>`\\ \\(status\\, "
"parameters\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.typing.GetParametersRes:1 of
msgid "Response when asked to return parameters."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ":py:obj:`GetPropertiesIns <flwr.common.GetPropertiesIns>`\\ \\(config\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.typing.GetPropertiesIns:1 of
msgid "Properties request for a client."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ""
":py:obj:`GetPropertiesRes <flwr.common.GetPropertiesRes>`\\ \\(status\\, "
"properties\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.typing.GetPropertiesRes:1 of
msgid "Properties response from a client."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ""
":py:obj:`Message <flwr.common.Message>`\\ \\(metadata\\[\\, content\\, "
"error\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.message.Message:1 of
msgid "State of your application from the viewpoint of the entity using it."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ":py:obj:`MessageType <flwr.common.MessageType>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.constant.MessageType:1 of
msgid "Message type."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ":py:obj:`MessageTypeLegacy <flwr.common.MessageTypeLegacy>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.constant.MessageTypeLegacy:1 of
msgid "Legacy message type."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ""
":py:obj:`Metadata <flwr.common.Metadata>`\\ \\(run\\_id\\, "
"message\\_id\\, src\\_node\\_id\\, ...\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.message.Metadata:1 of
msgid "A dataclass holding metadata associated with the current message."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ":py:obj:`Metrics <flwr.common.Metrics>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ""
":py:obj:`MetricsRecord <flwr.common.MetricsRecord>`\\ "
"\\(\\[metrics\\_dict\\, keep\\_input\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.record.metricsrecord.MetricsRecord:1 of
msgid "Metrics recod."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ":py:obj:`NDArray <flwr.common.NDArray>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ""
"alias of :py:class:`~numpy.ndarray`\\ [:py:obj:`~typing.Any`, "
":py:class:`~numpy.dtype`\\ [:py:obj:`~typing.Any`]]"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ":py:obj:`NDArrays <flwr.common.NDArrays>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ""
"alias of :py:class:`list`\\ [:py:class:`~numpy.ndarray`\\ "
"[:py:obj:`~typing.Any`, :py:class:`~numpy.dtype`\\ "
"[:py:obj:`~typing.Any`]]]"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ""
":py:obj:`Parameters <flwr.common.Parameters>`\\ \\(tensors\\, "
"tensor\\_type\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.typing.Parameters:1 of
msgid "Model parameters."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ""
":py:obj:`ParametersRecord <flwr.common.ParametersRecord>`\\ "
"\\(\\[array\\_dict\\, keep\\_input\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.record.parametersrecord.ParametersRecord:1 of
msgid "Parameters record."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ":py:obj:`Properties <flwr.common.Properties>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ":py:obj:`ReconnectIns <flwr.common.ReconnectIns>`\\ \\(seconds\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.typing.ReconnectIns:1 of
msgid "ReconnectIns message from server to client."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ""
":py:obj:`RecordSet <flwr.common.RecordSet>`\\ "
"\\(\\[parameters\\_records\\, ...\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.record.recordset.RecordSet:1 of
msgid "RecordSet stores groups of parameters, metrics and configs."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ""
":py:obj:`ServerMessage <flwr.common.ServerMessage>`\\ "
"\\(\\[get\\_properties\\_ins\\, ...\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.typing.ServerMessage:1 of
msgid "ServerMessage is a container used to hold one instruction message."
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
msgid ":py:obj:`Status <flwr.common.Status>`\\ \\(code\\, message\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.typing.Status:1 of
msgid "Client status."
msgstr ""

#: ../../source/ref-api/flwr.common.Array.rst:2
msgid "Array"
msgstr ""

#: flwr.common.record.parametersrecord.Array:3 of
msgid ""
"A dataclass containing serialized data from an array-like or tensor-like "
"object along with some metadata about it."
msgstr ""

#: flwr.common.record.parametersrecord.Array:6 of
msgid ""
"A string representing the data type of the serialised object (e.g. "
"`np.float32`)"
msgstr ""

#: flwr.common.record.parametersrecord.Array:8 of
msgid ""
"A list representing the shape of the unserialized array-like object. This"
" is used to deserialize the data (depending on the serialization method) "
"or simply as a metadata field."
msgstr ""

#: flwr.common.record.parametersrecord.Array:12 of
msgid ""
"A string indicating the type of serialisation mechanism used to generate "
"the bytes in `data` from an array-like or tensor-like object."
msgstr ""

#: flwr.common.record.parametersrecord.Array:15 of
msgid "A buffer of bytes containing the data."
msgstr ""

#: ../../source/ref-api/flwr.common.Array.rst:26:<autosummary>:1
msgid ":py:obj:`numpy <flwr.common.Array.numpy>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.Array.rst:26:<autosummary>:1
#: flwr.common.record.parametersrecord.Array.numpy:1 of
msgid "Return the array as a NumPy array."
msgstr ""

#: flwr.common.record.parametersrecord.Array.numpy:1:<autosummary>:1 of
msgid ":py:obj:`dtype <flwr.common.Array.dtype>`\\"
msgstr ""

#: flwr.common.record.parametersrecord.Array.numpy:1:<autosummary>:1 of
msgid ":py:obj:`shape <flwr.common.Array.shape>`\\"
msgstr ""

#: flwr.common.record.parametersrecord.Array.numpy:1:<autosummary>:1 of
msgid ":py:obj:`stype <flwr.common.Array.stype>`\\"
msgstr ""

#: flwr.common.record.parametersrecord.Array.numpy:1:<autosummary>:1 of
msgid ":py:obj:`data <flwr.common.Array.data>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.ClientMessage.rst:2
msgid "ClientMessage"
msgstr ""

#: ../../source/ref-api/flwr.common.ClientMessage.rst:31:<autosummary>:1
msgid ":py:obj:`evaluate_res <flwr.common.ClientMessage.evaluate_res>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.ClientMessage.rst:31:<autosummary>:1
msgid ":py:obj:`fit_res <flwr.common.ClientMessage.fit_res>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.ClientMessage.rst:31:<autosummary>:1
msgid ""
":py:obj:`get_parameters_res "
"<flwr.common.ClientMessage.get_parameters_res>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.ClientMessage.rst:31:<autosummary>:1
msgid ""
":py:obj:`get_properties_res "
"<flwr.common.ClientMessage.get_properties_res>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.Code.rst:2
msgid "Code"
msgstr ""

#: flwr.common.typing.Code:1 of
msgid "Bases: :py:class:`~enum.Enum`"
msgstr ""

#: ../../source/ref-api/flwr.common.Code.rst:26:<autosummary>:1
msgid ":py:obj:`OK <flwr.common.Code.OK>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.Code.rst:26:<autosummary>:1
msgid ""
":py:obj:`GET_PROPERTIES_NOT_IMPLEMENTED "
"<flwr.common.Code.GET_PROPERTIES_NOT_IMPLEMENTED>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.Code.rst:26:<autosummary>:1
msgid ""
":py:obj:`GET_PARAMETERS_NOT_IMPLEMENTED "
"<flwr.common.Code.GET_PARAMETERS_NOT_IMPLEMENTED>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.Code.rst:26:<autosummary>:1
msgid ":py:obj:`FIT_NOT_IMPLEMENTED <flwr.common.Code.FIT_NOT_IMPLEMENTED>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.Code.rst:26:<autosummary>:1
msgid ""
":py:obj:`EVALUATE_NOT_IMPLEMENTED "
"<flwr.common.Code.EVALUATE_NOT_IMPLEMENTED>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.Config.rst:2
msgid "Config"
msgstr ""

#: ../../source/ref-api/flwr.common.ConfigsRecord.rst:2
msgid "ConfigsRecord"
msgstr ""

#: flwr.common.record.configsrecord.ConfigsRecord:1 of
msgid ""
"Bases: :py:class:`~flwr.common.record.typeddict.TypedDict`\\ "
"[:py:class:`str`, :py:class:`int` | :py:class:`float` | :py:class:`str` |"
" :py:class:`bytes` | :py:class:`bool` | :py:class:`list`\\ "
"[:py:class:`int`] | :py:class:`list`\\ [:py:class:`float`] | "
":py:class:`list`\\ [:py:class:`str`] | :py:class:`list`\\ "
"[:py:class:`bytes`] | :py:class:`list`\\ [:py:class:`bool`]]"
msgstr ""

#: flwr.common.record.configsrecord.ConfigsRecord:3 of
msgid ""
"A :code:`ConfigsRecord` is a Python dictionary designed to ensure that "
"each key-value pair adheres to specified data types. A "
":code:`ConfigsRecord` is one of the types of records that a "
"`flwr.common.RecordSet <flwr.common.RecordSet.html#recordset>`_ supports "
"and can therefore be used to construct :code:`common.Message` objects."
msgstr ""

#: flwr.common.record.configsrecord.ConfigsRecord:9 of
msgid ""
"A dictionary that stores basic types (i.e. `str`, `int`, `float`, `bytes`"
" as defined in `ConfigsScalar`) and lists of such types (see "
"`ConfigsScalarList`)."
msgstr ""

#: flwr.common.record.configsrecord.ConfigsRecord:13 of
msgid ""
"A boolean indicating whether config passed should be deleted from the "
"input dictionary immediately after adding them to the record. When set to"
" True, the data is duplicated in memory. If memory is a concern, set it "
"to False."
msgstr ""

#: flwr.common.record.configsrecord.ConfigsRecord:21 of
msgid ""
"The usage of a :code:`ConfigsRecord` is envisioned for sending "
"configuration values telling the target node how to perform a certain "
"action (e.g. train/evaluate a model ). You can use standard Python built-"
"in types such as :code:`float`, :code:`str` , :code:`bytes`. All types "
"allowed are defined in :code:`flwr.common.ConfigsRecordValues`. While "
"lists are supported, we encourage you to use a :code:`ParametersRecord` "
"instead if these are of high dimensionality."
msgstr ""

#: flwr.common.record.configsrecord.ConfigsRecord:29 of
msgid ""
"Let's see some examples of how to construct a :code:`ConfigsRecord` from "
"scratch:"
msgstr ""

#: flwr.common.record.configsrecord.ConfigsRecord:42 of
msgid ""
"Just like the other types of records in a :code:`flwr.common.RecordSet`, "
"types are enforced. If you need to add a custom data structure or object,"
" we recommend to serialise it into bytes and save it as such (bytes are "
"allowed in a :code:`ConfigsRecord`)"
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
msgid ":py:obj:`clear <flwr.common.ConfigsRecord.clear>`\\ \\(\\)"
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
msgid ":py:obj:`count_bytes <flwr.common.ConfigsRecord.count_bytes>`\\ \\(\\)"
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1
#: flwr.common.record.configsrecord.ConfigsRecord.count_bytes:1
#: flwr.common.record.metricsrecord.MetricsRecord.count_bytes:1
#: flwr.common.record.parametersrecord.ParametersRecord.count_bytes:1 of
msgid "Return number of Bytes stored in this object."
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
msgid ":py:obj:`get <flwr.common.ConfigsRecord.get>`\\ \\(k\\[\\,d\\]\\)"
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
msgid ":py:obj:`items <flwr.common.ConfigsRecord.items>`\\ \\(\\)"
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
msgid ":py:obj:`keys <flwr.common.ConfigsRecord.keys>`\\ \\(\\)"
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
msgid ":py:obj:`pop <flwr.common.ConfigsRecord.pop>`\\ \\(k\\[\\,d\\]\\)"
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1
#: collections.abc.MutableMapping.pop:1 of
msgid "If key is not found, d is returned if given, otherwise KeyError is raised."
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
msgid ":py:obj:`popitem <flwr.common.ConfigsRecord.popitem>`\\ \\(\\)"
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1
#: collections.abc.MutableMapping.popitem:1 of
msgid "as a 2-tuple; but raise KeyError if D is empty."
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
msgid ""
":py:obj:`setdefault <flwr.common.ConfigsRecord.setdefault>`\\ "
"\\(k\\[\\,d\\]\\)"
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
msgid ""
":py:obj:`update <flwr.common.ConfigsRecord.update>`\\ \\(\\[E\\, "
"\\]\\*\\*F\\)"
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1
#: collections.abc.MutableMapping.update:1 of
msgid ""
"If E present and has a .keys() method, does:     for k in E: D[k] = E[k] "
"If E present and lacks .keys() method, does:     for (k, v) in E: D[k] = "
"v In either case, this is followed by: for k, v in F.items(): D[k] = v"
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
msgid ":py:obj:`values <flwr.common.ConfigsRecord.values>`\\ \\(\\)"
msgstr ""

#: flwr.common.record.configsrecord.ConfigsRecord.count_bytes:3 of
msgid "This function counts booleans as occupying 1 Byte."
msgstr ""

#: ../../source/ref-api/flwr.common.Context.rst:2
msgid "Context"
msgstr ""

#: flwr.common.context.Context:3 of
msgid "The ID that identifies the run."
msgstr ""

#: flwr.common.context.Context:5 of
msgid "The ID that identifies the node."
msgstr ""

#: flwr.common.context.Context:7 of
msgid ""
"A config (key/value mapping) unique to the node and independent of the "
"`run_config`. This config persists across all runs this node participates"
" in."
msgstr ""

#: flwr.common.context.Context:10 of
msgid ""
"Holds records added by the entity in a given `run_id` and that will stay "
"local. This means that the data it holds will never leave the system it's"
" running from. This can be used as an intermediate storage or scratchpad "
"when executing mods. It can also be used as a memory to access at "
"different points during the lifecycle of this entity (e.g. across "
"multiple rounds)"
msgstr ""

#: flwr.common.context.Context:17 of
msgid ""
"A config (key/value mapping) held by the entity in a given `run_id` and "
"that will stay local. It can be used at any point during the lifecycle of"
" this entity (e.g. across multiple rounds)"
msgstr ""

#: ../../source/ref-api/flwr.common.Context.rst:32:<autosummary>:1
msgid ":py:obj:`run_id <flwr.common.Context.run_id>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.Context.rst:32:<autosummary>:1
msgid ":py:obj:`node_id <flwr.common.Context.node_id>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.Context.rst:32:<autosummary>:1
msgid ":py:obj:`node_config <flwr.common.Context.node_config>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.Context.rst:32:<autosummary>:1
msgid ":py:obj:`state <flwr.common.Context.state>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.Context.rst:32:<autosummary>:1
msgid ":py:obj:`run_config <flwr.common.Context.run_config>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.DisconnectRes.rst:2
msgid "DisconnectRes"
msgstr ""

#: ../../source/ref-api/flwr.common.DisconnectRes.rst:28:<autosummary>:1
msgid ":py:obj:`reason <flwr.common.DisconnectRes.reason>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.Error.rst:2
msgid "Error"
msgstr ""

#: flwr.common.message.Error:3 of
msgid "An identifier for the error."
msgstr ""

#: flwr.common.message.Error:5 of
msgid "A reason for why the error arose (e.g. an exception stack-trace)"
msgstr ""

#: flwr.common.Error.code:1:<autosummary>:1 of
msgid ":py:obj:`code <flwr.common.Error.code>`\\"
msgstr ""

#: flwr.common.Error.code:1 flwr.common.Error.code:1:<autosummary>:1 of
msgid "Error code."
msgstr ""

#: flwr.common.Error.code:1:<autosummary>:1 of
msgid ":py:obj:`reason <flwr.common.Error.reason>`\\"
msgstr ""

#: flwr.common.Error.code:1:<autosummary>:1 flwr.common.Error.reason:1 of
msgid "Reason reported about the error."
msgstr ""

#: ../../source/ref-api/flwr.common.EvaluateIns.rst:2
msgid "EvaluateIns"
msgstr ""

#: ../../source/ref-api/flwr.common.EvaluateIns.rst:29:<autosummary>:1
msgid ":py:obj:`parameters <flwr.common.EvaluateIns.parameters>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.EvaluateIns.rst:29:<autosummary>:1
msgid ":py:obj:`config <flwr.common.EvaluateIns.config>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.EvaluateRes.rst:2
msgid "EvaluateRes"
msgstr ""

#: ../../source/ref-api/flwr.common.EvaluateRes.rst:31:<autosummary>:1
msgid ":py:obj:`status <flwr.common.EvaluateRes.status>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.EvaluateRes.rst:31:<autosummary>:1
msgid ":py:obj:`loss <flwr.common.EvaluateRes.loss>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.EvaluateRes.rst:31:<autosummary>:1
msgid ":py:obj:`num_examples <flwr.common.EvaluateRes.num_examples>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.EvaluateRes.rst:31:<autosummary>:1
msgid ":py:obj:`metrics <flwr.common.EvaluateRes.metrics>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:2
msgid "EventType"
msgstr ""

#: flwr.common.telemetry.EventType:1 of
msgid "Bases: :py:class:`str`, :py:class:`~enum.Enum`"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ""
":py:obj:`encode <flwr.common.EventType.encode>`\\ \\(\\[encoding\\, "
"errors\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.encode:1 of
msgid "Encode the string using the codec registered for encoding."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ""
":py:obj:`replace <flwr.common.EventType.replace>`\\ \\(old\\, new\\[\\, "
"count\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.replace:1 of
msgid "Return a copy with all occurrences of substring old replaced by new."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ""
":py:obj:`split <flwr.common.EventType.split>`\\ \\(\\[sep\\, "
"maxsplit\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.rsplit:1 flwr.common.EventType.split:1 of
msgid ""
"Return a list of the substrings in the string, using sep as the separator"
" string."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ""
":py:obj:`rsplit <flwr.common.EventType.rsplit>`\\ \\(\\[sep\\, "
"maxsplit\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ":py:obj:`join <flwr.common.EventType.join>`\\ \\(iterable\\, \\/\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.join:1 of
msgid "Concatenate any number of strings."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ":py:obj:`capitalize <flwr.common.EventType.capitalize>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.capitalize:1 of
msgid "Return a capitalized version of the string."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ":py:obj:`casefold <flwr.common.EventType.casefold>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.casefold:1 of
msgid "Return a version of the string suitable for caseless comparisons."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ":py:obj:`title <flwr.common.EventType.title>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.title:1 of
msgid "Return a version of the string where each word is titlecased."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ""
":py:obj:`center <flwr.common.EventType.center>`\\ \\(width\\[\\, "
"fillchar\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.center:1 of
msgid "Return a centered string of length width."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ""
":py:obj:`count <flwr.common.EventType.count>`\\ \\(sub\\[\\, start\\[\\, "
"end\\]\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ""
"Return the number of non-overlapping occurrences of substring sub in "
"string S[start:end]."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ""
":py:obj:`expandtabs <flwr.common.EventType.expandtabs>`\\ "
"\\(\\[tabsize\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.expandtabs:1 of
msgid "Return a copy where all tab characters are expanded using spaces."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ""
":py:obj:`find <flwr.common.EventType.find>`\\ \\(sub\\[\\, start\\[\\, "
"end\\]\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ""
"Return the lowest index in S where substring sub is found, such that sub "
"is contained within S[start:end]."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ":py:obj:`partition <flwr.common.EventType.partition>`\\ \\(sep\\, \\/\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.partition:1 flwr.common.EventType.rpartition:1 of
msgid "Partition the string into three parts using the given separator."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ""
":py:obj:`index <flwr.common.EventType.index>`\\ \\(sub\\[\\, start\\[\\, "
"end\\]\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ""
":py:obj:`ljust <flwr.common.EventType.ljust>`\\ \\(width\\[\\, "
"fillchar\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.ljust:1 of
msgid "Return a left-justified string of length width."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ":py:obj:`lower <flwr.common.EventType.lower>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.lower:1 of
msgid "Return a copy of the string converted to lowercase."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ":py:obj:`lstrip <flwr.common.EventType.lstrip>`\\ \\(\\[chars\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.lstrip:1 of
msgid "Return a copy of the string with leading whitespace removed."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ""
":py:obj:`rfind <flwr.common.EventType.rfind>`\\ \\(sub\\[\\, start\\[\\, "
"end\\]\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ""
"Return the highest index in S where substring sub is found, such that sub"
" is contained within S[start:end]."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ""
":py:obj:`rindex <flwr.common.EventType.rindex>`\\ \\(sub\\[\\, "
"start\\[\\, end\\]\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ""
":py:obj:`rjust <flwr.common.EventType.rjust>`\\ \\(width\\[\\, "
"fillchar\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.rjust:1 of
msgid "Return a right-justified string of length width."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ":py:obj:`rstrip <flwr.common.EventType.rstrip>`\\ \\(\\[chars\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.rstrip:1 of
msgid "Return a copy of the string with trailing whitespace removed."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ":py:obj:`rpartition <flwr.common.EventType.rpartition>`\\ \\(sep\\, \\/\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ""
":py:obj:`splitlines <flwr.common.EventType.splitlines>`\\ "
"\\(\\[keepends\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.splitlines:1 of
msgid "Return a list of the lines in the string, breaking at line boundaries."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ":py:obj:`strip <flwr.common.EventType.strip>`\\ \\(\\[chars\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.strip:1 of
msgid "Return a copy of the string with leading and trailing whitespace removed."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ":py:obj:`swapcase <flwr.common.EventType.swapcase>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.swapcase:1 of
msgid ""
"Convert uppercase characters to lowercase and lowercase characters to "
"uppercase."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ":py:obj:`translate <flwr.common.EventType.translate>`\\ \\(table\\, \\/\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.translate:1 of
msgid "Replace each character in the string using the given translation table."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ":py:obj:`upper <flwr.common.EventType.upper>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.upper:1 of
msgid "Return a copy of the string converted to uppercase."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ""
":py:obj:`startswith <flwr.common.EventType.startswith>`\\ \\(prefix\\[\\,"
" start\\[\\, end\\]\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid "Return True if S starts with the specified prefix, False otherwise."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ""
":py:obj:`endswith <flwr.common.EventType.endswith>`\\ \\(suffix\\[\\, "
"start\\[\\, end\\]\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid "Return True if S ends with the specified suffix, False otherwise."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ""
":py:obj:`removeprefix <flwr.common.EventType.removeprefix>`\\ "
"\\(prefix\\, \\/\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.removeprefix:1 of
msgid "Return a str with the given prefix string removed if present."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ""
":py:obj:`removesuffix <flwr.common.EventType.removesuffix>`\\ "
"\\(suffix\\, \\/\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.removesuffix:1 of
msgid "Return a str with the given suffix string removed if present."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ":py:obj:`isascii <flwr.common.EventType.isascii>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.isascii:1 of
msgid "Return True if all characters in the string are ASCII, False otherwise."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ":py:obj:`islower <flwr.common.EventType.islower>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.islower:1 of
msgid "Return True if the string is a lowercase string, False otherwise."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ":py:obj:`isupper <flwr.common.EventType.isupper>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.isupper:1 of
msgid "Return True if the string is an uppercase string, False otherwise."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ":py:obj:`istitle <flwr.common.EventType.istitle>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.istitle:1 of
msgid "Return True if the string is a title-cased string, False otherwise."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ":py:obj:`isspace <flwr.common.EventType.isspace>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.isspace:1 of
msgid "Return True if the string is a whitespace string, False otherwise."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ":py:obj:`isdecimal <flwr.common.EventType.isdecimal>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.isdecimal:1 of
msgid "Return True if the string is a decimal string, False otherwise."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ":py:obj:`isdigit <flwr.common.EventType.isdigit>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.isdigit:1 of
msgid "Return True if the string is a digit string, False otherwise."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ":py:obj:`isnumeric <flwr.common.EventType.isnumeric>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.isnumeric:1 of
msgid "Return True if the string is a numeric string, False otherwise."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ":py:obj:`isalpha <flwr.common.EventType.isalpha>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.isalpha:1 of
msgid "Return True if the string is an alphabetic string, False otherwise."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ":py:obj:`isalnum <flwr.common.EventType.isalnum>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.isalnum:1 of
msgid "Return True if the string is an alpha-numeric string, False otherwise."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ":py:obj:`isidentifier <flwr.common.EventType.isidentifier>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.isidentifier:1 of
msgid "Return True if the string is a valid Python identifier, False otherwise."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ":py:obj:`isprintable <flwr.common.EventType.isprintable>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.isprintable:1 of
msgid "Return True if the string is printable, False otherwise."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ":py:obj:`zfill <flwr.common.EventType.zfill>`\\ \\(width\\, \\/\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.zfill:1 of
msgid ""
"Pad a numeric string with zeros on the left, to fill a field of the given"
" width."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ""
":py:obj:`format <flwr.common.EventType.format>`\\ \\(\\*args\\, "
"\\*\\*kwargs\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid "Return a formatted version of S, using substitutions from args and kwargs."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ":py:obj:`format_map <flwr.common.EventType.format_map>`\\ \\(mapping\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid "Return a formatted version of S, using substitutions from mapping."
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
msgid ":py:obj:`maketrans <flwr.common.EventType.maketrans>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.maketrans:1 of
msgid "Return a translation table usable for str.translate()."
msgstr ""

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
msgid ":py:obj:`PING <flwr.common.EventType.PING>`\\"
msgstr ""

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
msgid ":py:obj:`START_CLIENT_ENTER <flwr.common.EventType.START_CLIENT_ENTER>`\\"
msgstr ""

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
msgid ":py:obj:`START_CLIENT_LEAVE <flwr.common.EventType.START_CLIENT_LEAVE>`\\"
msgstr ""

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
msgid ":py:obj:`START_SERVER_ENTER <flwr.common.EventType.START_SERVER_ENTER>`\\"
msgstr ""

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
msgid ":py:obj:`START_SERVER_LEAVE <flwr.common.EventType.START_SERVER_LEAVE>`\\"
msgstr ""

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
msgid ""
":py:obj:`START_SIMULATION_ENTER "
"<flwr.common.EventType.START_SIMULATION_ENTER>`\\"
msgstr ""

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
msgid ""
":py:obj:`START_SIMULATION_LEAVE "
"<flwr.common.EventType.START_SIMULATION_LEAVE>`\\"
msgstr ""

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
msgid ""
":py:obj:`CLI_FLOWER_SIMULATION_ENTER "
"<flwr.common.EventType.CLI_FLOWER_SIMULATION_ENTER>`\\"
msgstr ""

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
msgid ""
":py:obj:`CLI_FLOWER_SIMULATION_LEAVE "
"<flwr.common.EventType.CLI_FLOWER_SIMULATION_LEAVE>`\\"
msgstr ""

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
msgid ""
":py:obj:`PYTHON_API_RUN_SIMULATION_ENTER "
"<flwr.common.EventType.PYTHON_API_RUN_SIMULATION_ENTER>`\\"
msgstr ""

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
msgid ""
":py:obj:`PYTHON_API_RUN_SIMULATION_LEAVE "
"<flwr.common.EventType.PYTHON_API_RUN_SIMULATION_LEAVE>`\\"
msgstr ""

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
msgid ""
":py:obj:`RUN_SUPERLINK_ENTER "
"<flwr.common.EventType.RUN_SUPERLINK_ENTER>`\\"
msgstr ""

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
msgid ""
":py:obj:`RUN_SUPERLINK_LEAVE "
"<flwr.common.EventType.RUN_SUPERLINK_LEAVE>`\\"
msgstr ""

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
msgid ""
":py:obj:`RUN_SUPERNODE_ENTER "
"<flwr.common.EventType.RUN_SUPERNODE_ENTER>`\\"
msgstr ""

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
msgid ""
":py:obj:`RUN_SUPERNODE_LEAVE "
"<flwr.common.EventType.RUN_SUPERNODE_LEAVE>`\\"
msgstr ""

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
msgid ""
":py:obj:`RUN_SERVER_APP_ENTER "
"<flwr.common.EventType.RUN_SERVER_APP_ENTER>`\\"
msgstr ""

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
msgid ""
":py:obj:`RUN_SERVER_APP_LEAVE "
"<flwr.common.EventType.RUN_SERVER_APP_LEAVE>`\\"
msgstr ""

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
msgid ""
":py:obj:`RUN_CLIENT_APP_ENTER "
"<flwr.common.EventType.RUN_CLIENT_APP_ENTER>`\\"
msgstr ""

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
msgid ""
":py:obj:`RUN_CLIENT_APP_LEAVE "
"<flwr.common.EventType.RUN_CLIENT_APP_LEAVE>`\\"
msgstr ""

#: flwr.common.EventType.capitalize:3 of
msgid ""
"More specifically, make the first character have upper case and the rest "
"lower case."
msgstr ""

#: flwr.common.EventType.center:3 flwr.common.EventType.ljust:3
#: flwr.common.EventType.rjust:3 of
msgid "Padding is done using the specified fill character (default is a space)."
msgstr ""

#: flwr.common.EventType.count:1 of
msgid ""
"Return the number of non-overlapping occurrences of substring sub in "
"string S[start:end].  Optional arguments start and end are interpreted as"
" in slice notation."
msgstr ""

#: flwr.common.EventType.encode:3 of
msgid "encoding"
msgstr ""

#: flwr.common.EventType.encode:4 of
msgid "The encoding in which to encode the string."
msgstr ""

#: flwr.common.EventType.encode:9 of
msgid "errors"
msgstr ""

#: flwr.common.EventType.encode:6 of
msgid ""
"The error handling scheme to use for encoding errors. The default is "
"'strict' meaning that encoding errors raise a UnicodeEncodeError.  Other "
"possible values are 'ignore', 'replace' and 'xmlcharrefreplace' as well "
"as any other name registered with codecs.register_error that can handle "
"UnicodeEncodeErrors."
msgstr ""

#: flwr.common.EventType.endswith:1 of
msgid ""
"Return True if S ends with the specified suffix, False otherwise. With "
"optional start, test S beginning at that position. With optional end, "
"stop comparing S at that position. suffix can also be a tuple of strings "
"to try."
msgstr ""

#: flwr.common.EventType.expandtabs:3 of
msgid "If tabsize is not given, a tab size of 8 characters is assumed."
msgstr ""

#: flwr.common.EventType.find:1 flwr.common.EventType.index:1 of
msgid ""
"Return the lowest index in S where substring sub is found, such that sub "
"is contained within S[start:end].  Optional arguments start and end are "
"interpreted as in slice notation."
msgstr ""

#: flwr.common.EventType.find:5 flwr.common.EventType.rfind:5 of
msgid "Return -1 on failure."
msgstr ""

#: flwr.common.EventType.format:1 of
msgid ""
"Return a formatted version of S, using substitutions from args and "
"kwargs. The substitutions are identified by braces ('{' and '}')."
msgstr ""

#: flwr.common.EventType.format_map:1 of
msgid ""
"Return a formatted version of S, using substitutions from mapping. The "
"substitutions are identified by braces ('{' and '}')."
msgstr ""

#: flwr.common.EventType.index:5 flwr.common.EventType.rindex:5 of
msgid "Raises ValueError when the substring is not found."
msgstr ""

#: flwr.common.EventType.isalnum:3 of
msgid ""
"A string is alpha-numeric if all characters in the string are alpha-"
"numeric and there is at least one character in the string."
msgstr ""

#: flwr.common.EventType.isalpha:3 of
msgid ""
"A string is alphabetic if all characters in the string are alphabetic and"
" there is at least one character in the string."
msgstr ""

#: flwr.common.EventType.isascii:3 of
msgid ""
"ASCII characters have code points in the range U+0000-U+007F. Empty "
"string is ASCII too."
msgstr ""

#: flwr.common.EventType.isdecimal:3 of
msgid ""
"A string is a decimal string if all characters in the string are decimal "
"and there is at least one character in the string."
msgstr ""

#: flwr.common.EventType.isdigit:3 of
msgid ""
"A string is a digit string if all characters in the string are digits and"
" there is at least one character in the string."
msgstr ""

#: flwr.common.EventType.isidentifier:3 of
msgid ""
"Call keyword.iskeyword(s) to test whether string s is a reserved "
"identifier, such as \"def\" or \"class\"."
msgstr ""

#: flwr.common.EventType.islower:3 of
msgid ""
"A string is lowercase if all cased characters in the string are lowercase"
" and there is at least one cased character in the string."
msgstr ""

#: flwr.common.EventType.isnumeric:3 of
msgid ""
"A string is numeric if all characters in the string are numeric and there"
" is at least one character in the string."
msgstr ""

#: flwr.common.EventType.isprintable:3 of
msgid ""
"A string is printable if all of its characters are considered printable "
"in repr() or if it is empty."
msgstr ""

#: flwr.common.EventType.isspace:3 of
msgid ""
"A string is whitespace if all characters in the string are whitespace and"
" there is at least one character in the string."
msgstr ""

#: flwr.common.EventType.istitle:3 of
msgid ""
"In a title-cased string, upper- and title-case characters may only follow"
" uncased characters and lowercase characters only cased ones."
msgstr ""

#: flwr.common.EventType.isupper:3 of
msgid ""
"A string is uppercase if all cased characters in the string are uppercase"
" and there is at least one cased character in the string."
msgstr ""

#: flwr.common.EventType.join:3 of
msgid ""
"The string whose method is called is inserted in between each given "
"string. The result is returned as a new string."
msgstr ""

#: flwr.common.EventType.join:6 of
msgid "Example: '.'.join(['ab', 'pq', 'rs']) -> 'ab.pq.rs'"
msgstr ""

#: flwr.common.EventType.lstrip:3 flwr.common.EventType.rstrip:3
#: flwr.common.EventType.strip:3 of
msgid "If chars is given and not None, remove characters in chars instead."
msgstr ""

#: flwr.common.EventType.maketrans:3 of
msgid ""
"If there is only one argument, it must be a dictionary mapping Unicode "
"ordinals (integers) or characters to Unicode ordinals, strings or None. "
"Character keys will be then converted to ordinals. If there are two "
"arguments, they must be strings of equal length, and in the resulting "
"dictionary, each character in x will be mapped to the character at the "
"same position in y. If there is a third argument, it must be a string, "
"whose characters will be mapped to None in the result."
msgstr ""

#: flwr.common.EventType.partition:3 of
msgid ""
"This will search for the separator in the string.  If the separator is "
"found, returns a 3-tuple containing the part before the separator, the "
"separator itself, and the part after it."
msgstr ""

#: flwr.common.EventType.partition:7 of
msgid ""
"If the separator is not found, returns a 3-tuple containing the original "
"string and two empty strings."
msgstr ""

#: flwr.common.EventType.removeprefix:3 of
msgid ""
"If the string starts with the prefix string, return string[len(prefix):]."
" Otherwise, return a copy of the original string."
msgstr ""

#: flwr.common.EventType.removesuffix:3 of
msgid ""
"If the string ends with the suffix string and that suffix is not empty, "
"return string[:-len(suffix)]. Otherwise, return a copy of the original "
"string."
msgstr ""

#: flwr.common.EventType.replace:5 of
msgid "count"
msgstr ""

#: flwr.common.EventType.replace:4 of
msgid ""
"Maximum number of occurrences to replace. -1 (the default value) means "
"replace all occurrences."
msgstr ""

#: flwr.common.EventType.replace:7 of
msgid ""
"If the optional argument count is given, only the first count occurrences"
" are replaced."
msgstr ""

#: flwr.common.EventType.rfind:1 flwr.common.EventType.rindex:1 of
msgid ""
"Return the highest index in S where substring sub is found, such that sub"
" is contained within S[start:end].  Optional arguments start and end are "
"interpreted as in slice notation."
msgstr ""

#: flwr.common.EventType.rpartition:3 of
msgid ""
"This will search for the separator in the string, starting at the end. If"
" the separator is found, returns a 3-tuple containing the part before the"
" separator, the separator itself, and the part after it."
msgstr ""

#: flwr.common.EventType.rpartition:7 of
msgid ""
"If the separator is not found, returns a 3-tuple containing two empty "
"strings and the original string."
msgstr ""

#: flwr.common.EventType.rsplit:7 flwr.common.EventType.split:7 of
msgid "sep"
msgstr ""

#: flwr.common.EventType.rsplit:4 flwr.common.EventType.split:4 of
msgid "The separator used to split the string."
msgstr ""

#: flwr.common.EventType.rsplit:6 flwr.common.EventType.split:6 of
msgid ""
"When set to None (the default value), will split on any whitespace "
"character (including \\\\n \\\\r \\\\t \\\\f and spaces) and will discard"
" empty strings from the result."
msgstr ""

#: flwr.common.EventType.rsplit:11 flwr.common.EventType.split:11 of
msgid "maxsplit"
msgstr ""

#: flwr.common.EventType.rsplit:10 flwr.common.EventType.split:10 of
msgid ""
"Maximum number of splits (starting from the left). -1 (the default value)"
" means no limit."
msgstr ""

#: flwr.common.EventType.rsplit:13 of
msgid "Splitting starts at the end of the string and works to the front."
msgstr ""

#: flwr.common.EventType.split:13 of
msgid ""
"Note, str.split() is mainly useful for data that has been intentionally "
"delimited.  With natural text that includes punctuation, consider using "
"the regular expression module."
msgstr ""

#: flwr.common.EventType.splitlines:3 of
msgid ""
"Line breaks are not included in the resulting list unless keepends is "
"given and true."
msgstr ""

#: flwr.common.EventType.startswith:1 of
msgid ""
"Return True if S starts with the specified prefix, False otherwise. With "
"optional start, test S beginning at that position. With optional end, "
"stop comparing S at that position. prefix can also be a tuple of strings "
"to try."
msgstr ""

#: flwr.common.EventType.title:3 of
msgid ""
"More specifically, words start with uppercased characters and all "
"remaining cased characters have lower case."
msgstr ""

#: flwr.common.EventType.translate:5 of
msgid "table"
msgstr ""

#: flwr.common.EventType.translate:4 of
msgid ""
"Translation table, which must be a mapping of Unicode ordinals to Unicode"
" ordinals, strings, or None."
msgstr ""

#: flwr.common.EventType.translate:7 of
msgid ""
"The table must implement lookup/indexing via __getitem__, for instance a "
"dictionary or list.  If this operation raises LookupError, the character "
"is left untouched.  Characters mapped to None are deleted."
msgstr ""

#: flwr.common.EventType.zfill:3 of
msgid "The string is never truncated."
msgstr ""

#: ../../source/ref-api/flwr.common.FitIns.rst:2
msgid "FitIns"
msgstr ""

#: ../../source/ref-api/flwr.common.FitIns.rst:29:<autosummary>:1
msgid ":py:obj:`parameters <flwr.common.FitIns.parameters>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.FitIns.rst:29:<autosummary>:1
msgid ":py:obj:`config <flwr.common.FitIns.config>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.FitRes.rst:2
msgid "FitRes"
msgstr ""

#: ../../source/ref-api/flwr.common.FitRes.rst:31:<autosummary>:1
msgid ":py:obj:`status <flwr.common.FitRes.status>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.FitRes.rst:31:<autosummary>:1
msgid ":py:obj:`parameters <flwr.common.FitRes.parameters>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.FitRes.rst:31:<autosummary>:1
msgid ":py:obj:`num_examples <flwr.common.FitRes.num_examples>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.FitRes.rst:31:<autosummary>:1
msgid ":py:obj:`metrics <flwr.common.FitRes.metrics>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.GetParametersIns.rst:2
msgid "GetParametersIns"
msgstr ""

#: ../../source/ref-api/flwr.common.GetParametersIns.rst:28:<autosummary>:1
msgid ":py:obj:`config <flwr.common.GetParametersIns.config>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.GetParametersRes.rst:2
msgid "GetParametersRes"
msgstr ""

#: ../../source/ref-api/flwr.common.GetParametersRes.rst:29:<autosummary>:1
msgid ":py:obj:`status <flwr.common.GetParametersRes.status>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.GetParametersRes.rst:29:<autosummary>:1
msgid ":py:obj:`parameters <flwr.common.GetParametersRes.parameters>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.GetPropertiesIns.rst:2
msgid "GetPropertiesIns"
msgstr ""

#: ../../source/ref-api/flwr.common.GetPropertiesIns.rst:28:<autosummary>:1
msgid ":py:obj:`config <flwr.common.GetPropertiesIns.config>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.GetPropertiesRes.rst:2
msgid "GetPropertiesRes"
msgstr ""

#: ../../source/ref-api/flwr.common.GetPropertiesRes.rst:29:<autosummary>:1
msgid ":py:obj:`status <flwr.common.GetPropertiesRes.status>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.GetPropertiesRes.rst:29:<autosummary>:1
msgid ":py:obj:`properties <flwr.common.GetPropertiesRes.properties>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.Message.rst:2
msgid "Message"
msgstr ""

#: flwr.common.Message.content:1:<autosummary>:1 flwr.common.Message.metadata:1
#: flwr.common.message.Message:3 of
msgid "A dataclass including information about the message to be executed."
msgstr ""

#: flwr.common.message.Message:5 of
msgid ""
"Holds records either sent by another entity (e.g. sent by the server-side"
" logic to a client, or vice-versa) or that will be sent to it."
msgstr ""

#: flwr.common.message.Message:8 of
msgid ""
"A dataclass that captures information about an error that took place when"
" processing another message."
msgstr ""

#: ../../source/ref-api/flwr.common.Message.rst:35:<autosummary>:1
msgid ""
":py:obj:`create_error_reply <flwr.common.Message.create_error_reply>`\\ "
"\\(error\\[\\, ttl\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.Message.rst:35:<autosummary>:1
#: flwr.common.message.Message.create_error_reply:1 of
msgid "Construct a reply message indicating an error happened."
msgstr ""

#: ../../source/ref-api/flwr.common.Message.rst:35:<autosummary>:1
msgid ""
":py:obj:`create_reply <flwr.common.Message.create_reply>`\\ "
"\\(content\\[\\, ttl\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.Message.rst:35:<autosummary>:1
#: flwr.common.message.Message.create_reply:1 of
msgid "Create a reply to this message with specified content and TTL."
msgstr ""

#: ../../source/ref-api/flwr.common.Message.rst:35:<autosummary>:1
msgid ":py:obj:`has_content <flwr.common.Message.has_content>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.Message.rst:35:<autosummary>:1
#: flwr.common.message.Message.has_content:1 of
msgid "Return True if message has content, else False."
msgstr ""

#: ../../source/ref-api/flwr.common.Message.rst:35:<autosummary>:1
msgid ":py:obj:`has_error <flwr.common.Message.has_error>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.Message.rst:35:<autosummary>:1
#: flwr.common.message.Message.has_error:1 of
msgid "Return True if message has an error, else False."
msgstr ""

#: flwr.common.Message.content:1:<autosummary>:1 of
msgid ":py:obj:`content <flwr.common.Message.content>`\\"
msgstr ""

#: flwr.common.Message.content:1 flwr.common.Message.content:1:<autosummary>:1
#: of
msgid "The content of this message."
msgstr ""

#: flwr.common.Message.content:1:<autosummary>:1 of
msgid ":py:obj:`error <flwr.common.Message.error>`\\"
msgstr ""

#: flwr.common.Message.content:1:<autosummary>:1 flwr.common.Message.error:1 of
msgid "Error captured by this message."
msgstr ""

#: flwr.common.Message.content:1:<autosummary>:1 of
msgid ":py:obj:`metadata <flwr.common.Message.metadata>`\\"
msgstr ""

#: flwr.common.message.Message.create_error_reply:3 of
msgid "The error that was encountered."
msgstr ""

#: flwr.common.message.Message.create_error_reply:5
#: flwr.common.message.Message.create_reply:9 of
msgid ""
"Time-to-live for this message in seconds. If unset, it will be set based "
"on the remaining time for the received message before it expires. This "
"follows the equation:  ttl = msg.meta.ttl - (reply.meta.created_at - "
"msg.meta.created_at)"
msgstr ""

#: flwr.common.message.Message.create_error_reply:5
#: flwr.common.message.Message.create_reply:9 of
msgid ""
"Time-to-live for this message in seconds. If unset, it will be set based "
"on the remaining time for the received message before it expires. This "
"follows the equation:"
msgstr ""

#: flwr.common.message.Message.create_error_reply:9
#: flwr.common.message.Message.create_reply:13 of
msgid "ttl = msg.meta.ttl - (reply.meta.created_at - msg.meta.created_at)"
msgstr ""

#: flwr.common.message.Message.create_error_reply:12 of
msgid "**message** -- A Message containing only the relevant error and metadata."
msgstr ""

#: flwr.common.message.Message.create_reply:3 of
msgid ""
"The method generates a new `Message` as a reply to this message. It "
"inherits 'run_id', 'src_node_id', 'dst_node_id', and 'message_type' from "
"this message and sets 'reply_to_message' to the ID of this message."
msgstr ""

#: flwr.common.message.Message.create_reply:7 of
msgid "The content for the reply message."
msgstr ""

#: flwr.common.message.Message.create_reply:16 of
msgid "A new `Message` instance representing the reply."
msgstr ""

#: ../../source/ref-api/flwr.common.MessageType.rst:2
msgid "MessageType"
msgstr ""

#: ../../source/ref-api/flwr.common.MessageType.rst:30:<autosummary>:1
msgid ":py:obj:`EVALUATE <flwr.common.MessageType.EVALUATE>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.MessageType.rst:30:<autosummary>:1
msgid ":py:obj:`QUERY <flwr.common.MessageType.QUERY>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.MessageType.rst:30:<autosummary>:1
msgid ":py:obj:`TRAIN <flwr.common.MessageType.TRAIN>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.MessageTypeLegacy.rst:2
msgid "MessageTypeLegacy"
msgstr ""

#: ../../source/ref-api/flwr.common.MessageTypeLegacy.rst:29:<autosummary>:1
msgid ":py:obj:`GET_PARAMETERS <flwr.common.MessageTypeLegacy.GET_PARAMETERS>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.MessageTypeLegacy.rst:29:<autosummary>:1
msgid ":py:obj:`GET_PROPERTIES <flwr.common.MessageTypeLegacy.GET_PROPERTIES>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.Metadata.rst:2
msgid "Metadata"
msgstr ""

#: flwr.common.Metadata.created_at:1:<autosummary>:1
#: flwr.common.Metadata.run_id:1 flwr.common.message.Metadata:3 of
msgid "An identifier for the current run."
msgstr ""

#: flwr.common.Metadata.created_at:1:<autosummary>:1
#: flwr.common.Metadata.message_id:1 flwr.common.message.Metadata:5 of
msgid "An identifier for the current message."
msgstr ""

#: flwr.common.Metadata.created_at:1:<autosummary>:1
#: flwr.common.Metadata.src_node_id:1 flwr.common.message.Metadata:7 of
msgid "An identifier for the node sending this message."
msgstr ""

#: flwr.common.Metadata.created_at:1:<autosummary>:1
#: flwr.common.Metadata.dst_node_id:1 flwr.common.message.Metadata:9 of
msgid "An identifier for the node receiving this message."
msgstr ""

#: flwr.common.Metadata.created_at:1:<autosummary>:1
#: flwr.common.Metadata.reply_to_message:1 flwr.common.message.Metadata:11 of
msgid "An identifier for the message this message replies to."
msgstr ""

#: flwr.common.message.Metadata:13 of
msgid ""
"An identifier for grouping messages. In some settings, this is used as "
"the FL round."
msgstr ""

#: flwr.common.message.Metadata:16 of
msgid "Time-to-live for this message in seconds."
msgstr ""

#: flwr.common.Metadata.created_at:1:<autosummary>:1
#: flwr.common.Metadata.message_type:1 flwr.common.message.Metadata:18 of
msgid "A string that encodes the action to be executed on the receiving end."
msgstr ""

#: flwr.common.Metadata.created_at:1:<autosummary>:1 of
msgid ":py:obj:`created_at <flwr.common.Metadata.created_at>`\\"
msgstr ""

#: flwr.common.Metadata.created_at:1
#: flwr.common.Metadata.created_at:1:<autosummary>:1 of
msgid "Unix timestamp when the message was created."
msgstr ""

#: flwr.common.Metadata.created_at:1:<autosummary>:1 of
msgid ":py:obj:`dst_node_id <flwr.common.Metadata.dst_node_id>`\\"
msgstr ""

#: flwr.common.Metadata.created_at:1:<autosummary>:1 of
msgid ":py:obj:`group_id <flwr.common.Metadata.group_id>`\\"
msgstr ""

#: flwr.common.Metadata.created_at:1:<autosummary>:1
#: flwr.common.Metadata.group_id:1 of
msgid "An identifier for grouping messages."
msgstr ""

#: flwr.common.Metadata.created_at:1:<autosummary>:1 of
msgid ":py:obj:`message_id <flwr.common.Metadata.message_id>`\\"
msgstr ""

#: flwr.common.Metadata.created_at:1:<autosummary>:1 of
msgid ":py:obj:`message_type <flwr.common.Metadata.message_type>`\\"
msgstr ""

#: flwr.common.Metadata.created_at:1:<autosummary>:1 of
msgid ":py:obj:`reply_to_message <flwr.common.Metadata.reply_to_message>`\\"
msgstr ""

#: flwr.common.Metadata.created_at:1:<autosummary>:1 of
msgid ":py:obj:`run_id <flwr.common.Metadata.run_id>`\\"
msgstr ""

#: flwr.common.Metadata.created_at:1:<autosummary>:1 of
msgid ":py:obj:`src_node_id <flwr.common.Metadata.src_node_id>`\\"
msgstr ""

#: flwr.common.Metadata.created_at:1:<autosummary>:1 of
msgid ":py:obj:`ttl <flwr.common.Metadata.ttl>`\\"
msgstr ""

#: flwr.common.Metadata.created_at:1:<autosummary>:1 flwr.common.Metadata.ttl:1
#: of
msgid "Time-to-live for this message."
msgstr ""

#: ../../source/ref-api/flwr.common.Metrics.rst:2
msgid "Metrics"
msgstr ""

#: ../../source/ref-api/flwr.common.MetricsRecord.rst:2
msgid "MetricsRecord"
msgstr ""

#: flwr.common.record.metricsrecord.MetricsRecord:1 of
msgid ""
"Bases: :py:class:`~flwr.common.record.typeddict.TypedDict`\\ "
"[:py:class:`str`, :py:class:`int` | :py:class:`float` | "
":py:class:`list`\\ [:py:class:`int`] | :py:class:`list`\\ "
"[:py:class:`float`]]"
msgstr ""

#: flwr.common.record.metricsrecord.MetricsRecord:3 of
msgid ""
"A :code:`MetricsRecord` is a Python dictionary designed to ensure that "
"each key-value pair adheres to specified data types. A "
":code:`MetricsRecord` is one of the types of records that a "
"`flwr.common.RecordSet <flwr.common.RecordSet.html#recordset>`_ supports "
"and can therefore be used to construct :code:`common.Message` objects."
msgstr ""

#: flwr.common.record.metricsrecord.MetricsRecord:9 of
msgid ""
"A dictionary that stores basic types (i.e. `int`, `float` as defined in "
"`MetricsScalar`) and list of such types (see `MetricsScalarList`)."
msgstr ""

#: flwr.common.record.metricsrecord.MetricsRecord:12 of
msgid ""
"A boolean indicating whether metrics should be deleted from the input "
"dictionary immediately after adding them to the record. When set to True,"
" the data is duplicated in memory. If memory is a concern, set it to "
"False."
msgstr ""

#: flwr.common.record.metricsrecord.MetricsRecord:20 of
msgid ""
"The usage of a :code:`MetricsRecord` is envisioned for communicating "
"results obtained when a node performs an action. A few typical examples "
"include: communicating the training accuracy after a model is trained "
"locally by a :code:`ClientApp`, reporting the validation loss obtained at"
" a :code:`ClientApp`, or, more generally, the output of executing a query"
" by the :code:`ClientApp`. Common to these examples is that the output "
"can be typically represented by a single scalar (:code:`int`, "
":code:`float`) or list of scalars."
msgstr ""

#: flwr.common.record.metricsrecord.MetricsRecord:28 of
msgid ""
"Let's see some examples of how to construct a :code:`MetricsRecord` from "
"scratch:"
msgstr ""

#: flwr.common.record.metricsrecord.MetricsRecord:39 of
msgid ""
"Since types are enforced, the types of the objects inserted are checked. "
"For a :code:`MetricsRecord`, value types allowed are those in defined in "
":code:`flwr.common.MetricsRecordValues`. Similarly, only :code:`str` keys"
" are allowed."
msgstr ""

#: flwr.common.record.metricsrecord.MetricsRecord:50 of
msgid ""
"If you need a more versatily type of record try :code:`ConfigsRecord` or "
":code:`ParametersRecord`."
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
msgid ":py:obj:`clear <flwr.common.MetricsRecord.clear>`\\ \\(\\)"
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
msgid ":py:obj:`count_bytes <flwr.common.MetricsRecord.count_bytes>`\\ \\(\\)"
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
msgid ":py:obj:`get <flwr.common.MetricsRecord.get>`\\ \\(k\\[\\,d\\]\\)"
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
msgid ":py:obj:`items <flwr.common.MetricsRecord.items>`\\ \\(\\)"
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
msgid ":py:obj:`keys <flwr.common.MetricsRecord.keys>`\\ \\(\\)"
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
msgid ":py:obj:`pop <flwr.common.MetricsRecord.pop>`\\ \\(k\\[\\,d\\]\\)"
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
msgid ":py:obj:`popitem <flwr.common.MetricsRecord.popitem>`\\ \\(\\)"
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
msgid ""
":py:obj:`setdefault <flwr.common.MetricsRecord.setdefault>`\\ "
"\\(k\\[\\,d\\]\\)"
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
msgid ""
":py:obj:`update <flwr.common.MetricsRecord.update>`\\ \\(\\[E\\, "
"\\]\\*\\*F\\)"
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
msgid ":py:obj:`values <flwr.common.MetricsRecord.values>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.common.NDArray.rst:2
msgid "NDArray"
msgstr ""

#: ../../source/ref-api/flwr.common.NDArrays.rst:2
msgid "NDArrays"
msgstr ""

#: ../../source/ref-api/flwr.common.Parameters.rst:29:<autosummary>:1
msgid ":py:obj:`tensors <flwr.common.Parameters.tensors>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.Parameters.rst:29:<autosummary>:1
msgid ":py:obj:`tensor_type <flwr.common.Parameters.tensor_type>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.ParametersRecord.rst:2
msgid "ParametersRecord"
msgstr ""

#: flwr.common.record.parametersrecord.ParametersRecord:1 of
msgid ""
"Bases: :py:class:`~flwr.common.record.typeddict.TypedDict`\\ "
"[:py:class:`str`, :py:class:`~flwr.common.record.parametersrecord.Array`]"
msgstr ""

#: flwr.common.record.parametersrecord.ParametersRecord:3 of
msgid ""
"A dataclass storing named Arrays in order. This means that it holds "
"entries as an OrderedDict[str, Array]. ParametersRecord objects can be "
"viewed as an equivalent to PyTorch's state_dict, but holding serialised "
"tensors instead. A :code:`ParametersRecord`  is one of the types of "
"records that a `flwr.common.RecordSet "
"<flwr.common.RecordSet.html#recordset>`_ supports and can therefore be "
"used to construct :code:`common.Message` objects."
msgstr ""

#: flwr.common.record.parametersrecord.ParametersRecord:10 of
msgid "A dictionary that stores serialized array-like or tensor-like objects."
msgstr ""

#: flwr.common.record.parametersrecord.ParametersRecord:12 of
msgid ""
"A boolean indicating whether parameters should be deleted from the input "
"dictionary immediately after adding them to the record. If False, the "
"dictionary passed to `set_parameters()` will be empty once exiting from "
"that function. This is the desired behaviour when working with very large"
" models/tensors/arrays. However, if you plan to continue working with "
"your parameters after adding it to the record, set this flag to True. "
"When set to True, the data is duplicated in memory."
msgstr ""

#: flwr.common.record.parametersrecord.ParametersRecord:23 of
msgid ""
"The usage of :code:`ParametersRecord` is envisioned for storing data "
"arrays (e.g. parameters of a machine learning model). These first need to"
" be serialized into a :code:`flwr.common.Array` data structure."
msgstr ""

#: flwr.common.record.parametersrecord.ParametersRecord:27 of
msgid "Let's see some examples:"
msgstr ""

#: flwr.common.record.parametersrecord.ParametersRecord:50 of
msgid ""
"Now that the NumPy array is embedded into a :code:`ParametersRecord` it "
"could be sent if added as part of a :code:`common.Message` or it could be"
" saved as a persistent state of a :code:`ClientApp` via its context. "
"Regardless of the usecase, we will sooner or later want to recover the "
"array in its original NumPy representation. For the example above, where "
"the array was serialized using the built-in utility function, "
"deserialization can be done as follows:"
msgstr ""

#: flwr.common.record.parametersrecord.ParametersRecord:65 of
msgid ""
"If you need finer control on how your arrays are serialized and "
"deserialized, you can construct :code:`Array` objects directly like this:"
msgstr ""

#: flwr.common.record.parametersrecord.ParametersRecord:83 of
msgid ""
"Note that different arrays (e.g. from PyTorch, Tensorflow) might require "
"different serialization mechanism. Howerver, they often support a "
"conversion to NumPy, therefore allowing to use the same or similar steps "
"as in the example above."
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
msgid ":py:obj:`clear <flwr.common.ParametersRecord.clear>`\\ \\(\\)"
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
msgid ":py:obj:`count_bytes <flwr.common.ParametersRecord.count_bytes>`\\ \\(\\)"
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
msgid ":py:obj:`get <flwr.common.ParametersRecord.get>`\\ \\(k\\[\\,d\\]\\)"
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
msgid ":py:obj:`items <flwr.common.ParametersRecord.items>`\\ \\(\\)"
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
msgid ":py:obj:`keys <flwr.common.ParametersRecord.keys>`\\ \\(\\)"
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
msgid ":py:obj:`pop <flwr.common.ParametersRecord.pop>`\\ \\(k\\[\\,d\\]\\)"
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
msgid ":py:obj:`popitem <flwr.common.ParametersRecord.popitem>`\\ \\(\\)"
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
msgid ""
":py:obj:`setdefault <flwr.common.ParametersRecord.setdefault>`\\ "
"\\(k\\[\\,d\\]\\)"
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
msgid ""
":py:obj:`update <flwr.common.ParametersRecord.update>`\\ \\(\\[E\\, "
"\\]\\*\\*F\\)"
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
msgid ":py:obj:`values <flwr.common.ParametersRecord.values>`\\ \\(\\)"
msgstr ""

#: flwr.common.record.parametersrecord.ParametersRecord.count_bytes:3 of
msgid ""
"Note that a small amount of Bytes might also be included in this counting"
" that correspond to metadata of the serialized object (e.g. of NumPy "
"array) needed for deseralization."
msgstr ""

#: ../../source/ref-api/flwr.common.Properties.rst:2
msgid "Properties"
msgstr ""

#: ../../source/ref-api/flwr.common.ReconnectIns.rst:2
msgid "ReconnectIns"
msgstr ""

#: ../../source/ref-api/flwr.common.ReconnectIns.rst:28:<autosummary>:1
msgid ":py:obj:`seconds <flwr.common.ReconnectIns.seconds>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.RecordSet.rst:2
msgid "RecordSet"
msgstr ""

#: flwr.common.record.recordset.RecordSet:3 of
msgid ""
"A :code:`RecordSet` is the unified mechanism by which parameters, metrics"
" and configs can be either stored as part of a `flwr.common.Context "
"<flwr.common.Context.html>`_ in your apps or communicated as part of a "
"`flwr.common.Message <flwr.common.Message.html>`_ between your apps."
msgstr ""

#: flwr.common.record.recordset.RecordSet:9 of
msgid ""
"A dictionary of :code:`ParametersRecords` that can be used to record and "
"communicate model parameters and high-dimensional arrays."
msgstr ""

#: flwr.common.record.recordset.RecordSet:12 of
msgid ""
"A dictionary of :code:`MetricsRecord` that can be used to record and "
"communicate scalar-valued metrics that are the result of performing and "
"action, for example, by a :code:`ClientApp`."
msgstr ""

#: flwr.common.record.recordset.RecordSet:16 of
msgid ""
"A dictionary of :code:`ConfigsRecord` that can be used to record and "
"communicate configuration values to an entity (e.g. to a "
":code:`ClientApp`) for it to adjust how an action is performed."
msgstr ""

#: flwr.common.record.recordset.RecordSet:24 of
msgid ""
"A :code:`RecordSet` can hold three types of records, each designed with "
"an specific purpose. What is common to all of them is that they are "
"Python dictionaries designed to ensure that each key-value pair adheres "
"to specified data types."
msgstr ""

#: flwr.common.record.recordset.RecordSet:29 of
msgid "Let's see an example."
msgstr ""

#: flwr.common.record.recordset.RecordSet:47 of
msgid ""
"Adding a :code:`ParametersRecord` follows the same steps as above but "
"first, the array needs to be serialized and represented as a "
":code:`flwr.common.Array`. If the array is a :code:`NumPy` array, you can"
" use the built-in utility function `array_from_numpy "
"<flwr.common.array_from_numpy.html>`_. It is often possible to convert an"
" array first to :code:`NumPy` and then use the aforementioned function."
msgstr ""

#: flwr.common.record.recordset.RecordSet:66 of
msgid ""
"For additional examples on how to construct each of the records types "
"shown above, please refer to the documentation for :code:`ConfigsRecord`,"
" :code:`MetricsRecord` and :code:`ParametersRecord`."
msgstr ""

#: flwr.common.RecordSet.configs_records:1:<autosummary>:1 of
msgid ":py:obj:`configs_records <flwr.common.RecordSet.configs_records>`\\"
msgstr ""

#: flwr.common.RecordSet.configs_records:1
#: flwr.common.RecordSet.configs_records:1:<autosummary>:1 of
msgid "Dictionary holding ConfigsRecord instances."
msgstr ""

#: flwr.common.RecordSet.configs_records:1:<autosummary>:1 of
msgid ":py:obj:`metrics_records <flwr.common.RecordSet.metrics_records>`\\"
msgstr ""

#: flwr.common.RecordSet.configs_records:1:<autosummary>:1
#: flwr.common.RecordSet.metrics_records:1 of
msgid "Dictionary holding MetricsRecord instances."
msgstr ""

#: flwr.common.RecordSet.configs_records:1:<autosummary>:1 of
msgid ":py:obj:`parameters_records <flwr.common.RecordSet.parameters_records>`\\"
msgstr ""

#: flwr.common.RecordSet.configs_records:1:<autosummary>:1
#: flwr.common.RecordSet.parameters_records:1 of
msgid "Dictionary holding ParametersRecord instances."
msgstr ""

#: ../../source/ref-api/flwr.common.ServerMessage.rst:2
msgid "ServerMessage"
msgstr ""

#: ../../source/ref-api/flwr.common.ServerMessage.rst:31:<autosummary>:1
msgid ":py:obj:`evaluate_ins <flwr.common.ServerMessage.evaluate_ins>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.ServerMessage.rst:31:<autosummary>:1
msgid ":py:obj:`fit_ins <flwr.common.ServerMessage.fit_ins>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.ServerMessage.rst:31:<autosummary>:1
msgid ""
":py:obj:`get_parameters_ins "
"<flwr.common.ServerMessage.get_parameters_ins>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.ServerMessage.rst:31:<autosummary>:1
msgid ""
":py:obj:`get_properties_ins "
"<flwr.common.ServerMessage.get_properties_ins>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.Status.rst:2
msgid "Status"
msgstr ""

#: ../../source/ref-api/flwr.common.Status.rst:29:<autosummary>:1
msgid ":py:obj:`code <flwr.common.Status.code>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.Status.rst:29:<autosummary>:1
msgid ":py:obj:`message <flwr.common.Status.message>`\\"
msgstr ""

#: ../../source/ref-api/flwr.common.array_from_numpy.rst:2
msgid "array\\_from\\_numpy"
msgstr ""

#: ../../source/ref-api/flwr.common.bytes_to_ndarray.rst:2
msgid "bytes\\_to\\_ndarray"
msgstr ""

#: ../../source/ref-api/flwr.common.configure.rst:2
msgid "configure"
msgstr ""

#: ../../source/ref-api/flwr.common.event.rst:2
msgid "event"
msgstr ""

#: ../../source/ref-api/flwr.common.log.rst:2
msgid "log"
msgstr ""

#: logging.Logger.log:3 of
msgid ""
"To pass exception information, use the keyword argument exc_info with a "
"true value, e.g."
msgstr ""

#: logging.Logger.log:6 of
#, python-format
msgid "logger.log(level, \"We have a %s\", \"mysterious problem\", exc_info=1)"
msgstr ""

#: ../../source/ref-api/flwr.common.ndarray_to_bytes.rst:2
msgid "ndarray\\_to\\_bytes"
msgstr ""

#: ../../source/ref-api/flwr.common.ndarrays_to_parameters.rst:2
msgid "ndarrays\\_to\\_parameters"
msgstr ""

#: ../../source/ref-api/flwr.common.now.rst:2
msgid "now"
msgstr ""

#: ../../source/ref-api/flwr.common.parameters_to_ndarrays.rst:2
msgid "parameters\\_to\\_ndarrays"
msgstr ""

#: ../../source/ref-api/flwr.server.rst:2
msgid "server"
msgstr ""

#: ../../source/ref-api/flwr.server.rst:22:<autosummary>:1
msgid ""
":py:obj:`start_server <flwr.server.start_server>`\\ \\(\\*\\[\\, "
"server\\_address\\, server\\, ...\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.rst:22:<autosummary>:1
#: flwr.server.app.start_server:1 of
msgid "Start a Flower server using the gRPC transport layer."
msgstr ""

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
msgid ":py:obj:`ClientManager <flwr.server.ClientManager>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
#: flwr.server.client_manager.ClientManager:1 of
msgid "Abstract base class for managing Flower clients."
msgstr ""

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
msgid ":py:obj:`Driver <flwr.server.Driver>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
#: flwr.server.driver.driver.Driver:1 of
msgid "Abstract base Driver class for the ServerAppIo API."
msgstr ""

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
msgid ":py:obj:`History <flwr.server.History>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
#: flwr.server.history.History:1 of
msgid "History class for training and/or evaluation metrics collection."
msgstr ""

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
msgid ""
":py:obj:`LegacyContext <flwr.server.LegacyContext>`\\ \\(context\\[\\, "
"config\\, strategy\\, ...\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
#: flwr.server.compat.legacy_context.LegacyContext:1 of
msgid "Legacy Context."
msgstr ""

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
msgid ""
":py:obj:`Server <flwr.server.Server>`\\ \\(\\*\\, client\\_manager\\[\\, "
"strategy\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
msgid ""
":py:obj:`ServerApp <flwr.server.ServerApp>`\\ \\(\\[server\\, config\\, "
"strategy\\, ...\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
#: flwr.server.server_app.ServerApp:1 of
msgid "Flower ServerApp."
msgstr ""

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
msgid ""
":py:obj:`ServerAppComponents <flwr.server.ServerAppComponents>`\\ "
"\\(\\[server\\, config\\, ...\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
#: flwr.server.serverapp_components.ServerAppComponents:1 of
msgid "Components to construct a ServerApp."
msgstr ""

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
msgid ""
":py:obj:`ServerConfig <flwr.server.ServerConfig>`\\ \\(\\[num\\_rounds\\,"
" round\\_timeout\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
#: flwr.server.server_config.ServerConfig:1 of
msgid "Flower server config."
msgstr ""

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
msgid ":py:obj:`SimpleClientManager <flwr.server.SimpleClientManager>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
#: flwr.server.client_manager.SimpleClientManager:1 of
msgid "Provides a pool of available clients."
msgstr ""

#: ../../source/ref-api/flwr.server.rst:56:<autosummary>:1
msgid ":py:obj:`flwr.server.strategy <flwr.server.strategy>`\\"
msgstr ""

#: ../../source/ref-api/flwr.server.rst:56:<autosummary>:1
#: flwr.server.strategy:1 of
msgid "Contains the strategy abstraction and different implementations."
msgstr ""

#: ../../source/ref-api/flwr.server.rst:56:<autosummary>:1
msgid ":py:obj:`flwr.server.workflow <flwr.server.workflow>`\\"
msgstr ""

#: ../../source/ref-api/flwr.server.rst:56:<autosummary>:1
#: flwr.server.workflow:1 of
msgid "Workflows."
msgstr ""

#: ../../source/ref-api/flwr.server.ClientManager.rst:2
msgid "ClientManager"
msgstr ""

#: flwr.server.client_manager.ClientManager.all:1:<autosummary>:1 of
msgid ":py:obj:`all <flwr.server.ClientManager.all>`\\ \\(\\)"
msgstr ""

#: flwr.server.client_manager.ClientManager.all:1
#: flwr.server.client_manager.ClientManager.all:1:<autosummary>:1
#: flwr.server.client_manager.SimpleClientManager.all:1
#: flwr.server.client_manager.SimpleClientManager.all:1:<autosummary>:1 of
msgid "Return all available clients."
msgstr ""

#: flwr.server.client_manager.ClientManager.all:1:<autosummary>:1 of
msgid ":py:obj:`num_available <flwr.server.ClientManager.num_available>`\\ \\(\\)"
msgstr ""

#: flwr.server.client_manager.ClientManager.all:1:<autosummary>:1
#: flwr.server.client_manager.ClientManager.num_available:1
#: flwr.server.client_manager.SimpleClientManager.all:1:<autosummary>:1
#: flwr.server.client_manager.SimpleClientManager.num_available:1 of
msgid "Return the number of available clients."
msgstr ""

#: flwr.server.client_manager.ClientManager.all:1:<autosummary>:1 of
msgid ":py:obj:`register <flwr.server.ClientManager.register>`\\ \\(client\\)"
msgstr ""

#: flwr.server.client_manager.ClientManager.all:1:<autosummary>:1
#: flwr.server.client_manager.ClientManager.register:1
#: flwr.server.client_manager.SimpleClientManager.all:1:<autosummary>:1
#: flwr.server.client_manager.SimpleClientManager.register:1 of
msgid "Register Flower ClientProxy instance."
msgstr ""

#: flwr.server.client_manager.ClientManager.all:1:<autosummary>:1 of
msgid ""
":py:obj:`sample <flwr.server.ClientManager.sample>`\\ "
"\\(num\\_clients\\[\\, min\\_num\\_clients\\, criterion\\]\\)"
msgstr ""

#: flwr.server.client_manager.ClientManager.all:1:<autosummary>:1
#: flwr.server.client_manager.ClientManager.sample:1
#: flwr.server.client_manager.SimpleClientManager.all:1:<autosummary>:1
#: flwr.server.client_manager.SimpleClientManager.sample:1 of
msgid "Sample a number of Flower ClientProxy instances."
msgstr ""

#: flwr.server.client_manager.ClientManager.all:1:<autosummary>:1 of
msgid ":py:obj:`unregister <flwr.server.ClientManager.unregister>`\\ \\(client\\)"
msgstr ""

#: flwr.server.client_manager.ClientManager.all:1:<autosummary>:1
#: flwr.server.client_manager.ClientManager.unregister:1
#: flwr.server.client_manager.SimpleClientManager.all:1:<autosummary>:1
#: flwr.server.client_manager.SimpleClientManager.unregister:1 of
msgid "Unregister Flower ClientProxy instance."
msgstr ""

#: flwr.server.client_manager.ClientManager.all:1:<autosummary>:1 of
msgid ""
":py:obj:`wait_for <flwr.server.ClientManager.wait_for>`\\ "
"\\(num\\_clients\\, timeout\\)"
msgstr ""

#: flwr.server.client_manager.ClientManager.all:1:<autosummary>:1
#: flwr.server.client_manager.ClientManager.wait_for:1
#: flwr.server.client_manager.SimpleClientManager.all:1:<autosummary>:1
#: flwr.server.client_manager.SimpleClientManager.wait_for:1 of
msgid "Wait until at least `num_clients` are available."
msgstr ""

#: flwr.server.client_manager.ClientManager.num_available:3
#: flwr.server.client_manager.SimpleClientManager.num_available:3 of
msgid "**num_available** -- The number of currently available clients."
msgstr ""

#: flwr.server.client_manager.ClientManager.register:3 of
msgid "The ClientProxy of the Client to register."
msgstr ""

#: flwr.server.client_manager.ClientManager.register:6
#: flwr.server.client_manager.SimpleClientManager.register:6 of
msgid ""
"**success** -- Indicating if registration was successful. False if "
"ClientProxy is already registered or can not be registered for any "
"reason."
msgstr ""

#: flwr.server.client_manager.ClientManager.unregister:3
#: flwr.server.client_manager.SimpleClientManager.unregister:3 of
msgid "This method is idempotent."
msgstr ""

#: flwr.server.client_manager.ClientManager.unregister:5 of
msgid "The ClientProxy of the Client to unregister."
msgstr ""

#: ../../source/ref-api/flwr.server.Driver.rst:2
msgid "Driver"
msgstr ""

#: ../../source/ref-api/flwr.server.Driver.rst:41:<autosummary>:1
msgid ""
":py:obj:`create_message <flwr.server.Driver.create_message>`\\ "
"\\(content\\, message\\_type\\, ...\\[\\, ttl\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.Driver.rst:41:<autosummary>:1
#: flwr.server.driver.driver.Driver.create_message:1 of
msgid "Create a new message with specified parameters."
msgstr ""

#: ../../source/ref-api/flwr.server.Driver.rst:41:<autosummary>:1
msgid ":py:obj:`get_node_ids <flwr.server.Driver.get_node_ids>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.Driver.rst:41:<autosummary>:1
#: flwr.server.driver.driver.Driver.get_node_ids:1 of
msgid "Get node IDs."
msgstr ""

#: ../../source/ref-api/flwr.server.Driver.rst:41:<autosummary>:1
msgid ""
":py:obj:`pull_messages <flwr.server.Driver.pull_messages>`\\ "
"\\(message\\_ids\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.Driver.rst:41:<autosummary>:1
#: flwr.server.driver.driver.Driver.pull_messages:1 of
msgid "Pull messages based on message IDs."
msgstr ""

#: ../../source/ref-api/flwr.server.Driver.rst:41:<autosummary>:1
msgid ""
":py:obj:`push_messages <flwr.server.Driver.push_messages>`\\ "
"\\(messages\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.Driver.rst:41:<autosummary>:1
#: flwr.server.driver.driver.Driver.push_messages:1 of
msgid "Push messages to specified node IDs."
msgstr ""

#: ../../source/ref-api/flwr.server.Driver.rst:41:<autosummary>:1
msgid ""
":py:obj:`send_and_receive <flwr.server.Driver.send_and_receive>`\\ "
"\\(messages\\, \\*\\[\\, timeout\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.Driver.rst:41:<autosummary>:1
#: flwr.server.driver.driver.Driver.send_and_receive:1 of
msgid "Push messages to specified node IDs and pull the reply messages."
msgstr ""

#: ../../source/ref-api/flwr.server.Driver.rst:41:<autosummary>:1
msgid ":py:obj:`set_run <flwr.server.Driver.set_run>`\\ \\(run\\_id\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.Driver.rst:41:<autosummary>:1
#: flwr.server.driver.driver.Driver.set_run:1 of
msgid "Request a run to the SuperLink with a given `run_id`."
msgstr ""

#: flwr.server.driver.driver.Driver.create_message:1:<autosummary>:1 of
msgid ":py:obj:`run <flwr.server.Driver.run>`\\"
msgstr ""

#: flwr.server.Driver.run:1
#: flwr.server.driver.driver.Driver.create_message:1:<autosummary>:1 of
msgid "Run information."
msgstr ""

#: flwr.server.driver.driver.Driver.create_message:3 of
msgid ""
"This method constructs a new `Message` with given content and metadata. "
"The `run_id` and `src_node_id` will be set automatically."
msgstr ""

#: flwr.server.driver.driver.Driver.create_message:6 of
msgid ""
"The content for the new message. This holds records that are to be sent "
"to the destination node."
msgstr ""

#: flwr.server.driver.driver.Driver.create_message:9 of
msgid ""
"The type of the message, defining the action to be executed on the "
"receiving end."
msgstr ""

#: flwr.server.driver.driver.Driver.create_message:12 of
msgid "The ID of the destination node to which the message is being sent."
msgstr ""

#: flwr.server.driver.driver.Driver.create_message:14 of
msgid ""
"The ID of the group to which this message is associated. In some "
"settings, this is used as the FL round."
msgstr ""

#: flwr.server.driver.driver.Driver.create_message:17 of
msgid ""
"Time-to-live for the round trip of this message, i.e., the time from "
"sending this message to receiving a reply. It specifies in seconds the "
"duration for which the message and its potential reply are considered "
"valid. If unset, the default TTL (i.e., `common.DEFAULT_TTL`) will be "
"used."
msgstr ""

#: flwr.server.driver.driver.Driver.create_message:23 of
msgid ""
"**message** -- A new `Message` instance with the specified content and "
"metadata."
msgstr ""

#: flwr.server.driver.driver.Driver.pull_messages:3 of
msgid ""
"This method is used to collect messages from the SuperLink that "
"correspond to a set of given message IDs."
msgstr ""

#: flwr.server.driver.driver.Driver.pull_messages:6 of
msgid "An iterable of message IDs for which reply messages are to be retrieved."
msgstr ""

#: flwr.server.driver.driver.Driver.pull_messages:9 of
msgid "**messages** -- An iterable of messages received."
msgstr ""

#: flwr.server.driver.driver.Driver.push_messages:3 of
msgid ""
"This method takes an iterable of messages and sends each message to the "
"node specified in `dst_node_id`."
msgstr ""

#: flwr.server.driver.driver.Driver.push_messages:6
#: flwr.server.driver.driver.Driver.send_and_receive:7 of
msgid "An iterable of messages to be sent."
msgstr ""

#: flwr.server.driver.driver.Driver.push_messages:9 of
msgid ""
"**message_ids** -- An iterable of IDs for the messages that were sent, "
"which can be used to pull replies."
msgstr ""

#: flwr.server.driver.driver.Driver.send_and_receive:3 of
msgid ""
"This method sends a list of messages to their destination node IDs and "
"then waits for the replies. It continues to pull replies until either all"
" replies are received or the specified timeout duration is exceeded."
msgstr ""

#: flwr.server.driver.driver.Driver.send_and_receive:9 of
msgid ""
"The timeout duration in seconds. If specified, the method will wait for "
"replies for this duration. If `None`, there is no time limit and the "
"method will wait until replies for all messages are received."
msgstr ""

#: flwr.server.driver.driver.Driver.send_and_receive:14 of
msgid "**replies** -- An iterable of reply messages received from the SuperLink."
msgstr ""

#: flwr.server.driver.driver.Driver.send_and_receive:19 of
msgid ""
"This method uses `push_messages` to send the messages and `pull_messages`"
" to collect the replies. If `timeout` is set, the method may not return "
"replies for all sent messages. A message remains valid until its TTL, "
"which is not affected by `timeout`."
msgstr ""

#: flwr.server.driver.driver.Driver.set_run:3 of
msgid ""
"If a Run with the specified `run_id` exists, a local Run object will be "
"created. It enables further functionality in the driver, such as sending "
"`Messages`."
msgstr ""

#: flwr.server.driver.driver.Driver.set_run:7 of
msgid "The `run_id` of the Run this Driver object operates in."
msgstr ""

#: ../../source/ref-api/flwr.server.History.rst:2
msgid "History"
msgstr ""

#: flwr.server.history.History.add_loss_centralized:1:<autosummary>:1 of
msgid ""
":py:obj:`add_loss_centralized "
"<flwr.server.History.add_loss_centralized>`\\ \\(server\\_round\\, "
"loss\\)"
msgstr ""

#: flwr.server.history.History.add_loss_centralized:1
#: flwr.server.history.History.add_loss_centralized:1:<autosummary>:1 of
msgid "Add one loss entry (from centralized evaluation)."
msgstr ""

#: flwr.server.history.History.add_loss_centralized:1:<autosummary>:1 of
msgid ""
":py:obj:`add_loss_distributed "
"<flwr.server.History.add_loss_distributed>`\\ \\(server\\_round\\, "
"loss\\)"
msgstr ""

#: flwr.server.history.History.add_loss_centralized:1:<autosummary>:1
#: flwr.server.history.History.add_loss_distributed:1 of
msgid "Add one loss entry (from distributed evaluation)."
msgstr ""

#: flwr.server.history.History.add_loss_centralized:1:<autosummary>:1 of
msgid ""
":py:obj:`add_metrics_centralized "
"<flwr.server.History.add_metrics_centralized>`\\ \\(server\\_round\\, "
"metrics\\)"
msgstr ""

#: flwr.server.history.History.add_loss_centralized:1:<autosummary>:1
#: flwr.server.history.History.add_metrics_centralized:1 of
msgid "Add metrics entries (from centralized evaluation)."
msgstr ""

#: flwr.server.history.History.add_loss_centralized:1:<autosummary>:1 of
msgid ""
":py:obj:`add_metrics_distributed "
"<flwr.server.History.add_metrics_distributed>`\\ \\(server\\_round\\, "
"metrics\\)"
msgstr ""

#: flwr.server.history.History.add_loss_centralized:1:<autosummary>:1
#: flwr.server.history.History.add_metrics_distributed:1 of
msgid "Add metrics entries (from distributed evaluation)."
msgstr ""

#: flwr.server.history.History.add_loss_centralized:1:<autosummary>:1 of
msgid ""
":py:obj:`add_metrics_distributed_fit "
"<flwr.server.History.add_metrics_distributed_fit>`\\ \\(server\\_round\\,"
" ...\\)"
msgstr ""

#: flwr.server.history.History.add_loss_centralized:1:<autosummary>:1
#: flwr.server.history.History.add_metrics_distributed_fit:1 of
msgid "Add metrics entries (from distributed fit)."
msgstr ""

#: ../../source/ref-api/flwr.server.LegacyContext.rst:2
msgid "LegacyContext"
msgstr ""

#: flwr.server.compat.legacy_context.LegacyContext:1 of
msgid "Bases: :py:class:`~flwr.common.context.Context`"
msgstr ""

#: ../../source/ref-api/flwr.server.LegacyContext.rst:36:<autosummary>:1
msgid ":py:obj:`config <flwr.server.LegacyContext.config>`\\"
msgstr ""

#: ../../source/ref-api/flwr.server.LegacyContext.rst:36:<autosummary>:1
msgid ":py:obj:`strategy <flwr.server.LegacyContext.strategy>`\\"
msgstr ""

#: ../../source/ref-api/flwr.server.LegacyContext.rst:36:<autosummary>:1
msgid ":py:obj:`client_manager <flwr.server.LegacyContext.client_manager>`\\"
msgstr ""

#: ../../source/ref-api/flwr.server.LegacyContext.rst:36:<autosummary>:1
msgid ":py:obj:`history <flwr.server.LegacyContext.history>`\\"
msgstr ""

#: ../../source/ref-api/flwr.server.LegacyContext.rst:36:<autosummary>:1
msgid ":py:obj:`run_id <flwr.server.LegacyContext.run_id>`\\"
msgstr ""

#: ../../source/ref-api/flwr.server.LegacyContext.rst:36:<autosummary>:1
msgid ":py:obj:`node_id <flwr.server.LegacyContext.node_id>`\\"
msgstr ""

#: ../../source/ref-api/flwr.server.LegacyContext.rst:36:<autosummary>:1
msgid ":py:obj:`node_config <flwr.server.LegacyContext.node_config>`\\"
msgstr ""

#: ../../source/ref-api/flwr.server.LegacyContext.rst:36:<autosummary>:1
msgid ":py:obj:`state <flwr.server.LegacyContext.state>`\\"
msgstr ""

#: ../../source/ref-api/flwr.server.LegacyContext.rst:36:<autosummary>:1
msgid ":py:obj:`run_config <flwr.server.LegacyContext.run_config>`\\"
msgstr ""

#: ../../source/ref-api/flwr.server.Server.rst:2
msgid "Server"
msgstr ""

#: flwr.server.server.Server.client_manager:1:<autosummary>:1 of
msgid ":py:obj:`client_manager <flwr.server.Server.client_manager>`\\ \\(\\)"
msgstr ""

#: flwr.server.server.Server.client_manager:1
#: flwr.server.server.Server.client_manager:1:<autosummary>:1 of
msgid "Return ClientManager."
msgstr ""

#: flwr.server.server.Server.client_manager:1:<autosummary>:1 of
msgid ""
":py:obj:`disconnect_all_clients "
"<flwr.server.Server.disconnect_all_clients>`\\ \\(timeout\\)"
msgstr ""

#: flwr.server.server.Server.client_manager:1:<autosummary>:1
#: flwr.server.server.Server.disconnect_all_clients:1 of
msgid "Send shutdown signal to all clients."
msgstr ""

#: flwr.server.server.Server.client_manager:1:<autosummary>:1 of
msgid ""
":py:obj:`evaluate_round <flwr.server.Server.evaluate_round>`\\ "
"\\(server\\_round\\, timeout\\)"
msgstr ""

#: flwr.server.server.Server.client_manager:1:<autosummary>:1
#: flwr.server.server.Server.evaluate_round:1 of
msgid "Validate current global model on a number of clients."
msgstr ""

#: flwr.server.server.Server.client_manager:1:<autosummary>:1 of
msgid ":py:obj:`fit <flwr.server.Server.fit>`\\ \\(num\\_rounds\\, timeout\\)"
msgstr ""

#: flwr.server.server.Server.client_manager:1:<autosummary>:1
#: flwr.server.server.Server.fit:1 of
msgid "Run federated averaging for a number of rounds."
msgstr ""

#: flwr.server.server.Server.client_manager:1:<autosummary>:1 of
msgid ""
":py:obj:`fit_round <flwr.server.Server.fit_round>`\\ \\(server\\_round\\,"
" timeout\\)"
msgstr ""

#: flwr.server.server.Server.client_manager:1:<autosummary>:1
#: flwr.server.server.Server.fit_round:1 of
msgid "Perform a single round of federated averaging."
msgstr ""

#: flwr.server.server.Server.client_manager:1:<autosummary>:1 of
msgid ""
":py:obj:`set_max_workers <flwr.server.Server.set_max_workers>`\\ "
"\\(max\\_workers\\)"
msgstr ""

#: flwr.server.server.Server.client_manager:1:<autosummary>:1
#: flwr.server.server.Server.set_max_workers:1 of
msgid "Set the max_workers used by ThreadPoolExecutor."
msgstr ""

#: flwr.server.server.Server.client_manager:1:<autosummary>:1 of
msgid ":py:obj:`set_strategy <flwr.server.Server.set_strategy>`\\ \\(strategy\\)"
msgstr ""

#: flwr.server.server.Server.client_manager:1:<autosummary>:1
#: flwr.server.server.Server.set_strategy:1 of
msgid "Replace server strategy."
msgstr ""

#: flwr.server.server_app.ServerApp:5 of
msgid "Use the `ServerApp` with an existing `Strategy`:"
msgstr ""

#: flwr.server.server_app.ServerApp:17 of
msgid "Use the `ServerApp` with a custom main function:"
msgstr ""

#: flwr.server.server_app.ServerApp.main:1:<autosummary>:1 of
msgid ":py:obj:`main <flwr.server.ServerApp.main>`\\ \\(\\)"
msgstr ""

#: flwr.server.server_app.ServerApp.main:1
#: flwr.server.server_app.ServerApp.main:1:<autosummary>:1 of
msgid "Return a decorator that registers the main fn with the server app."
msgstr ""

#: ../../source/ref-api/flwr.server.ServerAppComponents.rst:2
msgid "ServerAppComponents"
msgstr ""

#: flwr.server.serverapp_components.ServerAppComponents:3 of
msgid ""
"A server implementation, either `flwr.server.Server` or a subclass "
"thereof. If no instance is provided, one will be created internally."
msgstr ""

#: flwr.server.app.start_server:14
#: flwr.server.serverapp_components.ServerAppComponents:6 of
msgid ""
"Currently supported values are `num_rounds` (int, default: 1) and "
"`round_timeout` in seconds (float, default: None)."
msgstr ""

#: flwr.server.serverapp_components.ServerAppComponents:9 of
msgid ""
"An implementation of the abstract base class "
"`flwr.server.strategy.Strategy`. If no strategy is provided, then "
"`flwr.server.strategy.FedAvg` will be used."
msgstr ""

#: flwr.server.serverapp_components.ServerAppComponents:13 of
msgid ""
"An implementation of the class `flwr.server.ClientManager`. If no "
"implementation is provided, then `flwr.server.SimpleClientManager` will "
"be used."
msgstr ""

#: ../../source/ref-api/flwr.server.ServerAppComponents.rst:31:<autosummary>:1
msgid ""
":py:obj:`client_manager "
"<flwr.server.ServerAppComponents.client_manager>`\\"
msgstr ""

#: ../../source/ref-api/flwr.server.ServerAppComponents.rst:31:<autosummary>:1
msgid ":py:obj:`config <flwr.server.ServerAppComponents.config>`\\"
msgstr ""

#: ../../source/ref-api/flwr.server.ServerAppComponents.rst:31:<autosummary>:1
msgid ":py:obj:`server <flwr.server.ServerAppComponents.server>`\\"
msgstr ""

#: ../../source/ref-api/flwr.server.ServerAppComponents.rst:31:<autosummary>:1
msgid ":py:obj:`strategy <flwr.server.ServerAppComponents.strategy>`\\"
msgstr ""

#: ../../source/ref-api/flwr.server.ServerConfig.rst:2
msgid "ServerConfig"
msgstr ""

#: flwr.server.server_config.ServerConfig:3 of
msgid ""
"All attributes have default values which allows users to configure just "
"the ones they care about."
msgstr ""

#: ../../source/ref-api/flwr.server.ServerConfig.rst:29:<autosummary>:1
msgid ":py:obj:`num_rounds <flwr.server.ServerConfig.num_rounds>`\\"
msgstr ""

#: ../../source/ref-api/flwr.server.ServerConfig.rst:29:<autosummary>:1
msgid ":py:obj:`round_timeout <flwr.server.ServerConfig.round_timeout>`\\"
msgstr ""

#: ../../source/ref-api/flwr.server.SimpleClientManager.rst:2
msgid "SimpleClientManager"
msgstr ""

#: flwr.server.client_manager.SimpleClientManager:1 of
msgid "Bases: :py:class:`~flwr.server.client_manager.ClientManager`"
msgstr ""

#: flwr.server.client_manager.SimpleClientManager.all:1:<autosummary>:1 of
msgid ":py:obj:`all <flwr.server.SimpleClientManager.all>`\\ \\(\\)"
msgstr ""

#: flwr.server.client_manager.SimpleClientManager.all:1:<autosummary>:1 of
msgid ""
":py:obj:`num_available <flwr.server.SimpleClientManager.num_available>`\\"
" \\(\\)"
msgstr ""

#: flwr.server.client_manager.SimpleClientManager.all:1:<autosummary>:1 of
msgid ""
":py:obj:`register <flwr.server.SimpleClientManager.register>`\\ "
"\\(client\\)"
msgstr ""

#: flwr.server.client_manager.SimpleClientManager.all:1:<autosummary>:1 of
msgid ""
":py:obj:`sample <flwr.server.SimpleClientManager.sample>`\\ "
"\\(num\\_clients\\[\\, min\\_num\\_clients\\, criterion\\]\\)"
msgstr ""

#: flwr.server.client_manager.SimpleClientManager.all:1:<autosummary>:1 of
msgid ""
":py:obj:`unregister <flwr.server.SimpleClientManager.unregister>`\\ "
"\\(client\\)"
msgstr ""

#: flwr.server.client_manager.SimpleClientManager.all:1:<autosummary>:1 of
msgid ""
":py:obj:`wait_for <flwr.server.SimpleClientManager.wait_for>`\\ "
"\\(num\\_clients\\[\\, timeout\\]\\)"
msgstr ""

#: flwr.server.client_manager.SimpleClientManager.wait_for:3 of
msgid ""
"Blocks until the requested number of clients is available or until a "
"timeout is reached. Current timeout default: 1 day."
msgstr ""

#: flwr.server.client_manager.SimpleClientManager.wait_for:6 of
msgid "The number of clients to wait for."
msgstr ""

#: flwr.server.client_manager.SimpleClientManager.wait_for:8 of
msgid "The time in seconds to wait for, defaults to 86400 (24h)."
msgstr ""

#: flwr.server.client_manager.SimpleClientManager.wait_for:11 of
msgid "**success**"
msgstr ""

#: ../../source/ref-api/flwr.server.start_server.rst:2
msgid "start\\_server"
msgstr ""

#: flwr.server.app.start_server:5 of
msgid ""
"This function is deprecated since 1.13.0. Use the :code:`flower-"
"superlink` command instead to start a SuperLink."
msgstr ""

#: flwr.server.app.start_server:8 of
msgid "The IPv4 or IPv6 address of the server. Defaults to `\"[::]:8080\"`."
msgstr ""

#: flwr.server.app.start_server:10 of
msgid ""
"A server implementation, either `flwr.server.Server` or a subclass "
"thereof. If no instance is provided, then `start_server` will create one."
msgstr ""

#: flwr.server.app.start_server:17 of
msgid ""
"An implementation of the abstract base class "
"`flwr.server.strategy.Strategy`. If no strategy is provided, then "
"`start_server` will use `flwr.server.strategy.FedAvg`."
msgstr ""

#: flwr.server.app.start_server:21 of
msgid ""
"An implementation of the abstract base class `flwr.server.ClientManager`."
" If no implementation is provided, then `start_server` will use "
"`flwr.server.client_manager.SimpleClientManager`."
msgstr ""

#: flwr.server.app.start_server:26 of
msgid ""
"The maximum length of gRPC messages that can be exchanged with the Flower"
" clients. The default should be sufficient for most models. Users who "
"train very large models might need to increase this value. Note that the "
"Flower clients need to be started with the same value (see "
"`flwr.client.start_client`), otherwise clients will not know about the "
"increased limit and block larger messages."
msgstr ""

#: flwr.server.app.start_server:33 of
msgid ""
"Tuple containing root certificate, server certificate, and private key to"
" start a secure SSL-enabled server. The tuple is expected to have three "
"bytes elements in the following order:      * CA certificate.     * "
"server certificate.     * server private key."
msgstr ""

#: flwr.server.app.start_server:33 of
msgid ""
"Tuple containing root certificate, server certificate, and private key to"
" start a secure SSL-enabled server. The tuple is expected to have three "
"bytes elements in the following order:"
msgstr ""

#: flwr.server.app.start_server:37 of
msgid "CA certificate."
msgstr ""

#: flwr.server.app.start_server:38 of
msgid "server certificate."
msgstr ""

#: flwr.server.app.start_server:39 of
msgid "server private key."
msgstr ""

#: flwr.server.app.start_server:42 of
msgid "**hist** -- Object containing training and evaluation metrics."
msgstr ""

#: flwr.server.app.start_server:47 of
msgid "Starting an insecure server:"
msgstr ""

#: flwr.server.app.start_server:51 of
msgid "Starting an SSL-enabled server:"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:2
msgid "strategy"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
msgid ""
":py:obj:`Bulyan <flwr.server.strategy.Bulyan>`\\ \\(\\*\\, "
"fraction\\_fit\\, fraction\\_evaluate\\, ...\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.bulyan.Bulyan:1 of
msgid "Bulyan strategy."
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
msgid ""
":py:obj:`DPFedAvgAdaptive <flwr.server.strategy.DPFedAvgAdaptive>`\\ "
"\\(strategy\\, num\\_sampled\\_clients\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.dpfedavg_adaptive.DPFedAvgAdaptive:1 of
msgid "Wrapper for configuring a Strategy for DP with Adaptive Clipping."
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
msgid ""
":py:obj:`DPFedAvgFixed <flwr.server.strategy.DPFedAvgFixed>`\\ "
"\\(strategy\\, num\\_sampled\\_clients\\, ...\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed:1 of
msgid "Wrapper for configuring a Strategy for DP with Fixed Clipping."
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
msgid ""
":py:obj:`DifferentialPrivacyClientSideAdaptiveClipping "
"<flwr.server.strategy.DifferentialPrivacyClientSideAdaptiveClipping>`\\ "
"\\(...\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping:1
#: of
msgid "Strategy wrapper for central DP with client-side adaptive clipping."
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
msgid ""
":py:obj:`DifferentialPrivacyClientSideFixedClipping "
"<flwr.server.strategy.DifferentialPrivacyClientSideFixedClipping>`\\ "
"\\(...\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping:1
#: of
msgid "Strategy wrapper for central DP with client-side fixed clipping."
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
msgid ""
":py:obj:`DifferentialPrivacyServerSideAdaptiveClipping "
"<flwr.server.strategy.DifferentialPrivacyServerSideAdaptiveClipping>`\\ "
"\\(...\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping:1
#: of
msgid "Strategy wrapper for central DP with server-side adaptive clipping."
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
msgid ""
":py:obj:`DifferentialPrivacyServerSideFixedClipping "
"<flwr.server.strategy.DifferentialPrivacyServerSideFixedClipping>`\\ "
"\\(...\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping:1
#: of
msgid "Strategy wrapper for central DP with server-side fixed clipping."
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
msgid ""
":py:obj:`FaultTolerantFedAvg "
"<flwr.server.strategy.FaultTolerantFedAvg>`\\ \\(\\*\\[\\, "
"fraction\\_fit\\, ...\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg:1 of
msgid "Configurable fault-tolerant FedAvg strategy implementation."
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
msgid ""
":py:obj:`FedAdagrad <flwr.server.strategy.FedAdagrad>`\\ \\(\\*\\[\\, "
"fraction\\_fit\\, ...\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.fedadagrad.FedAdagrad:1 of
msgid "FedAdagrad strategy - Adaptive Federated Optimization using Adagrad."
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
msgid ""
":py:obj:`FedAdam <flwr.server.strategy.FedAdam>`\\ \\(\\*\\[\\, "
"fraction\\_fit\\, ...\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.fedadam.FedAdam:1 of
msgid "FedAdam - Adaptive Federated Optimization using Adam."
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
msgid ""
":py:obj:`FedAvg <flwr.server.strategy.FedAvg>`\\ \\(\\*\\[\\, "
"fraction\\_fit\\, fraction\\_evaluate\\, ...\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.fedavg.FedAvg:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid:1 of
msgid "Federated Averaging strategy."
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
msgid ""
":py:obj:`FedAvgAndroid <flwr.server.strategy.FedAvgAndroid>`\\ "
"\\(\\*\\[\\, fraction\\_fit\\, ...\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
msgid ""
":py:obj:`FedAvgM <flwr.server.strategy.FedAvgM>`\\ \\(\\*\\[\\, "
"fraction\\_fit\\, ...\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.fedavgm.FedAvgM:1 of
msgid "Federated Averaging with Momentum strategy."
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
msgid ""
":py:obj:`FedMedian <flwr.server.strategy.FedMedian>`\\ \\(\\*\\[\\, "
"fraction\\_fit\\, ...\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.fedmedian.FedMedian:1 of
msgid "Configurable FedMedian strategy implementation."
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
msgid ""
":py:obj:`FedOpt <flwr.server.strategy.FedOpt>`\\ \\(\\*\\[\\, "
"fraction\\_fit\\, fraction\\_evaluate\\, ...\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.fedopt.FedOpt:1 of
msgid "Federated Optim strategy."
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
msgid ""
":py:obj:`FedProx <flwr.server.strategy.FedProx>`\\ \\(\\*\\[\\, "
"fraction\\_fit\\, ...\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.fedprox.FedProx:1 of
msgid "Federated Optimization strategy."
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
msgid ""
":py:obj:`FedTrimmedAvg <flwr.server.strategy.FedTrimmedAvg>`\\ "
"\\(\\*\\[\\, fraction\\_fit\\, ...\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg:1 of
msgid "Federated Averaging with Trimmed Mean [Dong Yin, et al., 2021]."
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
msgid ""
":py:obj:`FedXgbBagging <flwr.server.strategy.FedXgbBagging>`\\ "
"\\(\\[evaluate\\_function\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging:1 of
msgid "Configurable FedXgbBagging strategy implementation."
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
msgid ""
":py:obj:`FedXgbCyclic <flwr.server.strategy.FedXgbCyclic>`\\ "
"\\(\\*\\*kwargs\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic:1 of
msgid "Configurable FedXgbCyclic strategy implementation."
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
msgid ""
":py:obj:`FedXgbNnAvg <flwr.server.strategy.FedXgbNnAvg>`\\ \\(\\*args\\, "
"\\*\\*kwargs\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.fedxgb_nn_avg.FedXgbNnAvg:1 of
msgid "Configurable FedXgbNnAvg strategy implementation."
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
msgid ""
":py:obj:`FedYogi <flwr.server.strategy.FedYogi>`\\ \\(\\*\\[\\, "
"fraction\\_fit\\, ...\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.fedyogi.FedYogi:1 of
msgid "FedYogi [Reddi et al., 2020] strategy."
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
msgid ""
":py:obj:`Krum <flwr.server.strategy.Krum>`\\ \\(\\*\\[\\, "
"fraction\\_fit\\, fraction\\_evaluate\\, ...\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.krum.Krum:1 of
msgid "Krum [Blanchard et al., 2017] strategy."
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
msgid ""
":py:obj:`QFedAvg <flwr.server.strategy.QFedAvg>`\\ \\(\\*\\[\\, "
"q\\_param\\, qffl\\_learning\\_rate\\, ...\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.qfedavg.QFedAvg:1 of
msgid "Configurable QFedAvg strategy implementation."
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
msgid ":py:obj:`Strategy <flwr.server.strategy.Strategy>`\\ \\(\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.strategy.Strategy:1 of
msgid "Abstract base class for server strategy implementations."
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.Bulyan.rst:2
msgid "Bulyan"
msgstr ""

#: flwr.server.strategy.bulyan.Bulyan:1
#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg:1
#: flwr.server.strategy.fedavgm.FedAvgM:1
#: flwr.server.strategy.fedmedian.FedMedian:1
#: flwr.server.strategy.fedopt.FedOpt:1 flwr.server.strategy.fedprox.FedProx:1
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg:1
#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging:1
#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic:1
#: flwr.server.strategy.fedxgb_nn_avg.FedXgbNnAvg:1
#: flwr.server.strategy.krum.Krum:1 flwr.server.strategy.qfedavg.QFedAvg:1 of
msgid "Bases: :py:class:`~flwr.server.strategy.fedavg.FedAvg`"
msgstr ""

#: flwr.server.strategy.bulyan.Bulyan:3 of
msgid "Implementation based on https://arxiv.org/abs/1802.07927."
msgstr ""

#: flwr.server.strategy.bulyan.Bulyan:5
#: flwr.server.strategy.fedadagrad.FedAdagrad:5
#: flwr.server.strategy.fedadam.FedAdam:5
#: flwr.server.strategy.fedavg_android.FedAvgAndroid:5
#: flwr.server.strategy.fedavgm.FedAvgM:5 flwr.server.strategy.fedopt.FedOpt:5
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg:5
#: flwr.server.strategy.fedyogi.FedYogi:5 flwr.server.strategy.krum.Krum:5 of
msgid "Fraction of clients used during training. Defaults to 1.0."
msgstr ""

#: flwr.server.strategy.bulyan.Bulyan:7
#: flwr.server.strategy.fedadagrad.FedAdagrad:7
#: flwr.server.strategy.fedadam.FedAdam:7
#: flwr.server.strategy.fedavg_android.FedAvgAndroid:7
#: flwr.server.strategy.fedavgm.FedAvgM:7 flwr.server.strategy.fedopt.FedOpt:7
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg:7
#: flwr.server.strategy.fedyogi.FedYogi:7 flwr.server.strategy.krum.Krum:7 of
msgid "Fraction of clients used during validation. Defaults to 1.0."
msgstr ""

#: flwr.server.strategy.bulyan.Bulyan:9
#: flwr.server.strategy.fedadagrad.FedAdagrad:9
#: flwr.server.strategy.fedadam.FedAdam:9 flwr.server.strategy.fedavg.FedAvg:13
#: flwr.server.strategy.fedavg_android.FedAvgAndroid:9
#: flwr.server.strategy.fedavgm.FedAvgM:9 flwr.server.strategy.fedopt.FedOpt:9
#: flwr.server.strategy.fedprox.FedProx:45
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg:9
#: flwr.server.strategy.fedyogi.FedYogi:9 flwr.server.strategy.krum.Krum:9 of
msgid "Minimum number of clients used during training. Defaults to 2."
msgstr ""

#: flwr.server.strategy.bulyan.Bulyan:11
#: flwr.server.strategy.fedadagrad.FedAdagrad:11
#: flwr.server.strategy.fedadam.FedAdam:11
#: flwr.server.strategy.fedavg.FedAvg:15
#: flwr.server.strategy.fedavg_android.FedAvgAndroid:11
#: flwr.server.strategy.fedavgm.FedAvgM:11
#: flwr.server.strategy.fedopt.FedOpt:11
#: flwr.server.strategy.fedprox.FedProx:47
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg:11
#: flwr.server.strategy.fedyogi.FedYogi:11 flwr.server.strategy.krum.Krum:11 of
msgid "Minimum number of clients used during validation. Defaults to 2."
msgstr ""

#: flwr.server.strategy.bulyan.Bulyan:13
#: flwr.server.strategy.fedadagrad.FedAdagrad:13
#: flwr.server.strategy.fedadam.FedAdam:13
#: flwr.server.strategy.fedavg.FedAvg:17
#: flwr.server.strategy.fedavg_android.FedAvgAndroid:13
#: flwr.server.strategy.fedavgm.FedAvgM:13
#: flwr.server.strategy.fedopt.FedOpt:13
#: flwr.server.strategy.fedprox.FedProx:49
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg:13
#: flwr.server.strategy.fedyogi.FedYogi:13 flwr.server.strategy.krum.Krum:13 of
msgid "Minimum number of total clients in the system. Defaults to 2."
msgstr ""

#: flwr.server.strategy.bulyan.Bulyan:15 flwr.server.strategy.krum.Krum:15 of
msgid "Number of malicious clients in the system. Defaults to 0."
msgstr ""

#: flwr.server.strategy.bulyan.Bulyan:17
#: flwr.server.strategy.fedadagrad.FedAdagrad:15
#: flwr.server.strategy.fedadam.FedAdam:15
#: flwr.server.strategy.fedavg.FedAvg:19
#: flwr.server.strategy.fedavg_android.FedAvgAndroid:15
#: flwr.server.strategy.fedavgm.FedAvgM:15
#: flwr.server.strategy.fedopt.FedOpt:15
#: flwr.server.strategy.fedprox.FedProx:51
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg:15
#: flwr.server.strategy.fedyogi.FedYogi:17
#: flwr.server.strategy.fedyogi.FedYogi:18
#: flwr.server.strategy.fedyogi.FedYogi:19 flwr.server.strategy.krum.Krum:20 of
msgid "Optional function used for validation. Defaults to None."
msgstr ""

#: flwr.server.strategy.bulyan.Bulyan:19
#: flwr.server.strategy.fedadagrad.FedAdagrad:17
#: flwr.server.strategy.fedadam.FedAdam:17
#: flwr.server.strategy.fedavg.FedAvg:21
#: flwr.server.strategy.fedavg_android.FedAvgAndroid:17
#: flwr.server.strategy.fedavgm.FedAvgM:17
#: flwr.server.strategy.fedopt.FedOpt:17
#: flwr.server.strategy.fedprox.FedProx:53
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg:17
#: flwr.server.strategy.fedyogi.FedYogi:20 flwr.server.strategy.krum.Krum:22 of
msgid "Function used to configure training. Defaults to None."
msgstr ""

#: flwr.server.strategy.bulyan.Bulyan:21
#: flwr.server.strategy.fedadagrad.FedAdagrad:19
#: flwr.server.strategy.fedadam.FedAdam:19
#: flwr.server.strategy.fedavg.FedAvg:23
#: flwr.server.strategy.fedavg_android.FedAvgAndroid:19
#: flwr.server.strategy.fedavgm.FedAvgM:19
#: flwr.server.strategy.fedopt.FedOpt:19
#: flwr.server.strategy.fedprox.FedProx:55
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg:19
#: flwr.server.strategy.fedyogi.FedYogi:22 flwr.server.strategy.krum.Krum:24 of
msgid "Function used to configure validation. Defaults to None."
msgstr ""

#: flwr.server.strategy.bulyan.Bulyan:23
#: flwr.server.strategy.fedadagrad.FedAdagrad:25
#: flwr.server.strategy.fedadam.FedAdam:21
#: flwr.server.strategy.fedavg.FedAvg:25
#: flwr.server.strategy.fedavg_android.FedAvgAndroid:21
#: flwr.server.strategy.fedavgm.FedAvgM:21
#: flwr.server.strategy.fedopt.FedOpt:21
#: flwr.server.strategy.fedprox.FedProx:57
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg:21
#: flwr.server.strategy.fedyogi.FedYogi:24 flwr.server.strategy.krum.Krum:26 of
msgid "Whether or not accept rounds containing failures. Defaults to True."
msgstr ""

#: flwr.server.strategy.bulyan.Bulyan:25
#: flwr.server.strategy.fedadagrad.FedAdagrad:27
#: flwr.server.strategy.fedadam.FedAdam:23
#: flwr.server.strategy.fedavg.FedAvg:27
#: flwr.server.strategy.fedavg_android.FedAvgAndroid:24
#: flwr.server.strategy.fedavgm.FedAvgM:23
#: flwr.server.strategy.fedopt.FedOpt:23
#: flwr.server.strategy.fedprox.FedProx:59
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg:23
#: flwr.server.strategy.fedyogi.FedYogi:26 flwr.server.strategy.krum.Krum:28 of
msgid "Initial global model parameters."
msgstr ""

#: flwr.server.strategy.bulyan.Bulyan:27 of
msgid ""
"Byzantine resilient aggregation rule that is used as the first step of "
"the Bulyan (e.g., Krum)"
msgstr ""

#: flwr.server.strategy.bulyan.Bulyan:29 of
msgid "arguments to the first_aggregation rule"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.Bulyan.aggregate_evaluate>`\\ \\(server\\_round\\, "
"results\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1
#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1
#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1
#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid "Aggregate evaluation losses using weighted average."
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`aggregate_fit <flwr.server.strategy.Bulyan.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""

#: flwr.server.strategy.bulyan.Bulyan.aggregate_fit:1
#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid "Aggregate fit results using Bulyan."
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.Bulyan.configure_evaluate>`\\ \\(server\\_round\\, "
"parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.configure_evaluate:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.configure_evaluate:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.configure_evaluate:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.configure_evaluate:1
#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg.FedAvg.configure_evaluate:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.configure_evaluate:1
#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.configure_evaluate:1
#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.qfedavg.QFedAvg.configure_evaluate:1
#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.strategy.Strategy.configure_evaluate:1 of
msgid "Configure the next round of evaluation."
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`configure_fit <flwr.server.strategy.Bulyan.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.configure_fit:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.configure_fit:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.configure_fit:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.configure_fit:1
#: flwr.server.strategy.dpfedavg_adaptive.DPFedAvgAdaptive.configure_fit:1
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg.FedAvg.configure_fit:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.configure_fit:1
#: flwr.server.strategy.fedprox.FedProx.configure_fit:1
#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.configure_fit:1
#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.qfedavg.QFedAvg.configure_fit:1
#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.strategy.Strategy.configure_fit:1 of
msgid "Configure the next round of training."
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`evaluate <flwr.server.strategy.Bulyan.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg.FedAvg.evaluate:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.evaluate:1
#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.evaluate:1
#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedxgb_nn_avg.FedXgbNnAvg.evaluate:1
#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid "Evaluate model parameters using an evaluation function."
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.Bulyan.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg.FedAvg.initialize_parameters:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.initialize_parameters:1
#: flwr.server.strategy.fedavgm.FedAvgM.initialize_parameters:1
#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid "Initialize global model parameters."
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.Bulyan.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg.FedAvg.num_evaluation_clients:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.num_evaluation_clients:1
#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.qfedavg.QFedAvg.num_evaluation_clients:1 of
msgid "Use a fraction of available clients for evaluation."
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`num_fit_clients <flwr.server.strategy.Bulyan.num_fit_clients>`\\"
" \\(num\\_available\\_clients\\)"
msgstr ""

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg.FedAvg.num_fit_clients:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.num_fit_clients:1
#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.qfedavg.QFedAvg.num_fit_clients:1 of
msgid "Return the sample size and the required number of available clients."
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.DPFedAvgAdaptive.rst:2
msgid "DPFedAvgAdaptive"
msgstr ""

#: flwr.server.strategy.dpfedavg_adaptive.DPFedAvgAdaptive:1 of
msgid "Bases: :py:class:`~flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed`"
msgstr ""

#: flwr.server.strategy.dpfedavg_adaptive.DPFedAvgAdaptive:3
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed:3 of
msgid "This class is deprecated and will be removed in a future release."
msgstr ""

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.DPFedAvgAdaptive.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_evaluate:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_evaluate:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.aggregate_evaluate:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.aggregate_evaluate:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: of
msgid "Aggregate evaluation losses using the given strategy."
msgstr ""

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.DPFedAvgAdaptive.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""

#: flwr.server.strategy.dpfedavg_adaptive.DPFedAvgAdaptive.aggregate_fit:1
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: of
msgid "Aggregate training results as in DPFedAvgFixed and update clip norms."
msgstr ""

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.DPFedAvgAdaptive.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_evaluate:1 of
msgid "Configure the next round of evaluation using the specified strategy."
msgstr ""

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`configure_fit "
"<flwr.server.strategy.DPFedAvgAdaptive.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`evaluate <flwr.server.strategy.DPFedAvgAdaptive.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.evaluate:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.evaluate:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.evaluate:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.evaluate:1
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.evaluate:1 of
msgid "Evaluate model parameters using an evaluation function from the strategy."
msgstr ""

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.DPFedAvgAdaptive.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.initialize_parameters:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.initialize_parameters:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.initialize_parameters:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.initialize_parameters:1
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.initialize_parameters:1 of
msgid "Initialize global model parameters using given strategy."
msgstr ""

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_evaluate:3
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_fit:6
#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:3
#: flwr.server.strategy.strategy.Strategy.aggregate_fit:3
#: flwr.server.strategy.strategy.Strategy.configure_evaluate:3
#: flwr.server.strategy.strategy.Strategy.configure_fit:3
#: flwr.server.strategy.strategy.Strategy.evaluate:6 of
msgid "The current round of federated learning."
msgstr ""

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_evaluate:7
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_fit:10
#: flwr.server.strategy.strategy.Strategy.configure_evaluate:7
#: flwr.server.strategy.strategy.Strategy.configure_fit:7
#: flwr.server.strategy.strategy.Strategy.initialize_parameters:3 of
msgid "The client manager which holds all currently connected clients."
msgstr ""

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_evaluate:10
#: flwr.server.strategy.strategy.Strategy.configure_evaluate:10 of
msgid ""
"**evaluate_configuration** -- A list of tuples. Each tuple in the list "
"identifies a `ClientProxy` and the `EvaluateIns` for this particular "
"`ClientProxy`. If a particular `ClientProxy` is not included in this "
"list, it means that this `ClientProxy` will not participate in the next "
"round of federated evaluation."
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.DPFedAvgFixed.rst:2
msgid "DPFedAvgFixed"
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping:1
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed:1
#: flwr.server.strategy.fedavg.FedAvg:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid:1 of
msgid "Bases: :py:class:`~flwr.server.strategy.strategy.Strategy`"
msgstr ""

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.DPFedAvgFixed.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"
msgstr ""

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.DPFedAvgFixed.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_fit:1 of
msgid "Aggregate training results using unweighted aggregation."
msgstr ""

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.DPFedAvgFixed.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`configure_fit "
"<flwr.server.strategy.DPFedAvgFixed.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_fit:1 of
msgid ""
"Configure the next round of training incorporating Differential Privacy "
"(DP)."
msgstr ""

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`evaluate <flwr.server.strategy.DPFedAvgFixed.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.DPFedAvgFixed.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_fit:3 of
msgid ""
"Configuration of the next training round includes information related to "
"DP, such as clip norm and noise stddev."
msgstr ""

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_fit:13
#: flwr.server.strategy.strategy.Strategy.configure_fit:10 of
msgid ""
"**fit_configuration** -- A list of tuples. Each tuple in the list "
"identifies a `ClientProxy` and the `FitIns` for this particular "
"`ClientProxy`. If a particular `ClientProxy` is not included in this "
"list, it means that this `ClientProxy` will not participate in the next "
"round of federated learning."
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.DifferentialPrivacyClientSideAdaptiveClipping.rst:2
msgid "DifferentialPrivacyClientSideAdaptiveClipping"
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping:3
#: of
msgid "Use `adaptiveclipping_mod` modifier at the client side."
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping:5
#: of
msgid ""
"In comparison to `DifferentialPrivacyServerSideAdaptiveClipping`, which "
"performs clipping on the server-side, "
"`DifferentialPrivacyClientSideAdaptiveClipping` expects clipping to "
"happen on the client-side, usually by using the built-in "
"`adaptiveclipping_mod`."
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping:10
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping:3
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping:10
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping:3
#: of
msgid "The strategy to which DP functionalities will be added by this wrapper."
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping:12
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping:5
#: of
msgid "The noise multiplier for the Gaussian mechanism for model updates."
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping:14
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping:7
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping:17
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping:10
#: of
msgid "The number of clients that are sampled on each round."
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping:16
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping:9
#: of
msgid ""
"The initial value of clipping norm. Defaults to 0.1. Andrew et al. "
"recommends to set to 0.1."
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping:19
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping:12
#: of
msgid "The desired quantile of updates which should be clipped. Defaults to 0.5."
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping:21
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping:14
#: of
msgid ""
"The learning rate for the clipping norm adaptation. Defaults to 0.2. "
"Andrew et al. recommends to set to 0.2."
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping:24
#: of
msgid ""
"The stddev of the noise added to the count of updates currently below the"
" estimate. Andrew et al. recommends to set to `expected_num_records/20`"
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping:30
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping:23
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping:22
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping:15
#: of
msgid "Create a strategy:"
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping:34
#: of
msgid ""
"Wrap the strategy with the "
"`DifferentialPrivacyClientSideAdaptiveClipping` wrapper:"
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping:40
#: of
msgid "On the client, add the `adaptiveclipping_mod` to the client-side mods:"
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_evaluate>`\\"
" \\(server\\_round\\, results\\, ...\\)"
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_fit>`\\"
" \\(server\\_round\\, results\\, failures\\)"
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_fit:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_fit:1
#: of
msgid "Aggregate training results and update clip norms."
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.DifferentialPrivacyClientSideAdaptiveClipping.configure_evaluate>`\\"
" \\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`configure_fit "
"<flwr.server.strategy.DifferentialPrivacyClientSideAdaptiveClipping.configure_fit>`\\"
" \\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`evaluate "
"<flwr.server.strategy.DifferentialPrivacyClientSideAdaptiveClipping.evaluate>`\\"
" \\(server\\_round\\, parameters\\)"
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.DifferentialPrivacyClientSideAdaptiveClipping.initialize_parameters>`\\"
" \\(client\\_manager\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.DifferentialPrivacyClientSideFixedClipping.rst:2
msgid "DifferentialPrivacyClientSideFixedClipping"
msgstr ""

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping:3
#: of
msgid "Use `fixedclipping_mod` modifier at the client side."
msgstr ""

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping:5
#: of
msgid ""
"In comparison to `DifferentialPrivacyServerSideFixedClipping`, which "
"performs clipping on the server-side, "
"`DifferentialPrivacyClientSideFixedClipping` expects clipping to happen "
"on the client-side, usually by using the built-in `fixedclipping_mod`."
msgstr ""

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping:12
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping:5
#: of
msgid ""
"The noise multiplier for the Gaussian mechanism for model updates. A "
"value of 1.0 or higher is recommended for strong privacy."
msgstr ""

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping:26
#: of
msgid ""
"Wrap the strategy with the `DifferentialPrivacyClientSideFixedClipping` "
"wrapper:"
msgstr ""

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping:32
#: of
msgid "On the client, add the `fixedclipping_mod` to the client-side mods:"
msgstr ""

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.DifferentialPrivacyClientSideFixedClipping.aggregate_evaluate>`\\"
" \\(server\\_round\\, results\\, ...\\)"
msgstr ""

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.DifferentialPrivacyClientSideFixedClipping.aggregate_fit>`\\"
" \\(server\\_round\\, results\\, failures\\)"
msgstr ""

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.aggregate_fit:1
#: of
msgid "Add noise to the aggregated parameters."
msgstr ""

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.DifferentialPrivacyClientSideFixedClipping.configure_evaluate>`\\"
" \\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`configure_fit "
"<flwr.server.strategy.DifferentialPrivacyClientSideFixedClipping.configure_fit>`\\"
" \\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`evaluate "
"<flwr.server.strategy.DifferentialPrivacyClientSideFixedClipping.evaluate>`\\"
" \\(server\\_round\\, parameters\\)"
msgstr ""

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.DifferentialPrivacyClientSideFixedClipping.initialize_parameters>`\\"
" \\(client\\_manager\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.DifferentialPrivacyServerSideAdaptiveClipping.rst:2
msgid "DifferentialPrivacyServerSideAdaptiveClipping"
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping:17
#: of
msgid ""
"The standard deviation of the noise added to the count of updates below "
"the estimate. Andrew et al. recommends to set to "
"`expected_num_records/20`"
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping:27
#: of
msgid ""
"Wrap the strategy with the DifferentialPrivacyServerSideAdaptiveClipping "
"wrapper"
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_evaluate>`\\"
" \\(server\\_round\\, results\\, ...\\)"
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_fit>`\\"
" \\(server\\_round\\, results\\, failures\\)"
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.DifferentialPrivacyServerSideAdaptiveClipping.configure_evaluate>`\\"
" \\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`configure_fit "
"<flwr.server.strategy.DifferentialPrivacyServerSideAdaptiveClipping.configure_fit>`\\"
" \\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`evaluate "
"<flwr.server.strategy.DifferentialPrivacyServerSideAdaptiveClipping.evaluate>`\\"
" \\(server\\_round\\, parameters\\)"
msgstr ""

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.DifferentialPrivacyServerSideAdaptiveClipping.initialize_parameters>`\\"
" \\(client\\_manager\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.DifferentialPrivacyServerSideFixedClipping.rst:2
msgid "DifferentialPrivacyServerSideFixedClipping"
msgstr ""

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping:19
#: of
msgid ""
"Wrap the strategy with the DifferentialPrivacyServerSideFixedClipping "
"wrapper"
msgstr ""

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.DifferentialPrivacyServerSideFixedClipping.aggregate_evaluate>`\\"
" \\(server\\_round\\, results\\, ...\\)"
msgstr ""

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.DifferentialPrivacyServerSideFixedClipping.aggregate_fit>`\\"
" \\(server\\_round\\, results\\, failures\\)"
msgstr ""

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.aggregate_fit:1
#: of
msgid "Compute the updates, clip, and pass them for aggregation."
msgstr ""

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.DifferentialPrivacyServerSideFixedClipping.configure_evaluate>`\\"
" \\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`configure_fit "
"<flwr.server.strategy.DifferentialPrivacyServerSideFixedClipping.configure_fit>`\\"
" \\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`evaluate "
"<flwr.server.strategy.DifferentialPrivacyServerSideFixedClipping.evaluate>`\\"
" \\(server\\_round\\, parameters\\)"
msgstr ""

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.DifferentialPrivacyServerSideFixedClipping.initialize_parameters>`\\"
" \\(client\\_manager\\)"
msgstr ""

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.aggregate_fit:3
#: of
msgid "Afterward, add noise to the aggregated parameters."
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.FaultTolerantFedAvg.rst:2
msgid "FaultTolerantFedAvg"
msgstr ""

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FaultTolerantFedAvg.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.FaultTolerantFedAvg.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_fit:1
#: flwr.server.strategy.fedadagrad.FedAdagrad.aggregate_fit:1
#: flwr.server.strategy.fedadam.FedAdam.aggregate_fit:1
#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg.FedAvg.aggregate_fit:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_fit:1
#: flwr.server.strategy.fedavgm.FedAvgM.aggregate_fit:1
#: flwr.server.strategy.fedxgb_nn_avg.FedXgbNnAvg.aggregate_fit:1
#: flwr.server.strategy.fedyogi.FedYogi.aggregate_fit:1
#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_fit:1 of
msgid "Aggregate fit results using weighted average."
msgstr ""

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FaultTolerantFedAvg.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`configure_fit "
"<flwr.server.strategy.FaultTolerantFedAvg.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`evaluate <flwr.server.strategy.FaultTolerantFedAvg.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FaultTolerantFedAvg.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FaultTolerantFedAvg.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FaultTolerantFedAvg.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.FedAdagrad.rst:2
#: ../../source/ref-changelog.md:1434
msgid "FedAdagrad"
msgstr ""

#: flwr.server.strategy.fedadagrad.FedAdagrad:1
#: flwr.server.strategy.fedadam.FedAdam:1
#: flwr.server.strategy.fedyogi.FedYogi:1 of
msgid "Bases: :py:class:`~flwr.server.strategy.fedopt.FedOpt`"
msgstr ""

#: flwr.server.strategy.fedadagrad.FedAdagrad:3
#: flwr.server.strategy.fedadam.FedAdam:3 flwr.server.strategy.fedopt.FedOpt:3
#: flwr.server.strategy.fedyogi.FedYogi:3 of
msgid "Implementation based on https://arxiv.org/abs/2003.00295v5"
msgstr ""

#: flwr.server.strategy.fedadagrad.FedAdagrad:21
#: flwr.server.strategy.fedadagrad.FedAdagrad:23
#: flwr.server.strategy.fedadam.FedAdam:25
#: flwr.server.strategy.fedadam.FedAdam:27
#: flwr.server.strategy.fedavg.FedAvg:29 flwr.server.strategy.fedavg.FedAvg:31
#: flwr.server.strategy.fedopt.FedOpt:25 flwr.server.strategy.fedopt.FedOpt:27
#: flwr.server.strategy.fedprox.FedProx:61
#: flwr.server.strategy.fedprox.FedProx:63
#: flwr.server.strategy.fedyogi.FedYogi:28
#: flwr.server.strategy.fedyogi.FedYogi:30 of
msgid "Metrics aggregation function, optional."
msgstr ""

#: flwr.server.strategy.fedadagrad.FedAdagrad:29
#: flwr.server.strategy.fedadam.FedAdam:29
#: flwr.server.strategy.fedopt.FedOpt:29 of
msgid "Server-side learning rate. Defaults to 1e-1."
msgstr ""

#: flwr.server.strategy.fedadagrad.FedAdagrad:31
#: flwr.server.strategy.fedadam.FedAdam:31
#: flwr.server.strategy.fedopt.FedOpt:31 of
msgid "Client-side learning rate. Defaults to 1e-1."
msgstr ""

#: flwr.server.strategy.fedadagrad.FedAdagrad:33
#: flwr.server.strategy.fedadam.FedAdam:37
#: flwr.server.strategy.fedopt.FedOpt:37 of
msgid "Controls the algorithm's degree of adaptability. Defaults to 1e-9."
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedAdagrad.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`aggregate_fit <flwr.server.strategy.FedAdagrad.aggregate_fit>`\\"
" \\(server\\_round\\, results\\, failures\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedAdagrad.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`configure_fit <flwr.server.strategy.FedAdagrad.configure_fit>`\\"
" \\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`evaluate <flwr.server.strategy.FedAdagrad.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedAdagrad.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedAdagrad.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedAdagrad.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.FedAdam.rst:2
msgid "FedAdam"
msgstr ""

#: flwr.server.strategy.fedadam.FedAdam:33
#: flwr.server.strategy.fedyogi.FedYogi:36 of
msgid "Momentum parameter. Defaults to 0.9."
msgstr ""

#: flwr.server.strategy.fedadam.FedAdam:35
#: flwr.server.strategy.fedyogi.FedYogi:38 of
msgid "Second moment parameter. Defaults to 0.99."
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedAdam.aggregate_evaluate>`\\ \\(server\\_round\\,"
" results\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`aggregate_fit <flwr.server.strategy.FedAdam.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedAdam.configure_evaluate>`\\ \\(server\\_round\\,"
" parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`configure_fit <flwr.server.strategy.FedAdam.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`evaluate <flwr.server.strategy.FedAdam.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedAdam.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedAdam.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedAdam.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.FedAvg.rst:2
msgid "FedAvg"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg:3
#: flwr.server.strategy.fedavg_android.FedAvgAndroid:3 of
msgid "Implementation based on https://arxiv.org/abs/1602.05629"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg:5 flwr.server.strategy.fedprox.FedProx:37
#: of
msgid ""
"Fraction of clients used during training. In case `min_fit_clients` is "
"larger than `fraction_fit * available_clients`, `min_fit_clients` will "
"still be sampled. Defaults to 1.0."
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg:9 flwr.server.strategy.fedprox.FedProx:41
#: of
msgid ""
"Fraction of clients used during validation. In case "
"`min_evaluate_clients` is larger than `fraction_evaluate * "
"available_clients`, `min_evaluate_clients` will still be sampled. "
"Defaults to 1.0."
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg:33 of
msgid "Enable (True) or disable (False) in-place aggregation of model updates."
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedAvg.aggregate_evaluate>`\\ \\(server\\_round\\, "
"results\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`aggregate_fit <flwr.server.strategy.FedAvg.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedAvg.configure_evaluate>`\\ \\(server\\_round\\, "
"parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`configure_fit <flwr.server.strategy.FedAvg.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`evaluate <flwr.server.strategy.FedAvg.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedAvg.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedAvg.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`num_fit_clients <flwr.server.strategy.FedAvg.num_fit_clients>`\\"
" \\(num\\_available\\_clients\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.FedAvgAndroid.rst:2
msgid "FedAvgAndroid"
msgstr ""

#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedAvgAndroid.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.FedAvgAndroid.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""

#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`bytes_to_ndarray "
"<flwr.server.strategy.FedAvgAndroid.bytes_to_ndarray>`\\ \\(tensor\\)"
msgstr ""

#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.bytes_to_ndarray:1 of
msgid "Deserialize NumPy array from bytes."
msgstr ""

#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedAvgAndroid.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`configure_fit "
"<flwr.server.strategy.FedAvgAndroid.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`evaluate <flwr.server.strategy.FedAvgAndroid.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""

#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedAvgAndroid.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""

#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`ndarray_to_bytes "
"<flwr.server.strategy.FedAvgAndroid.ndarray_to_bytes>`\\ \\(ndarray\\)"
msgstr ""

#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.ndarray_to_bytes:1 of
msgid "Serialize NumPy array to bytes."
msgstr ""

#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`ndarrays_to_parameters "
"<flwr.server.strategy.FedAvgAndroid.ndarrays_to_parameters>`\\ "
"\\(ndarrays\\)"
msgstr ""

#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedAvgAndroid.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""

#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedAvgAndroid.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""

#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`parameters_to_ndarrays "
"<flwr.server.strategy.FedAvgAndroid.parameters_to_ndarrays>`\\ "
"\\(parameters\\)"
msgstr ""

#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.parameters_to_ndarrays:1
#: of
msgid "Convert parameters object to NumPy weights."
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.FedAvgM.rst:2
msgid "FedAvgM"
msgstr ""

#: flwr.server.strategy.fedavgm.FedAvgM:3 of
msgid "Implementation based on https://arxiv.org/abs/1909.06335"
msgstr ""

#: flwr.server.strategy.fedavgm.FedAvgM:25 of
msgid ""
"Server-side learning rate used in server-side optimization. Defaults to "
"1.0."
msgstr ""

#: flwr.server.strategy.fedavgm.FedAvgM:28 of
msgid "Server-side momentum factor used for FedAvgM. Defaults to 0.0."
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedAvgM.aggregate_evaluate>`\\ \\(server\\_round\\,"
" results\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`aggregate_fit <flwr.server.strategy.FedAvgM.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedAvgM.configure_evaluate>`\\ \\(server\\_round\\,"
" parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`configure_fit <flwr.server.strategy.FedAvgM.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`evaluate <flwr.server.strategy.FedAvgM.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedAvgM.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedAvgM.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedAvgM.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.FedMedian.rst:2
msgid "FedMedian"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedMedian.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`aggregate_fit <flwr.server.strategy.FedMedian.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedmedian.FedMedian.aggregate_fit:1 of
msgid "Aggregate fit results using median."
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedMedian.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`configure_fit <flwr.server.strategy.FedMedian.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`evaluate <flwr.server.strategy.FedMedian.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedMedian.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedMedian.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedMedian.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.FedOpt.rst:2
msgid "FedOpt"
msgstr ""

#: flwr.server.strategy.fedopt.FedOpt:33 of
msgid "Momentum parameter. Defaults to 0.0."
msgstr ""

#: flwr.server.strategy.fedopt.FedOpt:35 of
msgid "Second moment parameter. Defaults to 0.0."
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedOpt.aggregate_evaluate>`\\ \\(server\\_round\\, "
"results\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`aggregate_fit <flwr.server.strategy.FedOpt.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedOpt.configure_evaluate>`\\ \\(server\\_round\\, "
"parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`configure_fit <flwr.server.strategy.FedOpt.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`evaluate <flwr.server.strategy.FedOpt.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedOpt.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedOpt.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`num_fit_clients <flwr.server.strategy.FedOpt.num_fit_clients>`\\"
" \\(num\\_available\\_clients\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.FedProx.rst:2
msgid "FedProx"
msgstr ""

#: flwr.server.strategy.fedprox.FedProx:3 of
msgid "Implementation based on https://arxiv.org/abs/1812.06127"
msgstr ""

#: flwr.server.strategy.fedprox.FedProx:5 of
msgid ""
"The strategy in itself will not be different than FedAvg, the client "
"needs to be adjusted. A proximal term needs to be added to the loss "
"function during the training:"
msgstr ""

#: flwr.server.strategy.fedprox.FedProx:9 of
msgid ""
"\\\\frac{\\\\mu}{2} || w - w^t ||^2\n"
"\n"
msgstr ""

#: flwr.server.strategy.fedprox.FedProx:12 of
msgid ""
"Where $w^t$ are the global parameters and $w$ are the local weights the "
"function will be optimized with."
msgstr ""

#: flwr.server.strategy.fedprox.FedProx:15 of
msgid "In PyTorch, for example, the loss would go from:"
msgstr ""

#: flwr.server.strategy.fedprox.FedProx:21 of
msgid "To:"
msgstr ""

#: flwr.server.strategy.fedprox.FedProx:30 of
msgid ""
"With `global_params` being a copy of the parameters before the training "
"takes place."
msgstr ""

#: flwr.server.strategy.fedprox.FedProx:65 of
msgid ""
"The weight of the proximal term used in the optimization. 0.0 makes this "
"strategy equivalent to FedAvg, and the higher the coefficient, the more "
"regularization will be used (that is, the client parameters will need to "
"be closer to the server parameters during training)."
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedProx.aggregate_evaluate>`\\ \\(server\\_round\\,"
" results\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`aggregate_fit <flwr.server.strategy.FedProx.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedProx.configure_evaluate>`\\ \\(server\\_round\\,"
" parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`configure_fit <flwr.server.strategy.FedProx.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`evaluate <flwr.server.strategy.FedProx.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedProx.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedProx.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedProx.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""

#: flwr.server.strategy.fedprox.FedProx.configure_fit:3 of
msgid "Sends the proximal factor mu to the clients"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.FedTrimmedAvg.rst:2
msgid "FedTrimmedAvg"
msgstr ""

#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg:3 of
msgid "Implemented based on: https://arxiv.org/abs/1803.01498"
msgstr ""

#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg:25 of
msgid "Fraction to cut off of both tails of the distribution. Defaults to 0.2."
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedTrimmedAvg.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.FedTrimmedAvg.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg.aggregate_fit:1 of
msgid "Aggregate fit results using trimmed average."
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedTrimmedAvg.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`configure_fit "
"<flwr.server.strategy.FedTrimmedAvg.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`evaluate <flwr.server.strategy.FedTrimmedAvg.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedTrimmedAvg.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedTrimmedAvg.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedTrimmedAvg.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.FedXgbBagging.rst:2
msgid "FedXgbBagging"
msgstr ""

#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedXgbBagging.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1
#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1
#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: of
msgid "Aggregate evaluation metrics using average."
msgstr ""

#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.FedXgbBagging.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""

#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_fit:1
#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_fit:1 of
msgid "Aggregate fit results using bagging."
msgstr ""

#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedXgbBagging.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`configure_fit "
"<flwr.server.strategy.FedXgbBagging.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`evaluate <flwr.server.strategy.FedXgbBagging.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""

#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedXgbBagging.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""

#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedXgbBagging.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""

#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedXgbBagging.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.FedXgbCyclic.rst:2
msgid "FedXgbCyclic"
msgstr ""

#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedXgbCyclic.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.FedXgbCyclic.aggregate_fit>`\\ \\(server\\_round\\,"
" results\\, failures\\)"
msgstr ""

#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedXgbCyclic.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`configure_fit "
"<flwr.server.strategy.FedXgbCyclic.configure_fit>`\\ \\(server\\_round\\,"
" parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`evaluate <flwr.server.strategy.FedXgbCyclic.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""

#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedXgbCyclic.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""

#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedXgbCyclic.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""

#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedXgbCyclic.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.FedXgbNnAvg.rst:2
msgid "FedXgbNnAvg"
msgstr ""

#: flwr.server.strategy.fedxgb_nn_avg.FedXgbNnAvg:5 of
msgid ""
"This strategy is deprecated, but a copy of it is available in Flower "
"Baselines: "
"https://github.com/adap/flower/tree/main/baselines/hfedxgboost."
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedXgbNnAvg.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.FedXgbNnAvg.aggregate_fit>`\\ \\(server\\_round\\, "
"results\\, failures\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedXgbNnAvg.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`configure_fit "
"<flwr.server.strategy.FedXgbNnAvg.configure_fit>`\\ \\(server\\_round\\, "
"parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`evaluate <flwr.server.strategy.FedXgbNnAvg.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedXgbNnAvg.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedXgbNnAvg.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedXgbNnAvg.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.FedYogi.rst:2
msgid "FedYogi"
msgstr ""

#: flwr.server.strategy.fedyogi.FedYogi:32 of
msgid "Server-side learning rate. Defaults to 1e-2."
msgstr ""

#: flwr.server.strategy.fedyogi.FedYogi:34 of
msgid "Client-side learning rate. Defaults to 0.0316."
msgstr ""

#: flwr.server.strategy.fedyogi.FedYogi:40 of
msgid "Controls the algorithm's degree of adaptability. Defaults to 1e-3."
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedYogi.aggregate_evaluate>`\\ \\(server\\_round\\,"
" results\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`aggregate_fit <flwr.server.strategy.FedYogi.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedYogi.configure_evaluate>`\\ \\(server\\_round\\,"
" parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`configure_fit <flwr.server.strategy.FedYogi.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`evaluate <flwr.server.strategy.FedYogi.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedYogi.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedYogi.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedYogi.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.Krum.rst:2
msgid "Krum"
msgstr ""

#: flwr.server.strategy.krum.Krum:3 of
msgid "Implementation based on https://arxiv.org/abs/1703.02757"
msgstr ""

#: flwr.server.strategy.krum.Krum:17 of
msgid ""
"Number of clients to keep before averaging (MultiKrum). Defaults to 0, in"
" that case classical Krum is applied."
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.Krum.aggregate_evaluate>`\\ \\(server\\_round\\, "
"results\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`aggregate_fit <flwr.server.strategy.Krum.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.krum.Krum.aggregate_fit:1 of
msgid "Aggregate fit results using Krum."
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.Krum.configure_evaluate>`\\ \\(server\\_round\\, "
"parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`configure_fit <flwr.server.strategy.Krum.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`evaluate <flwr.server.strategy.Krum.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.Krum.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.Krum.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`num_fit_clients <flwr.server.strategy.Krum.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.QFedAvg.rst:2
msgid "QFedAvg"
msgstr ""

#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.QFedAvg.aggregate_evaluate>`\\ \\(server\\_round\\,"
" results\\, ...\\)"
msgstr ""

#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`aggregate_fit <flwr.server.strategy.QFedAvg.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""

#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.QFedAvg.configure_evaluate>`\\ \\(server\\_round\\,"
" parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`configure_fit <flwr.server.strategy.QFedAvg.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`evaluate <flwr.server.strategy.QFedAvg.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""

#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.QFedAvg.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""

#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.QFedAvg.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""

#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.QFedAvg.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.strategy.Strategy.rst:2
msgid "Strategy"
msgstr ""

#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.Strategy.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"
msgstr ""

#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:1
#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:1:<autosummary>:1
#: of
msgid "Aggregate evaluation results."
msgstr ""

#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`aggregate_fit <flwr.server.strategy.Strategy.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""

#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.strategy.Strategy.aggregate_fit:1 of
msgid "Aggregate training results."
msgstr ""

#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.Strategy.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`configure_fit <flwr.server.strategy.Strategy.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""

#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`evaluate <flwr.server.strategy.Strategy.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""

#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.strategy.Strategy.evaluate:1 of
msgid "Evaluate the current model parameters."
msgstr ""

#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:1:<autosummary>:1
#: of
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.Strategy.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""

#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.strategy.Strategy.initialize_parameters:1 of
msgid "Initialize the (global) model parameters."
msgstr ""

#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:5 of
msgid ""
"Successful updates from the previously selected and configured clients. "
"Each pair of `(ClientProxy, FitRes` constitutes a successful update from "
"one of the previously selected clients. Not that not all previously "
"selected clients are necessarily included in this list: a client might "
"drop out and not submit a result. For each client that did not submit an "
"update, there should be an `Exception` in `failures`."
msgstr ""

#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:13
#: flwr.server.strategy.strategy.Strategy.aggregate_fit:13 of
msgid "Exceptions that occurred while the server was waiting for client updates."
msgstr ""

#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:16 of
msgid ""
"**aggregation_result** -- The aggregated evaluation result. Aggregation "
"typically uses some variant of a weighted average."
msgstr ""

#: flwr.server.strategy.strategy.Strategy.aggregate_fit:5 of
msgid ""
"Successful updates from the previously selected and configured clients. "
"Each pair of `(ClientProxy, FitRes)` constitutes a successful update from"
" one of the previously selected clients. Not that not all previously "
"selected clients are necessarily included in this list: a client might "
"drop out and not submit a result. For each client that did not submit an "
"update, there should be an `Exception` in `failures`."
msgstr ""

#: flwr.server.strategy.strategy.Strategy.aggregate_fit:17 of
msgid ""
"**parameters** -- If parameters are returned, then the server will treat "
"these as the new global model parameters (i.e., it will replace the "
"previous parameters with the ones returned from this method). If `None` "
"is returned (e.g., because there were only failures and no viable "
"results) then the server will no update the previous model parameters, "
"the updates received in this round are discarded, and the global model "
"parameters remain the same."
msgstr ""

#: flwr.server.strategy.strategy.Strategy.evaluate:3 of
msgid ""
"This function can be used to perform centralized (i.e., server-side) "
"evaluation of model parameters."
msgstr ""

#: flwr.server.strategy.strategy.Strategy.evaluate:11 of
msgid ""
"**evaluation_result** -- The evaluation result, usually a Tuple "
"containing loss and a dictionary containing task-specific metrics (e.g., "
"accuracy)."
msgstr ""

#: flwr.server.strategy.strategy.Strategy.initialize_parameters:6 of
msgid ""
"**parameters** -- If parameters are returned, then the server will treat "
"these as the initial global model parameters."
msgstr ""

#: ../../source/ref-api/flwr.server.workflow.rst:2
msgid "workflow"
msgstr ""

#: ../../source/ref-api/flwr.server.workflow.rst:24:<autosummary>:1
msgid ""
":py:obj:`DefaultWorkflow <flwr.server.workflow.DefaultWorkflow>`\\ "
"\\(\\[fit\\_workflow\\, ...\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.workflow.rst:24:<autosummary>:1
#: flwr.server.workflow.default_workflows.DefaultWorkflow:1 of
msgid "Default workflow in Flower."
msgstr ""

#: ../../source/ref-api/flwr.server.workflow.rst:24:<autosummary>:1
msgid ""
":py:obj:`SecAggPlusWorkflow <flwr.server.workflow.SecAggPlusWorkflow>`\\ "
"\\(num\\_shares\\, ...\\[\\, ...\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.workflow.rst:24:<autosummary>:1
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:1
#: of
msgid "The workflow for the SecAgg+ protocol."
msgstr ""

#: ../../source/ref-api/flwr.server.workflow.rst:24:<autosummary>:1
msgid ""
":py:obj:`SecAggWorkflow <flwr.server.workflow.SecAggWorkflow>`\\ "
"\\(reconstruction\\_threshold\\, \\*\\)"
msgstr ""

#: ../../source/ref-api/flwr.server.workflow.rst:24:<autosummary>:1
#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:1 of
msgid "The workflow for the SecAgg protocol."
msgstr ""

#: ../../source/ref-api/flwr.server.workflow.DefaultWorkflow.rst:2
msgid "DefaultWorkflow"
msgstr ""

#: ../../source/ref-api/flwr.server.workflow.SecAggPlusWorkflow.rst:2
msgid "SecAggPlusWorkflow"
msgstr ""

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:3
#: of
msgid ""
"The SecAgg+ protocol ensures the secure summation of integer vectors "
"owned by multiple parties, without accessing any individual integer "
"vector. This workflow allows the server to compute the weighted average "
"of model parameters across all clients, ensuring individual contributions"
" remain private. This is achieved by clients sending both, a weighting "
"factor and a weighted version of the locally updated parameters, both of "
"which are masked for privacy. Specifically, each client uploads \"[w, w *"
" params]\" with masks, where weighting factor 'w' is the number of "
"examples ('num_examples') and 'params' represents the model parameters "
"('parameters') from the client's `FitRes`. The server then aggregates "
"these contributions to compute the weighted average of model parameters."
msgstr ""

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:14
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:14
#: of
msgid "The protocol involves four main stages:"
msgstr ""

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:16
#: of
msgid ""
"'setup': Send SecAgg+ configuration to clients and collect their public "
"keys."
msgstr ""

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:17
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:17
#: of
msgid ""
"'share keys': Broadcast public keys among clients and collect encrypted "
"secret key shares."
msgstr ""

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:19
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:19
#: of
msgid ""
"'collect masked vectors': Forward encrypted secret key shares to target "
"clients and collect masked model parameters."
msgstr ""

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:21
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:21
#: of
msgid ""
"'unmask': Collect secret key shares to decrypt and aggregate the model "
"parameters."
msgstr ""

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:23
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:23
#: of
msgid ""
"Only the aggregated model parameters are exposed and passed to "
"`Strategy.aggregate_fit`, ensuring individual data privacy."
msgstr ""

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:26
#: of
msgid ""
"The number of shares into which each client's private key is split under "
"the SecAgg+ protocol. If specified as a float, it represents the "
"proportion of all selected clients, and the number of shares will be set "
"dynamically in the run time. A private key can be reconstructed from "
"these shares, allowing for the secure aggregation of model updates. Each "
"client sends one share to each of its neighbors while retaining one."
msgstr ""

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:26
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:33
#: of
msgid ""
"The minimum number of shares required to reconstruct a client's private "
"key, or, if specified as a float, it represents the proportion of the "
"total number of shares needed for reconstruction. This threshold ensures "
"privacy by allowing for the recovery of contributions from dropped "
"clients during aggregation, without compromising individual client data."
msgstr ""

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:32
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:39
#: of
msgid ""
"The maximum value of the weight that can be assigned to any single "
"client's update during the weighted average calculation on the server "
"side, e.g., in the FedAvg algorithm."
msgstr ""

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:36
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:43
#: of
msgid ""
"The range within which model parameters are clipped before quantization. "
"This parameter ensures each model parameter is bounded within "
"[-clipping_range, clipping_range], facilitating quantization."
msgstr ""

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:40
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:47
#: of
msgid ""
"The size of the range into which floating-point model parameters are "
"quantized, mapping each parameter to an integer in [0, "
"quantization_range-1]. This facilitates cryptographic operations on the "
"model updates."
msgstr ""

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:44
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:51
#: of
msgid ""
"The range of values from which random mask entries are uniformly sampled "
"([0, modulus_range-1]). `modulus_range` must be less than 4294967296. "
"Please use 2**n values for `modulus_range` to prevent overflow issues."
msgstr ""

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:48
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:55
#: of
msgid ""
"The timeout duration in seconds. If specified, the workflow will wait for"
" replies for this duration each time. If `None`, there is no time limit "
"and the workflow will wait until replies for all messages are received."
msgstr ""

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:62
#: of
msgid ""
"Generally, higher `num_shares` means more robust to dropouts while "
"increasing the computational costs; higher `reconstruction_threshold` "
"means better privacy guarantees but less tolerance to dropouts."
msgstr ""

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:59
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:65
#: of
msgid "Too large `max_weight` may compromise the precision of the quantization."
msgstr ""

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:60
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:66
#: of
msgid "`modulus_range` must be 2**n and larger than `quantization_range`."
msgstr ""

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:67
#: of
msgid ""
"When `num_shares` is a float, it is interpreted as the proportion of all "
"selected clients, and hence the number of shares will be determined in "
"the runtime. This allows for dynamic adjustment based on the total number"
" of participating clients."
msgstr ""

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:70
#: of
msgid ""
"Similarly, when `reconstruction_threshold` is a float, it is interpreted "
"as the proportion of the number of shares needed for the reconstruction "
"of a private key. This feature enables flexibility in setting the "
"security threshold relative to the number of distributed shares."
msgstr ""

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:74
#: of
msgid ""
"`num_shares`, `reconstruction_threshold`, and the quantization parameters"
" (`clipping_range`, `quantization_range`, `modulus_range`) play critical "
"roles in balancing privacy, robustness, and efficiency within the SecAgg+"
" protocol."
msgstr ""

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.collect_masked_vectors_stage:1:<autosummary>:1
#: of
msgid ""
":py:obj:`collect_masked_vectors_stage "
"<flwr.server.workflow.SecAggPlusWorkflow.collect_masked_vectors_stage>`\\"
" \\(driver\\, ...\\)"
msgstr ""

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.collect_masked_vectors_stage:1
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.collect_masked_vectors_stage:1:<autosummary>:1
#: of
msgid "Execute the 'collect masked vectors' stage."
msgstr ""

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.collect_masked_vectors_stage:1:<autosummary>:1
#: of
msgid ""
":py:obj:`setup_stage "
"<flwr.server.workflow.SecAggPlusWorkflow.setup_stage>`\\ \\(driver\\, "
"context\\, state\\)"
msgstr ""

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.collect_masked_vectors_stage:1:<autosummary>:1
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.setup_stage:1
#: of
msgid "Execute the 'setup' stage."
msgstr ""

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.collect_masked_vectors_stage:1:<autosummary>:1
#: of
msgid ""
":py:obj:`share_keys_stage "
"<flwr.server.workflow.SecAggPlusWorkflow.share_keys_stage>`\\ "
"\\(driver\\, context\\, state\\)"
msgstr ""

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.collect_masked_vectors_stage:1:<autosummary>:1
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.share_keys_stage:1
#: of
msgid "Execute the 'share keys' stage."
msgstr ""

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.collect_masked_vectors_stage:1:<autosummary>:1
#: of
msgid ""
":py:obj:`unmask_stage "
"<flwr.server.workflow.SecAggPlusWorkflow.unmask_stage>`\\ \\(driver\\, "
"context\\, state\\)"
msgstr ""

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.collect_masked_vectors_stage:1:<autosummary>:1
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.unmask_stage:1
#: of
msgid "Execute the 'unmask' stage."
msgstr ""

#: ../../source/ref-api/flwr.server.workflow.SecAggWorkflow.rst:2
msgid "SecAggWorkflow"
msgstr ""

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:1 of
msgid ""
"Bases: "
":py:class:`~flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow`"
msgstr ""

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:3 of
msgid ""
"The SecAgg protocol ensures the secure summation of integer vectors owned"
" by multiple parties, without accessing any individual integer vector. "
"This workflow allows the server to compute the weighted average of model "
"parameters across all clients, ensuring individual contributions remain "
"private. This is achieved by clients sending both, a weighting factor and"
" a weighted version of the locally updated parameters, both of which are "
"masked for privacy. Specifically, each client uploads \"[w, w * params]\""
" with masks, where weighting factor 'w' is the number of examples "
"('num_examples') and 'params' represents the model parameters "
"('parameters') from the client's `FitRes`. The server then aggregates "
"these contributions to compute the weighted average of model parameters."
msgstr ""

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:16 of
msgid ""
"'setup': Send SecAgg configuration to clients and collect their public "
"keys."
msgstr ""

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:55 of
msgid ""
"Each client's private key is split into N shares under the SecAgg "
"protocol, where N is the number of selected clients."
msgstr ""

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:57 of
msgid ""
"Generally, higher `reconstruction_threshold` means better privacy "
"guarantees but less tolerance to dropouts."
msgstr ""

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:61 of
msgid ""
"When `reconstruction_threshold` is a float, it is interpreted as the "
"proportion of the number of all selected clients needed for the "
"reconstruction of a private key. This feature enables flexibility in "
"setting the security threshold relative to the number of selected "
"clients."
msgstr ""

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:65 of
msgid ""
"`reconstruction_threshold`, and the quantization parameters "
"(`clipping_range`, `quantization_range`, `modulus_range`) play critical "
"roles in balancing privacy, robustness, and efficiency within the SecAgg "
"protocol."
msgstr ""

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.collect_masked_vectors_stage:1:<autosummary>:1
#: of
msgid ""
":py:obj:`collect_masked_vectors_stage "
"<flwr.server.workflow.SecAggWorkflow.collect_masked_vectors_stage>`\\ "
"\\(driver\\, ...\\)"
msgstr ""

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.collect_masked_vectors_stage:1:<autosummary>:1
#: of
msgid ""
":py:obj:`setup_stage <flwr.server.workflow.SecAggWorkflow.setup_stage>`\\"
" \\(driver\\, context\\, state\\)"
msgstr ""

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.collect_masked_vectors_stage:1:<autosummary>:1
#: of
msgid ""
":py:obj:`share_keys_stage "
"<flwr.server.workflow.SecAggWorkflow.share_keys_stage>`\\ \\(driver\\, "
"context\\, state\\)"
msgstr ""

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.collect_masked_vectors_stage:1:<autosummary>:1
#: of
msgid ""
":py:obj:`unmask_stage "
"<flwr.server.workflow.SecAggWorkflow.unmask_stage>`\\ \\(driver\\, "
"context\\, state\\)"
msgstr ""

#: ../../source/ref-api/flwr.simulation.rst:2
msgid "simulation"
msgstr ""

#: ../../source/ref-api/flwr.simulation.rst:24:<autosummary>:1
msgid ""
":py:obj:`run_simulation <flwr.simulation.run_simulation>`\\ "
"\\(server\\_app\\, client\\_app\\, ...\\)"
msgstr ""

#: ../../source/ref-api/flwr.simulation.rst:24:<autosummary>:1
#: flwr.simulation.run_simulation.run_simulation:1 of
msgid "Run a Flower App using the Simulation Engine."
msgstr ""

#: ../../source/ref-api/flwr.simulation.rst:24:<autosummary>:1
msgid ""
":py:obj:`run_simulation_process "
"<flwr.simulation.run_simulation_process>`\\ \\(...\\[\\, flwr\\_dir\\_\\,"
" ...\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.simulation.rst:24:<autosummary>:1
#: flwr.simulation.app.run_simulation_process:1 of
msgid "Run Flower Simulation process."
msgstr ""

#: ../../source/ref-api/flwr.simulation.rst:24:<autosummary>:1
msgid ""
":py:obj:`start_simulation <flwr.simulation.start_simulation>`\\ "
"\\(\\*args\\, \\*\\*kwargs\\)"
msgstr ""

#: ../../source/ref-api/flwr.simulation.rst:24:<autosummary>:1
#: flwr.simulation.start_simulation:1 of
msgid "Log error stating that module `ray` could not be imported."
msgstr ""

#: ../../source/ref-api/flwr.simulation.rst:31:<autosummary>:1
msgid ""
":py:obj:`SimulationIoConnection "
"<flwr.simulation.SimulationIoConnection>`\\ \\(\\[...\\]\\)"
msgstr ""

#: ../../source/ref-api/flwr.simulation.rst:31:<autosummary>:1
#: flwr.simulation.simulationio_connection.SimulationIoConnection:1 of
msgid "`SimulationIoConnection` provides an interface to the SimulationIo API."
msgstr ""

#: ../../source/ref-api/flwr.simulation.SimulationIoConnection.rst:2
msgid "SimulationIoConnection"
msgstr ""

#: flwr.simulation.simulationio_connection.SimulationIoConnection:3 of
msgid "The address (URL, IPv6, IPv4) of the SuperLink SimulationIo API service."
msgstr ""

#: flwr.simulation.simulationio_connection.SimulationIoConnection:5 of
msgid ""
"The PEM-encoded root certificates as a byte string. If provided, a secure"
" connection using the certificates will be established to an SSL-enabled "
"Flower server."
msgstr ""

#: ../../source/ref-api/flwr.simulation.run_simulation.rst:2
msgid "run\\_simulation"
msgstr ""

#: flwr.simulation.run_simulation.run_simulation:3 of
msgid ""
"The `ServerApp` to be executed. It will send messages to different "
"`ClientApp` instances running on different (virtual) SuperNodes."
msgstr ""

#: flwr.simulation.run_simulation.run_simulation:6 of
msgid ""
"The `ClientApp` to be executed by each of the SuperNodes. It will receive"
" messages sent by the `ServerApp`."
msgstr ""

#: flwr.simulation.run_simulation.run_simulation:9 of
msgid ""
"Number of nodes that run a ClientApp. They can be sampled by a Driver in "
"the ServerApp and receive a Message describing what the ClientApp should "
"perform."
msgstr ""

#: flwr.simulation.run_simulation.run_simulation:12 of
msgid "A simulation backend that runs `ClientApp`s."
msgstr ""

#: flwr.simulation.run_simulation.run_simulation:14 of
msgid ""
"'A dictionary to configure a backend. Separate dictionaries to configure "
"different elements of backend. Supported top-level keys are `init_args` "
"for values parsed to initialisation of backend, `client_resources` to "
"define the resources for clients, and `actor` to define the actor "
"parameters. Values supported in <value> are those included by "
"`flwr.common.typing.ConfigsRecordValues`."
msgstr ""

#: flwr.simulation.run_simulation.run_simulation:21 of
msgid ""
"A boolean to indicate whether to enable GPU growth on the main thread. "
"This is desirable if you make use of a TensorFlow model on your "
"`ServerApp` while having your `ClientApp` running on the same GPU. "
"Without enabling this, you might encounter an out-of-memory error because"
" TensorFlow, by default, allocates all GPU memory. Read more about how "
"`tf.config.experimental.set_memory_growth()` works in the TensorFlow "
"documentation: https://www.tensorflow.org/api/stable."
msgstr ""

#: flwr.simulation.run_simulation.run_simulation:28 of
msgid ""
"When disabled, only INFO, WARNING and ERROR log messages will be shown. "
"If enabled, DEBUG-level logs will be displayed."
msgstr ""

#: ../../source/ref-api/flwr.simulation.run_simulation_process.rst:2
msgid "run\\_simulation\\_process"
msgstr ""

#: ../../source/ref-api/flwr.simulation.start_simulation.rst:2
msgid "start\\_simulation"
msgstr ""

#: ../../source/ref-changelog.md:1
msgid "Changelog"
msgstr ""

#: ../../source/ref-changelog.md:3
msgid "v1.13.1 (2024-11-26)"
msgstr ""

#: ../../source/ref-changelog.md:5 ../../source/ref-changelog.md:37
#: ../../source/ref-changelog.md:138 ../../source/ref-changelog.md:208
#: ../../source/ref-changelog.md:240 ../../source/ref-changelog.md:344
#: ../../source/ref-changelog.md:442 ../../source/ref-changelog.md:542
#: ../../source/ref-changelog.md:606 ../../source/ref-changelog.md:699
#: ../../source/ref-changelog.md:799 ../../source/ref-changelog.md:883
#: ../../source/ref-changelog.md:947 ../../source/ref-changelog.md:1005
#: ../../source/ref-changelog.md:1074 ../../source/ref-changelog.md:1143
msgid "Thanks to our contributors"
msgstr ""

#: ../../source/ref-changelog.md:7 ../../source/ref-changelog.md:39
#: ../../source/ref-changelog.md:140 ../../source/ref-changelog.md:210
#: ../../source/ref-changelog.md:242 ../../source/ref-changelog.md:346
#: ../../source/ref-changelog.md:444 ../../source/ref-changelog.md:544
#: ../../source/ref-changelog.md:608 ../../source/ref-changelog.md:701
#: ../../source/ref-changelog.md:801 ../../source/ref-changelog.md:885
#: ../../source/ref-changelog.md:949 ../../source/ref-changelog.md:1007
msgid ""
"We would like to give our special thanks to all the contributors who made"
" the new version of Flower possible (in `git shortlog` order):"
msgstr ""

#: ../../source/ref-changelog.md:9
msgid ""
"`Adam Narozniak`, `Charles Beauville`, `Heng Pan`, `Javier`, `Robert "
"Steiner` <!---TOKEN_v1.13.1-->"
msgstr ""

#: ../../source/ref-changelog.md:11 ../../source/ref-changelog.md:43
#: ../../source/ref-changelog.md:144 ../../source/ref-changelog.md:246
#: ../../source/ref-changelog.md:350 ../../source/ref-changelog.md:448
#: ../../source/ref-changelog.md:548 ../../source/ref-changelog.md:612
#: ../../source/ref-changelog.md:705 ../../source/ref-changelog.md:805
#: ../../source/ref-changelog.md:889 ../../source/ref-changelog.md:953
#: ../../source/ref-changelog.md:1011 ../../source/ref-changelog.md:1080
#: ../../source/ref-changelog.md:1209 ../../source/ref-changelog.md:1251
#: ../../source/ref-changelog.md:1318 ../../source/ref-changelog.md:1384
#: ../../source/ref-changelog.md:1429 ../../source/ref-changelog.md:1468
#: ../../source/ref-changelog.md:1501 ../../source/ref-changelog.md:1551
msgid "What's new?"
msgstr ""

#: ../../source/ref-changelog.md:13
msgid ""
"**Fix `SimulationEngine` Executor for SuperLink** "
"([#4563](https://github.com/adap/flower/pull/4563), "
"[#4568](https://github.com/adap/flower/pull/4568), "
"[#4570](https://github.com/adap/flower/pull/4570))"
msgstr ""

#: ../../source/ref-changelog.md:15
msgid ""
"Resolved an issue that prevented SuperLink from functioning correctly "
"when using the `SimulationEngine` executor."
msgstr ""

#: ../../source/ref-changelog.md:17
msgid ""
"**Improve FAB build and install** "
"([#4571](https://github.com/adap/flower/pull/4571))"
msgstr ""

#: ../../source/ref-changelog.md:19
msgid ""
"An updated FAB build and install process produces smaller FAB files and "
"doesn't rely on `pip install` any more. It also resolves an issue where "
"all files were unnecessarily included in the FAB file. The `flwr` CLI "
"commands now correctly pack only the necessary files, such as `.md`, "
"`.toml` and `.py`, ensuring more efficient and accurate packaging."
msgstr ""

#: ../../source/ref-changelog.md:21
msgid ""
"**Update** `embedded-devices` **example** "
"([#4381](https://github.com/adap/flower/pull/4381))"
msgstr ""

#: ../../source/ref-changelog.md:23
msgid "The example now uses the `flwr run` command and the Deployment Engine."
msgstr ""

#: ../../source/ref-changelog.md:25
msgid ""
"**Update Documentation** "
"([#4566](https://github.com/adap/flower/pull/4566), "
"[#4569](https://github.com/adap/flower/pull/4569), "
"[#4560](https://github.com/adap/flower/pull/4560), "
"[#4556](https://github.com/adap/flower/pull/4556), "
"[#4581](https://github.com/adap/flower/pull/4581), "
"[#4537](https://github.com/adap/flower/pull/4537), "
"[#4562](https://github.com/adap/flower/pull/4562), "
"[#4582](https://github.com/adap/flower/pull/4582))"
msgstr ""

#: ../../source/ref-changelog.md:27
msgid ""
"Enhanced documentation across various aspects, including updates to "
"translation workflows, Docker-related READMEs, and recommended datasets. "
"Improvements also include formatting fixes for dataset partitioning docs "
"and better references to resources in the datasets documentation index."
msgstr ""

#: ../../source/ref-changelog.md:29
msgid ""
"**Update Infrastructure and CI/CD** "
"([#4577](https://github.com/adap/flower/pull/4577), "
"[#4578](https://github.com/adap/flower/pull/4578), "
"[#4558](https://github.com/adap/flower/pull/4558), "
"[#4551](https://github.com/adap/flower/pull/4551), "
"[#3356](https://github.com/adap/flower/pull/3356), "
"[#4559](https://github.com/adap/flower/pull/4559), "
"[#4575](https://github.com/adap/flower/pull/4575))"
msgstr ""

#: ../../source/ref-changelog.md:31
msgid ""
"**General improvements** "
"([#4557](https://github.com/adap/flower/pull/4557), "
"[#4564](https://github.com/adap/flower/pull/4564), "
"[#4573](https://github.com/adap/flower/pull/4573), "
"[#4561](https://github.com/adap/flower/pull/4561), "
"[#4579](https://github.com/adap/flower/pull/4579), "
"[#4572](https://github.com/adap/flower/pull/4572))"
msgstr ""

#: ../../source/ref-changelog.md:33 ../../source/ref-changelog.md:102
#: ../../source/ref-changelog.md:198 ../../source/ref-changelog.md:301
#: ../../source/ref-changelog.md:408
msgid ""
"As always, many parts of the Flower framework and quality infrastructure "
"were improved and updated."
msgstr ""

#: ../../source/ref-changelog.md:35
msgid "v1.13.0 (2024-11-20)"
msgstr ""

#: ../../source/ref-changelog.md:41
msgid ""
"`Adam Narozniak`, `Charles Beauville`, `Chong Shen Ng`, `Daniel J. "
"Beutel`, `Daniel Nata Nugraha`, `Dimitris Stripelis`, `Heng Pan`, "
"`Javier`, `Mohammad Naseri`, `Robert Steiner`, `Waris Gill`, `William "
"Lindskog`, `Yan Gao`, `Yao Xu`, `wwjang` <!---TOKEN_v1.13.0-->"
msgstr ""

#: ../../source/ref-changelog.md:45
msgid ""
"**Introduce `flwr ls` command** "
"([#4460](https://github.com/adap/flower/pull/4460), "
"[#4459](https://github.com/adap/flower/pull/4459), "
"[#4477](https://github.com/adap/flower/pull/4477))"
msgstr ""

#: ../../source/ref-changelog.md:47
msgid ""
"The `flwr ls` command is now available to display details about all runs "
"(or one specific run). It supports the following usage options:"
msgstr ""

#: ../../source/ref-changelog.md:49
msgid "`flwr ls --runs [<app>] [<federation>]`: Lists all runs."
msgstr ""

#: ../../source/ref-changelog.md:50
msgid ""
"`flwr ls --run-id <run-id> [<app>] [<federation>]`: Displays details for "
"a specific run."
msgstr ""

#: ../../source/ref-changelog.md:52
msgid ""
"This command provides information including the run ID, FAB ID and "
"version, run status, elapsed time, and timestamps for when the run was "
"created, started running, and finished."
msgstr ""

#: ../../source/ref-changelog.md:54
msgid ""
"**Fuse SuperLink and SuperExec** "
"([#4358](https://github.com/adap/flower/pull/4358), "
"[#4403](https://github.com/adap/flower/pull/4403), "
"[#4406](https://github.com/adap/flower/pull/4406), "
"[#4357](https://github.com/adap/flower/pull/4357), "
"[#4359](https://github.com/adap/flower/pull/4359), "
"[#4354](https://github.com/adap/flower/pull/4354), "
"[#4229](https://github.com/adap/flower/pull/4229), "
"[#4283](https://github.com/adap/flower/pull/4283), "
"[#4352](https://github.com/adap/flower/pull/4352))"
msgstr ""

#: ../../source/ref-changelog.md:56
msgid ""
"SuperExec has been integrated into SuperLink, enabling SuperLink to "
"directly manage ServerApp processes (`flwr-serverapp`). The `flwr` CLI "
"now targets SuperLink's Exec API. Additionally, SuperLink introduces two "
"isolation modes for running ServerApps: `subprocess` (default) and "
"`process`, which can be specified using the `--isolation "
"{subprocess,process}` flag."
msgstr ""

#: ../../source/ref-changelog.md:58
msgid ""
"**Introduce `flwr-serverapp` command** "
"([#4394](https://github.com/adap/flower/pull/4394), "
"[#4370](https://github.com/adap/flower/pull/4370), "
"[#4367](https://github.com/adap/flower/pull/4367), "
"[#4350](https://github.com/adap/flower/pull/4350), "
"[#4364](https://github.com/adap/flower/pull/4364), "
"[#4400](https://github.com/adap/flower/pull/4400), "
"[#4363](https://github.com/adap/flower/pull/4363), "
"[#4401](https://github.com/adap/flower/pull/4401), "
"[#4388](https://github.com/adap/flower/pull/4388), "
"[#4402](https://github.com/adap/flower/pull/4402))"
msgstr ""

#: ../../source/ref-changelog.md:60
msgid ""
"The `flwr-serverapp` command has been introduced as a CLI entry point "
"that runs a `ServerApp` process. This process communicates with SuperLink"
" to load and execute the `ServerApp` object, enabling isolated execution "
"and more flexible deployment."
msgstr ""

#: ../../source/ref-changelog.md:62
msgid ""
"**Improve simulation engine and introduce `flwr-simulation` command** "
"([#4433](https://github.com/adap/flower/pull/4433), "
"[#4486](https://github.com/adap/flower/pull/4486), "
"[#4448](https://github.com/adap/flower/pull/4448), "
"[#4427](https://github.com/adap/flower/pull/4427), "
"[#4438](https://github.com/adap/flower/pull/4438), "
"[#4421](https://github.com/adap/flower/pull/4421), "
"[#4430](https://github.com/adap/flower/pull/4430), "
"[#4462](https://github.com/adap/flower/pull/4462))"
msgstr ""

#: ../../source/ref-changelog.md:64
msgid ""
"The simulation engine has been significantly improved, resulting in "
"dramatically faster simulations. Additionally, the `flwr-simulation` "
"command has been introduced to enhance maintainability and provide a "
"dedicated entry point for running simulations."
msgstr ""

#: ../../source/ref-changelog.md:66
msgid ""
"**Improve SuperLink message management** "
"([#4378](https://github.com/adap/flower/pull/4378), "
"[#4369](https://github.com/adap/flower/pull/4369))"
msgstr ""

#: ../../source/ref-changelog.md:68
msgid ""
"SuperLink now validates the destination node ID of instruction messages "
"and checks the TTL (time-to-live) for reply messages. When pulling reply "
"messages, an error reply will be generated and returned if the "
"corresponding instruction message does not exist, has expired, or if the "
"reply message exists but has expired."
msgstr ""

#: ../../source/ref-changelog.md:70
msgid ""
"**Introduce FedDebug baseline** "
"([#3783](https://github.com/adap/flower/pull/3783))"
msgstr ""

#: ../../source/ref-changelog.md:72
msgid ""
"FedDebug is a framework that enhances debugging in Federated Learning by "
"enabling interactive inspection of the training process and automatically"
" identifying clients responsible for degrading the global model's "
"performance—all without requiring testing data or labels. Learn more in "
"the [FedDebug baseline "
"documentation](https://flower.ai/docs/baselines/feddebug.html)."
msgstr ""

#: ../../source/ref-changelog.md:74
msgid ""
"**Update documentation** "
"([#4511](https://github.com/adap/flower/pull/4511), "
"[#4010](https://github.com/adap/flower/pull/4010), "
"[#4396](https://github.com/adap/flower/pull/4396), "
"[#4499](https://github.com/adap/flower/pull/4499), "
"[#4269](https://github.com/adap/flower/pull/4269), "
"[#3340](https://github.com/adap/flower/pull/3340), "
"[#4482](https://github.com/adap/flower/pull/4482), "
"[#4387](https://github.com/adap/flower/pull/4387), "
"[#4342](https://github.com/adap/flower/pull/4342), "
"[#4492](https://github.com/adap/flower/pull/4492), "
"[#4474](https://github.com/adap/flower/pull/4474), "
"[#4500](https://github.com/adap/flower/pull/4500), "
"[#4514](https://github.com/adap/flower/pull/4514), "
"[#4236](https://github.com/adap/flower/pull/4236), "
"[#4112](https://github.com/adap/flower/pull/4112), "
"[#3367](https://github.com/adap/flower/pull/3367), "
"[#4501](https://github.com/adap/flower/pull/4501), "
"[#4373](https://github.com/adap/flower/pull/4373), "
"[#4409](https://github.com/adap/flower/pull/4409), "
"[#4356](https://github.com/adap/flower/pull/4356), "
"[#4520](https://github.com/adap/flower/pull/4520), "
"[#4524](https://github.com/adap/flower/pull/4524), "
"[#4525](https://github.com/adap/flower/pull/4525), "
"[#4526](https://github.com/adap/flower/pull/4526), "
"[#4527](https://github.com/adap/flower/pull/4527), "
"[#4528](https://github.com/adap/flower/pull/4528), "
"[#4545](https://github.com/adap/flower/pull/4545), "
"[#4522](https://github.com/adap/flower/pull/4522), "
"[#4534](https://github.com/adap/flower/pull/4534), "
"[#4513](https://github.com/adap/flower/pull/4513), "
"[#4529](https://github.com/adap/flower/pull/4529), "
"[#4441](https://github.com/adap/flower/pull/4441), "
"[#4530](https://github.com/adap/flower/pull/4530), "
"[#4470](https://github.com/adap/flower/pull/4470), "
"[#4553](https://github.com/adap/flower/pull/4553), "
"[#4531](https://github.com/adap/flower/pull/4531), "
"[#4554](https://github.com/adap/flower/pull/4554), "
"[#4555](https://github.com/adap/flower/pull/4555), "
"[#4552](https://github.com/adap/flower/pull/4552), "
"[#4533](https://github.com/adap/flower/pull/4533))"
msgstr ""

#: ../../source/ref-changelog.md:76
msgid ""
"Many documentation pages and tutorials have been updated to improve "
"clarity, fix typos, incorporate user feedback, and stay aligned with the "
"latest features in the framework. Key updates include adding a guide for "
"designing stateful `ClientApp` objects, updating the comprehensive guide "
"for setting up and running Flower's `Simulation Engine`, updating the "
"XGBoost, scikit-learn, and JAX quickstart tutorials to use `flwr run`, "
"updating DP guide, removing outdated pages, updating Docker docs, and "
"marking legacy functions as deprecated. The [Secure Aggregation "
"Protocols](https://flower.ai/docs/framework/contributor-ref-secure-"
"aggregation-protocols.html) page has also been updated."
msgstr ""

#: ../../source/ref-changelog.md:78
msgid ""
"**Update examples and templates** "
"([#4510](https://github.com/adap/flower/pull/4510), "
"[#4368](https://github.com/adap/flower/pull/4368), "
"[#4121](https://github.com/adap/flower/pull/4121), "
"[#4329](https://github.com/adap/flower/pull/4329), "
"[#4382](https://github.com/adap/flower/pull/4382), "
"[#4248](https://github.com/adap/flower/pull/4248), "
"[#4395](https://github.com/adap/flower/pull/4395), "
"[#4386](https://github.com/adap/flower/pull/4386), "
"[#4408](https://github.com/adap/flower/pull/4408))"
msgstr ""

#: ../../source/ref-changelog.md:80
msgid ""
"Multiple examples and templates have been updated to enhance usability "
"and correctness. The updates include the `30-minute-tutorial`, "
"`quickstart-jax`, `quickstart-pytorch`, `advanced-tensorflow` examples, "
"and the FlowerTune template."
msgstr ""

#: ../../source/ref-changelog.md:82
msgid ""
"**Improve Docker support** "
"([#4506](https://github.com/adap/flower/pull/4506), "
"[#4424](https://github.com/adap/flower/pull/4424), "
"[#4224](https://github.com/adap/flower/pull/4224), "
"[#4413](https://github.com/adap/flower/pull/4413), "
"[#4414](https://github.com/adap/flower/pull/4414), "
"[#4336](https://github.com/adap/flower/pull/4336), "
"[#4420](https://github.com/adap/flower/pull/4420), "
"[#4407](https://github.com/adap/flower/pull/4407), "
"[#4422](https://github.com/adap/flower/pull/4422), "
"[#4532](https://github.com/adap/flower/pull/4532), "
"[#4540](https://github.com/adap/flower/pull/4540))"
msgstr ""

#: ../../source/ref-changelog.md:84
msgid ""
"Docker images and configurations have been updated, including updating "
"Docker Compose files to version 1.13.0, refactoring the Docker build "
"matrix for better maintainability, updating `docker/build-push-action` to"
" 6.9.0, and improving Docker documentation."
msgstr ""

#: ../../source/ref-changelog.md:86
msgid ""
"**Allow app installation without internet access** "
"([#4479](https://github.com/adap/flower/pull/4479), "
"[#4475](https://github.com/adap/flower/pull/4475))"
msgstr ""

#: ../../source/ref-changelog.md:88
msgid ""
"The `flwr build` command now includes a wheel file in the FAB, enabling "
"Flower app installation in environments without internet access via `flwr"
" install`."
msgstr ""

#: ../../source/ref-changelog.md:90
msgid ""
"**Improve `flwr log` command** "
"([#4391](https://github.com/adap/flower/pull/4391), "
"[#4411](https://github.com/adap/flower/pull/4411), "
"[#4390](https://github.com/adap/flower/pull/4390), "
"[#4397](https://github.com/adap/flower/pull/4397))"
msgstr ""

#: ../../source/ref-changelog.md:92
msgid ""
"**Refactor SuperNode for better maintainability and efficiency** "
"([#4439](https://github.com/adap/flower/pull/4439), "
"[#4348](https://github.com/adap/flower/pull/4348), "
"[#4512](https://github.com/adap/flower/pull/4512), "
"[#4485](https://github.com/adap/flower/pull/4485))"
msgstr ""

#: ../../source/ref-changelog.md:94
msgid ""
"**Support NumPy `2.0`** "
"([#4440](https://github.com/adap/flower/pull/4440))"
msgstr ""

#: ../../source/ref-changelog.md:96
msgid ""
"**Update infrastructure and CI/CD** "
"([#4466](https://github.com/adap/flower/pull/4466), "
"[#4419](https://github.com/adap/flower/pull/4419), "
"[#4338](https://github.com/adap/flower/pull/4338), "
"[#4334](https://github.com/adap/flower/pull/4334), "
"[#4456](https://github.com/adap/flower/pull/4456), "
"[#4446](https://github.com/adap/flower/pull/4446), "
"[#4415](https://github.com/adap/flower/pull/4415))"
msgstr ""

#: ../../source/ref-changelog.md:98
msgid ""
"**Bugfixes** ([#4404](https://github.com/adap/flower/pull/4404), "
"[#4518](https://github.com/adap/flower/pull/4518), "
"[#4452](https://github.com/adap/flower/pull/4452), "
"[#4376](https://github.com/adap/flower/pull/4376), "
"[#4493](https://github.com/adap/flower/pull/4493), "
"[#4436](https://github.com/adap/flower/pull/4436), "
"[#4410](https://github.com/adap/flower/pull/4410), "
"[#4442](https://github.com/adap/flower/pull/4442), "
"[#4375](https://github.com/adap/flower/pull/4375), "
"[#4515](https://github.com/adap/flower/pull/4515))"
msgstr ""

#: ../../source/ref-changelog.md:100
msgid ""
"**General improvements** "
"([#4454](https://github.com/adap/flower/pull/4454), "
"[#4365](https://github.com/adap/flower/pull/4365), "
"[#4423](https://github.com/adap/flower/pull/4423), "
"[#4516](https://github.com/adap/flower/pull/4516), "
"[#4509](https://github.com/adap/flower/pull/4509), "
"[#4498](https://github.com/adap/flower/pull/4498), "
"[#4371](https://github.com/adap/flower/pull/4371), "
"[#4449](https://github.com/adap/flower/pull/4449), "
"[#4488](https://github.com/adap/flower/pull/4488), "
"[#4478](https://github.com/adap/flower/pull/4478), "
"[#4392](https://github.com/adap/flower/pull/4392), "
"[#4483](https://github.com/adap/flower/pull/4483), "
"[#4517](https://github.com/adap/flower/pull/4517), "
"[#4330](https://github.com/adap/flower/pull/4330), "
"[#4458](https://github.com/adap/flower/pull/4458), "
"[#4347](https://github.com/adap/flower/pull/4347), "
"[#4429](https://github.com/adap/flower/pull/4429), "
"[#4463](https://github.com/adap/flower/pull/4463), "
"[#4496](https://github.com/adap/flower/pull/4496), "
"[#4508](https://github.com/adap/flower/pull/4508), "
"[#4444](https://github.com/adap/flower/pull/4444), "
"[#4417](https://github.com/adap/flower/pull/4417), "
"[#4504](https://github.com/adap/flower/pull/4504), "
"[#4418](https://github.com/adap/flower/pull/4418), "
"[#4480](https://github.com/adap/flower/pull/4480), "
"[#4455](https://github.com/adap/flower/pull/4455), "
"[#4468](https://github.com/adap/flower/pull/4468), "
"[#4385](https://github.com/adap/flower/pull/4385), "
"[#4487](https://github.com/adap/flower/pull/4487), "
"[#4393](https://github.com/adap/flower/pull/4393), "
"[#4489](https://github.com/adap/flower/pull/4489), "
"[#4389](https://github.com/adap/flower/pull/4389), "
"[#4507](https://github.com/adap/flower/pull/4507), "
"[#4469](https://github.com/adap/flower/pull/4469), "
"[#4340](https://github.com/adap/flower/pull/4340), "
"[#4353](https://github.com/adap/flower/pull/4353), "
"[#4494](https://github.com/adap/flower/pull/4494), "
"[#4461](https://github.com/adap/flower/pull/4461), "
"[#4362](https://github.com/adap/flower/pull/4362), "
"[#4473](https://github.com/adap/flower/pull/4473), "
"[#4405](https://github.com/adap/flower/pull/4405), "
"[#4416](https://github.com/adap/flower/pull/4416), "
"[#4453](https://github.com/adap/flower/pull/4453), "
"[#4491](https://github.com/adap/flower/pull/4491), "
"[#4539](https://github.com/adap/flower/pull/4539), "
"[#4542](https://github.com/adap/flower/pull/4542), "
"[#4538](https://github.com/adap/flower/pull/4538), "
"[#4543](https://github.com/adap/flower/pull/4543), "
"[#4541](https://github.com/adap/flower/pull/4541), "
"[#4550](https://github.com/adap/flower/pull/4550), "
"[#4481](https://github.com/adap/flower/pull/4481))"
msgstr ""

#: ../../source/ref-changelog.md:104 ../../source/ref-changelog.md:303
#: ../../source/ref-changelog.md:420 ../../source/ref-changelog.md:512
#: ../../source/ref-changelog.md:1495
msgid "Deprecations"
msgstr ""

#: ../../source/ref-changelog.md:106
msgid "**Deprecate Python 3.9**"
msgstr ""

#: ../../source/ref-changelog.md:108
msgid ""
"Flower is deprecating support for Python 3.9 as several of its "
"dependencies are phasing out compatibility with this version. While no "
"immediate changes have been made, users are encouraged to plan for "
"upgrading to a supported Python version."
msgstr ""

#: ../../source/ref-changelog.md:110 ../../source/ref-changelog.md:200
#: ../../source/ref-changelog.md:234 ../../source/ref-changelog.md:314
#: ../../source/ref-changelog.md:430 ../../source/ref-changelog.md:526
#: ../../source/ref-changelog.md:600 ../../source/ref-changelog.md:675
#: ../../source/ref-changelog.md:787 ../../source/ref-changelog.md:877
#: ../../source/ref-changelog.md:941 ../../source/ref-changelog.md:999
#: ../../source/ref-changelog.md:1068 ../../source/ref-changelog.md:1130
#: ../../source/ref-changelog.md:1149 ../../source/ref-changelog.md:1305
#: ../../source/ref-changelog.md:1376 ../../source/ref-changelog.md:1413
#: ../../source/ref-changelog.md:1456
msgid "Incompatible changes"
msgstr ""

#: ../../source/ref-changelog.md:112
msgid ""
"**Remove `flower-superexec` command** "
"([#4351](https://github.com/adap/flower/pull/4351))"
msgstr ""

#: ../../source/ref-changelog.md:114
msgid ""
"The `flower-superexec` command, previously used to launch SuperExec, is "
"no longer functional as SuperExec has been merged into SuperLink. "
"Starting an additional SuperExec is no longer necessary when SuperLink is"
" initiated."
msgstr ""

#: ../../source/ref-changelog.md:116
msgid ""
"**Remove `flower-server-app` command** "
"([#4490](https://github.com/adap/flower/pull/4490))"
msgstr ""

#: ../../source/ref-changelog.md:118
msgid ""
"The `flower-server-app` command has been removed. To start a Flower app, "
"please use the `flwr run` command instead."
msgstr ""

#: ../../source/ref-changelog.md:120
msgid ""
"**Remove `app` argument from `flower-supernode` command** "
"([#4497](https://github.com/adap/flower/pull/4497))"
msgstr ""

#: ../../source/ref-changelog.md:122
msgid ""
"The usage of `flower-supernode <app-dir>` has been removed. SuperNode "
"will now load the FAB delivered by SuperLink, and it is no longer "
"possible to directly specify an app directory."
msgstr ""

#: ../../source/ref-changelog.md:124
msgid ""
"**Remove support for non-app simulations** "
"([#4431](https://github.com/adap/flower/pull/4431))"
msgstr ""

#: ../../source/ref-changelog.md:126
msgid ""
"The simulation engine (via `flower-simulation`) now exclusively supports "
"passing an app."
msgstr ""

#: ../../source/ref-changelog.md:128
msgid ""
"**Rename CLI arguments for `flower-superlink` command** "
"([#4412](https://github.com/adap/flower/pull/4412))"
msgstr ""

#: ../../source/ref-changelog.md:130
msgid ""
"The `--driver-api-address` argument has been renamed to `--serverappio-"
"api-address` in the `flower-superlink` command to reflect the renaming of"
" the `Driver` service to the `ServerAppIo` service."
msgstr ""

#: ../../source/ref-changelog.md:132
msgid ""
"**Rename CLI arguments for `flwr-serverapp` and `flwr-clientapp` "
"commands** ([#4495](https://github.com/adap/flower/pull/4495))"
msgstr ""

#: ../../source/ref-changelog.md:134
msgid ""
"The CLI arguments have been renamed for clarity and consistency. "
"Specifically, `--superlink` for `flwr-serverapp` is now `--serverappio-"
"api-address`, and `--supernode` for `flwr-clientapp` is now "
"`--clientappio-api-address`."
msgstr ""

#: ../../source/ref-changelog.md:136
msgid "v1.12.0 (2024-10-14)"
msgstr ""

#: ../../source/ref-changelog.md:142
msgid ""
"`Adam Narozniak`, `Audris`, `Charles Beauville`, `Chong Shen Ng`, `Daniel"
" J. Beutel`, `Daniel Nata Nugraha`, `Heng Pan`, `Javier`, `Jiahao Tan`, "
"`Julian Rußmeyer`, `Mohammad Naseri`, `Ray Sun`, `Robert Steiner`, `Yan "
"Gao`, `xiliguguagua` <!---TOKEN_v1.12.0-->"
msgstr ""

#: ../../source/ref-changelog.md:146
msgid ""
"**Introduce SuperExec log streaming** "
"([#3577](https://github.com/adap/flower/pull/3577), "
"[#3584](https://github.com/adap/flower/pull/3584), "
"[#4242](https://github.com/adap/flower/pull/4242), "
"[#3611](https://github.com/adap/flower/pull/3611), "
"[#3613](https://github.com/adap/flower/pull/3613))"
msgstr ""

#: ../../source/ref-changelog.md:148
msgid ""
"Flower now supports log streaming from a remote SuperExec using the `flwr"
" log` command. This new feature allows you to monitor logs from SuperExec"
" in real time via `flwr log <run-id>` (or `flwr log <run-id> <app-dir> "
"<federation>`)."
msgstr ""

#: ../../source/ref-changelog.md:150
msgid ""
"**Improve `flwr new` templates** "
"([#4291](https://github.com/adap/flower/pull/4291), "
"[#4292](https://github.com/adap/flower/pull/4292), "
"[#4293](https://github.com/adap/flower/pull/4293), "
"[#4294](https://github.com/adap/flower/pull/4294), "
"[#4295](https://github.com/adap/flower/pull/4295))"
msgstr ""

#: ../../source/ref-changelog.md:152
msgid ""
"The `flwr new` command templates for MLX, NumPy, sklearn, JAX, and "
"PyTorch have been updated to improve usability and consistency across "
"frameworks."
msgstr ""

#: ../../source/ref-changelog.md:154
msgid ""
"**Migrate ID handling to use unsigned 64-bit integers** "
"([#4170](https://github.com/adap/flower/pull/4170), "
"[#4237](https://github.com/adap/flower/pull/4237), "
"[#4243](https://github.com/adap/flower/pull/4243))"
msgstr ""

#: ../../source/ref-changelog.md:156
msgid ""
"Node IDs, run IDs, and related fields have been migrated from signed "
"64-bit integers (`sint64`) to unsigned 64-bit integers (`uint64`). To "
"support this change, the `uint64` type is fully supported in all "
"communications. You may now use `uint64` values in config and metric "
"dictionaries. For Python users, that means using `int` values larger than"
" the maximum value of `sint64` but less than the maximum value of "
"`uint64`."
msgstr ""

#: ../../source/ref-changelog.md:158
msgid ""
"**Add Flower architecture explanation** "
"([#3270](https://github.com/adap/flower/pull/3270))"
msgstr ""

#: ../../source/ref-changelog.md:160
msgid ""
"A new [Flower architecture explainer](https://flower.ai/docs/framework"
"/explanation-flower-architecture.html) page introduces Flower components "
"step-by-step. Check out the `EXPLANATIONS` section of the Flower "
"documentation if you're interested."
msgstr ""

#: ../../source/ref-changelog.md:162
msgid ""
"**Introduce FedRep baseline** "
"([#3790](https://github.com/adap/flower/pull/3790))"
msgstr ""

#: ../../source/ref-changelog.md:164
msgid ""
"FedRep is a federated learning algorithm that learns shared data "
"representations across clients while allowing each to maintain "
"personalized local models, balancing collaboration and individual "
"adaptation. Read all the details in the paper: \"Exploiting Shared "
"Representations for Personalized Federated Learning\" "
"([arxiv](https://arxiv.org/abs/2102.07078))"
msgstr ""

#: ../../source/ref-changelog.md:166
msgid ""
"**Improve FlowerTune template and LLM evaluation pipelines** "
"([#4286](https://github.com/adap/flower/pull/4286), "
"[#3769](https://github.com/adap/flower/pull/3769), "
"[#4272](https://github.com/adap/flower/pull/4272), "
"[#4257](https://github.com/adap/flower/pull/4257), "
"[#4220](https://github.com/adap/flower/pull/4220), "
"[#4282](https://github.com/adap/flower/pull/4282), "
"[#4171](https://github.com/adap/flower/pull/4171), "
"[#4228](https://github.com/adap/flower/pull/4228), "
"[#4258](https://github.com/adap/flower/pull/4258), "
"[#4296](https://github.com/adap/flower/pull/4296), "
"[#4287](https://github.com/adap/flower/pull/4287), "
"[#4217](https://github.com/adap/flower/pull/4217), "
"[#4249](https://github.com/adap/flower/pull/4249), "
"[#4324](https://github.com/adap/flower/pull/4324), "
"[#4219](https://github.com/adap/flower/pull/4219), "
"[#4327](https://github.com/adap/flower/pull/4327))"
msgstr ""

#: ../../source/ref-changelog.md:168
msgid ""
"Refined evaluation pipelines, metrics, and documentation for the upcoming"
" FlowerTune LLM Leaderboard across multiple domains including Finance, "
"Medical, and general NLP. Stay tuned for the official launch—we welcome "
"all federated learning and LLM enthusiasts to participate in this "
"exciting challenge!"
msgstr ""

#: ../../source/ref-changelog.md:170
msgid ""
"**Enhance Docker Support and Documentation** "
"([#4191](https://github.com/adap/flower/pull/4191), "
"[#4251](https://github.com/adap/flower/pull/4251), "
"[#4190](https://github.com/adap/flower/pull/4190), "
"[#3928](https://github.com/adap/flower/pull/3928), "
"[#4298](https://github.com/adap/flower/pull/4298), "
"[#4192](https://github.com/adap/flower/pull/4192), "
"[#4136](https://github.com/adap/flower/pull/4136), "
"[#4187](https://github.com/adap/flower/pull/4187), "
"[#4261](https://github.com/adap/flower/pull/4261), "
"[#4177](https://github.com/adap/flower/pull/4177), "
"[#4176](https://github.com/adap/flower/pull/4176), "
"[#4189](https://github.com/adap/flower/pull/4189), "
"[#4297](https://github.com/adap/flower/pull/4297), "
"[#4226](https://github.com/adap/flower/pull/4226))"
msgstr ""

#: ../../source/ref-changelog.md:172
msgid ""
"Upgraded Ubuntu base image to 24.04, added SBOM and gcc to Docker images,"
" and comprehensively updated [Docker "
"documentation](https://flower.ai/docs/framework/docker/index.html) "
"including quickstart guides and distributed Docker Compose instructions."
msgstr ""

#: ../../source/ref-changelog.md:174
msgid ""
"**Introduce Flower glossary** "
"([#4165](https://github.com/adap/flower/pull/4165), "
"[#4235](https://github.com/adap/flower/pull/4235))"
msgstr ""

#: ../../source/ref-changelog.md:176
msgid ""
"Added the [Federated Learning glossary](https://flower.ai/glossary/) to "
"the Flower repository, located under the `flower/glossary/` directory. "
"This resource aims to provide clear definitions and explanations of key "
"FL concepts. Community contributions are highly welcomed to help expand "
"and refine this knowledge base — this is probably the easiest way to "
"become a Flower contributor!"
msgstr ""

#: ../../source/ref-changelog.md:178
msgid ""
"**Implement Message Time-to-Live (TTL)** "
"([#3620](https://github.com/adap/flower/pull/3620), "
"[#3596](https://github.com/adap/flower/pull/3596), "
"[#3615](https://github.com/adap/flower/pull/3615), "
"[#3609](https://github.com/adap/flower/pull/3609), "
"[#3635](https://github.com/adap/flower/pull/3635))"
msgstr ""

#: ../../source/ref-changelog.md:180
msgid ""
"Added comprehensive TTL support for messages in Flower's SuperLink. "
"Messages are now automatically expired and cleaned up based on "
"configurable TTL values, available through the low-level API (and used by"
" default in the high-level API)."
msgstr ""

#: ../../source/ref-changelog.md:182
msgid ""
"**Improve FAB handling** "
"([#4303](https://github.com/adap/flower/pull/4303), "
"[#4264](https://github.com/adap/flower/pull/4264), "
"[#4305](https://github.com/adap/flower/pull/4305), "
"[#4304](https://github.com/adap/flower/pull/4304))"
msgstr ""

#: ../../source/ref-changelog.md:184
msgid ""
"An 8-character hash is now appended to the FAB file name. The `flwr "
"install` command installs FABs with a more flattened folder structure, "
"reducing it from 3 levels to 1."
msgstr ""

#: ../../source/ref-changelog.md:186
msgid ""
"**Update documentation** "
"([#3341](https://github.com/adap/flower/pull/3341), "
"[#3338](https://github.com/adap/flower/pull/3338), "
"[#3927](https://github.com/adap/flower/pull/3927), "
"[#4152](https://github.com/adap/flower/pull/4152), "
"[#4151](https://github.com/adap/flower/pull/4151), "
"[#3993](https://github.com/adap/flower/pull/3993))"
msgstr ""

#: ../../source/ref-changelog.md:188
msgid ""
"Updated quickstart tutorials (PyTorch Lightning, TensorFlow, Hugging "
"Face, Fastai) to use the new `flwr run` command and removed default title"
" from documentation base template. A new blockchain example has been "
"added to FAQ."
msgstr ""

#: ../../source/ref-changelog.md:190
msgid ""
"**Update example projects** "
"([#3716](https://github.com/adap/flower/pull/3716), "
"[#4007](https://github.com/adap/flower/pull/4007), "
"[#4130](https://github.com/adap/flower/pull/4130), "
"[#4234](https://github.com/adap/flower/pull/4234), "
"[#4206](https://github.com/adap/flower/pull/4206), "
"[#4188](https://github.com/adap/flower/pull/4188), "
"[#4247](https://github.com/adap/flower/pull/4247), "
"[#4331](https://github.com/adap/flower/pull/4331))"
msgstr ""

#: ../../source/ref-changelog.md:192
msgid ""
"Refreshed multiple example projects including vertical FL, PyTorch "
"(advanced), Pandas, Secure Aggregation, and XGBoost examples. Optimized "
"Hugging Face quickstart with a smaller language model and removed legacy "
"simulation examples."
msgstr ""

#: ../../source/ref-changelog.md:194
msgid ""
"**Update translations** "
"([#4070](https://github.com/adap/flower/pull/4070), "
"[#4316](https://github.com/adap/flower/pull/4316), "
"[#4252](https://github.com/adap/flower/pull/4252), "
"[#4256](https://github.com/adap/flower/pull/4256), "
"[#4210](https://github.com/adap/flower/pull/4210), "
"[#4263](https://github.com/adap/flower/pull/4263), "
"[#4259](https://github.com/adap/flower/pull/4259))"
msgstr ""

#: ../../source/ref-changelog.md:196
msgid ""
"**General improvements** "
"([#4239](https://github.com/adap/flower/pull/4239), "
"[4276](https://github.com/adap/flower/pull/4276), "
"[4204](https://github.com/adap/flower/pull/4204), "
"[4184](https://github.com/adap/flower/pull/4184), "
"[4227](https://github.com/adap/flower/pull/4227), "
"[4183](https://github.com/adap/flower/pull/4183), "
"[4202](https://github.com/adap/flower/pull/4202), "
"[4250](https://github.com/adap/flower/pull/4250), "
"[4267](https://github.com/adap/flower/pull/4267), "
"[4246](https://github.com/adap/flower/pull/4246), "
"[4240](https://github.com/adap/flower/pull/4240), "
"[4265](https://github.com/adap/flower/pull/4265), "
"[4238](https://github.com/adap/flower/pull/4238), "
"[4275](https://github.com/adap/flower/pull/4275), "
"[4318](https://github.com/adap/flower/pull/4318), "
"[#4178](https://github.com/adap/flower/pull/4178), "
"[#4315](https://github.com/adap/flower/pull/4315), "
"[#4241](https://github.com/adap/flower/pull/4241), "
"[#4289](https://github.com/adap/flower/pull/4289), "
"[#4290](https://github.com/adap/flower/pull/4290), "
"[#4181](https://github.com/adap/flower/pull/4181), "
"[#4208](https://github.com/adap/flower/pull/4208), "
"[#4225](https://github.com/adap/flower/pull/4225), "
"[#4314](https://github.com/adap/flower/pull/4314), "
"[#4174](https://github.com/adap/flower/pull/4174), "
"[#4203](https://github.com/adap/flower/pull/4203), "
"[#4274](https://github.com/adap/flower/pull/4274), "
"[#3154](https://github.com/adap/flower/pull/3154), "
"[#4201](https://github.com/adap/flower/pull/4201), "
"[#4268](https://github.com/adap/flower/pull/4268), "
"[#4254](https://github.com/adap/flower/pull/4254), "
"[#3990](https://github.com/adap/flower/pull/3990), "
"[#4212](https://github.com/adap/flower/pull/4212), "
"[#2938](https://github.com/adap/flower/pull/2938), "
"[#4205](https://github.com/adap/flower/pull/4205), "
"[#4222](https://github.com/adap/flower/pull/4222), "
"[#4313](https://github.com/adap/flower/pull/4313), "
"[#3936](https://github.com/adap/flower/pull/3936), "
"[#4278](https://github.com/adap/flower/pull/4278), "
"[#4319](https://github.com/adap/flower/pull/4319), "
"[#4332](https://github.com/adap/flower/pull/4332), "
"[#4333](https://github.com/adap/flower/pull/4333))"
msgstr ""

#: ../../source/ref-changelog.md:202
msgid ""
"**Drop Python 3.8 support and update minimum version to 3.9** "
"([#4180](https://github.com/adap/flower/pull/4180), "
"[#4213](https://github.com/adap/flower/pull/4213), "
"[#4193](https://github.com/adap/flower/pull/4193), "
"[#4199](https://github.com/adap/flower/pull/4199), "
"[#4196](https://github.com/adap/flower/pull/4196), "
"[#4195](https://github.com/adap/flower/pull/4195), "
"[#4198](https://github.com/adap/flower/pull/4198), "
"[#4194](https://github.com/adap/flower/pull/4194))"
msgstr ""

#: ../../source/ref-changelog.md:204
msgid ""
"Python 3.8 support was deprecated in Flower 1.9, and this release removes"
" support. Flower now requires Python 3.9 or later (Python 3.11 is "
"recommended). CI and documentation were updated to use Python 3.9 as the "
"minimum supported version. Flower now supports Python 3.9 to 3.12."
msgstr ""

#: ../../source/ref-changelog.md:206
msgid "v1.11.1 (2024-09-11)"
msgstr ""

#: ../../source/ref-changelog.md:212
msgid ""
"`Charles Beauville`, `Chong Shen Ng`, `Daniel J. Beutel`, `Heng Pan`, "
"`Javier`, `Robert Steiner`, `Yan Gao` <!---TOKEN_v1.11.1-->"
msgstr ""

#: ../../source/ref-changelog.md:214
msgid "Improvements"
msgstr ""

#: ../../source/ref-changelog.md:216
msgid ""
"**Implement** `keys/values/items` **methods for** `TypedDict` "
"([#4146](https://github.com/adap/flower/pull/4146))"
msgstr ""

#: ../../source/ref-changelog.md:218
msgid ""
"**Fix parsing of** `--executor-config` **if present** "
"([#4125](https://github.com/adap/flower/pull/4125))"
msgstr ""

#: ../../source/ref-changelog.md:220
msgid ""
"**Adjust framework name in templates docstrings** "
"([#4127](https://github.com/adap/flower/pull/4127))"
msgstr ""

#: ../../source/ref-changelog.md:222
msgid ""
"**Update** `flwr new` **Hugging Face template** "
"([#4169](https://github.com/adap/flower/pull/4169))"
msgstr ""

#: ../../source/ref-changelog.md:224
msgid ""
"**Fix** `flwr new` **FlowerTune template** "
"([#4123](https://github.com/adap/flower/pull/4123))"
msgstr ""

#: ../../source/ref-changelog.md:226
msgid ""
"**Add buffer time after** `ServerApp` **thread initialization** "
"([#4119](https://github.com/adap/flower/pull/4119))"
msgstr ""

#: ../../source/ref-changelog.md:228
msgid ""
"**Handle unsuitable resources for simulation** "
"([#4143](https://github.com/adap/flower/pull/4143))"
msgstr ""

#: ../../source/ref-changelog.md:230
msgid ""
"**Update example READMEs** "
"([#4117](https://github.com/adap/flower/pull/4117))"
msgstr ""

#: ../../source/ref-changelog.md:232
msgid ""
"**Update SuperNode authentication docs** "
"([#4160](https://github.com/adap/flower/pull/4160))"
msgstr ""

#: ../../source/ref-changelog.md:238
msgid "v1.11.0 (2024-08-30)"
msgstr ""

#: ../../source/ref-changelog.md:244
msgid ""
"`Adam Narozniak`, `Charles Beauville`, `Chong Shen Ng`, `Daniel J. "
"Beutel`, `Daniel Nata Nugraha`, `Danny`, `Edoardo Gabrielli`, `Heng Pan`,"
" `Javier`, `Meng Yan`, `Michal Danilowski`, `Mohammad Naseri`, `Robert "
"Steiner`, `Steve Laskaridis`, `Taner Topal`, `Yan Gao` <!---"
"TOKEN_v1.11.0-->"
msgstr ""

#: ../../source/ref-changelog.md:248
msgid ""
"**Deliver Flower App Bundle (FAB) to SuperLink and SuperNodes** "
"([#4006](https://github.com/adap/flower/pull/4006), "
"[#3945](https://github.com/adap/flower/pull/3945), "
"[#3999](https://github.com/adap/flower/pull/3999), "
"[#4027](https://github.com/adap/flower/pull/4027), "
"[#3851](https://github.com/adap/flower/pull/3851), "
"[#3946](https://github.com/adap/flower/pull/3946), "
"[#4003](https://github.com/adap/flower/pull/4003), "
"[#4029](https://github.com/adap/flower/pull/4029), "
"[#3942](https://github.com/adap/flower/pull/3942), "
"[#3957](https://github.com/adap/flower/pull/3957), "
"[#4020](https://github.com/adap/flower/pull/4020), "
"[#4044](https://github.com/adap/flower/pull/4044), "
"[#3852](https://github.com/adap/flower/pull/3852), "
"[#4019](https://github.com/adap/flower/pull/4019), "
"[#4031](https://github.com/adap/flower/pull/4031), "
"[#4036](https://github.com/adap/flower/pull/4036), "
"[#4049](https://github.com/adap/flower/pull/4049), "
"[#4017](https://github.com/adap/flower/pull/4017), "
"[#3943](https://github.com/adap/flower/pull/3943), "
"[#3944](https://github.com/adap/flower/pull/3944), "
"[#4011](https://github.com/adap/flower/pull/4011), "
"[#3619](https://github.com/adap/flower/pull/3619))"
msgstr ""

#: ../../source/ref-changelog.md:250
msgid ""
"Dynamic code updates are here! `flwr run` can now ship and install the "
"latest version of your `ServerApp` and `ClientApp` to an already-running "
"federation (SuperLink and SuperNodes)."
msgstr ""

#: ../../source/ref-changelog.md:252
msgid ""
"How does it work? `flwr run` bundles your Flower app into a single FAB "
"(Flower App Bundle) file. It then ships this FAB file, via the SuperExec,"
" to both the SuperLink and those SuperNodes that need it. This allows you"
" to keep SuperExec, SuperLink and SuperNodes running as permanent "
"infrastructure, and then ship code updates (including completely new "
"projects!) dynamically."
msgstr ""

#: ../../source/ref-changelog.md:254
msgid "`flwr run` is all you need."
msgstr ""

#: ../../source/ref-changelog.md:256
msgid ""
"**Introduce isolated** `ClientApp` **execution** "
"([#3970](https://github.com/adap/flower/pull/3970), "
"[#3976](https://github.com/adap/flower/pull/3976), "
"[#4002](https://github.com/adap/flower/pull/4002), "
"[#4001](https://github.com/adap/flower/pull/4001), "
"[#4034](https://github.com/adap/flower/pull/4034), "
"[#4037](https://github.com/adap/flower/pull/4037), "
"[#3977](https://github.com/adap/flower/pull/3977), "
"[#4042](https://github.com/adap/flower/pull/4042), "
"[#3978](https://github.com/adap/flower/pull/3978), "
"[#4039](https://github.com/adap/flower/pull/4039), "
"[#4033](https://github.com/adap/flower/pull/4033), "
"[#3971](https://github.com/adap/flower/pull/3971), "
"[#4035](https://github.com/adap/flower/pull/4035), "
"[#3973](https://github.com/adap/flower/pull/3973), "
"[#4032](https://github.com/adap/flower/pull/4032))"
msgstr ""

#: ../../source/ref-changelog.md:258
msgid ""
"The SuperNode can now run your `ClientApp` in a fully isolated way. In an"
" enterprise deployment, this allows you to set strict limits on what the "
"`ClientApp` can and cannot do."
msgstr ""

#: ../../source/ref-changelog.md:260
msgid "`flower-supernode` supports three `--isolation` modes:"
msgstr ""

#: ../../source/ref-changelog.md:262
msgid ""
"Unset: The SuperNode runs the `ClientApp` in the same process (as in "
"previous versions of Flower). This is the default mode."
msgstr ""

#: ../../source/ref-changelog.md:263
msgid ""
"`--isolation=subprocess`: The SuperNode starts a subprocess to run the "
"`ClientApp`."
msgstr ""

#: ../../source/ref-changelog.md:264
msgid ""
"`--isolation=process`: The SuperNode expects an externally-managed "
"process to run the `ClientApp`. This external process is not managed by "
"the SuperNode, so it has to be started beforehand and terminated "
"manually. The common way to use this isolation mode is via the new "
"`flwr/clientapp` Docker image."
msgstr ""

#: ../../source/ref-changelog.md:266
msgid ""
"**Improve Docker support for enterprise deployments** "
"([#4050](https://github.com/adap/flower/pull/4050), "
"[#4090](https://github.com/adap/flower/pull/4090), "
"[#3784](https://github.com/adap/flower/pull/3784), "
"[#3998](https://github.com/adap/flower/pull/3998), "
"[#4094](https://github.com/adap/flower/pull/4094), "
"[#3722](https://github.com/adap/flower/pull/3722))"
msgstr ""

#: ../../source/ref-changelog.md:268
msgid ""
"Flower 1.11 ships many Docker improvements that are especially useful for"
" enterprise deployments:"
msgstr ""

#: ../../source/ref-changelog.md:270
msgid "`flwr/supernode` comes with a new Alpine Docker image."
msgstr ""

#: ../../source/ref-changelog.md:271
msgid ""
"`flwr/clientapp` is a new image to be used with the `--isolation=process`"
" option. In this mode, SuperNode and `ClientApp` run in two different "
"Docker containers. `flwr/supernode` (preferably the Alpine version) runs "
"the long-running SuperNode with `--isolation=process`. `flwr/clientapp` "
"runs the `ClientApp`. This is the recommended way to deploy Flower in "
"enterprise settings."
msgstr ""

#: ../../source/ref-changelog.md:272
msgid ""
"New all-in-one Docker Compose enables you to easily start a full Flower "
"Deployment Engine on a single machine."
msgstr ""

#: ../../source/ref-changelog.md:273
msgid ""
"Completely new Docker documentation: "
"https://flower.ai/docs/framework/docker/index.html"
msgstr ""

#: ../../source/ref-changelog.md:275
msgid ""
"**Improve SuperNode authentication** "
"([#4043](https://github.com/adap/flower/pull/4043), "
"[#4047](https://github.com/adap/flower/pull/4047), "
"[#4074](https://github.com/adap/flower/pull/4074))"
msgstr ""

#: ../../source/ref-changelog.md:277
msgid ""
"SuperNode auth has been improved in several ways, including improved "
"logging, improved testing, and improved error handling."
msgstr ""

#: ../../source/ref-changelog.md:279
msgid ""
"**Update** `flwr new` **templates** "
"([#3933](https://github.com/adap/flower/pull/3933), "
"[#3894](https://github.com/adap/flower/pull/3894), "
"[#3930](https://github.com/adap/flower/pull/3930), "
"[#3931](https://github.com/adap/flower/pull/3931), "
"[#3997](https://github.com/adap/flower/pull/3997), "
"[#3979](https://github.com/adap/flower/pull/3979), "
"[#3965](https://github.com/adap/flower/pull/3965), "
"[#4013](https://github.com/adap/flower/pull/4013), "
"[#4064](https://github.com/adap/flower/pull/4064))"
msgstr ""

#: ../../source/ref-changelog.md:281
msgid ""
"All `flwr new` templates have been updated to show the latest recommended"
" use of Flower APIs."
msgstr ""

#: ../../source/ref-changelog.md:283
msgid ""
"**Improve Simulation Engine** "
"([#4095](https://github.com/adap/flower/pull/4095), "
"[#3913](https://github.com/adap/flower/pull/3913), "
"[#4059](https://github.com/adap/flower/pull/4059), "
"[#3954](https://github.com/adap/flower/pull/3954), "
"[#4071](https://github.com/adap/flower/pull/4071), "
"[#3985](https://github.com/adap/flower/pull/3985), "
"[#3988](https://github.com/adap/flower/pull/3988))"
msgstr ""

#: ../../source/ref-changelog.md:285
msgid ""
"The Flower Simulation Engine comes with several updates, including "
"improved run config support, verbose logging, simulation backend "
"configuration via `flwr run`, and more."
msgstr ""

#: ../../source/ref-changelog.md:287
msgid ""
"**Improve** `RecordSet` "
"([#4052](https://github.com/adap/flower/pull/4052), "
"[#3218](https://github.com/adap/flower/pull/3218), "
"[#4016](https://github.com/adap/flower/pull/4016))"
msgstr ""

#: ../../source/ref-changelog.md:289
msgid ""
"`RecordSet` is the core object to exchange model parameters, "
"configuration values and metrics between `ClientApp` and `ServerApp`. "
"This release ships several smaller improvements to `RecordSet` and "
"related `*Record` types."
msgstr ""

#: ../../source/ref-changelog.md:291
msgid ""
"**Update documentation** "
"([#3972](https://github.com/adap/flower/pull/3972), "
"[#3925](https://github.com/adap/flower/pull/3925), "
"[#4061](https://github.com/adap/flower/pull/4061), "
"[#3984](https://github.com/adap/flower/pull/3984), "
"[#3917](https://github.com/adap/flower/pull/3917), "
"[#3900](https://github.com/adap/flower/pull/3900), "
"[#4066](https://github.com/adap/flower/pull/4066), "
"[#3765](https://github.com/adap/flower/pull/3765), "
"[#4021](https://github.com/adap/flower/pull/4021), "
"[#3906](https://github.com/adap/flower/pull/3906), "
"[#4063](https://github.com/adap/flower/pull/4063), "
"[#4076](https://github.com/adap/flower/pull/4076), "
"[#3920](https://github.com/adap/flower/pull/3920), "
"[#3916](https://github.com/adap/flower/pull/3916))"
msgstr ""

#: ../../source/ref-changelog.md:293
msgid ""
"Many parts of the documentation, including the main tutorial, have been "
"migrated to show new Flower APIs and other new Flower features like the "
"improved Docker support."
msgstr ""

#: ../../source/ref-changelog.md:295
msgid ""
"**Migrate code example to use new Flower APIs** "
"([#3758](https://github.com/adap/flower/pull/3758), "
"[#3701](https://github.com/adap/flower/pull/3701), "
"[#3919](https://github.com/adap/flower/pull/3919), "
"[#3918](https://github.com/adap/flower/pull/3918), "
"[#3934](https://github.com/adap/flower/pull/3934), "
"[#3893](https://github.com/adap/flower/pull/3893), "
"[#3833](https://github.com/adap/flower/pull/3833), "
"[#3922](https://github.com/adap/flower/pull/3922), "
"[#3846](https://github.com/adap/flower/pull/3846), "
"[#3777](https://github.com/adap/flower/pull/3777), "
"[#3874](https://github.com/adap/flower/pull/3874), "
"[#3873](https://github.com/adap/flower/pull/3873), "
"[#3935](https://github.com/adap/flower/pull/3935), "
"[#3754](https://github.com/adap/flower/pull/3754), "
"[#3980](https://github.com/adap/flower/pull/3980), "
"[#4089](https://github.com/adap/flower/pull/4089), "
"[#4046](https://github.com/adap/flower/pull/4046), "
"[#3314](https://github.com/adap/flower/pull/3314), "
"[#3316](https://github.com/adap/flower/pull/3316), "
"[#3295](https://github.com/adap/flower/pull/3295), "
"[#3313](https://github.com/adap/flower/pull/3313))"
msgstr ""

#: ../../source/ref-changelog.md:297
msgid "Many code examples have been migrated to use new Flower APIs."
msgstr ""

#: ../../source/ref-changelog.md:299
msgid ""
"**Update Flower framework, framework internals and quality "
"infrastructure** ([#4018](https://github.com/adap/flower/pull/4018), "
"[#4053](https://github.com/adap/flower/pull/4053), "
"[#4098](https://github.com/adap/flower/pull/4098), "
"[#4067](https://github.com/adap/flower/pull/4067), "
"[#4105](https://github.com/adap/flower/pull/4105), "
"[#4048](https://github.com/adap/flower/pull/4048), "
"[#4107](https://github.com/adap/flower/pull/4107), "
"[#4069](https://github.com/adap/flower/pull/4069), "
"[#3915](https://github.com/adap/flower/pull/3915), "
"[#4101](https://github.com/adap/flower/pull/4101), "
"[#4108](https://github.com/adap/flower/pull/4108), "
"[#3914](https://github.com/adap/flower/pull/3914), "
"[#4068](https://github.com/adap/flower/pull/4068), "
"[#4041](https://github.com/adap/flower/pull/4041), "
"[#4040](https://github.com/adap/flower/pull/4040), "
"[#3986](https://github.com/adap/flower/pull/3986), "
"[#4026](https://github.com/adap/flower/pull/4026), "
"[#3961](https://github.com/adap/flower/pull/3961), "
"[#3975](https://github.com/adap/flower/pull/3975), "
"[#3983](https://github.com/adap/flower/pull/3983), "
"[#4091](https://github.com/adap/flower/pull/4091), "
"[#3982](https://github.com/adap/flower/pull/3982), "
"[#4079](https://github.com/adap/flower/pull/4079), "
"[#4073](https://github.com/adap/flower/pull/4073), "
"[#4060](https://github.com/adap/flower/pull/4060), "
"[#4106](https://github.com/adap/flower/pull/4106), "
"[#4080](https://github.com/adap/flower/pull/4080), "
"[#3974](https://github.com/adap/flower/pull/3974), "
"[#3996](https://github.com/adap/flower/pull/3996), "
"[#3991](https://github.com/adap/flower/pull/3991), "
"[#3981](https://github.com/adap/flower/pull/3981), "
"[#4093](https://github.com/adap/flower/pull/4093), "
"[#4100](https://github.com/adap/flower/pull/4100), "
"[#3939](https://github.com/adap/flower/pull/3939), "
"[#3955](https://github.com/adap/flower/pull/3955), "
"[#3940](https://github.com/adap/flower/pull/3940), "
"[#4038](https://github.com/adap/flower/pull/4038))"
msgstr ""

#: ../../source/ref-changelog.md:305
msgid ""
"**Deprecate accessing `Context` via `Client.context`** "
"([#3797](https://github.com/adap/flower/pull/3797))"
msgstr ""

#: ../../source/ref-changelog.md:307
msgid ""
"Now that both `client_fn` and `server_fn` receive a `Context` object, "
"accessing `Context` via `Client.context` is deprecated. `Client.context` "
"will be removed in a future release. If you need to access `Context` in "
"your `Client` implementation, pass it manually when creating the `Client`"
" instance in `client_fn`:"
msgstr ""

#: ../../source/ref-changelog.md:316
msgid ""
"**Update CLIs to accept an app directory instead of** `ClientApp` **and**"
" `ServerApp` ([#3952](https://github.com/adap/flower/pull/3952), "
"[#4077](https://github.com/adap/flower/pull/4077), "
"[#3850](https://github.com/adap/flower/pull/3850))"
msgstr ""

#: ../../source/ref-changelog.md:318
msgid ""
"The CLI commands `flower-supernode` and `flower-server-app` now accept an"
" app directory as argument (instead of references to a `ClientApp` or "
"`ServerApp`). An app directory is any directory containing a "
"`pyproject.toml` file (with the appropriate Flower config fields set). "
"The easiest way to generate a compatible project structure is to use "
"`flwr new`."
msgstr ""

#: ../../source/ref-changelog.md:320
msgid ""
"**Disable** `flower-client-app` **CLI command** "
"([#4022](https://github.com/adap/flower/pull/4022))"
msgstr ""

#: ../../source/ref-changelog.md:322
msgid "`flower-client-app` has been disabled. Use `flower-supernode` instead."
msgstr ""

#: ../../source/ref-changelog.md:324
msgid ""
"**Use spaces instead of commas for separating config args** "
"([#4000](https://github.com/adap/flower/pull/4000))"
msgstr ""

#: ../../source/ref-changelog.md:326
msgid ""
"When passing configs (run config, node config) to Flower, you now need to"
" separate key-value pairs using spaces instead of commas. For example:"
msgstr ""

#: ../../source/ref-changelog.md:332
msgid "Previously, you could pass configs using commas, like this:"
msgstr ""

#: ../../source/ref-changelog.md:338
msgid ""
"**Remove** `flwr example` **CLI command** "
"([#4084](https://github.com/adap/flower/pull/4084))"
msgstr ""

#: ../../source/ref-changelog.md:340
msgid ""
"The experimental `flwr example` CLI command has been removed. Use `flwr "
"new` to generate a project and then run it using `flwr run`."
msgstr ""

#: ../../source/ref-changelog.md:342
msgid "v1.10.0 (2024-07-24)"
msgstr ""

#: ../../source/ref-changelog.md:348
msgid ""
"`Adam Narozniak`, `Charles Beauville`, `Chong Shen Ng`, `Daniel J. "
"Beutel`, `Daniel Nata Nugraha`, `Danny`, `Gustavo Bertoli`, `Heng Pan`, "
"`Ikko Eltociear Ashimine`, `Javier`, `Jiahao Tan`, `Mohammad Naseri`, "
"`Robert Steiner`, `Sebastian van der Voort`, `Taner Topal`, `Yan Gao` <!"
"---TOKEN_v1.10.0-->"
msgstr ""

#: ../../source/ref-changelog.md:352
msgid ""
"**Introduce** `flwr run` **(beta)** "
"([#3810](https://github.com/adap/flower/pull/3810), "
"[#3826](https://github.com/adap/flower/pull/3826), "
"[#3880](https://github.com/adap/flower/pull/3880), "
"[#3807](https://github.com/adap/flower/pull/3807), "
"[#3800](https://github.com/adap/flower/pull/3800), "
"[#3814](https://github.com/adap/flower/pull/3814), "
"[#3811](https://github.com/adap/flower/pull/3811), "
"[#3809](https://github.com/adap/flower/pull/3809), "
"[#3819](https://github.com/adap/flower/pull/3819))"
msgstr ""

#: ../../source/ref-changelog.md:354
msgid ""
"Flower 1.10 ships the first beta release of the new `flwr run` command. "
"`flwr run` can run different projects using `flwr run path/to/project`, "
"it enables you to easily switch between different federations using `flwr"
" run . federation` and it runs your Flower project using either local "
"simulation or the new (experimental) SuperExec service. This allows "
"Flower to scale federatated learning from fast local simulation to large-"
"scale production deployment, seamlessly. All projects generated with "
"`flwr new` are immediately runnable using `flwr run`. Give it a try: use "
"`flwr new` to generate a project and then run it using `flwr run`."
msgstr ""

#: ../../source/ref-changelog.md:356
msgid ""
"**Introduce run config** "
"([#3751](https://github.com/adap/flower/pull/3751), "
"[#3750](https://github.com/adap/flower/pull/3750), "
"[#3845](https://github.com/adap/flower/pull/3845), "
"[#3824](https://github.com/adap/flower/pull/3824), "
"[#3746](https://github.com/adap/flower/pull/3746), "
"[#3728](https://github.com/adap/flower/pull/3728), "
"[#3730](https://github.com/adap/flower/pull/3730), "
"[#3725](https://github.com/adap/flower/pull/3725), "
"[#3729](https://github.com/adap/flower/pull/3729), "
"[#3580](https://github.com/adap/flower/pull/3580), "
"[#3578](https://github.com/adap/flower/pull/3578), "
"[#3576](https://github.com/adap/flower/pull/3576), "
"[#3798](https://github.com/adap/flower/pull/3798), "
"[#3732](https://github.com/adap/flower/pull/3732), "
"[#3815](https://github.com/adap/flower/pull/3815))"
msgstr ""

#: ../../source/ref-changelog.md:358
msgid ""
"The new run config feature allows you to run your Flower project in "
"different configurations without having to change a single line of code. "
"You can now build a configurable `ServerApp` and `ClientApp` that read "
"configuration values at runtime. This enables you to specify config "
"values like `learning-rate=0.01` in `pyproject.toml` (under the "
"`[tool.flwr.app.config]` key). These config values can then be easily "
"overridden via `flwr run --run-config learning-rate=0.02`, and read from "
"`Context` using `lr = context.run_config[\"learning-rate\"]`. Create a "
"new project using `flwr new` to see run config in action."
msgstr ""

#: ../../source/ref-changelog.md:360
msgid ""
"**Generalize** `client_fn` **signature to** `client_fn(context: Context) "
"-> Client` ([#3779](https://github.com/adap/flower/pull/3779), "
"[#3697](https://github.com/adap/flower/pull/3697), "
"[#3694](https://github.com/adap/flower/pull/3694), "
"[#3696](https://github.com/adap/flower/pull/3696))"
msgstr ""

#: ../../source/ref-changelog.md:362
msgid ""
"The `client_fn` signature has been generalized to `client_fn(context: "
"Context) -> Client`. It now receives a `Context` object instead of the "
"(now depreacated) `cid: str`. `Context` allows accessing `node_id`, "
"`node_config` and `run_config`, among other things. This enables you to "
"build a configurable `ClientApp` that leverages the new run config "
"system."
msgstr ""

#: ../../source/ref-changelog.md:364
msgid ""
"The previous signature `client_fn(cid: str)` is now deprecated and "
"support for it will be removed in a future release. Use "
"`client_fn(context: Context) -> Client` everywhere."
msgstr ""

#: ../../source/ref-changelog.md:366
msgid ""
"**Introduce new** `server_fn(context)` "
"([#3773](https://github.com/adap/flower/pull/3773), "
"[#3796](https://github.com/adap/flower/pull/3796), "
"[#3771](https://github.com/adap/flower/pull/3771))"
msgstr ""

#: ../../source/ref-changelog.md:368
msgid ""
"In addition to the new `client_fn(context:Context)`, a new "
"`server_fn(context: Context) -> ServerAppComponents` can now be passed to"
" `ServerApp` (instead of passing, for example, `Strategy`, directly). "
"This enables you to leverage the full `Context` on the server-side to "
"build a configurable `ServerApp`."
msgstr ""

#: ../../source/ref-changelog.md:370
msgid ""
"**Relaunch all** `flwr new` **templates** "
"([#3877](https://github.com/adap/flower/pull/3877), "
"[#3821](https://github.com/adap/flower/pull/3821), "
"[#3587](https://github.com/adap/flower/pull/3587), "
"[#3795](https://github.com/adap/flower/pull/3795), "
"[#3875](https://github.com/adap/flower/pull/3875), "
"[#3859](https://github.com/adap/flower/pull/3859), "
"[#3760](https://github.com/adap/flower/pull/3760))"
msgstr ""

#: ../../source/ref-changelog.md:372
msgid ""
"All `flwr new` templates have been significantly updated to showcase new "
"Flower features and best practices. This includes using `flwr run` and "
"the new run config feature. You can now easily create a new project using"
" `flwr new` and, after following the instructions to install it, `flwr "
"run` it."
msgstr ""

#: ../../source/ref-changelog.md:374
msgid ""
"**Introduce** `flower-supernode` **(preview)** "
"([#3353](https://github.com/adap/flower/pull/3353))"
msgstr ""

#: ../../source/ref-changelog.md:376
msgid ""
"The new `flower-supernode` CLI is here to replace `flower-client-app`. "
"`flower-supernode` brings full multi-app support to the Flower client-"
"side. It also allows to pass `--node-config` to the SuperNode, which is "
"accessible in your `ClientApp` via `Context` (using the new "
"`client_fn(context: Context)` signature)."
msgstr ""

#: ../../source/ref-changelog.md:378
msgid ""
"**Introduce node config** "
"([#3782](https://github.com/adap/flower/pull/3782), "
"[#3780](https://github.com/adap/flower/pull/3780), "
"[#3695](https://github.com/adap/flower/pull/3695), "
"[#3886](https://github.com/adap/flower/pull/3886))"
msgstr ""

#: ../../source/ref-changelog.md:380
msgid ""
"A new node config feature allows you to pass a static configuration to "
"the SuperNode. This configuration is read-only and available to every "
"`ClientApp` running on that SuperNode. A `ClientApp` can access the node "
"config via `Context` (`context.node_config`)."
msgstr ""

#: ../../source/ref-changelog.md:382
msgid ""
"**Introduce SuperExec (experimental)** "
"([#3605](https://github.com/adap/flower/pull/3605), "
"[#3723](https://github.com/adap/flower/pull/3723), "
"[#3731](https://github.com/adap/flower/pull/3731), "
"[#3589](https://github.com/adap/flower/pull/3589), "
"[#3604](https://github.com/adap/flower/pull/3604), "
"[#3622](https://github.com/adap/flower/pull/3622), "
"[#3838](https://github.com/adap/flower/pull/3838), "
"[#3720](https://github.com/adap/flower/pull/3720), "
"[#3606](https://github.com/adap/flower/pull/3606), "
"[#3602](https://github.com/adap/flower/pull/3602), "
"[#3603](https://github.com/adap/flower/pull/3603), "
"[#3555](https://github.com/adap/flower/pull/3555), "
"[#3808](https://github.com/adap/flower/pull/3808), "
"[#3724](https://github.com/adap/flower/pull/3724), "
"[#3658](https://github.com/adap/flower/pull/3658), "
"[#3629](https://github.com/adap/flower/pull/3629))"
msgstr ""

#: ../../source/ref-changelog.md:384
msgid ""
"This is the first experimental release of Flower SuperExec, a new service"
" that executes your runs. It's not ready for production deployment just "
"yet, but don't hesitate to give it a try if you're interested."
msgstr ""

#: ../../source/ref-changelog.md:386
msgid ""
"**Add new federated learning with tabular data example** "
"([#3568](https://github.com/adap/flower/pull/3568))"
msgstr ""

#: ../../source/ref-changelog.md:388
msgid ""
"A new code example exemplifies a federated learning setup using the "
"Flower framework on the Adult Census Income tabular dataset."
msgstr ""

#: ../../source/ref-changelog.md:390
msgid ""
"**Create generic adapter layer (preview)** "
"([#3538](https://github.com/adap/flower/pull/3538), "
"[#3536](https://github.com/adap/flower/pull/3536), "
"[#3540](https://github.com/adap/flower/pull/3540))"
msgstr ""

#: ../../source/ref-changelog.md:392
msgid ""
"A new generic gRPC adapter layer allows 3rd-party frameworks to integrate"
" with Flower in a transparent way. This makes Flower more modular and "
"allows for integration into other federated learning solutions and "
"platforms."
msgstr ""

#: ../../source/ref-changelog.md:394
msgid ""
"**Refactor Flower Simulation Engine** "
"([#3581](https://github.com/adap/flower/pull/3581), "
"[#3471](https://github.com/adap/flower/pull/3471), "
"[#3804](https://github.com/adap/flower/pull/3804), "
"[#3468](https://github.com/adap/flower/pull/3468), "
"[#3839](https://github.com/adap/flower/pull/3839), "
"[#3806](https://github.com/adap/flower/pull/3806), "
"[#3861](https://github.com/adap/flower/pull/3861), "
"[#3543](https://github.com/adap/flower/pull/3543), "
"[#3472](https://github.com/adap/flower/pull/3472), "
"[#3829](https://github.com/adap/flower/pull/3829), "
"[#3469](https://github.com/adap/flower/pull/3469))"
msgstr ""

#: ../../source/ref-changelog.md:396
msgid ""
"The Simulation Engine was significantly refactored. This results in "
"faster and more stable simulations. It is also the foundation for "
"upcoming changes that aim to provide the next level of performance and "
"configurability in federated learning simulations."
msgstr ""

#: ../../source/ref-changelog.md:398
msgid ""
"**Optimize Docker containers** "
"([#3591](https://github.com/adap/flower/pull/3591))"
msgstr ""

#: ../../source/ref-changelog.md:400
msgid ""
"Flower Docker containers were optimized and updated to use that latest "
"Flower framework features."
msgstr ""

#: ../../source/ref-changelog.md:402
msgid ""
"**Improve logging** ([#3776](https://github.com/adap/flower/pull/3776), "
"[#3789](https://github.com/adap/flower/pull/3789))"
msgstr ""

#: ../../source/ref-changelog.md:404
msgid ""
"Improved logging aims to be more concise and helpful to show you the "
"details you actually care about."
msgstr ""

#: ../../source/ref-changelog.md:406
msgid ""
"**Refactor framework internals** "
"([#3621](https://github.com/adap/flower/pull/3621), "
"[#3792](https://github.com/adap/flower/pull/3792), "
"[#3772](https://github.com/adap/flower/pull/3772), "
"[#3805](https://github.com/adap/flower/pull/3805), "
"[#3583](https://github.com/adap/flower/pull/3583), "
"[#3825](https://github.com/adap/flower/pull/3825), "
"[#3597](https://github.com/adap/flower/pull/3597), "
"[#3802](https://github.com/adap/flower/pull/3802), "
"[#3569](https://github.com/adap/flower/pull/3569))"
msgstr ""

#: ../../source/ref-changelog.md:410
msgid "Documentation improvements"
msgstr ""

#: ../../source/ref-changelog.md:412
msgid ""
"**Add 🇰🇷 Korean translations** "
"([#3680](https://github.com/adap/flower/pull/3680))"
msgstr ""

#: ../../source/ref-changelog.md:414
msgid ""
"**Update translations** "
"([#3586](https://github.com/adap/flower/pull/3586), "
"[#3679](https://github.com/adap/flower/pull/3679), "
"[#3570](https://github.com/adap/flower/pull/3570), "
"[#3681](https://github.com/adap/flower/pull/3681), "
"[#3617](https://github.com/adap/flower/pull/3617), "
"[#3674](https://github.com/adap/flower/pull/3674), "
"[#3671](https://github.com/adap/flower/pull/3671), "
"[#3572](https://github.com/adap/flower/pull/3572), "
"[#3631](https://github.com/adap/flower/pull/3631))"
msgstr ""

#: ../../source/ref-changelog.md:416
msgid ""
"**Update documentation** "
"([#3864](https://github.com/adap/flower/pull/3864), "
"[#3688](https://github.com/adap/flower/pull/3688), "
"[#3562](https://github.com/adap/flower/pull/3562), "
"[#3641](https://github.com/adap/flower/pull/3641), "
"[#3384](https://github.com/adap/flower/pull/3384), "
"[#3634](https://github.com/adap/flower/pull/3634), "
"[#3823](https://github.com/adap/flower/pull/3823), "
"[#3793](https://github.com/adap/flower/pull/3793), "
"[#3707](https://github.com/adap/flower/pull/3707))"
msgstr ""

#: ../../source/ref-changelog.md:418
msgid ""
"Updated documentation includes new install instructions for different "
"shells, a new Flower Code Examples documentation landing page, new `flwr`"
" CLI docs and an updated federated XGBoost code example."
msgstr ""

#: ../../source/ref-changelog.md:422
msgid "**Deprecate** `client_fn(cid: str)`"
msgstr ""

#: ../../source/ref-changelog.md:424
msgid ""
"`client_fn` used to have a signature `client_fn(cid: str) -> Client`. "
"This signature is now deprecated. Use the new signature "
"`client_fn(context: Context) -> Client` instead. The new argument "
"`context` allows accessing `node_id`, `node_config`, `run_config` and "
"other `Context` features. When running using the simulation engine (or "
"using `flower-supernode` with a custom `--node-config partition-id=...`),"
" `context.node_config[\"partition-id\"]` will return an `int` partition "
"ID that can be used with Flower Datasets to load a different partition of"
" the dataset on each simulated or deployed SuperNode."
msgstr ""

#: ../../source/ref-changelog.md:426
msgid ""
"**Deprecate passing** `Server/ServerConfig/Strategy/ClientManager` **to**"
" `ServerApp` **directly**"
msgstr ""

#: ../../source/ref-changelog.md:428
msgid ""
"Creating `ServerApp` using `ServerApp(config=config, strategy=strategy)` "
"is now deprecated. Instead of passing "
"`Server/ServerConfig/Strategy/ClientManager` to `ServerApp` directly, "
"pass them wrapped in a `server_fn(context: Context) -> "
"ServerAppComponents` function, like this: "
"`ServerApp(server_fn=server_fn)`. `ServerAppComponents` can hold "
"references to `Server/ServerConfig/Strategy/ClientManager`. In addition "
"to that, `server_fn` allows you to access `Context` (for example, to read"
" the `run_config`)."
msgstr ""

#: ../../source/ref-changelog.md:432
msgid ""
"**Remove support for `client_ids` in `start_simulation`** "
"([#3699](https://github.com/adap/flower/pull/3699))"
msgstr ""

#: ../../source/ref-changelog.md:434
msgid ""
"The (rarely used) feature that allowed passing custom `client_ids` to the"
" `start_simulation` function was removed. This removal is part of a "
"bigger effort to refactor the simulation engine and unify how the Flower "
"internals work in simulation and deployment."
msgstr ""

#: ../../source/ref-changelog.md:436
msgid ""
"**Remove `flower-driver-api` and `flower-fleet-api`** "
"([#3418](https://github.com/adap/flower/pull/3418))"
msgstr ""

#: ../../source/ref-changelog.md:438
msgid ""
"The two deprecated CLI commands `flower-driver-api` and `flower-fleet-"
"api` were removed in an effort to streamline the SuperLink developer "
"experience. Use `flower-superlink` instead."
msgstr ""

#: ../../source/ref-changelog.md:440
msgid "v1.9.0 (2024-06-10)"
msgstr ""

#: ../../source/ref-changelog.md:446
msgid ""
"`Adam Narozniak`, `Charles Beauville`, `Chong Shen Ng`, `Daniel J. "
"Beutel`, `Daniel Nata Nugraha`, `Heng Pan`, `Javier`, `Mahdi Beitollahi`,"
" `Robert Steiner`, `Taner Topal`, `Yan Gao`, `bapic`, `mohammadnaseri` <!"
"---TOKEN_v1.9.0-->"
msgstr ""

#: ../../source/ref-changelog.md:450
msgid ""
"**Introduce built-in authentication (preview)** "
"([#2946](https://github.com/adap/flower/pull/2946), "
"[#3388](https://github.com/adap/flower/pull/3388), "
"[#2948](https://github.com/adap/flower/pull/2948), "
"[#2917](https://github.com/adap/flower/pull/2917), "
"[#3386](https://github.com/adap/flower/pull/3386), "
"[#3308](https://github.com/adap/flower/pull/3308), "
"[#3001](https://github.com/adap/flower/pull/3001), "
"[#3409](https://github.com/adap/flower/pull/3409), "
"[#2999](https://github.com/adap/flower/pull/2999), "
"[#2979](https://github.com/adap/flower/pull/2979), "
"[#3389](https://github.com/adap/flower/pull/3389), "
"[#3503](https://github.com/adap/flower/pull/3503), "
"[#3366](https://github.com/adap/flower/pull/3366), "
"[#3357](https://github.com/adap/flower/pull/3357))"
msgstr ""

#: ../../source/ref-changelog.md:452
msgid ""
"Flower 1.9 introduces the first build-in version of client node "
"authentication. In previous releases, users often wrote glue code to "
"connect Flower to external authentication systems. With this release, the"
" SuperLink can authenticate SuperNodes using a built-in authentication "
"system. A new [how-to guide](https://flower.ai/docs/framework/how-to-"
"authenticate-supernodes.html) and a new [code "
"example](https://github.com/adap/flower/tree/main/examples/flower-"
"authentication) help you to get started."
msgstr ""

#: ../../source/ref-changelog.md:454
msgid ""
"This is the first preview release of the Flower-native authentication "
"system. Many additional features are on the roadmap for upcoming Flower "
"releases - stay tuned."
msgstr ""

#: ../../source/ref-changelog.md:456
msgid ""
"**Introduce end-to-end Docker support** "
"([#3483](https://github.com/adap/flower/pull/3483), "
"[#3266](https://github.com/adap/flower/pull/3266), "
"[#3390](https://github.com/adap/flower/pull/3390), "
"[#3283](https://github.com/adap/flower/pull/3283), "
"[#3285](https://github.com/adap/flower/pull/3285), "
"[#3391](https://github.com/adap/flower/pull/3391), "
"[#3403](https://github.com/adap/flower/pull/3403), "
"[#3458](https://github.com/adap/flower/pull/3458), "
"[#3533](https://github.com/adap/flower/pull/3533), "
"[#3453](https://github.com/adap/flower/pull/3453), "
"[#3486](https://github.com/adap/flower/pull/3486), "
"[#3290](https://github.com/adap/flower/pull/3290))"
msgstr ""

#: ../../source/ref-changelog.md:458
msgid ""
"Full Flower Next Docker support is here! With the release of Flower 1.9, "
"Flower provides stable Docker images for the Flower SuperLink, the Flower"
" SuperNode, and the Flower `ServerApp`. This set of images enables you to"
" run all Flower components in Docker. Check out the new [how-to "
"guide](https://flower.ai/docs/framework/how-to-run-flower-using-"
"docker.html) to get stated."
msgstr ""

#: ../../source/ref-changelog.md:460
msgid ""
"**Re-architect Flower Next simulation engine** "
"([#3307](https://github.com/adap/flower/pull/3307), "
"[#3355](https://github.com/adap/flower/pull/3355), "
"[#3272](https://github.com/adap/flower/pull/3272), "
"[#3273](https://github.com/adap/flower/pull/3273), "
"[#3417](https://github.com/adap/flower/pull/3417), "
"[#3281](https://github.com/adap/flower/pull/3281), "
"[#3343](https://github.com/adap/flower/pull/3343), "
"[#3326](https://github.com/adap/flower/pull/3326))"
msgstr ""

#: ../../source/ref-changelog.md:462
msgid ""
"Flower Next simulations now use a new in-memory `Driver` that improves "
"the reliability of simulations, especially in notebook environments. This"
" is a significant step towards a complete overhaul of the Flower Next "
"simulation architecture."
msgstr ""

#: ../../source/ref-changelog.md:464
msgid ""
"**Upgrade simulation engine** "
"([#3354](https://github.com/adap/flower/pull/3354), "
"[#3378](https://github.com/adap/flower/pull/3378), "
"[#3262](https://github.com/adap/flower/pull/3262), "
"[#3435](https://github.com/adap/flower/pull/3435), "
"[#3501](https://github.com/adap/flower/pull/3501), "
"[#3482](https://github.com/adap/flower/pull/3482), "
"[#3494](https://github.com/adap/flower/pull/3494))"
msgstr ""

#: ../../source/ref-changelog.md:466
msgid ""
"The Flower Next simulation engine comes with improved and configurable "
"logging. The Ray-based simulation backend in Flower 1.9 was updated to "
"use Ray 2.10."
msgstr ""

#: ../../source/ref-changelog.md:468
msgid ""
"**Introduce FedPFT baseline** "
"([#3268](https://github.com/adap/flower/pull/3268))"
msgstr ""

#: ../../source/ref-changelog.md:470
msgid ""
"FedPFT allows you to perform one-shot Federated Learning by leveraging "
"widely available foundational models, dramatically reducing communication"
" costs while delivering high performing models. This is work led by Mahdi"
" Beitollahi from Huawei Noah's Ark Lab (Montreal, Canada). Read all the "
"details in their paper: \"Parametric Feature Transfer: One-shot Federated"
" Learning with Foundation Models\" "
"([arxiv](https://arxiv.org/abs/2402.01862))"
msgstr ""

#: ../../source/ref-changelog.md:472
msgid ""
"**Launch additional** `flwr new` **templates for Apple MLX, Hugging Face "
"Transformers, scikit-learn and TensorFlow** "
"([#3291](https://github.com/adap/flower/pull/3291), "
"[#3139](https://github.com/adap/flower/pull/3139), "
"[#3284](https://github.com/adap/flower/pull/3284), "
"[#3251](https://github.com/adap/flower/pull/3251), "
"[#3376](https://github.com/adap/flower/pull/3376), "
"[#3287](https://github.com/adap/flower/pull/3287))"
msgstr ""

#: ../../source/ref-changelog.md:474
msgid ""
"The `flwr` CLI's `flwr new` command is starting to become everone's "
"favorite way of creating new Flower projects. This release introduces "
"additional `flwr new` templates for Apple MLX, Hugging Face Transformers,"
" scikit-learn and TensorFlow. In addition to that, existing templates "
"also received updates."
msgstr ""

#: ../../source/ref-changelog.md:476
msgid ""
"**Refine** `RecordSet` **API** "
"([#3209](https://github.com/adap/flower/pull/3209), "
"[#3331](https://github.com/adap/flower/pull/3331), "
"[#3334](https://github.com/adap/flower/pull/3334), "
"[#3335](https://github.com/adap/flower/pull/3335), "
"[#3375](https://github.com/adap/flower/pull/3375), "
"[#3368](https://github.com/adap/flower/pull/3368))"
msgstr ""

#: ../../source/ref-changelog.md:478
msgid ""
"`RecordSet` is part of the Flower Next low-level API preview release. In "
"Flower 1.9, `RecordSet` received a number of usability improvements that "
"make it easier to build `RecordSet`-based `ServerApp`s and `ClientApp`s."
msgstr ""

#: ../../source/ref-changelog.md:480
msgid ""
"**Beautify logging** ([#3379](https://github.com/adap/flower/pull/3379), "
"[#3430](https://github.com/adap/flower/pull/3430), "
"[#3461](https://github.com/adap/flower/pull/3461), "
"[#3360](https://github.com/adap/flower/pull/3360), "
"[#3433](https://github.com/adap/flower/pull/3433))"
msgstr ""

#: ../../source/ref-changelog.md:482
msgid ""
"Logs received a substantial update. Not only are logs now much nicer to "
"look at, but they are also more configurable."
msgstr ""

#: ../../source/ref-changelog.md:484
msgid ""
"**Improve reliability** "
"([#3564](https://github.com/adap/flower/pull/3564), "
"[#3561](https://github.com/adap/flower/pull/3561), "
"[#3566](https://github.com/adap/flower/pull/3566), "
"[#3462](https://github.com/adap/flower/pull/3462), "
"[#3225](https://github.com/adap/flower/pull/3225), "
"[#3514](https://github.com/adap/flower/pull/3514), "
"[#3535](https://github.com/adap/flower/pull/3535), "
"[#3372](https://github.com/adap/flower/pull/3372))"
msgstr ""

#: ../../source/ref-changelog.md:486
msgid ""
"Flower 1.9 includes reliability improvements across many parts of the "
"system. One example is a much improved SuperNode shutdown procedure."
msgstr ""

#: ../../source/ref-changelog.md:488
msgid ""
"**Update Swift and C++ SDKs** "
"([#3321](https://github.com/adap/flower/pull/3321), "
"[#2763](https://github.com/adap/flower/pull/2763))"
msgstr ""

#: ../../source/ref-changelog.md:490
msgid ""
"In the C++ SDK, communication-related code is now separate from main "
"client logic. A new abstract class `Communicator` has been introduced "
"alongside a gRPC implementation of it."
msgstr ""

#: ../../source/ref-changelog.md:492
msgid ""
"**Improve testing, tooling and CI/CD infrastructure** "
"([#3294](https://github.com/adap/flower/pull/3294), "
"[#3282](https://github.com/adap/flower/pull/3282), "
"[#3311](https://github.com/adap/flower/pull/3311), "
"[#2878](https://github.com/adap/flower/pull/2878), "
"[#3333](https://github.com/adap/flower/pull/3333), "
"[#3255](https://github.com/adap/flower/pull/3255), "
"[#3349](https://github.com/adap/flower/pull/3349), "
"[#3400](https://github.com/adap/flower/pull/3400), "
"[#3401](https://github.com/adap/flower/pull/3401), "
"[#3399](https://github.com/adap/flower/pull/3399), "
"[#3346](https://github.com/adap/flower/pull/3346), "
"[#3398](https://github.com/adap/flower/pull/3398), "
"[#3397](https://github.com/adap/flower/pull/3397), "
"[#3347](https://github.com/adap/flower/pull/3347), "
"[#3502](https://github.com/adap/flower/pull/3502), "
"[#3387](https://github.com/adap/flower/pull/3387), "
"[#3542](https://github.com/adap/flower/pull/3542), "
"[#3396](https://github.com/adap/flower/pull/3396), "
"[#3496](https://github.com/adap/flower/pull/3496), "
"[#3465](https://github.com/adap/flower/pull/3465), "
"[#3473](https://github.com/adap/flower/pull/3473), "
"[#3484](https://github.com/adap/flower/pull/3484), "
"[#3521](https://github.com/adap/flower/pull/3521), "
"[#3363](https://github.com/adap/flower/pull/3363), "
"[#3497](https://github.com/adap/flower/pull/3497), "
"[#3464](https://github.com/adap/flower/pull/3464), "
"[#3495](https://github.com/adap/flower/pull/3495), "
"[#3478](https://github.com/adap/flower/pull/3478), "
"[#3271](https://github.com/adap/flower/pull/3271))"
msgstr ""

#: ../../source/ref-changelog.md:494
msgid ""
"As always, the Flower tooling, testing, and CI/CD infrastructure has "
"received many updates."
msgstr ""

#: ../../source/ref-changelog.md:496
msgid ""
"**Improve documentation** "
"([#3530](https://github.com/adap/flower/pull/3530), "
"[#3539](https://github.com/adap/flower/pull/3539), "
"[#3425](https://github.com/adap/flower/pull/3425), "
"[#3520](https://github.com/adap/flower/pull/3520), "
"[#3286](https://github.com/adap/flower/pull/3286), "
"[#3516](https://github.com/adap/flower/pull/3516), "
"[#3523](https://github.com/adap/flower/pull/3523), "
"[#3545](https://github.com/adap/flower/pull/3545), "
"[#3498](https://github.com/adap/flower/pull/3498), "
"[#3439](https://github.com/adap/flower/pull/3439), "
"[#3440](https://github.com/adap/flower/pull/3440), "
"[#3382](https://github.com/adap/flower/pull/3382), "
"[#3559](https://github.com/adap/flower/pull/3559), "
"[#3432](https://github.com/adap/flower/pull/3432), "
"[#3278](https://github.com/adap/flower/pull/3278), "
"[#3371](https://github.com/adap/flower/pull/3371), "
"[#3519](https://github.com/adap/flower/pull/3519), "
"[#3267](https://github.com/adap/flower/pull/3267), "
"[#3204](https://github.com/adap/flower/pull/3204), "
"[#3274](https://github.com/adap/flower/pull/3274))"
msgstr ""

#: ../../source/ref-changelog.md:498
msgid ""
"As always, the Flower documentation has received many updates. Notable "
"new pages include:"
msgstr ""

#: ../../source/ref-changelog.md:500
msgid ""
"[How-to upgrate to Flower Next (Flower Next migration "
"guide)](https://flower.ai/docs/framework/how-to-upgrade-to-flower-"
"next.html)"
msgstr ""

#: ../../source/ref-changelog.md:502
msgid ""
"[How-to run Flower using Docker](https://flower.ai/docs/framework/how-to-"
"run-flower-using-docker.html)"
msgstr ""

#: ../../source/ref-changelog.md:504
msgid ""
"[Flower Mods reference](https://flower.ai/docs/framework/ref-"
"api/flwr.client.mod.html#module-flwr.client.mod)"
msgstr ""

#: ../../source/ref-changelog.md:506
msgid ""
"**General updates to Flower Examples** "
"([#3205](https://github.com/adap/flower/pull/3205), "
"[#3226](https://github.com/adap/flower/pull/3226), "
"[#3211](https://github.com/adap/flower/pull/3211), "
"[#3252](https://github.com/adap/flower/pull/3252), "
"[#3427](https://github.com/adap/flower/pull/3427), "
"[#3410](https://github.com/adap/flower/pull/3410), "
"[#3426](https://github.com/adap/flower/pull/3426), "
"[#3228](https://github.com/adap/flower/pull/3228), "
"[#3342](https://github.com/adap/flower/pull/3342), "
"[#3200](https://github.com/adap/flower/pull/3200), "
"[#3202](https://github.com/adap/flower/pull/3202), "
"[#3394](https://github.com/adap/flower/pull/3394), "
"[#3488](https://github.com/adap/flower/pull/3488), "
"[#3329](https://github.com/adap/flower/pull/3329), "
"[#3526](https://github.com/adap/flower/pull/3526), "
"[#3392](https://github.com/adap/flower/pull/3392), "
"[#3474](https://github.com/adap/flower/pull/3474), "
"[#3269](https://github.com/adap/flower/pull/3269))"
msgstr ""

#: ../../source/ref-changelog.md:508
msgid "As always, Flower code examples have received many updates."
msgstr ""

#: ../../source/ref-changelog.md:510
msgid ""
"**General improvements** "
"([#3532](https://github.com/adap/flower/pull/3532), "
"[#3318](https://github.com/adap/flower/pull/3318), "
"[#3565](https://github.com/adap/flower/pull/3565), "
"[#3296](https://github.com/adap/flower/pull/3296), "
"[#3305](https://github.com/adap/flower/pull/3305), "
"[#3246](https://github.com/adap/flower/pull/3246), "
"[#3224](https://github.com/adap/flower/pull/3224), "
"[#3475](https://github.com/adap/flower/pull/3475), "
"[#3297](https://github.com/adap/flower/pull/3297), "
"[#3317](https://github.com/adap/flower/pull/3317), "
"[#3429](https://github.com/adap/flower/pull/3429), "
"[#3196](https://github.com/adap/flower/pull/3196), "
"[#3534](https://github.com/adap/flower/pull/3534), "
"[#3240](https://github.com/adap/flower/pull/3240), "
"[#3365](https://github.com/adap/flower/pull/3365), "
"[#3407](https://github.com/adap/flower/pull/3407), "
"[#3563](https://github.com/adap/flower/pull/3563), "
"[#3344](https://github.com/adap/flower/pull/3344), "
"[#3330](https://github.com/adap/flower/pull/3330), "
"[#3436](https://github.com/adap/flower/pull/3436), "
"[#3300](https://github.com/adap/flower/pull/3300), "
"[#3327](https://github.com/adap/flower/pull/3327), "
"[#3254](https://github.com/adap/flower/pull/3254), "
"[#3253](https://github.com/adap/flower/pull/3253), "
"[#3419](https://github.com/adap/flower/pull/3419), "
"[#3289](https://github.com/adap/flower/pull/3289), "
"[#3208](https://github.com/adap/flower/pull/3208), "
"[#3245](https://github.com/adap/flower/pull/3245), "
"[#3319](https://github.com/adap/flower/pull/3319), "
"[#3203](https://github.com/adap/flower/pull/3203), "
"[#3423](https://github.com/adap/flower/pull/3423), "
"[#3352](https://github.com/adap/flower/pull/3352), "
"[#3292](https://github.com/adap/flower/pull/3292), "
"[#3261](https://github.com/adap/flower/pull/3261))"
msgstr ""

#: ../../source/ref-changelog.md:514
msgid "**Deprecate Python 3.8 support**"
msgstr ""

#: ../../source/ref-changelog.md:516
msgid ""
"Python 3.8 will stop receiving security fixes in [October "
"2024](https://devguide.python.org/versions/). Support for Python 3.8 is "
"now deprecated and will be removed in an upcoming release."
msgstr ""

#: ../../source/ref-changelog.md:518
msgid ""
"**Deprecate (experimental)** `flower-driver-api` **and** `flower-fleet-"
"api` ([#3416](https://github.com/adap/flower/pull/3416), "
"[#3420](https://github.com/adap/flower/pull/3420))"
msgstr ""

#: ../../source/ref-changelog.md:520
msgid ""
"Flower 1.9 deprecates the two (experimental) commands `flower-driver-api`"
" and `flower-fleet-api`. Both commands will be removed in an upcoming "
"release. Use `flower-superlink` instead."
msgstr ""

#: ../../source/ref-changelog.md:522
msgid ""
"**Deprecate** `--server` **in favor of** `--superlink` "
"([#3518](https://github.com/adap/flower/pull/3518))"
msgstr ""

#: ../../source/ref-changelog.md:524
msgid ""
"The commands `flower-server-app` and `flower-client-app` should use "
"`--superlink` instead of the now deprecated `--server`. Support for "
"`--server` will be removed in a future release."
msgstr ""

#: ../../source/ref-changelog.md:528
msgid ""
"**Replace** `flower-superlink` **CLI option** `--certificates` **with** "
"`--ssl-ca-certfile` **,** `--ssl-certfile` **and** `--ssl-keyfile` "
"([#3512](https://github.com/adap/flower/pull/3512), "
"[#3408](https://github.com/adap/flower/pull/3408))"
msgstr ""

#: ../../source/ref-changelog.md:530
msgid ""
"SSL-related `flower-superlink` CLI arguments were restructured in an "
"incompatible way. Instead of passing a single `--certificates` flag with "
"three values, you now need to pass three flags (`--ssl-ca-certfile`, "
"`--ssl-certfile` and `--ssl-keyfile`) with one value each. Check out the "
"[SSL connections](https://flower.ai/docs/framework/how-to-enable-ssl-"
"connections.html) documentation page for details."
msgstr ""

#: ../../source/ref-changelog.md:532
msgid ""
"**Remove SuperLink** `--vce` **option** "
"([#3513](https://github.com/adap/flower/pull/3513))"
msgstr ""

#: ../../source/ref-changelog.md:534
msgid ""
"Instead of separately starting a SuperLink and a `ServerApp` for "
"simulation, simulations must now be started using the single `flower-"
"simulation` command."
msgstr ""

#: ../../source/ref-changelog.md:536
msgid ""
"**Merge** `--grpc-rere` **and** `--rest` **SuperLink options** "
"([#3527](https://github.com/adap/flower/pull/3527))"
msgstr ""

#: ../../source/ref-changelog.md:538
msgid ""
"To simplify the usage of `flower-superlink`, previously separate sets of "
"CLI options for gRPC and REST were merged into one unified set of "
"options. Consult the [Flower CLI reference "
"documentation](https://flower.ai/docs/framework/ref-api-cli.html) for "
"details."
msgstr ""

#: ../../source/ref-changelog.md:540
msgid "v1.8.0 (2024-04-03)"
msgstr ""

#: ../../source/ref-changelog.md:546
msgid ""
"`Adam Narozniak`, `Charles Beauville`, `Daniel J. Beutel`, `Daniel Nata "
"Nugraha`, `Danny`, `Gustavo Bertoli`, `Heng Pan`, `Ikko Eltociear "
"Ashimine`, `Jack Cook`, `Javier`, `Raj Parekh`, `Robert Steiner`, "
"`Sebastian van der Voort`, `Taner Topal`, `Yan Gao`, `mohammadnaseri`, "
"`tabdar-khan` <!---TOKEN_v1.8.0-->"
msgstr ""

#: ../../source/ref-changelog.md:550
msgid ""
"**Introduce Flower Next high-level API (stable)** "
"([#3002](https://github.com/adap/flower/pull/3002), "
"[#2934](https://github.com/adap/flower/pull/2934), "
"[#2958](https://github.com/adap/flower/pull/2958), "
"[#3173](https://github.com/adap/flower/pull/3173), "
"[#3174](https://github.com/adap/flower/pull/3174), "
"[#2923](https://github.com/adap/flower/pull/2923), "
"[#2691](https://github.com/adap/flower/pull/2691), "
"[#3079](https://github.com/adap/flower/pull/3079), "
"[#2961](https://github.com/adap/flower/pull/2961), "
"[#2924](https://github.com/adap/flower/pull/2924), "
"[#3166](https://github.com/adap/flower/pull/3166), "
"[#3031](https://github.com/adap/flower/pull/3031), "
"[#3057](https://github.com/adap/flower/pull/3057), "
"[#3000](https://github.com/adap/flower/pull/3000), "
"[#3113](https://github.com/adap/flower/pull/3113), "
"[#2957](https://github.com/adap/flower/pull/2957), "
"[#3183](https://github.com/adap/flower/pull/3183), "
"[#3180](https://github.com/adap/flower/pull/3180), "
"[#3035](https://github.com/adap/flower/pull/3035), "
"[#3189](https://github.com/adap/flower/pull/3189), "
"[#3185](https://github.com/adap/flower/pull/3185), "
"[#3190](https://github.com/adap/flower/pull/3190), "
"[#3191](https://github.com/adap/flower/pull/3191), "
"[#3195](https://github.com/adap/flower/pull/3195), "
"[#3197](https://github.com/adap/flower/pull/3197))"
msgstr ""

#: ../../source/ref-changelog.md:552
msgid ""
"The Flower Next high-level API is stable! Flower Next is the future of "
"Flower - all new features (like Flower Mods) will be built on top of it. "
"You can start to migrate your existing projects to Flower Next by using "
"`ServerApp` and `ClientApp` (check out `quickstart-pytorch` or "
"`quickstart-tensorflow`, a detailed migration guide will follow shortly)."
" Flower Next allows you to run multiple projects concurrently (we call "
"this multi-run) and execute the same project in either simulation "
"environments or deployment environments without having to change a single"
" line of code. The best part? It's fully compatible with existing Flower "
"projects that use `Strategy`, `NumPyClient` & co."
msgstr ""

#: ../../source/ref-changelog.md:554
msgid ""
"**Introduce Flower Next low-level API (preview)** "
"([#3062](https://github.com/adap/flower/pull/3062), "
"[#3034](https://github.com/adap/flower/pull/3034), "
"[#3069](https://github.com/adap/flower/pull/3069))"
msgstr ""

#: ../../source/ref-changelog.md:556
msgid ""
"In addition to the Flower Next *high-level* API that uses `Strategy`, "
"`NumPyClient` & co, Flower 1.8 also comes with a preview version of the "
"new Flower Next *low-level* API. The low-level API allows for granular "
"control of every aspect of the learning process by sending/receiving "
"individual messages to/from client nodes. The new `ServerApp` supports "
"registering a custom `main` function that allows writing custom training "
"loops for methods like async FL, cyclic training, or federated analytics."
" The new `ClientApp` supports registering `train`, `evaluate` and `query`"
" functions that can access the raw message received from the `ServerApp`."
" New abstractions like `RecordSet`, `Message` and `Context` further "
"enable sending multiple models, multiple sets of config values and "
"metrics, stateful computations on the client node and implementations of "
"custom SMPC protocols, to name just a few."
msgstr ""

#: ../../source/ref-changelog.md:558
msgid ""
"**Introduce Flower Mods (preview)** "
"([#3054](https://github.com/adap/flower/pull/3054), "
"[#2911](https://github.com/adap/flower/pull/2911), "
"[#3083](https://github.com/adap/flower/pull/3083))"
msgstr ""

#: ../../source/ref-changelog.md:560
msgid ""
"Flower Modifiers (we call them Mods) can intercept messages and analyze, "
"edit or handle them directly. Mods can be used to develop pluggable "
"modules that work across different projects. Flower 1.8 already includes "
"mods to log the size of a message, the number of parameters sent over the"
" network, differential privacy with fixed clipping and adaptive clipping,"
" local differential privacy and secure aggregation protocols SecAgg and "
"SecAgg+. The Flower Mods API is released as a preview, but researchers "
"can already use it to experiment with arbirtrary SMPC protocols."
msgstr ""

#: ../../source/ref-changelog.md:562
msgid ""
"**Fine-tune LLMs with LLM FlowerTune** "
"([#3029](https://github.com/adap/flower/pull/3029), "
"[#3089](https://github.com/adap/flower/pull/3089), "
"[#3092](https://github.com/adap/flower/pull/3092), "
"[#3100](https://github.com/adap/flower/pull/3100), "
"[#3114](https://github.com/adap/flower/pull/3114), "
"[#3162](https://github.com/adap/flower/pull/3162), "
"[#3172](https://github.com/adap/flower/pull/3172))"
msgstr ""

#: ../../source/ref-changelog.md:564
msgid ""
"We are introducing LLM FlowerTune, an introductory example that "
"demonstrates federated LLM fine-tuning of pre-trained Llama2 models on "
"the Alpaca-GPT4 dataset. The example is built to be easily adapted to use"
" different models and/or datasets. Read our blog post [LLM FlowerTune: "
"Federated LLM Fine-tuning with Flower](https://flower.ai/blog/2024-03-14"
"-llm-flowertune-federated-llm-finetuning-with-flower/) for more details."
msgstr ""

#: ../../source/ref-changelog.md:566
msgid ""
"**Introduce built-in Differential Privacy (preview)** "
"([#2798](https://github.com/adap/flower/pull/2798), "
"[#2959](https://github.com/adap/flower/pull/2959), "
"[#3038](https://github.com/adap/flower/pull/3038), "
"[#3147](https://github.com/adap/flower/pull/3147), "
"[#2909](https://github.com/adap/flower/pull/2909), "
"[#2893](https://github.com/adap/flower/pull/2893), "
"[#2892](https://github.com/adap/flower/pull/2892), "
"[#3039](https://github.com/adap/flower/pull/3039), "
"[#3074](https://github.com/adap/flower/pull/3074))"
msgstr ""

#: ../../source/ref-changelog.md:568
msgid ""
"Built-in Differential Privacy is here! Flower supports both central and "
"local differential privacy (DP). Central DP can be configured with either"
" fixed or adaptive clipping. The clipping can happen either on the "
"server-side or the client-side. Local DP does both clipping and noising "
"on the client-side. A new documentation page [explains Differential "
"Privacy approaches](https://flower.ai/docs/framework/explanation-"
"differential-privacy.html) and a new how-to guide describes [how to use "
"the new Differential Privacy components](https://flower.ai/docs/framework"
"/how-to-use-differential-privacy.html) in Flower."
msgstr ""

#: ../../source/ref-changelog.md:570
msgid ""
"**Introduce built-in Secure Aggregation (preview)** "
"([#3120](https://github.com/adap/flower/pull/3120), "
"[#3110](https://github.com/adap/flower/pull/3110), "
"[#3108](https://github.com/adap/flower/pull/3108))"
msgstr ""

#: ../../source/ref-changelog.md:572
msgid ""
"Built-in Secure Aggregation is here! Flower now supports different secure"
" aggregation protocols out-of-the-box. The best part? You can add secure "
"aggregation to your Flower projects with only a few lines of code. In "
"this initial release, we inlcude support for SecAgg and SecAgg+, but more"
" protocols will be implemented shortly. We'll also add detailed docs that"
" explain secure aggregation and how to use it in Flower. You can already "
"check out the new code example that shows how to use Flower to easily "
"combine Federated Learning, Differential Privacy and Secure Aggregation "
"in the same project."
msgstr ""

#: ../../source/ref-changelog.md:574
msgid ""
"**Introduce** `flwr` **CLI (preview)** "
"([#2942](https://github.com/adap/flower/pull/2942), "
"[#3055](https://github.com/adap/flower/pull/3055), "
"[#3111](https://github.com/adap/flower/pull/3111), "
"[#3130](https://github.com/adap/flower/pull/3130), "
"[#3136](https://github.com/adap/flower/pull/3136), "
"[#3094](https://github.com/adap/flower/pull/3094), "
"[#3059](https://github.com/adap/flower/pull/3059), "
"[#3049](https://github.com/adap/flower/pull/3049), "
"[#3142](https://github.com/adap/flower/pull/3142))"
msgstr ""

#: ../../source/ref-changelog.md:576
msgid ""
"A new `flwr` CLI command allows creating new Flower projects (`flwr new`)"
" and then running them using the Simulation Engine (`flwr run`)."
msgstr ""

#: ../../source/ref-changelog.md:578
msgid ""
"**Introduce Flower Next Simulation Engine** "
"([#3024](https://github.com/adap/flower/pull/3024), "
"[#3061](https://github.com/adap/flower/pull/3061), "
"[#2997](https://github.com/adap/flower/pull/2997), "
"[#2783](https://github.com/adap/flower/pull/2783), "
"[#3184](https://github.com/adap/flower/pull/3184), "
"[#3075](https://github.com/adap/flower/pull/3075), "
"[#3047](https://github.com/adap/flower/pull/3047), "
"[#2998](https://github.com/adap/flower/pull/2998), "
"[#3009](https://github.com/adap/flower/pull/3009), "
"[#3008](https://github.com/adap/flower/pull/3008))"
msgstr ""

#: ../../source/ref-changelog.md:580
msgid ""
"The Flower Simulation Engine can now run Flower Next projects. For "
"notebook environments, there's also a new `run_simulation` function that "
"can run `ServerApp` and `ClientApp`."
msgstr ""

#: ../../source/ref-changelog.md:582
msgid ""
"**Handle SuperNode connection errors** "
"([#2969](https://github.com/adap/flower/pull/2969))"
msgstr ""

#: ../../source/ref-changelog.md:584
msgid ""
"A SuperNode will now try to reconnect indefinitely to the SuperLink in "
"case of connection errors. The arguments `--max-retries` and `--max-wait-"
"time` can now be passed to the `flower-client-app` command. `--max-"
"retries` will define the number of tentatives the client should make "
"before it gives up trying to reconnect to the SuperLink, and, `--max-"
"wait-time` defines the time before the SuperNode gives up trying to "
"reconnect to the SuperLink."
msgstr ""

#: ../../source/ref-changelog.md:586
msgid ""
"**General updates to Flower Baselines** "
"([#2904](https://github.com/adap/flower/pull/2904), "
"[#2482](https://github.com/adap/flower/pull/2482), "
"[#2985](https://github.com/adap/flower/pull/2985), "
"[#2968](https://github.com/adap/flower/pull/2968))"
msgstr ""

#: ../../source/ref-changelog.md:588
msgid ""
"There's a new [FedStar](https://flower.ai/docs/baselines/fedstar.html) "
"baseline. Several other baselined have been updated as well."
msgstr ""

#: ../../source/ref-changelog.md:590
msgid ""
"**Improve documentation and translations** "
"([#3050](https://github.com/adap/flower/pull/3050), "
"[#3044](https://github.com/adap/flower/pull/3044), "
"[#3043](https://github.com/adap/flower/pull/3043), "
"[#2986](https://github.com/adap/flower/pull/2986), "
"[#3041](https://github.com/adap/flower/pull/3041), "
"[#3046](https://github.com/adap/flower/pull/3046), "
"[#3042](https://github.com/adap/flower/pull/3042), "
"[#2978](https://github.com/adap/flower/pull/2978), "
"[#2952](https://github.com/adap/flower/pull/2952), "
"[#3167](https://github.com/adap/flower/pull/3167), "
"[#2953](https://github.com/adap/flower/pull/2953), "
"[#3045](https://github.com/adap/flower/pull/3045), "
"[#2654](https://github.com/adap/flower/pull/2654), "
"[#3082](https://github.com/adap/flower/pull/3082), "
"[#2990](https://github.com/adap/flower/pull/2990), "
"[#2989](https://github.com/adap/flower/pull/2989))"
msgstr ""

#: ../../source/ref-changelog.md:592
msgid ""
"As usual, we merged many smaller and larger improvements to the "
"documentation. A special thank you goes to [Sebastian van der "
"Voort](https://github.com/svdvoort) for landing a big documentation PR!"
msgstr ""

#: ../../source/ref-changelog.md:594
msgid ""
"**General updates to Flower Examples** "
"([3134](https://github.com/adap/flower/pull/3134), "
"[2996](https://github.com/adap/flower/pull/2996), "
"[2930](https://github.com/adap/flower/pull/2930), "
"[2967](https://github.com/adap/flower/pull/2967), "
"[2467](https://github.com/adap/flower/pull/2467), "
"[2910](https://github.com/adap/flower/pull/2910), "
"[#2918](https://github.com/adap/flower/pull/2918), "
"[#2773](https://github.com/adap/flower/pull/2773), "
"[#3063](https://github.com/adap/flower/pull/3063), "
"[#3116](https://github.com/adap/flower/pull/3116), "
"[#3117](https://github.com/adap/flower/pull/3117))"
msgstr ""

#: ../../source/ref-changelog.md:596
msgid ""
"Two new examples show federated training of a Vision Transformer (ViT) "
"and federated learning in a medical context using the popular MONAI "
"library. `quickstart-pytorch` and `quickstart-tensorflow` demonstrate the"
" new Flower Next `ServerApp` and `ClientApp`. Many other examples "
"received considerable updates as well."
msgstr ""

#: ../../source/ref-changelog.md:598
msgid ""
"**General improvements** "
"([#3171](https://github.com/adap/flower/pull/3171), "
"[3099](https://github.com/adap/flower/pull/3099), "
"[3003](https://github.com/adap/flower/pull/3003), "
"[3145](https://github.com/adap/flower/pull/3145), "
"[3017](https://github.com/adap/flower/pull/3017), "
"[3085](https://github.com/adap/flower/pull/3085), "
"[3012](https://github.com/adap/flower/pull/3012), "
"[3119](https://github.com/adap/flower/pull/3119), "
"[2991](https://github.com/adap/flower/pull/2991), "
"[2970](https://github.com/adap/flower/pull/2970), "
"[2980](https://github.com/adap/flower/pull/2980), "
"[3086](https://github.com/adap/flower/pull/3086), "
"[2932](https://github.com/adap/flower/pull/2932), "
"[2928](https://github.com/adap/flower/pull/2928), "
"[2941](https://github.com/adap/flower/pull/2941), "
"[2933](https://github.com/adap/flower/pull/2933), "
"[3181](https://github.com/adap/flower/pull/3181), "
"[2973](https://github.com/adap/flower/pull/2973), "
"[2992](https://github.com/adap/flower/pull/2992), "
"[2915](https://github.com/adap/flower/pull/2915), "
"[3040](https://github.com/adap/flower/pull/3040), "
"[3022](https://github.com/adap/flower/pull/3022), "
"[3032](https://github.com/adap/flower/pull/3032), "
"[2902](https://github.com/adap/flower/pull/2902), "
"[2931](https://github.com/adap/flower/pull/2931), "
"[3005](https://github.com/adap/flower/pull/3005), "
"[3132](https://github.com/adap/flower/pull/3132), "
"[3115](https://github.com/adap/flower/pull/3115), "
"[2944](https://github.com/adap/flower/pull/2944), "
"[3064](https://github.com/adap/flower/pull/3064), "
"[3106](https://github.com/adap/flower/pull/3106), "
"[2974](https://github.com/adap/flower/pull/2974), "
"[3178](https://github.com/adap/flower/pull/3178), "
"[2993](https://github.com/adap/flower/pull/2993), "
"[3186](https://github.com/adap/flower/pull/3186), "
"[3091](https://github.com/adap/flower/pull/3091), "
"[3125](https://github.com/adap/flower/pull/3125), "
"[3093](https://github.com/adap/flower/pull/3093), "
"[3013](https://github.com/adap/flower/pull/3013), "
"[3033](https://github.com/adap/flower/pull/3033), "
"[3133](https://github.com/adap/flower/pull/3133), "
"[3068](https://github.com/adap/flower/pull/3068), "
"[2916](https://github.com/adap/flower/pull/2916), "
"[2975](https://github.com/adap/flower/pull/2975), "
"[2984](https://github.com/adap/flower/pull/2984), "
"[2846](https://github.com/adap/flower/pull/2846), "
"[3077](https://github.com/adap/flower/pull/3077), "
"[3143](https://github.com/adap/flower/pull/3143), "
"[2921](https://github.com/adap/flower/pull/2921), "
"[3101](https://github.com/adap/flower/pull/3101), "
"[2927](https://github.com/adap/flower/pull/2927), "
"[2995](https://github.com/adap/flower/pull/2995), "
"[2972](https://github.com/adap/flower/pull/2972), "
"[2912](https://github.com/adap/flower/pull/2912), "
"[3065](https://github.com/adap/flower/pull/3065), "
"[3028](https://github.com/adap/flower/pull/3028), "
"[2922](https://github.com/adap/flower/pull/2922), "
"[2982](https://github.com/adap/flower/pull/2982), "
"[2914](https://github.com/adap/flower/pull/2914), "
"[3179](https://github.com/adap/flower/pull/3179), "
"[3080](https://github.com/adap/flower/pull/3080), "
"[2994](https://github.com/adap/flower/pull/2994), "
"[3187](https://github.com/adap/flower/pull/3187), "
"[2926](https://github.com/adap/flower/pull/2926), "
"[3018](https://github.com/adap/flower/pull/3018), "
"[3144](https://github.com/adap/flower/pull/3144), "
"[3011](https://github.com/adap/flower/pull/3011), "
"[#3152](https://github.com/adap/flower/pull/3152), "
"[#2836](https://github.com/adap/flower/pull/2836), "
"[#2929](https://github.com/adap/flower/pull/2929), "
"[#2943](https://github.com/adap/flower/pull/2943), "
"[#2955](https://github.com/adap/flower/pull/2955), "
"[#2954](https://github.com/adap/flower/pull/2954))"
msgstr ""

#: ../../source/ref-changelog.md:604
msgid "v1.7.0 (2024-02-05)"
msgstr ""

#: ../../source/ref-changelog.md:610
msgid ""
"`Aasheesh Singh`, `Adam Narozniak`, `Aml Hassan Esmil`, `Charles "
"Beauville`, `Daniel J. Beutel`, `Daniel Nata Nugraha`, `Edoardo "
"Gabrielli`, `Gustavo Bertoli`, `HelinLin`, `Heng Pan`, `Javier`, `M S "
"Chaitanya Kumar`, `Mohammad Naseri`, `Nikos Vlachakis`, `Pritam Neog`, "
"`Robert Kuska`, `Robert Steiner`, `Taner Topal`, `Yahia Salaheldin "
"Shaaban`, `Yan Gao`, `Yasar Abbas` <!---TOKEN_v1.7.0-->"
msgstr ""

#: ../../source/ref-changelog.md:614
msgid ""
"**Introduce stateful clients (experimental)** "
"([#2770](https://github.com/adap/flower/pull/2770), "
"[#2686](https://github.com/adap/flower/pull/2686), "
"[#2696](https://github.com/adap/flower/pull/2696), "
"[#2643](https://github.com/adap/flower/pull/2643), "
"[#2769](https://github.com/adap/flower/pull/2769))"
msgstr ""

#: ../../source/ref-changelog.md:616
msgid ""
"Subclasses of `Client` and `NumPyClient` can now store local state that "
"remains on the client. Let's start with the highlight first: this new "
"feature is compatible with both simulated clients (via "
"`start_simulation`) and networked clients (via `start_client`). It's also"
" the first preview of new abstractions like `Context` and `RecordSet`. "
"Clients can access state of type `RecordSet` via `state: RecordSet = "
"self.context.state`. Changes to this `RecordSet` are preserved across "
"different rounds of execution to enable stateful computations in a "
"unified way across simulation and deployment."
msgstr ""

#: ../../source/ref-changelog.md:618
msgid ""
"**Improve performance** "
"([#2293](https://github.com/adap/flower/pull/2293))"
msgstr ""

#: ../../source/ref-changelog.md:620
msgid ""
"Flower is faster than ever. All `FedAvg`-derived strategies now use in-"
"place aggregation to reduce memory consumption. The Flower client "
"serialization/deserialization has been rewritten from the ground up, "
"which results in significant speedups, especially when the client-side "
"training time is short."
msgstr ""

#: ../../source/ref-changelog.md:622
msgid ""
"**Support Federated Learning with Apple MLX and Flower** "
"([#2693](https://github.com/adap/flower/pull/2693))"
msgstr ""

#: ../../source/ref-changelog.md:624
msgid ""
"Flower has official support for federated learning using [Apple "
"MLX](https://ml-explore.github.io/mlx) via the new `quickstart-mlx` code "
"example."
msgstr ""

#: ../../source/ref-changelog.md:626
msgid ""
"**Introduce new XGBoost cyclic strategy** "
"([#2666](https://github.com/adap/flower/pull/2666), "
"[#2668](https://github.com/adap/flower/pull/2668))"
msgstr ""

#: ../../source/ref-changelog.md:628
msgid ""
"A new strategy called `FedXgbCyclic` supports a client-by-client style of"
" training (often called cyclic). The `xgboost-comprehensive` code example"
" shows how to use it in a full project. In addition to that, `xgboost-"
"comprehensive` now also supports simulation mode. With this, Flower "
"offers best-in-class XGBoost support."
msgstr ""

#: ../../source/ref-changelog.md:630
msgid ""
"**Support Python 3.11** "
"([#2394](https://github.com/adap/flower/pull/2394))"
msgstr ""

#: ../../source/ref-changelog.md:632
msgid ""
"Framework tests now run on Python 3.8, 3.9, 3.10, and 3.11. This will "
"ensure better support for users using more recent Python versions."
msgstr ""

#: ../../source/ref-changelog.md:634
msgid ""
"**Update gRPC and ProtoBuf dependencies** "
"([#2814](https://github.com/adap/flower/pull/2814))"
msgstr ""

#: ../../source/ref-changelog.md:636
msgid ""
"The `grpcio` and `protobuf` dependencies were updated to their latest "
"versions for improved security and performance."
msgstr ""

#: ../../source/ref-changelog.md:638
msgid ""
"**Introduce Docker image for Flower server** "
"([#2700](https://github.com/adap/flower/pull/2700), "
"[#2688](https://github.com/adap/flower/pull/2688), "
"[#2705](https://github.com/adap/flower/pull/2705), "
"[#2695](https://github.com/adap/flower/pull/2695), "
"[#2747](https://github.com/adap/flower/pull/2747), "
"[#2746](https://github.com/adap/flower/pull/2746), "
"[#2680](https://github.com/adap/flower/pull/2680), "
"[#2682](https://github.com/adap/flower/pull/2682), "
"[#2701](https://github.com/adap/flower/pull/2701))"
msgstr ""

#: ../../source/ref-changelog.md:640
msgid ""
"The Flower server can now be run using an official Docker image. A new "
"how-to guide explains [how to run Flower using "
"Docker](https://flower.ai/docs/framework/how-to-run-flower-using-"
"docker.html). An official Flower client Docker image will follow."
msgstr ""

#: ../../source/ref-changelog.md:642
msgid ""
"**Introduce** `flower-via-docker-compose` **example** "
"([#2626](https://github.com/adap/flower/pull/2626))"
msgstr ""

#: ../../source/ref-changelog.md:644
msgid ""
"**Introduce** `quickstart-sklearn-tabular` **example** "
"([#2719](https://github.com/adap/flower/pull/2719))"
msgstr ""

#: ../../source/ref-changelog.md:646
msgid ""
"**Introduce** `custom-metrics` **example** "
"([#1958](https://github.com/adap/flower/pull/1958))"
msgstr ""

#: ../../source/ref-changelog.md:648
msgid ""
"**Update code examples to use Flower Datasets** "
"([#2450](https://github.com/adap/flower/pull/2450), "
"[#2456](https://github.com/adap/flower/pull/2456), "
"[#2318](https://github.com/adap/flower/pull/2318), "
"[#2712](https://github.com/adap/flower/pull/2712))"
msgstr ""

#: ../../source/ref-changelog.md:650
msgid ""
"Several code examples were updated to use [Flower "
"Datasets](https://flower.ai/docs/datasets/)."
msgstr ""

#: ../../source/ref-changelog.md:652
msgid ""
"**General updates to Flower Examples** "
"([#2381](https://github.com/adap/flower/pull/2381), "
"[#2805](https://github.com/adap/flower/pull/2805), "
"[#2782](https://github.com/adap/flower/pull/2782), "
"[#2806](https://github.com/adap/flower/pull/2806), "
"[#2829](https://github.com/adap/flower/pull/2829), "
"[#2825](https://github.com/adap/flower/pull/2825), "
"[#2816](https://github.com/adap/flower/pull/2816), "
"[#2726](https://github.com/adap/flower/pull/2726), "
"[#2659](https://github.com/adap/flower/pull/2659), "
"[#2655](https://github.com/adap/flower/pull/2655))"
msgstr ""

#: ../../source/ref-changelog.md:654
msgid "Many Flower code examples received substantial updates."
msgstr ""

#: ../../source/ref-changelog.md:656 ../../source/ref-changelog.md:749
msgid "**Update Flower Baselines**"
msgstr ""

#: ../../source/ref-changelog.md:658
msgid ""
"HFedXGBoost ([#2226](https://github.com/adap/flower/pull/2226), "
"[#2771](https://github.com/adap/flower/pull/2771))"
msgstr ""

#: ../../source/ref-changelog.md:659
msgid "FedVSSL ([#2412](https://github.com/adap/flower/pull/2412))"
msgstr ""

#: ../../source/ref-changelog.md:660
msgid "FedNova ([#2179](https://github.com/adap/flower/pull/2179))"
msgstr ""

#: ../../source/ref-changelog.md:661
msgid "HeteroFL ([#2439](https://github.com/adap/flower/pull/2439))"
msgstr ""

#: ../../source/ref-changelog.md:662
msgid "FedAvgM ([#2246](https://github.com/adap/flower/pull/2246))"
msgstr ""

#: ../../source/ref-changelog.md:663
msgid "FedPara ([#2722](https://github.com/adap/flower/pull/2722))"
msgstr ""

#: ../../source/ref-changelog.md:665
msgid ""
"**Improve documentation** "
"([#2674](https://github.com/adap/flower/pull/2674), "
"[#2480](https://github.com/adap/flower/pull/2480), "
"[#2826](https://github.com/adap/flower/pull/2826), "
"[#2727](https://github.com/adap/flower/pull/2727), "
"[#2761](https://github.com/adap/flower/pull/2761), "
"[#2900](https://github.com/adap/flower/pull/2900))"
msgstr ""

#: ../../source/ref-changelog.md:667
msgid ""
"**Improved testing and development infrastructure** "
"([#2797](https://github.com/adap/flower/pull/2797), "
"[#2676](https://github.com/adap/flower/pull/2676), "
"[#2644](https://github.com/adap/flower/pull/2644), "
"[#2656](https://github.com/adap/flower/pull/2656), "
"[#2848](https://github.com/adap/flower/pull/2848), "
"[#2675](https://github.com/adap/flower/pull/2675), "
"[#2735](https://github.com/adap/flower/pull/2735), "
"[#2767](https://github.com/adap/flower/pull/2767), "
"[#2732](https://github.com/adap/flower/pull/2732), "
"[#2744](https://github.com/adap/flower/pull/2744), "
"[#2681](https://github.com/adap/flower/pull/2681), "
"[#2699](https://github.com/adap/flower/pull/2699), "
"[#2745](https://github.com/adap/flower/pull/2745), "
"[#2734](https://github.com/adap/flower/pull/2734), "
"[#2731](https://github.com/adap/flower/pull/2731), "
"[#2652](https://github.com/adap/flower/pull/2652), "
"[#2720](https://github.com/adap/flower/pull/2720), "
"[#2721](https://github.com/adap/flower/pull/2721), "
"[#2717](https://github.com/adap/flower/pull/2717), "
"[#2864](https://github.com/adap/flower/pull/2864), "
"[#2694](https://github.com/adap/flower/pull/2694), "
"[#2709](https://github.com/adap/flower/pull/2709), "
"[#2658](https://github.com/adap/flower/pull/2658), "
"[#2796](https://github.com/adap/flower/pull/2796), "
"[#2692](https://github.com/adap/flower/pull/2692), "
"[#2657](https://github.com/adap/flower/pull/2657), "
"[#2813](https://github.com/adap/flower/pull/2813), "
"[#2661](https://github.com/adap/flower/pull/2661), "
"[#2398](https://github.com/adap/flower/pull/2398))"
msgstr ""

#: ../../source/ref-changelog.md:669
msgid ""
"The Flower testing and development infrastructure has received "
"substantial updates. This makes Flower 1.7 the most tested release ever."
msgstr ""

#: ../../source/ref-changelog.md:671
msgid ""
"**Update dependencies** "
"([#2753](https://github.com/adap/flower/pull/2753), "
"[#2651](https://github.com/adap/flower/pull/2651), "
"[#2739](https://github.com/adap/flower/pull/2739), "
"[#2837](https://github.com/adap/flower/pull/2837), "
"[#2788](https://github.com/adap/flower/pull/2788), "
"[#2811](https://github.com/adap/flower/pull/2811), "
"[#2774](https://github.com/adap/flower/pull/2774), "
"[#2790](https://github.com/adap/flower/pull/2790), "
"[#2751](https://github.com/adap/flower/pull/2751), "
"[#2850](https://github.com/adap/flower/pull/2850), "
"[#2812](https://github.com/adap/flower/pull/2812), "
"[#2872](https://github.com/adap/flower/pull/2872), "
"[#2736](https://github.com/adap/flower/pull/2736), "
"[#2756](https://github.com/adap/flower/pull/2756), "
"[#2857](https://github.com/adap/flower/pull/2857), "
"[#2757](https://github.com/adap/flower/pull/2757), "
"[#2810](https://github.com/adap/flower/pull/2810), "
"[#2740](https://github.com/adap/flower/pull/2740), "
"[#2789](https://github.com/adap/flower/pull/2789))"
msgstr ""

#: ../../source/ref-changelog.md:673
msgid ""
"**General improvements** "
"([#2803](https://github.com/adap/flower/pull/2803), "
"[#2847](https://github.com/adap/flower/pull/2847), "
"[#2877](https://github.com/adap/flower/pull/2877), "
"[#2690](https://github.com/adap/flower/pull/2690), "
"[#2889](https://github.com/adap/flower/pull/2889), "
"[#2874](https://github.com/adap/flower/pull/2874), "
"[#2819](https://github.com/adap/flower/pull/2819), "
"[#2689](https://github.com/adap/flower/pull/2689), "
"[#2457](https://github.com/adap/flower/pull/2457), "
"[#2870](https://github.com/adap/flower/pull/2870), "
"[#2669](https://github.com/adap/flower/pull/2669), "
"[#2876](https://github.com/adap/flower/pull/2876), "
"[#2885](https://github.com/adap/flower/pull/2885), "
"[#2858](https://github.com/adap/flower/pull/2858), "
"[#2867](https://github.com/adap/flower/pull/2867), "
"[#2351](https://github.com/adap/flower/pull/2351), "
"[#2886](https://github.com/adap/flower/pull/2886), "
"[#2860](https://github.com/adap/flower/pull/2860), "
"[#2828](https://github.com/adap/flower/pull/2828), "
"[#2869](https://github.com/adap/flower/pull/2869), "
"[#2875](https://github.com/adap/flower/pull/2875), "
"[#2733](https://github.com/adap/flower/pull/2733), "
"[#2488](https://github.com/adap/flower/pull/2488), "
"[#2646](https://github.com/adap/flower/pull/2646), "
"[#2879](https://github.com/adap/flower/pull/2879), "
"[#2821](https://github.com/adap/flower/pull/2821), "
"[#2855](https://github.com/adap/flower/pull/2855), "
"[#2800](https://github.com/adap/flower/pull/2800), "
"[#2807](https://github.com/adap/flower/pull/2807), "
"[#2801](https://github.com/adap/flower/pull/2801), "
"[#2804](https://github.com/adap/flower/pull/2804), "
"[#2851](https://github.com/adap/flower/pull/2851), "
"[#2787](https://github.com/adap/flower/pull/2787), "
"[#2852](https://github.com/adap/flower/pull/2852), "
"[#2672](https://github.com/adap/flower/pull/2672), "
"[#2759](https://github.com/adap/flower/pull/2759))"
msgstr ""

#: ../../source/ref-changelog.md:677
msgid ""
"**Deprecate** `start_numpy_client` "
"([#2563](https://github.com/adap/flower/pull/2563), "
"[#2718](https://github.com/adap/flower/pull/2718))"
msgstr ""

#: ../../source/ref-changelog.md:679
msgid ""
"Until now, clients of type `NumPyClient` needed to be started via "
"`start_numpy_client`. In our efforts to consolidate framework APIs, we "
"have introduced changes, and now all client types should start via "
"`start_client`. To continue using `NumPyClient` clients, you simply need "
"to first call the `.to_client()` method and then pass returned `Client` "
"object to `start_client`. The examples and the documentation have been "
"updated accordingly."
msgstr ""

#: ../../source/ref-changelog.md:681
msgid ""
"**Deprecate legacy DP wrappers** "
"([#2749](https://github.com/adap/flower/pull/2749))"
msgstr ""

#: ../../source/ref-changelog.md:683
msgid ""
"Legacy DP wrapper classes are deprecated, but still functional. This is "
"in preparation for an all-new pluggable version of differential privacy "
"support in Flower."
msgstr ""

#: ../../source/ref-changelog.md:685
msgid ""
"**Make optional arg** `--callable` **in** `flower-client` **a required "
"positional arg** ([#2673](https://github.com/adap/flower/pull/2673))"
msgstr ""

#: ../../source/ref-changelog.md:687
msgid ""
"**Rename** `certificates` **to** `root_certificates` **in** `Driver` "
"([#2890](https://github.com/adap/flower/pull/2890))"
msgstr ""

#: ../../source/ref-changelog.md:689
msgid ""
"**Drop experimental** `Task` **fields** "
"([#2866](https://github.com/adap/flower/pull/2866), "
"[#2865](https://github.com/adap/flower/pull/2865))"
msgstr ""

#: ../../source/ref-changelog.md:691
msgid ""
"Experimental fields `sa`, `legacy_server_message` and "
"`legacy_client_message` were removed from `Task` message. The removed "
"fields are superseded by the new `RecordSet` abstraction."
msgstr ""

#: ../../source/ref-changelog.md:693
msgid ""
"**Retire MXNet examples** "
"([#2724](https://github.com/adap/flower/pull/2724))"
msgstr ""

#: ../../source/ref-changelog.md:695
msgid ""
"The development of the MXNet fremework has ended and the project is now "
"[archived on GitHub](https://github.com/apache/mxnet). Existing MXNet "
"examples won't receive updates."
msgstr ""

#: ../../source/ref-changelog.md:697
msgid "v1.6.0 (2023-11-28)"
msgstr ""

#: ../../source/ref-changelog.md:703
msgid ""
"`Aashish Kolluri`, `Adam Narozniak`, `Alessio Mora`, `Barathwaja S`, "
"`Charles Beauville`, `Daniel J. Beutel`, `Daniel Nata Nugraha`, `Gabriel "
"Mota`, `Heng Pan`, `Ivan Agarský`, `JS.KIM`, `Javier`, `Marius Schlegel`,"
" `Navin Chandra`, `Nic Lane`, `Peterpan828`, `Qinbin Li`, `Shaz-hash`, "
"`Steve Laskaridis`, `Taner Topal`, `William Lindskog`, `Yan Gao`, "
"`cnxdeveloper`, `k3nfalt` <!---TOKEN_v1.6.0-->"
msgstr ""

#: ../../source/ref-changelog.md:707
msgid ""
"**Add experimental support for Python 3.12** "
"([#2565](https://github.com/adap/flower/pull/2565))"
msgstr ""

#: ../../source/ref-changelog.md:709
msgid ""
"**Add new XGBoost examples** "
"([#2612](https://github.com/adap/flower/pull/2612), "
"[#2554](https://github.com/adap/flower/pull/2554), "
"[#2617](https://github.com/adap/flower/pull/2617), "
"[#2618](https://github.com/adap/flower/pull/2618), "
"[#2619](https://github.com/adap/flower/pull/2619), "
"[#2567](https://github.com/adap/flower/pull/2567))"
msgstr ""

#: ../../source/ref-changelog.md:711
msgid ""
"We have added a new `xgboost-quickstart` example alongside a new "
"`xgboost-comprehensive` example that goes more in-depth."
msgstr ""

#: ../../source/ref-changelog.md:713
msgid ""
"**Add Vertical FL example** "
"([#2598](https://github.com/adap/flower/pull/2598))"
msgstr ""

#: ../../source/ref-changelog.md:715
msgid ""
"We had many questions about Vertical Federated Learning using Flower, so "
"we decided to add an simple example for it on the [Titanic "
"dataset](https://www.kaggle.com/competitions/titanic/data) alongside a "
"tutorial (in the README)."
msgstr ""

#: ../../source/ref-changelog.md:717
msgid ""
"**Support custom** `ClientManager` **in** `start_driver()` "
"([#2292](https://github.com/adap/flower/pull/2292))"
msgstr ""

#: ../../source/ref-changelog.md:719
msgid ""
"**Update REST API to support create and delete nodes** "
"([#2283](https://github.com/adap/flower/pull/2283))"
msgstr ""

#: ../../source/ref-changelog.md:721
msgid ""
"**Update the Android SDK** "
"([#2187](https://github.com/adap/flower/pull/2187))"
msgstr ""

#: ../../source/ref-changelog.md:723
msgid "Add gRPC request-response capability to the Android SDK."
msgstr ""

#: ../../source/ref-changelog.md:725
msgid ""
"**Update the C++ SDK** "
"([#2537](https://github.com/adap/flower/pull/2537), "
"[#2528](https://github.com/adap/flower/pull/2528), "
"[#2523](https://github.com/adap/flower/pull/2523), "
"[#2522](https://github.com/adap/flower/pull/2522))"
msgstr ""

#: ../../source/ref-changelog.md:727
msgid "Add gRPC request-response capability to the C++ SDK."
msgstr ""

#: ../../source/ref-changelog.md:729
msgid ""
"**Make HTTPS the new default** "
"([#2591](https://github.com/adap/flower/pull/2591), "
"[#2636](https://github.com/adap/flower/pull/2636))"
msgstr ""

#: ../../source/ref-changelog.md:731
msgid ""
"Flower is moving to HTTPS by default. The new `flower-server` requires "
"passing `--certificates`, but users can enable `--insecure` to use HTTP "
"for prototyping. The same applies to `flower-client`, which can either "
"use user-provided credentials or gRPC-bundled certificates to connect to "
"an HTTPS-enabled server or requires opt-out via passing `--insecure` to "
"enable insecure HTTP connections."
msgstr ""

#: ../../source/ref-changelog.md:733
msgid ""
"For backward compatibility, `start_client()` and `start_numpy_client()` "
"will still start in insecure mode by default. In a future release, "
"insecure connections will require user opt-in by passing `insecure=True`."
msgstr ""

#: ../../source/ref-changelog.md:735
msgid ""
"**Unify client API** ([#2303](https://github.com/adap/flower/pull/2303), "
"[#2390](https://github.com/adap/flower/pull/2390), "
"[#2493](https://github.com/adap/flower/pull/2493))"
msgstr ""

#: ../../source/ref-changelog.md:737
msgid ""
"Using the `client_fn`, Flower clients can interchangeably run as "
"standalone processes (i.e. via `start_client`) or in simulation (i.e. via"
" `start_simulation`) without requiring changes to how the client class is"
" defined and instantiated. The `to_client()` function is introduced to "
"convert a `NumPyClient` to a `Client`."
msgstr ""

#: ../../source/ref-changelog.md:739
msgid ""
"**Add new** `Bulyan` **strategy** "
"([#1817](https://github.com/adap/flower/pull/1817), "
"[#1891](https://github.com/adap/flower/pull/1891))"
msgstr ""

#: ../../source/ref-changelog.md:741
msgid ""
"The new `Bulyan` strategy implements Bulyan by [El Mhamdi et al., "
"2018](https://arxiv.org/abs/1802.07927)"
msgstr ""

#: ../../source/ref-changelog.md:743
msgid ""
"**Add new** `XGB Bagging` **strategy** "
"([#2611](https://github.com/adap/flower/pull/2611))"
msgstr ""

#: ../../source/ref-changelog.md:745 ../../source/ref-changelog.md:747
msgid ""
"**Introduce `WorkloadState`** "
"([#2564](https://github.com/adap/flower/pull/2564), "
"[#2632](https://github.com/adap/flower/pull/2632))"
msgstr ""

#: ../../source/ref-changelog.md:751
msgid ""
"FedProx ([#2210](https://github.com/adap/flower/pull/2210), "
"[#2286](https://github.com/adap/flower/pull/2286), "
"[#2509](https://github.com/adap/flower/pull/2509))"
msgstr ""

#: ../../source/ref-changelog.md:753
msgid ""
"Baselines Docs ([#2290](https://github.com/adap/flower/pull/2290), "
"[#2400](https://github.com/adap/flower/pull/2400))"
msgstr ""

#: ../../source/ref-changelog.md:755
msgid ""
"FedMLB ([#2340](https://github.com/adap/flower/pull/2340), "
"[#2507](https://github.com/adap/flower/pull/2507))"
msgstr ""

#: ../../source/ref-changelog.md:757
msgid ""
"TAMUNA ([#2254](https://github.com/adap/flower/pull/2254), "
"[#2508](https://github.com/adap/flower/pull/2508))"
msgstr ""

#: ../../source/ref-changelog.md:759
msgid "FedMeta [#2438](https://github.com/adap/flower/pull/2438)"
msgstr ""

#: ../../source/ref-changelog.md:761
msgid "FjORD [#2431](https://github.com/adap/flower/pull/2431)"
msgstr ""

#: ../../source/ref-changelog.md:763
msgid "MOON [#2421](https://github.com/adap/flower/pull/2421)"
msgstr ""

#: ../../source/ref-changelog.md:765
msgid "DepthFL [#2295](https://github.com/adap/flower/pull/2295)"
msgstr ""

#: ../../source/ref-changelog.md:767
msgid "FedPer [#2266](https://github.com/adap/flower/pull/2266)"
msgstr ""

#: ../../source/ref-changelog.md:769
msgid "FedWav2vec [#2551](https://github.com/adap/flower/pull/2551)"
msgstr ""

#: ../../source/ref-changelog.md:771
msgid "niid-Bench [#2428](https://github.com/adap/flower/pull/2428)"
msgstr ""

#: ../../source/ref-changelog.md:773
msgid ""
"FedBN ([#2608](https://github.com/adap/flower/pull/2608), "
"[#2615](https://github.com/adap/flower/pull/2615))"
msgstr ""

#: ../../source/ref-changelog.md:775
msgid ""
"**General updates to Flower Examples** "
"([#2384](https://github.com/adap/flower/pull/2384), "
"[#2425](https://github.com/adap/flower/pull/2425), "
"[#2526](https://github.com/adap/flower/pull/2526), "
"[#2302](https://github.com/adap/flower/pull/2302), "
"[#2545](https://github.com/adap/flower/pull/2545))"
msgstr ""

#: ../../source/ref-changelog.md:777
msgid ""
"**General updates to Flower Baselines** "
"([#2301](https://github.com/adap/flower/pull/2301), "
"[#2305](https://github.com/adap/flower/pull/2305), "
"[#2307](https://github.com/adap/flower/pull/2307), "
"[#2327](https://github.com/adap/flower/pull/2327), "
"[#2435](https://github.com/adap/flower/pull/2435), "
"[#2462](https://github.com/adap/flower/pull/2462), "
"[#2463](https://github.com/adap/flower/pull/2463), "
"[#2461](https://github.com/adap/flower/pull/2461), "
"[#2469](https://github.com/adap/flower/pull/2469), "
"[#2466](https://github.com/adap/flower/pull/2466), "
"[#2471](https://github.com/adap/flower/pull/2471), "
"[#2472](https://github.com/adap/flower/pull/2472), "
"[#2470](https://github.com/adap/flower/pull/2470))"
msgstr ""

#: ../../source/ref-changelog.md:779
msgid ""
"**General updates to the simulation engine** "
"([#2331](https://github.com/adap/flower/pull/2331), "
"[#2447](https://github.com/adap/flower/pull/2447), "
"[#2448](https://github.com/adap/flower/pull/2448), "
"[#2294](https://github.com/adap/flower/pull/2294))"
msgstr ""

#: ../../source/ref-changelog.md:781
msgid ""
"**General updates to Flower SDKs** "
"([#2288](https://github.com/adap/flower/pull/2288), "
"[#2429](https://github.com/adap/flower/pull/2429), "
"[#2555](https://github.com/adap/flower/pull/2555), "
"[#2543](https://github.com/adap/flower/pull/2543), "
"[#2544](https://github.com/adap/flower/pull/2544), "
"[#2597](https://github.com/adap/flower/pull/2597), "
"[#2623](https://github.com/adap/flower/pull/2623))"
msgstr ""

#: ../../source/ref-changelog.md:783
msgid ""
"**General improvements** "
"([#2309](https://github.com/adap/flower/pull/2309), "
"[#2310](https://github.com/adap/flower/pull/2310), "
"[#2313](https://github.com/adap/flower/pull/2313), "
"[#2316](https://github.com/adap/flower/pull/2316), "
"[#2317](https://github.com/adap/flower/pull/2317), "
"[#2349](https://github.com/adap/flower/pull/2349), "
"[#2360](https://github.com/adap/flower/pull/2360), "
"[#2402](https://github.com/adap/flower/pull/2402), "
"[#2446](https://github.com/adap/flower/pull/2446), "
"[#2561](https://github.com/adap/flower/pull/2561), "
"[#2273](https://github.com/adap/flower/pull/2273), "
"[#2267](https://github.com/adap/flower/pull/2267), "
"[#2274](https://github.com/adap/flower/pull/2274), "
"[#2275](https://github.com/adap/flower/pull/2275), "
"[#2432](https://github.com/adap/flower/pull/2432), "
"[#2251](https://github.com/adap/flower/pull/2251), "
"[#2321](https://github.com/adap/flower/pull/2321), "
"[#1936](https://github.com/adap/flower/pull/1936), "
"[#2408](https://github.com/adap/flower/pull/2408), "
"[#2413](https://github.com/adap/flower/pull/2413), "
"[#2401](https://github.com/adap/flower/pull/2401), "
"[#2531](https://github.com/adap/flower/pull/2531), "
"[#2534](https://github.com/adap/flower/pull/2534), "
"[#2535](https://github.com/adap/flower/pull/2535), "
"[#2521](https://github.com/adap/flower/pull/2521), "
"[#2553](https://github.com/adap/flower/pull/2553), "
"[#2596](https://github.com/adap/flower/pull/2596))"
msgstr ""

#: ../../source/ref-changelog.md:785 ../../source/ref-changelog.md:875
#: ../../source/ref-changelog.md:939 ../../source/ref-changelog.md:993
#: ../../source/ref-changelog.md:1060
msgid "Flower received many improvements under the hood, too many to list here."
msgstr ""

#: ../../source/ref-changelog.md:789
msgid ""
"**Remove support for Python 3.7** "
"([#2280](https://github.com/adap/flower/pull/2280), "
"[#2299](https://github.com/adap/flower/pull/2299), "
"[#2304](https://github.com/adap/flower/pull/2304), "
"[#2306](https://github.com/adap/flower/pull/2306), "
"[#2355](https://github.com/adap/flower/pull/2355), "
"[#2356](https://github.com/adap/flower/pull/2356))"
msgstr ""

#: ../../source/ref-changelog.md:791
msgid ""
"Python 3.7 support was deprecated in Flower 1.5, and this release removes"
" support. Flower now requires Python 3.8."
msgstr ""

#: ../../source/ref-changelog.md:793
msgid ""
"**Remove experimental argument** `rest` **from** `start_client` "
"([#2324](https://github.com/adap/flower/pull/2324))"
msgstr ""

#: ../../source/ref-changelog.md:795
msgid ""
"The (still experimental) argument `rest` was removed from `start_client` "
"and `start_numpy_client`. Use `transport=\"rest\"` to opt into the "
"experimental REST API instead."
msgstr ""

#: ../../source/ref-changelog.md:797
msgid "v1.5.0 (2023-08-31)"
msgstr ""

#: ../../source/ref-changelog.md:803
msgid ""
"`Adam Narozniak`, `Anass Anhari`, `Charles Beauville`, `Dana-Farber`, "
"`Daniel J. Beutel`, `Daniel Nata Nugraha`, `Edoardo Gabrielli`, `Gustavo "
"Bertoli`, `Heng Pan`, `Javier`, `Mahdi`, `Steven Hé (Sīchàng)`, `Taner "
"Topal`, `achiverram28`, `danielnugraha`, `eunchung`, `ruthgal` <!---"
"TOKEN_v1.5.0-->"
msgstr ""

#: ../../source/ref-changelog.md:807
msgid ""
"**Introduce new simulation engine** "
"([#1969](https://github.com/adap/flower/pull/1969), "
"[#2221](https://github.com/adap/flower/pull/2221), "
"[#2248](https://github.com/adap/flower/pull/2248))"
msgstr ""

#: ../../source/ref-changelog.md:809
msgid ""
"The new simulation engine has been rewritten from the ground up, yet it "
"remains fully backwards compatible. It offers much improved stability and"
" memory handling, especially when working with GPUs. Simulations "
"transparently adapt to different settings to scale simulation in CPU-"
"only, CPU+GPU, multi-GPU, or multi-node multi-GPU environments."
msgstr ""

#: ../../source/ref-changelog.md:811
msgid ""
"Comprehensive documentation includes a new [how-to run "
"simulations](https://flower.ai/docs/framework/how-to-run-"
"simulations.html) guide, new [simulation-"
"pytorch](https://flower.ai/docs/examples/simulation-pytorch.html) and "
"[simulation-tensorflow](https://flower.ai/docs/examples/simulation-"
"tensorflow.html) notebooks, and a new [YouTube tutorial "
"series](https://www.youtube.com/watch?v=cRebUIGB5RU&list=PLNG4feLHqCWlnj8a_E1A_n5zr2-8pafTB)."
msgstr ""

#: ../../source/ref-changelog.md:813
msgid ""
"**Restructure Flower Docs** "
"([#1824](https://github.com/adap/flower/pull/1824), "
"[#1865](https://github.com/adap/flower/pull/1865), "
"[#1884](https://github.com/adap/flower/pull/1884), "
"[#1887](https://github.com/adap/flower/pull/1887), "
"[#1919](https://github.com/adap/flower/pull/1919), "
"[#1922](https://github.com/adap/flower/pull/1922), "
"[#1920](https://github.com/adap/flower/pull/1920), "
"[#1923](https://github.com/adap/flower/pull/1923), "
"[#1924](https://github.com/adap/flower/pull/1924), "
"[#1962](https://github.com/adap/flower/pull/1962), "
"[#2006](https://github.com/adap/flower/pull/2006), "
"[#2133](https://github.com/adap/flower/pull/2133), "
"[#2203](https://github.com/adap/flower/pull/2203), "
"[#2215](https://github.com/adap/flower/pull/2215), "
"[#2122](https://github.com/adap/flower/pull/2122), "
"[#2223](https://github.com/adap/flower/pull/2223), "
"[#2219](https://github.com/adap/flower/pull/2219), "
"[#2232](https://github.com/adap/flower/pull/2232), "
"[#2233](https://github.com/adap/flower/pull/2233), "
"[#2234](https://github.com/adap/flower/pull/2234), "
"[#2235](https://github.com/adap/flower/pull/2235), "
"[#2237](https://github.com/adap/flower/pull/2237), "
"[#2238](https://github.com/adap/flower/pull/2238), "
"[#2242](https://github.com/adap/flower/pull/2242), "
"[#2231](https://github.com/adap/flower/pull/2231), "
"[#2243](https://github.com/adap/flower/pull/2243), "
"[#2227](https://github.com/adap/flower/pull/2227))"
msgstr ""

#: ../../source/ref-changelog.md:815
msgid ""
"Much effort went into a completely restructured Flower docs experience. "
"The documentation on [flower.ai/docs](https://flower.ai/docs) is now "
"divided into Flower Framework, Flower Baselines, Flower Android SDK, "
"Flower iOS SDK, and code example projects."
msgstr ""

#: ../../source/ref-changelog.md:817
msgid ""
"**Introduce Flower Swift SDK** "
"([#1858](https://github.com/adap/flower/pull/1858), "
"[#1897](https://github.com/adap/flower/pull/1897))"
msgstr ""

#: ../../source/ref-changelog.md:819
msgid ""
"This is the first preview release of the Flower Swift SDK. Flower support"
" on iOS is improving, and alongside the Swift SDK and code example, there"
" is now also an iOS quickstart tutorial."
msgstr ""

#: ../../source/ref-changelog.md:821
msgid ""
"**Introduce Flower Android SDK** "
"([#2131](https://github.com/adap/flower/pull/2131))"
msgstr ""

#: ../../source/ref-changelog.md:823
msgid ""
"This is the first preview release of the Flower Kotlin SDK. Flower "
"support on Android is improving, and alongside the Kotlin SDK and code "
"example, there is now also an Android quickstart tutorial."
msgstr ""

#: ../../source/ref-changelog.md:825
msgid ""
"**Introduce new end-to-end testing infrastructure** "
"([#1842](https://github.com/adap/flower/pull/1842), "
"[#2071](https://github.com/adap/flower/pull/2071), "
"[#2072](https://github.com/adap/flower/pull/2072), "
"[#2068](https://github.com/adap/flower/pull/2068), "
"[#2067](https://github.com/adap/flower/pull/2067), "
"[#2069](https://github.com/adap/flower/pull/2069), "
"[#2073](https://github.com/adap/flower/pull/2073), "
"[#2070](https://github.com/adap/flower/pull/2070), "
"[#2074](https://github.com/adap/flower/pull/2074), "
"[#2082](https://github.com/adap/flower/pull/2082), "
"[#2084](https://github.com/adap/flower/pull/2084), "
"[#2093](https://github.com/adap/flower/pull/2093), "
"[#2109](https://github.com/adap/flower/pull/2109), "
"[#2095](https://github.com/adap/flower/pull/2095), "
"[#2140](https://github.com/adap/flower/pull/2140), "
"[#2137](https://github.com/adap/flower/pull/2137), "
"[#2165](https://github.com/adap/flower/pull/2165))"
msgstr ""

#: ../../source/ref-changelog.md:827
msgid ""
"A new testing infrastructure ensures that new changes stay compatible "
"with existing framework integrations or strategies."
msgstr ""

#: ../../source/ref-changelog.md:829
msgid "**Deprecate Python 3.7**"
msgstr ""

#: ../../source/ref-changelog.md:831
msgid ""
"Since Python 3.7 reached its end of life (EOL) on 2023-06-27, support for"
" Python 3.7 is now deprecated and will be removed in an upcoming release."
msgstr ""

#: ../../source/ref-changelog.md:833
msgid ""
"**Add new** `FedTrimmedAvg` **strategy** "
"([#1769](https://github.com/adap/flower/pull/1769), "
"[#1853](https://github.com/adap/flower/pull/1853))"
msgstr ""

#: ../../source/ref-changelog.md:835
msgid ""
"The new `FedTrimmedAvg` strategy implements Trimmed Mean by [Dong Yin, "
"2018](https://arxiv.org/abs/1803.01498)."
msgstr ""

#: ../../source/ref-changelog.md:837
msgid ""
"**Introduce start_driver** "
"([#1697](https://github.com/adap/flower/pull/1697))"
msgstr ""

#: ../../source/ref-changelog.md:839
msgid ""
"In addition to `start_server` and using the raw Driver API, there is a "
"new `start_driver` function that allows for running `start_server` "
"scripts as a Flower driver with only a single-line code change. Check out"
" the `mt-pytorch` code example to see a working example using "
"`start_driver`."
msgstr ""

#: ../../source/ref-changelog.md:841
msgid ""
"**Add parameter aggregation to** `mt-pytorch` **code example** "
"([#1785](https://github.com/adap/flower/pull/1785))"
msgstr ""

#: ../../source/ref-changelog.md:843
msgid ""
"The `mt-pytorch` example shows how to aggregate parameters when writing a"
" driver script. The included `driver.py` and `server.py` have been "
"aligned to demonstrate both the low-level way and the high-level way of "
"building server-side logic."
msgstr ""

#: ../../source/ref-changelog.md:845
msgid ""
"**Migrate experimental REST API to Starlette** "
"([2171](https://github.com/adap/flower/pull/2171))"
msgstr ""

#: ../../source/ref-changelog.md:847
msgid ""
"The (experimental) REST API used to be implemented in "
"[FastAPI](https://fastapi.tiangolo.com/), but it has now been migrated to"
" use [Starlette](https://www.starlette.io/) directly."
msgstr ""

#: ../../source/ref-changelog.md:849
msgid ""
"Please note: The REST request-response API is still experimental and will"
" likely change significantly over time."
msgstr ""

#: ../../source/ref-changelog.md:851
msgid ""
"**Introduce experimental gRPC request-response API** "
"([#1867](https://github.com/adap/flower/pull/1867), "
"[#1901](https://github.com/adap/flower/pull/1901))"
msgstr ""

#: ../../source/ref-changelog.md:853
msgid ""
"In addition to the existing gRPC API (based on bidirectional streaming) "
"and the experimental REST API, there is now a new gRPC API that uses a "
"request-response model to communicate with client nodes."
msgstr ""

#: ../../source/ref-changelog.md:855
msgid ""
"Please note: The gRPC request-response API is still experimental and will"
" likely change significantly over time."
msgstr ""

#: ../../source/ref-changelog.md:857
msgid ""
"**Replace the experimental** `start_client(rest=True)` **with the new** "
"`start_client(transport=\"rest\")` "
"([#1880](https://github.com/adap/flower/pull/1880))"
msgstr ""

#: ../../source/ref-changelog.md:859
msgid ""
"The (experimental) `start_client` argument `rest` was deprecated in "
"favour of a new argument `transport`. `start_client(transport=\"rest\")` "
"will yield the same behaviour as `start_client(rest=True)` did before. "
"All code should migrate to the new argument `transport`. The deprecated "
"argument `rest` will be removed in a future release."
msgstr ""

#: ../../source/ref-changelog.md:861
msgid ""
"**Add a new gRPC option** "
"([#2197](https://github.com/adap/flower/pull/2197))"
msgstr ""

#: ../../source/ref-changelog.md:863
msgid ""
"We now start a gRPC server with the `grpc.keepalive_permit_without_calls`"
" option set to 0 by default. This prevents the clients from sending "
"keepalive pings when there is no outstanding stream."
msgstr ""

#: ../../source/ref-changelog.md:865
msgid ""
"**Improve example notebooks** "
"([#2005](https://github.com/adap/flower/pull/2005))"
msgstr ""

#: ../../source/ref-changelog.md:867
msgid "There's a new 30min Federated Learning PyTorch tutorial!"
msgstr ""

#: ../../source/ref-changelog.md:869
msgid ""
"**Example updates** ([#1772](https://github.com/adap/flower/pull/1772), "
"[#1873](https://github.com/adap/flower/pull/1873), "
"[#1981](https://github.com/adap/flower/pull/1981), "
"[#1988](https://github.com/adap/flower/pull/1988), "
"[#1984](https://github.com/adap/flower/pull/1984), "
"[#1982](https://github.com/adap/flower/pull/1982), "
"[#2112](https://github.com/adap/flower/pull/2112), "
"[#2144](https://github.com/adap/flower/pull/2144), "
"[#2174](https://github.com/adap/flower/pull/2174), "
"[#2225](https://github.com/adap/flower/pull/2225), "
"[#2183](https://github.com/adap/flower/pull/2183))"
msgstr ""

#: ../../source/ref-changelog.md:871
msgid ""
"Many examples have received significant updates, including simplified "
"advanced-tensorflow and advanced-pytorch examples, improved macOS "
"compatibility of TensorFlow examples, and code examples for simulation. A"
" major upgrade is that all code examples now have a `requirements.txt` "
"(in addition to `pyproject.toml`)."
msgstr ""

#: ../../source/ref-changelog.md:873
msgid ""
"**General improvements** "
"([#1872](https://github.com/adap/flower/pull/1872), "
"[#1866](https://github.com/adap/flower/pull/1866), "
"[#1884](https://github.com/adap/flower/pull/1884), "
"[#1837](https://github.com/adap/flower/pull/1837), "
"[#1477](https://github.com/adap/flower/pull/1477), "
"[#2171](https://github.com/adap/flower/pull/2171))"
msgstr ""

#: ../../source/ref-changelog.md:881
msgid "v1.4.0 (2023-04-21)"
msgstr ""

#: ../../source/ref-changelog.md:887
msgid ""
"`Adam Narozniak`, `Alexander Viala Bellander`, `Charles Beauville`, "
"`Chenyang Ma (Danny)`, `Daniel J. Beutel`, `Edoardo`, `Gautam Jajoo`, "
"`Iacob-Alexandru-Andrei`, `JDRanpariya`, `Jean Charle Yaacoub`, `Kunal "
"Sarkhel`, `L. Jiang`, `Lennart Behme`, `Max Kapsecker`, `Michał`, `Nic "
"Lane`, `Nikolaos Episkopos`, `Ragy`, `Saurav Maheshkar`, `Semo Yang`, "
"`Steve Laskaridis`, `Steven Hé (Sīchàng)`, `Taner Topal`"
msgstr ""

#: ../../source/ref-changelog.md:891
msgid ""
"**Introduce support for XGBoost (**`FedXgbNnAvg` **strategy and "
"example)** ([#1694](https://github.com/adap/flower/pull/1694), "
"[#1709](https://github.com/adap/flower/pull/1709), "
"[#1715](https://github.com/adap/flower/pull/1715), "
"[#1717](https://github.com/adap/flower/pull/1717), "
"[#1763](https://github.com/adap/flower/pull/1763), "
"[#1795](https://github.com/adap/flower/pull/1795))"
msgstr ""

#: ../../source/ref-changelog.md:893
msgid ""
"XGBoost is a tree-based ensemble machine learning algorithm that uses "
"gradient boosting to improve model accuracy. We added a new `FedXgbNnAvg`"
" "
"[strategy](https://github.com/adap/flower/tree/main/src/py/flwr/server/strategy/fedxgb_nn_avg.py),"
" and a [code example](https://github.com/adap/flower/tree/main/examples"
"/xgboost-quickstart) that demonstrates the usage of this new strategy in "
"an XGBoost project."
msgstr ""

#: ../../source/ref-changelog.md:895
msgid ""
"**Introduce iOS SDK (preview)** "
"([#1621](https://github.com/adap/flower/pull/1621), "
"[#1764](https://github.com/adap/flower/pull/1764))"
msgstr ""

#: ../../source/ref-changelog.md:897
msgid ""
"This is a major update for anyone wanting to implement Federated Learning"
" on iOS mobile devices. We now have a swift iOS SDK present under "
"[src/swift/flwr](https://github.com/adap/flower/tree/main/src/swift/flwr)"
" that will facilitate greatly the app creating process. To showcase its "
"use, the [iOS "
"example](https://github.com/adap/flower/tree/main/examples/ios) has also "
"been updated!"
msgstr ""

#: ../../source/ref-changelog.md:899
msgid ""
"**Introduce new \"What is Federated Learning?\" tutorial** "
"([#1657](https://github.com/adap/flower/pull/1657), "
"[#1721](https://github.com/adap/flower/pull/1721))"
msgstr ""

#: ../../source/ref-changelog.md:901
msgid ""
"A new [entry-level tutorial](https://flower.ai/docs/framework/tutorial-"
"what-is-federated-learning.html) in our documentation explains the basics"
" of Fedetated Learning. It enables anyone who's unfamiliar with Federated"
" Learning to start their journey with Flower. Forward it to anyone who's "
"interested in Federated Learning!"
msgstr ""

#: ../../source/ref-changelog.md:903
msgid ""
"**Introduce new Flower Baseline: FedProx MNIST** "
"([#1513](https://github.com/adap/flower/pull/1513), "
"[#1680](https://github.com/adap/flower/pull/1680), "
"[#1681](https://github.com/adap/flower/pull/1681), "
"[#1679](https://github.com/adap/flower/pull/1679))"
msgstr ""

#: ../../source/ref-changelog.md:905
msgid ""
"This new baseline replicates the MNIST+CNN task from the paper [Federated"
" Optimization in Heterogeneous Networks (Li et al., "
"2018)](https://arxiv.org/abs/1812.06127). It uses the `FedProx` strategy,"
" which aims at making convergence more robust in heterogeneous settings."
msgstr ""

#: ../../source/ref-changelog.md:907
msgid ""
"**Introduce new Flower Baseline: FedAvg FEMNIST** "
"([#1655](https://github.com/adap/flower/pull/1655))"
msgstr ""

#: ../../source/ref-changelog.md:909
msgid ""
"This new baseline replicates an experiment evaluating the performance of "
"the FedAvg algorithm on the FEMNIST dataset from the paper [LEAF: A "
"Benchmark for Federated Settings (Caldas et al., "
"2018)](https://arxiv.org/abs/1812.01097)."
msgstr ""

#: ../../source/ref-changelog.md:911
msgid ""
"**Introduce (experimental) REST API** "
"([#1594](https://github.com/adap/flower/pull/1594), "
"[#1690](https://github.com/adap/flower/pull/1690), "
"[#1695](https://github.com/adap/flower/pull/1695), "
"[#1712](https://github.com/adap/flower/pull/1712), "
"[#1802](https://github.com/adap/flower/pull/1802), "
"[#1770](https://github.com/adap/flower/pull/1770), "
"[#1733](https://github.com/adap/flower/pull/1733))"
msgstr ""

#: ../../source/ref-changelog.md:913
msgid ""
"A new REST API has been introduced as an alternative to the gRPC-based "
"communication stack. In this initial version, the REST API only supports "
"anonymous clients."
msgstr ""

#: ../../source/ref-changelog.md:915
msgid ""
"Please note: The REST API is still experimental and will likely change "
"significantly over time."
msgstr ""

#: ../../source/ref-changelog.md:917
msgid ""
"**Improve the (experimental) Driver API** "
"([#1663](https://github.com/adap/flower/pull/1663), "
"[#1666](https://github.com/adap/flower/pull/1666), "
"[#1667](https://github.com/adap/flower/pull/1667), "
"[#1664](https://github.com/adap/flower/pull/1664), "
"[#1675](https://github.com/adap/flower/pull/1675), "
"[#1676](https://github.com/adap/flower/pull/1676), "
"[#1693](https://github.com/adap/flower/pull/1693), "
"[#1662](https://github.com/adap/flower/pull/1662), "
"[#1794](https://github.com/adap/flower/pull/1794))"
msgstr ""

#: ../../source/ref-changelog.md:919
msgid ""
"The Driver API is still an experimental feature, but this release "
"introduces some major upgrades. One of the main improvements is the "
"introduction of an SQLite database to store server state on disk (instead"
" of in-memory). Another improvement is that tasks (instructions or "
"results) that have been delivered will now be deleted. This greatly "
"improves the memory efficiency of a long-running Flower server."
msgstr ""

#: ../../source/ref-changelog.md:921
msgid ""
"**Fix spilling issues related to Ray during simulations** "
"([#1698](https://github.com/adap/flower/pull/1698))"
msgstr ""

#: ../../source/ref-changelog.md:923
msgid ""
"While running long simulations, `ray` was sometimes spilling huge amounts"
" of data that would make the training unable to continue. This is now "
"fixed! 🎉"
msgstr ""

#: ../../source/ref-changelog.md:925
msgid ""
"**Add new example using** `TabNet` **and Flower** "
"([#1725](https://github.com/adap/flower/pull/1725))"
msgstr ""

#: ../../source/ref-changelog.md:927
msgid ""
"TabNet is a powerful and flexible framework for training machine learning"
" models on tabular data. We now have a federated example using Flower: "
"[quickstart-tabnet](https://github.com/adap/flower/tree/main/examples"
"/quickstart-tabnet)."
msgstr ""

#: ../../source/ref-changelog.md:929
msgid ""
"**Add new how-to guide for monitoring simulations** "
"([#1649](https://github.com/adap/flower/pull/1649))"
msgstr ""

#: ../../source/ref-changelog.md:931
msgid ""
"We now have a documentation guide to help users monitor their performance"
" during simulations."
msgstr ""

#: ../../source/ref-changelog.md:933
msgid ""
"**Add training metrics to** `History` **object during simulations** "
"([#1696](https://github.com/adap/flower/pull/1696))"
msgstr ""

#: ../../source/ref-changelog.md:935
msgid ""
"The `fit_metrics_aggregation_fn` can be used to aggregate training "
"metrics, but previous releases did not save the results in the `History` "
"object. This is now the case!"
msgstr ""

#: ../../source/ref-changelog.md:937
msgid ""
"**General improvements** "
"([#1659](https://github.com/adap/flower/pull/1659), "
"[#1646](https://github.com/adap/flower/pull/1646), "
"[#1647](https://github.com/adap/flower/pull/1647), "
"[#1471](https://github.com/adap/flower/pull/1471), "
"[#1648](https://github.com/adap/flower/pull/1648), "
"[#1651](https://github.com/adap/flower/pull/1651), "
"[#1652](https://github.com/adap/flower/pull/1652), "
"[#1653](https://github.com/adap/flower/pull/1653), "
"[#1659](https://github.com/adap/flower/pull/1659), "
"[#1665](https://github.com/adap/flower/pull/1665), "
"[#1670](https://github.com/adap/flower/pull/1670), "
"[#1672](https://github.com/adap/flower/pull/1672), "
"[#1677](https://github.com/adap/flower/pull/1677), "
"[#1684](https://github.com/adap/flower/pull/1684), "
"[#1683](https://github.com/adap/flower/pull/1683), "
"[#1686](https://github.com/adap/flower/pull/1686), "
"[#1682](https://github.com/adap/flower/pull/1682), "
"[#1685](https://github.com/adap/flower/pull/1685), "
"[#1692](https://github.com/adap/flower/pull/1692), "
"[#1705](https://github.com/adap/flower/pull/1705), "
"[#1708](https://github.com/adap/flower/pull/1708), "
"[#1711](https://github.com/adap/flower/pull/1711), "
"[#1713](https://github.com/adap/flower/pull/1713), "
"[#1714](https://github.com/adap/flower/pull/1714), "
"[#1718](https://github.com/adap/flower/pull/1718), "
"[#1716](https://github.com/adap/flower/pull/1716), "
"[#1723](https://github.com/adap/flower/pull/1723), "
"[#1735](https://github.com/adap/flower/pull/1735), "
"[#1678](https://github.com/adap/flower/pull/1678), "
"[#1750](https://github.com/adap/flower/pull/1750), "
"[#1753](https://github.com/adap/flower/pull/1753), "
"[#1736](https://github.com/adap/flower/pull/1736), "
"[#1766](https://github.com/adap/flower/pull/1766), "
"[#1760](https://github.com/adap/flower/pull/1760), "
"[#1775](https://github.com/adap/flower/pull/1775), "
"[#1776](https://github.com/adap/flower/pull/1776), "
"[#1777](https://github.com/adap/flower/pull/1777), "
"[#1779](https://github.com/adap/flower/pull/1779), "
"[#1784](https://github.com/adap/flower/pull/1784), "
"[#1773](https://github.com/adap/flower/pull/1773), "
"[#1755](https://github.com/adap/flower/pull/1755), "
"[#1789](https://github.com/adap/flower/pull/1789), "
"[#1788](https://github.com/adap/flower/pull/1788), "
"[#1798](https://github.com/adap/flower/pull/1798), "
"[#1799](https://github.com/adap/flower/pull/1799), "
"[#1739](https://github.com/adap/flower/pull/1739), "
"[#1800](https://github.com/adap/flower/pull/1800), "
"[#1804](https://github.com/adap/flower/pull/1804), "
"[#1805](https://github.com/adap/flower/pull/1805))"
msgstr ""

#: ../../source/ref-changelog.md:945
msgid "v1.3.0 (2023-02-06)"
msgstr ""

#: ../../source/ref-changelog.md:951
msgid ""
"`Adam Narozniak`, `Alexander Viala Bellander`, `Charles Beauville`, "
"`Daniel J. Beutel`, `JDRanpariya`, `Lennart Behme`, `Taner Topal`"
msgstr ""

#: ../../source/ref-changelog.md:955
msgid ""
"**Add support for** `workload_id` **and** `group_id` **in Driver API** "
"([#1595](https://github.com/adap/flower/pull/1595))"
msgstr ""

#: ../../source/ref-changelog.md:957
msgid ""
"The (experimental) Driver API now supports a `workload_id` that can be "
"used to identify which workload a task belongs to. It also supports a new"
" `group_id` that can be used, for example, to indicate the current "
"training round. Both the `workload_id` and `group_id` enable client nodes"
" to decide whether they want to handle a task or not."
msgstr ""

#: ../../source/ref-changelog.md:959
msgid ""
"**Make Driver API and Fleet API address configurable** "
"([#1637](https://github.com/adap/flower/pull/1637))"
msgstr ""

#: ../../source/ref-changelog.md:961
msgid ""
"The (experimental) long-running Flower server (Driver API and Fleet API) "
"can now configure the server address of both Driver API (via `--driver-"
"api-address`) and Fleet API (via `--fleet-api-address`) when starting:"
msgstr ""

#: ../../source/ref-changelog.md:963
msgid ""
"`flower-server --driver-api-address \"0.0.0.0:8081\" --fleet-api-address "
"\"0.0.0.0:8086\"`"
msgstr ""

#: ../../source/ref-changelog.md:965
msgid "Both IPv4 and IPv6 addresses are supported."
msgstr ""

#: ../../source/ref-changelog.md:967
msgid ""
"**Add new example of Federated Learning using fastai and Flower** "
"([#1598](https://github.com/adap/flower/pull/1598))"
msgstr ""

#: ../../source/ref-changelog.md:969
msgid ""
"A new code example (`quickstart-fastai`) demonstrates federated learning "
"with [fastai](https://www.fast.ai/) and Flower. You can find it here: "
"[quickstart-fastai](https://github.com/adap/flower/tree/main/examples"
"/quickstart-fastai)."
msgstr ""

#: ../../source/ref-changelog.md:971
msgid ""
"**Make Android example compatible with** `flwr >= 1.0.0` **and the latest"
" versions of Android** "
"([#1603](https://github.com/adap/flower/pull/1603))"
msgstr ""

#: ../../source/ref-changelog.md:973
msgid ""
"The Android code example has received a substantial update: the project "
"is compatible with Flower 1.0 (and later), the UI received a full "
"refresh, and the project is updated to be compatible with newer Android "
"tooling."
msgstr ""

#: ../../source/ref-changelog.md:975
msgid ""
"**Add new `FedProx` strategy** "
"([#1619](https://github.com/adap/flower/pull/1619))"
msgstr ""

#: ../../source/ref-changelog.md:977
msgid ""
"This "
"[strategy](https://github.com/adap/flower/blob/main/src/py/flwr/server/strategy/fedprox.py)"
" is almost identical to "
"[`FedAvg`](https://github.com/adap/flower/blob/main/src/py/flwr/server/strategy/fedavg.py),"
" but helps users replicate what is described in this "
"[paper](https://arxiv.org/abs/1812.06127). It essentially adds a "
"parameter called `proximal_mu` to regularize the local models with "
"respect to the global models."
msgstr ""

#: ../../source/ref-changelog.md:979
msgid ""
"**Add new metrics to telemetry events** "
"([#1640](https://github.com/adap/flower/pull/1640))"
msgstr ""

#: ../../source/ref-changelog.md:981
msgid ""
"An updated event structure allows, for example, the clustering of events "
"within the same workload."
msgstr ""

#: ../../source/ref-changelog.md:983
msgid ""
"**Add new custom strategy tutorial section** "
"[#1623](https://github.com/adap/flower/pull/1623)"
msgstr ""

#: ../../source/ref-changelog.md:985
msgid ""
"The Flower tutorial now has a new section that covers implementing a "
"custom strategy from scratch: [Open in "
"Colab](https://colab.research.google.com/github/adap/flower/blob/main/doc/source"
"/tutorial-build-a-strategy-from-scratch-pytorch.ipynb)"
msgstr ""

#: ../../source/ref-changelog.md:987
msgid ""
"**Add new custom serialization tutorial section** "
"([#1622](https://github.com/adap/flower/pull/1622))"
msgstr ""

#: ../../source/ref-changelog.md:989
msgid ""
"The Flower tutorial now has a new section that covers custom "
"serialization: [Open in "
"Colab](https://colab.research.google.com/github/adap/flower/blob/main/doc/source"
"/tutorial-customize-the-client-pytorch.ipynb)"
msgstr ""

#: ../../source/ref-changelog.md:991
msgid ""
"**General improvements** "
"([#1638](https://github.com/adap/flower/pull/1638), "
"[#1634](https://github.com/adap/flower/pull/1634), "
"[#1636](https://github.com/adap/flower/pull/1636), "
"[#1635](https://github.com/adap/flower/pull/1635), "
"[#1633](https://github.com/adap/flower/pull/1633), "
"[#1632](https://github.com/adap/flower/pull/1632), "
"[#1631](https://github.com/adap/flower/pull/1631), "
"[#1630](https://github.com/adap/flower/pull/1630), "
"[#1627](https://github.com/adap/flower/pull/1627), "
"[#1593](https://github.com/adap/flower/pull/1593), "
"[#1616](https://github.com/adap/flower/pull/1616), "
"[#1615](https://github.com/adap/flower/pull/1615), "
"[#1607](https://github.com/adap/flower/pull/1607), "
"[#1609](https://github.com/adap/flower/pull/1609), "
"[#1608](https://github.com/adap/flower/pull/1608), "
"[#1603](https://github.com/adap/flower/pull/1603), "
"[#1590](https://github.com/adap/flower/pull/1590), "
"[#1580](https://github.com/adap/flower/pull/1580), "
"[#1599](https://github.com/adap/flower/pull/1599), "
"[#1600](https://github.com/adap/flower/pull/1600), "
"[#1601](https://github.com/adap/flower/pull/1601), "
"[#1597](https://github.com/adap/flower/pull/1597), "
"[#1595](https://github.com/adap/flower/pull/1595), "
"[#1591](https://github.com/adap/flower/pull/1591), "
"[#1588](https://github.com/adap/flower/pull/1588), "
"[#1589](https://github.com/adap/flower/pull/1589), "
"[#1587](https://github.com/adap/flower/pull/1587), "
"[#1573](https://github.com/adap/flower/pull/1573), "
"[#1581](https://github.com/adap/flower/pull/1581), "
"[#1578](https://github.com/adap/flower/pull/1578), "
"[#1574](https://github.com/adap/flower/pull/1574), "
"[#1572](https://github.com/adap/flower/pull/1572), "
"[#1586](https://github.com/adap/flower/pull/1586))"
msgstr ""

#: ../../source/ref-changelog.md:995
msgid ""
"**Updated documentation** "
"([#1629](https://github.com/adap/flower/pull/1629), "
"[#1628](https://github.com/adap/flower/pull/1628), "
"[#1620](https://github.com/adap/flower/pull/1620), "
"[#1618](https://github.com/adap/flower/pull/1618), "
"[#1617](https://github.com/adap/flower/pull/1617), "
"[#1613](https://github.com/adap/flower/pull/1613), "
"[#1614](https://github.com/adap/flower/pull/1614))"
msgstr ""

#: ../../source/ref-changelog.md:997 ../../source/ref-changelog.md:1064
msgid ""
"As usual, the documentation has improved quite a bit. It is another step "
"in our effort to make the Flower documentation the best documentation of "
"any project. Stay tuned and as always, feel free to provide feedback!"
msgstr ""

#: ../../source/ref-changelog.md:1003
msgid "v1.2.0 (2023-01-13)"
msgstr ""

#: ../../source/ref-changelog.md:1009
msgid ""
"`Adam Narozniak`, `Charles Beauville`, `Daniel J. Beutel`, `Edoardo`, `L."
" Jiang`, `Ragy`, `Taner Topal`, `dannymcy`"
msgstr ""

#: ../../source/ref-changelog.md:1013
msgid ""
"**Introduce new Flower Baseline: FedAvg MNIST** "
"([#1497](https://github.com/adap/flower/pull/1497), "
"[#1552](https://github.com/adap/flower/pull/1552))"
msgstr ""

#: ../../source/ref-changelog.md:1015
msgid ""
"Over the coming weeks, we will be releasing a number of new reference "
"implementations useful especially to FL newcomers. They will typically "
"revisit well known papers from the literature, and be suitable for "
"integration in your own application or for experimentation, in order to "
"deepen your knowledge of FL in general. Today's release is the first in "
"this series. [Read more.](https://flower.ai/blog/2023-01-12-fl-starter-"
"pack-fedavg-mnist-cnn/)"
msgstr ""

#: ../../source/ref-changelog.md:1017
msgid ""
"**Improve GPU support in simulations** "
"([#1555](https://github.com/adap/flower/pull/1555))"
msgstr ""

#: ../../source/ref-changelog.md:1019
msgid ""
"The Ray-based Virtual Client Engine (`start_simulation`) has been updated"
" to improve GPU support. The update includes some of the hard-earned "
"lessons from scaling simulations in GPU cluster environments. New "
"defaults make running GPU-based simulations substantially more robust."
msgstr ""

#: ../../source/ref-changelog.md:1021
msgid ""
"**Improve GPU support in Jupyter Notebook tutorials** "
"([#1527](https://github.com/adap/flower/pull/1527), "
"[#1558](https://github.com/adap/flower/pull/1558))"
msgstr ""

#: ../../source/ref-changelog.md:1023
msgid ""
"Some users reported that Jupyter Notebooks have not always been easy to "
"use on GPU instances. We listened and made improvements to all of our "
"Jupyter notebooks! Check out the updated notebooks here:"
msgstr ""

#: ../../source/ref-changelog.md:1025
msgid ""
"[An Introduction to Federated Learning](https://flower.ai/docs/framework"
"/tutorial-get-started-with-flower-pytorch.html)"
msgstr ""

#: ../../source/ref-changelog.md:1026
msgid ""
"[Strategies in Federated Learning](https://flower.ai/docs/framework"
"/tutorial-use-a-federated-learning-strategy-pytorch.html)"
msgstr ""

#: ../../source/ref-changelog.md:1027
msgid ""
"[Building a Strategy](https://flower.ai/docs/framework/tutorial-build-a"
"-strategy-from-scratch-pytorch.html)"
msgstr ""

#: ../../source/ref-changelog.md:1028
msgid ""
"[Client and NumPyClient](https://flower.ai/docs/framework/tutorial-"
"customize-the-client-pytorch.html)"
msgstr ""

#: ../../source/ref-changelog.md:1030
msgid ""
"**Introduce optional telemetry** "
"([#1533](https://github.com/adap/flower/pull/1533), "
"[#1544](https://github.com/adap/flower/pull/1544), "
"[#1584](https://github.com/adap/flower/pull/1584))"
msgstr ""

#: ../../source/ref-changelog.md:1032
msgid ""
"After a [request for "
"feedback](https://github.com/adap/flower/issues/1534) from the community,"
" the Flower open-source project introduces optional collection of "
"*anonymous* usage metrics to make well-informed decisions to improve "
"Flower. Doing this enables the Flower team to understand how Flower is "
"used and what challenges users might face."
msgstr ""

#: ../../source/ref-changelog.md:1034
msgid ""
"**Flower is a friendly framework for collaborative AI and data science.**"
" Staying true to this statement, Flower makes it easy to disable "
"telemetry for users who do not want to share anonymous usage metrics. "
"[Read more.](https://flower.ai/docs/telemetry.html)."
msgstr ""

#: ../../source/ref-changelog.md:1036
msgid ""
"**Introduce (experimental) Driver API** "
"([#1520](https://github.com/adap/flower/pull/1520), "
"[#1525](https://github.com/adap/flower/pull/1525), "
"[#1545](https://github.com/adap/flower/pull/1545), "
"[#1546](https://github.com/adap/flower/pull/1546), "
"[#1550](https://github.com/adap/flower/pull/1550), "
"[#1551](https://github.com/adap/flower/pull/1551), "
"[#1567](https://github.com/adap/flower/pull/1567))"
msgstr ""

#: ../../source/ref-changelog.md:1038
msgid ""
"Flower now has a new (experimental) Driver API which will enable fully "
"programmable, async, and multi-tenant Federated Learning and Federated "
"Analytics applications. Phew, that's a lot! Going forward, the Driver API"
" will be the abstraction that many upcoming features will be built on - "
"and you can start building those things now, too."
msgstr ""

#: ../../source/ref-changelog.md:1040
msgid ""
"The Driver API also enables a new execution mode in which the server runs"
" indefinitely. Multiple individual workloads can run concurrently and "
"start and stop their execution independent of the server. This is "
"especially useful for users who want to deploy Flower in production."
msgstr ""

#: ../../source/ref-changelog.md:1042
msgid ""
"To learn more, check out the `mt-pytorch` code example. We look forward "
"to you feedback!"
msgstr ""

#: ../../source/ref-changelog.md:1044
msgid ""
"Please note: *The Driver API is still experimental and will likely change"
" significantly over time.*"
msgstr ""

#: ../../source/ref-changelog.md:1046
msgid ""
"**Add new Federated Analytics with Pandas example** "
"([#1469](https://github.com/adap/flower/pull/1469), "
"[#1535](https://github.com/adap/flower/pull/1535))"
msgstr ""

#: ../../source/ref-changelog.md:1048
msgid ""
"A new code example (`quickstart-pandas`) demonstrates federated analytics"
" with Pandas and Flower. You can find it here: [quickstart-"
"pandas](https://github.com/adap/flower/tree/main/examples/quickstart-"
"pandas)."
msgstr ""

#: ../../source/ref-changelog.md:1050
msgid ""
"**Add new strategies: Krum and MultiKrum** "
"([#1481](https://github.com/adap/flower/pull/1481))"
msgstr ""

#: ../../source/ref-changelog.md:1052
msgid ""
"Edoardo, a computer science student at the Sapienza University of Rome, "
"contributed a new `Krum` strategy that enables users to easily use Krum "
"and MultiKrum in their workloads."
msgstr ""

#: ../../source/ref-changelog.md:1054
msgid ""
"**Update C++ example to be compatible with Flower v1.2.0** "
"([#1495](https://github.com/adap/flower/pull/1495))"
msgstr ""

#: ../../source/ref-changelog.md:1056
msgid ""
"The C++ code example has received a substantial update to make it "
"compatible with the latest version of Flower."
msgstr ""

#: ../../source/ref-changelog.md:1058
msgid ""
"**General improvements** "
"([#1491](https://github.com/adap/flower/pull/1491), "
"[#1504](https://github.com/adap/flower/pull/1504), "
"[#1506](https://github.com/adap/flower/pull/1506), "
"[#1514](https://github.com/adap/flower/pull/1514), "
"[#1522](https://github.com/adap/flower/pull/1522), "
"[#1523](https://github.com/adap/flower/pull/1523), "
"[#1526](https://github.com/adap/flower/pull/1526), "
"[#1528](https://github.com/adap/flower/pull/1528), "
"[#1547](https://github.com/adap/flower/pull/1547), "
"[#1549](https://github.com/adap/flower/pull/1549), "
"[#1560](https://github.com/adap/flower/pull/1560), "
"[#1564](https://github.com/adap/flower/pull/1564), "
"[#1566](https://github.com/adap/flower/pull/1566))"
msgstr ""

#: ../../source/ref-changelog.md:1062
msgid ""
"**Updated documentation** "
"([#1494](https://github.com/adap/flower/pull/1494), "
"[#1496](https://github.com/adap/flower/pull/1496), "
"[#1500](https://github.com/adap/flower/pull/1500), "
"[#1503](https://github.com/adap/flower/pull/1503), "
"[#1505](https://github.com/adap/flower/pull/1505), "
"[#1524](https://github.com/adap/flower/pull/1524), "
"[#1518](https://github.com/adap/flower/pull/1518), "
"[#1519](https://github.com/adap/flower/pull/1519), "
"[#1515](https://github.com/adap/flower/pull/1515))"
msgstr ""

#: ../../source/ref-changelog.md:1066
msgid ""
"One highlight is the new [first time contributor "
"guide](https://flower.ai/docs/first-time-contributors.html): if you've "
"never contributed on GitHub before, this is the perfect place to start!"
msgstr ""

#: ../../source/ref-changelog.md:1072
msgid "v1.1.0 (2022-10-31)"
msgstr ""

#: ../../source/ref-changelog.md:1076
msgid ""
"We would like to give our **special thanks** to all the contributors who "
"made the new version of Flower possible (in `git shortlog` order):"
msgstr ""

#: ../../source/ref-changelog.md:1078
msgid ""
"`Akis Linardos`, `Christopher S`, `Daniel J. Beutel`, `George`, `Jan "
"Schlicht`, `Mohammad Fares`, `Pedro Porto Buarque de Gusmão`, `Philipp "
"Wiesner`, `Rob Luke`, `Taner Topal`, `VasundharaAgarwal`, "
"`danielnugraha`, `edogab33`"
msgstr ""

#: ../../source/ref-changelog.md:1082
msgid ""
"**Introduce Differential Privacy wrappers (preview)** "
"([#1357](https://github.com/adap/flower/pull/1357), "
"[#1460](https://github.com/adap/flower/pull/1460))"
msgstr ""

#: ../../source/ref-changelog.md:1084
msgid ""
"The first (experimental) preview of pluggable Differential Privacy "
"wrappers enables easy configuration and usage of differential privacy "
"(DP). The pluggable DP wrappers enable framework-agnostic **and** "
"strategy-agnostic usage of both client-side DP and server-side DP. Head "
"over to the Flower docs, a new explainer goes into more detail."
msgstr ""

#: ../../source/ref-changelog.md:1086
msgid ""
"**New iOS CoreML code example** "
"([#1289](https://github.com/adap/flower/pull/1289))"
msgstr ""

#: ../../source/ref-changelog.md:1088
msgid ""
"Flower goes iOS! A massive new code example shows how Flower clients can "
"be built for iOS. The code example contains both Flower iOS SDK "
"components that can be used for many tasks, and one task example running "
"on CoreML."
msgstr ""

#: ../../source/ref-changelog.md:1090
msgid ""
"**New FedMedian strategy** "
"([#1461](https://github.com/adap/flower/pull/1461))"
msgstr ""

#: ../../source/ref-changelog.md:1092
msgid ""
"The new `FedMedian` strategy implements Federated Median (FedMedian) by "
"[Yin et al., 2018](https://arxiv.org/pdf/1803.01498v1.pdf)."
msgstr ""

#: ../../source/ref-changelog.md:1094
msgid ""
"**Log** `Client` **exceptions in Virtual Client Engine** "
"([#1493](https://github.com/adap/flower/pull/1493))"
msgstr ""

#: ../../source/ref-changelog.md:1096
msgid ""
"All `Client` exceptions happening in the VCE are now logged by default "
"and not just exposed to the configured `Strategy` (via the `failures` "
"argument)."
msgstr ""

#: ../../source/ref-changelog.md:1098
msgid ""
"**Improve Virtual Client Engine internals** "
"([#1401](https://github.com/adap/flower/pull/1401), "
"[#1453](https://github.com/adap/flower/pull/1453))"
msgstr ""

#: ../../source/ref-changelog.md:1100
msgid ""
"Some internals of the Virtual Client Engine have been revamped. The VCE "
"now uses Ray 2.0 under the hood, the value type of the `client_resources`"
" dictionary changed to `float` to allow fractions of resources to be "
"allocated."
msgstr ""

#: ../../source/ref-changelog.md:1102
msgid ""
"**Support optional** `Client`**/**`NumPyClient` **methods in Virtual "
"Client Engine**"
msgstr ""

#: ../../source/ref-changelog.md:1104
msgid ""
"The Virtual Client Engine now has full support for optional `Client` (and"
" `NumPyClient`) methods."
msgstr ""

#: ../../source/ref-changelog.md:1106
msgid ""
"**Provide type information to packages using** `flwr` "
"([#1377](https://github.com/adap/flower/pull/1377))"
msgstr ""

#: ../../source/ref-changelog.md:1108
msgid ""
"The package `flwr` is now bundled with a `py.typed` file indicating that "
"the package is typed. This enables typing support for projects or "
"packages that use `flwr` by enabling them to improve their code using "
"static type checkers like `mypy`."
msgstr ""

#: ../../source/ref-changelog.md:1110
msgid ""
"**Updated code example** "
"([#1344](https://github.com/adap/flower/pull/1344), "
"[#1347](https://github.com/adap/flower/pull/1347))"
msgstr ""

#: ../../source/ref-changelog.md:1112
msgid ""
"The code examples covering scikit-learn and PyTorch Lightning have been "
"updated to work with the latest version of Flower."
msgstr ""

#: ../../source/ref-changelog.md:1114
msgid ""
"**Updated documentation** "
"([#1355](https://github.com/adap/flower/pull/1355), "
"[#1558](https://github.com/adap/flower/pull/1558), "
"[#1379](https://github.com/adap/flower/pull/1379), "
"[#1380](https://github.com/adap/flower/pull/1380), "
"[#1381](https://github.com/adap/flower/pull/1381), "
"[#1332](https://github.com/adap/flower/pull/1332), "
"[#1391](https://github.com/adap/flower/pull/1391), "
"[#1403](https://github.com/adap/flower/pull/1403), "
"[#1364](https://github.com/adap/flower/pull/1364), "
"[#1409](https://github.com/adap/flower/pull/1409), "
"[#1419](https://github.com/adap/flower/pull/1419), "
"[#1444](https://github.com/adap/flower/pull/1444), "
"[#1448](https://github.com/adap/flower/pull/1448), "
"[#1417](https://github.com/adap/flower/pull/1417), "
"[#1449](https://github.com/adap/flower/pull/1449), "
"[#1465](https://github.com/adap/flower/pull/1465), "
"[#1467](https://github.com/adap/flower/pull/1467))"
msgstr ""

#: ../../source/ref-changelog.md:1116
msgid ""
"There have been so many documentation updates that it doesn't even make "
"sense to list them individually."
msgstr ""

#: ../../source/ref-changelog.md:1118
msgid ""
"**Restructured documentation** "
"([#1387](https://github.com/adap/flower/pull/1387))"
msgstr ""

#: ../../source/ref-changelog.md:1120
msgid ""
"The documentation has been restructured to make it easier to navigate. "
"This is just the first step in a larger effort to make the Flower "
"documentation the best documentation of any project ever. Stay tuned!"
msgstr ""

#: ../../source/ref-changelog.md:1122
msgid ""
"**Open in Colab button** "
"([#1389](https://github.com/adap/flower/pull/1389))"
msgstr ""

#: ../../source/ref-changelog.md:1124
msgid ""
"The four parts of the Flower Federated Learning Tutorial now come with a "
"new `Open in Colab` button. No need to install anything on your local "
"machine, you can now use and learn about Flower in your browser, it's "
"only a single click away."
msgstr ""

#: ../../source/ref-changelog.md:1126
msgid ""
"**Improved tutorial** ([#1468](https://github.com/adap/flower/pull/1468),"
" [#1470](https://github.com/adap/flower/pull/1470), "
"[#1472](https://github.com/adap/flower/pull/1472), "
"[#1473](https://github.com/adap/flower/pull/1473), "
"[#1474](https://github.com/adap/flower/pull/1474), "
"[#1475](https://github.com/adap/flower/pull/1475))"
msgstr ""

#: ../../source/ref-changelog.md:1128
msgid ""
"The Flower Federated Learning Tutorial has two brand-new parts covering "
"custom strategies (still WIP) and the distinction between `Client` and "
"`NumPyClient`. The existing parts one and two have also been improved "
"(many small changes and fixes)."
msgstr ""

#: ../../source/ref-changelog.md:1134
msgid "v1.0.0 (2022-07-28)"
msgstr ""

#: ../../source/ref-changelog.md:1136
msgid "Highlights"
msgstr ""

#: ../../source/ref-changelog.md:1138
msgid "Stable **Virtual Client Engine** (accessible via `start_simulation`)"
msgstr ""

#: ../../source/ref-changelog.md:1139
msgid "All `Client`/`NumPyClient` methods are now optional"
msgstr ""

#: ../../source/ref-changelog.md:1140
msgid "Configurable `get_parameters`"
msgstr ""

#: ../../source/ref-changelog.md:1141
msgid ""
"Tons of small API cleanups resulting in a more coherent developer "
"experience"
msgstr ""

#: ../../source/ref-changelog.md:1145
msgid ""
"We would like to give our **special thanks** to all the contributors who "
"made Flower 1.0 possible (in reverse [GitHub "
"Contributors](https://github.com/adap/flower/graphs/contributors) order):"
msgstr ""

#: ../../source/ref-changelog.md:1147
msgid ""
"[@rtaiello](https://github.com/rtaiello), "
"[@g-pichler](https://github.com/g-pichler), [@rob-"
"luke](https://github.com/rob-luke), [@andreea-zaharia](https://github.com"
"/andreea-zaharia), [@kinshukdua](https://github.com/kinshukdua), "
"[@nfnt](https://github.com/nfnt), "
"[@tatiana-s](https://github.com/tatiana-s), "
"[@TParcollet](https://github.com/TParcollet), "
"[@vballoli](https://github.com/vballoli), "
"[@negedng](https://github.com/negedng), "
"[@RISHIKESHAVAN](https://github.com/RISHIKESHAVAN), "
"[@hei411](https://github.com/hei411), "
"[@SebastianSpeitel](https://github.com/SebastianSpeitel), "
"[@AmitChaulwar](https://github.com/AmitChaulwar), "
"[@Rubiel1](https://github.com/Rubiel1), [@FANTOME-PAN](https://github.com"
"/FANTOME-PAN), [@Rono-BC](https://github.com/Rono-BC), "
"[@lbhm](https://github.com/lbhm), "
"[@sishtiaq](https://github.com/sishtiaq), "
"[@remde](https://github.com/remde), [@Jueun-Park](https://github.com"
"/Jueun-Park), [@architjen](https://github.com/architjen), "
"[@PratikGarai](https://github.com/PratikGarai), "
"[@mrinaald](https://github.com/mrinaald), "
"[@zliel](https://github.com/zliel), "
"[@MeiruiJiang](https://github.com/MeiruiJiang), "
"[@sancarlim](https://github.com/sancarlim), "
"[@gubertoli](https://github.com/gubertoli), "
"[@Vingt100](https://github.com/Vingt100), "
"[@MakGulati](https://github.com/MakGulati), "
"[@cozek](https://github.com/cozek), "
"[@jafermarq](https://github.com/jafermarq), "
"[@sisco0](https://github.com/sisco0), "
"[@akhilmathurs](https://github.com/akhilmathurs), "
"[@CanTuerk](https://github.com/CanTuerk), "
"[@mariaboerner1987](https://github.com/mariaboerner1987), "
"[@pedropgusmao](https://github.com/pedropgusmao), "
"[@tanertopal](https://github.com/tanertopal), "
"[@danieljanes](https://github.com/danieljanes)."
msgstr ""

#: ../../source/ref-changelog.md:1151
msgid ""
"**All arguments must be passed as keyword arguments** "
"([#1338](https://github.com/adap/flower/pull/1338))"
msgstr ""

#: ../../source/ref-changelog.md:1153
msgid ""
"Pass all arguments as keyword arguments, positional arguments are not "
"longer supported. Code that uses positional arguments (e.g., "
"`start_client(\"127.0.0.1:8080\", FlowerClient())`) must add the keyword "
"for each positional argument (e.g., "
"`start_client(server_address=\"127.0.0.1:8080\", "
"client=FlowerClient())`)."
msgstr ""

#: ../../source/ref-changelog.md:1155
msgid ""
"**Introduce configuration object** `ServerConfig` **in** `start_server` "
"**and** `start_simulation` "
"([#1317](https://github.com/adap/flower/pull/1317))"
msgstr ""

#: ../../source/ref-changelog.md:1157
msgid ""
"Instead of a config dictionary `{\"num_rounds\": 3, \"round_timeout\": "
"600.0}`, `start_server` and `start_simulation` now expect a configuration"
" object of type `flwr.server.ServerConfig`. `ServerConfig` takes the same"
" arguments that as the previous config dict, but it makes writing type-"
"safe code easier and the default parameters values more transparent."
msgstr ""

#: ../../source/ref-changelog.md:1159
msgid ""
"**Rename built-in strategy parameters for clarity** "
"([#1334](https://github.com/adap/flower/pull/1334))"
msgstr ""

#: ../../source/ref-changelog.md:1161
msgid ""
"The following built-in strategy parameters were renamed to improve "
"readability and consistency with other API's:"
msgstr ""

#: ../../source/ref-changelog.md:1163
msgid "`fraction_eval` --> `fraction_evaluate`"
msgstr ""

#: ../../source/ref-changelog.md:1164
msgid "`min_eval_clients` --> `min_evaluate_clients`"
msgstr ""

#: ../../source/ref-changelog.md:1165
msgid "`eval_fn` --> `evaluate_fn`"
msgstr ""

#: ../../source/ref-changelog.md:1167
msgid ""
"**Update default arguments of built-in strategies** "
"([#1278](https://github.com/adap/flower/pull/1278))"
msgstr ""

#: ../../source/ref-changelog.md:1169
msgid ""
"All built-in strategies now use `fraction_fit=1.0` and "
"`fraction_evaluate=1.0`, which means they select *all* currently "
"available clients for training and evaluation. Projects that relied on "
"the previous default values can get the previous behaviour by "
"initializing the strategy in the following way:"
msgstr ""

#: ../../source/ref-changelog.md:1171
msgid "`strategy = FedAvg(fraction_fit=0.1, fraction_evaluate=0.1)`"
msgstr ""

#: ../../source/ref-changelog.md:1173
msgid ""
"**Add** `server_round` **to** `Strategy.evaluate` "
"([#1334](https://github.com/adap/flower/pull/1334))"
msgstr ""

#: ../../source/ref-changelog.md:1175
msgid ""
"The `Strategy` method `evaluate` now receives the current round of "
"federated learning/evaluation as the first parameter."
msgstr ""

#: ../../source/ref-changelog.md:1177
msgid ""
"**Add** `server_round` **and** `config` **parameters to** `evaluate_fn` "
"([#1334](https://github.com/adap/flower/pull/1334))"
msgstr ""

#: ../../source/ref-changelog.md:1179
msgid ""
"The `evaluate_fn` passed to built-in strategies like `FedAvg` now takes "
"three parameters: (1) The current round of federated learning/evaluation "
"(`server_round`), (2) the model parameters to evaluate (`parameters`), "
"and (3) a config dictionary (`config`)."
msgstr ""

#: ../../source/ref-changelog.md:1181
msgid ""
"**Rename** `rnd` **to** `server_round` "
"([#1321](https://github.com/adap/flower/pull/1321))"
msgstr ""

#: ../../source/ref-changelog.md:1183
msgid ""
"Several Flower methods and functions (`evaluate_fn`, `configure_fit`, "
"`aggregate_fit`, `configure_evaluate`, `aggregate_evaluate`) receive the "
"current round of federated learning/evaluation as their first parameter. "
"To improve reaability and avoid confusion with *random*, this parameter "
"has been renamed from `rnd` to `server_round`."
msgstr ""

#: ../../source/ref-changelog.md:1185
msgid ""
"**Move** `flwr.dataset` **to** `flwr_baselines` "
"([#1273](https://github.com/adap/flower/pull/1273))"
msgstr ""

#: ../../source/ref-changelog.md:1187
msgid "The experimental package `flwr.dataset` was migrated to Flower Baselines."
msgstr ""

#: ../../source/ref-changelog.md:1189
msgid ""
"**Remove experimental strategies** "
"([#1280](https://github.com/adap/flower/pull/1280))"
msgstr ""

#: ../../source/ref-changelog.md:1191
msgid ""
"Remove unmaintained experimental strategies (`FastAndSlow`, `FedFSv0`, "
"`FedFSv1`)."
msgstr ""

#: ../../source/ref-changelog.md:1193
msgid ""
"**Rename** `Weights` **to** `NDArrays` "
"([#1258](https://github.com/adap/flower/pull/1258), "
"[#1259](https://github.com/adap/flower/pull/1259))"
msgstr ""

#: ../../source/ref-changelog.md:1195
msgid ""
"`flwr.common.Weights` was renamed to `flwr.common.NDArrays` to better "
"capture what this type is all about."
msgstr ""

#: ../../source/ref-changelog.md:1197
msgid ""
"**Remove antiquated** `force_final_distributed_eval` **from** "
"`start_server` ([#1258](https://github.com/adap/flower/pull/1258), "
"[#1259](https://github.com/adap/flower/pull/1259))"
msgstr ""

#: ../../source/ref-changelog.md:1199
msgid ""
"The `start_server` parameter `force_final_distributed_eval` has long been"
" a historic artefact, in this release it is finally gone for good."
msgstr ""

#: ../../source/ref-changelog.md:1201
msgid ""
"**Make** `get_parameters` **configurable** "
"([#1242](https://github.com/adap/flower/pull/1242))"
msgstr ""

#: ../../source/ref-changelog.md:1203
msgid ""
"The `get_parameters` method now accepts a configuration dictionary, just "
"like `get_properties`, `fit`, and `evaluate`."
msgstr ""

#: ../../source/ref-changelog.md:1205
msgid ""
"**Replace** `num_rounds` **in** `start_simulation` **with new** `config` "
"**parameter** ([#1281](https://github.com/adap/flower/pull/1281))"
msgstr ""

#: ../../source/ref-changelog.md:1207
msgid ""
"The `start_simulation` function now accepts a configuration dictionary "
"`config` instead of the `num_rounds` integer. This improves the "
"consistency between `start_simulation` and `start_server` and makes "
"transitioning between the two easier."
msgstr ""

#: ../../source/ref-changelog.md:1211
msgid ""
"**Support Python 3.10** "
"([#1320](https://github.com/adap/flower/pull/1320))"
msgstr ""

#: ../../source/ref-changelog.md:1213
msgid ""
"The previous Flower release introduced experimental support for Python "
"3.10, this release declares Python 3.10 support as stable."
msgstr ""

#: ../../source/ref-changelog.md:1215
msgid ""
"**Make all** `Client` **and** `NumPyClient` **methods optional** "
"([#1260](https://github.com/adap/flower/pull/1260), "
"[#1277](https://github.com/adap/flower/pull/1277))"
msgstr ""

#: ../../source/ref-changelog.md:1217
msgid ""
"The `Client`/`NumPyClient` methods `get_properties`, `get_parameters`, "
"`fit`, and `evaluate` are all optional. This enables writing clients that"
" implement, for example, only `fit`, but no other method. No need to "
"implement `evaluate` when using centralized evaluation!"
msgstr ""

#: ../../source/ref-changelog.md:1219
msgid ""
"**Enable passing a** `Server` **instance to** `start_simulation` "
"([#1281](https://github.com/adap/flower/pull/1281))"
msgstr ""

#: ../../source/ref-changelog.md:1221
msgid ""
"Similar to `start_server`, `start_simulation` now accepts a full `Server`"
" instance. This enables users to heavily customize the execution of "
"eperiments and opens the door to running, for example, async FL using the"
" Virtual Client Engine."
msgstr ""

#: ../../source/ref-changelog.md:1223
msgid ""
"**Update code examples** "
"([#1291](https://github.com/adap/flower/pull/1291), "
"[#1286](https://github.com/adap/flower/pull/1286), "
"[#1282](https://github.com/adap/flower/pull/1282))"
msgstr ""

#: ../../source/ref-changelog.md:1225
msgid ""
"Many code examples received small or even large maintenance updates, "
"among them are"
msgstr ""

#: ../../source/ref-changelog.md:1227
msgid "`scikit-learn`"
msgstr ""

#: ../../source/ref-changelog.md:1228
msgid "`simulation_pytorch`"
msgstr ""

#: ../../source/ref-changelog.md:1229
msgid "`quickstart_pytorch`"
msgstr ""

#: ../../source/ref-changelog.md:1230
msgid "`quickstart_simulation`"
msgstr ""

#: ../../source/ref-changelog.md:1231
msgid "`quickstart_tensorflow`"
msgstr ""

#: ../../source/ref-changelog.md:1232
msgid "`advanced_tensorflow`"
msgstr ""

#: ../../source/ref-changelog.md:1234
msgid ""
"**Remove the obsolete simulation example** "
"([#1328](https://github.com/adap/flower/pull/1328))"
msgstr ""

#: ../../source/ref-changelog.md:1236
msgid ""
"Removes the obsolete `simulation` example and renames "
"`quickstart_simulation` to `simulation_tensorflow` so it fits withs the "
"naming of `simulation_pytorch`"
msgstr ""

#: ../../source/ref-changelog.md:1238
msgid ""
"**Update documentation** "
"([#1223](https://github.com/adap/flower/pull/1223), "
"[#1209](https://github.com/adap/flower/pull/1209), "
"[#1251](https://github.com/adap/flower/pull/1251), "
"[#1257](https://github.com/adap/flower/pull/1257), "
"[#1267](https://github.com/adap/flower/pull/1267), "
"[#1268](https://github.com/adap/flower/pull/1268), "
"[#1300](https://github.com/adap/flower/pull/1300), "
"[#1304](https://github.com/adap/flower/pull/1304), "
"[#1305](https://github.com/adap/flower/pull/1305), "
"[#1307](https://github.com/adap/flower/pull/1307))"
msgstr ""

#: ../../source/ref-changelog.md:1240
msgid ""
"One substantial documentation update fixes multiple smaller rendering "
"issues, makes titles more succinct to improve navigation, removes a "
"deprecated library, updates documentation dependencies, includes the "
"`flwr.common` module in the API reference, includes support for markdown-"
"based documentation, migrates the changelog from `.rst` to `.md`, and "
"fixes a number of smaller details!"
msgstr ""

#: ../../source/ref-changelog.md:1242 ../../source/ref-changelog.md:1297
#: ../../source/ref-changelog.md:1366 ../../source/ref-changelog.md:1405
msgid "**Minor updates**"
msgstr ""

#: ../../source/ref-changelog.md:1244
msgid ""
"Add round number to fit and evaluate log messages "
"([#1266](https://github.com/adap/flower/pull/1266))"
msgstr ""

#: ../../source/ref-changelog.md:1245
msgid ""
"Add secure gRPC connection to the `advanced_tensorflow` code example "
"([#847](https://github.com/adap/flower/pull/847))"
msgstr ""

#: ../../source/ref-changelog.md:1246
msgid ""
"Update developer tooling "
"([#1231](https://github.com/adap/flower/pull/1231), "
"[#1276](https://github.com/adap/flower/pull/1276), "
"[#1301](https://github.com/adap/flower/pull/1301), "
"[#1310](https://github.com/adap/flower/pull/1310))"
msgstr ""

#: ../../source/ref-changelog.md:1247
msgid ""
"Rename ProtoBuf messages to improve consistency "
"([#1214](https://github.com/adap/flower/pull/1214), "
"[#1258](https://github.com/adap/flower/pull/1258), "
"[#1259](https://github.com/adap/flower/pull/1259))"
msgstr ""

#: ../../source/ref-changelog.md:1249
msgid "v0.19.0 (2022-05-18)"
msgstr ""

#: ../../source/ref-changelog.md:1253
msgid ""
"**Flower Baselines (preview): FedOpt, FedBN, FedAvgM** "
"([#919](https://github.com/adap/flower/pull/919), "
"[#1127](https://github.com/adap/flower/pull/1127), "
"[#914](https://github.com/adap/flower/pull/914))"
msgstr ""

#: ../../source/ref-changelog.md:1255
msgid ""
"The first preview release of Flower Baselines has arrived! We're "
"kickstarting Flower Baselines with implementations of FedOpt (FedYogi, "
"FedAdam, FedAdagrad), FedBN, and FedAvgM. Check the documentation on how "
"to use [Flower Baselines](https://flower.ai/docs/using-baselines.html). "
"With this first preview release we're also inviting the community to "
"[contribute their own baselines](https://flower.ai/docs/baselines/how-to-"
"contribute-baselines.html)."
msgstr ""

#: ../../source/ref-changelog.md:1257
msgid ""
"**C++ client SDK (preview) and code example** "
"([#1111](https://github.com/adap/flower/pull/1111))"
msgstr ""

#: ../../source/ref-changelog.md:1259
msgid ""
"Preview support for Flower clients written in C++. The C++ preview "
"includes a Flower client SDK and a quickstart code example that "
"demonstrates a simple C++ client using the SDK."
msgstr ""

#: ../../source/ref-changelog.md:1261
msgid ""
"**Add experimental support for Python 3.10 and Python 3.11** "
"([#1135](https://github.com/adap/flower/pull/1135))"
msgstr ""

#: ../../source/ref-changelog.md:1263
msgid ""
"Python 3.10 is the latest stable release of Python and Python 3.11 is due"
" to be released in October. This Flower release adds experimental support"
" for both Python versions."
msgstr ""

#: ../../source/ref-changelog.md:1265
msgid ""
"**Aggregate custom metrics through user-provided functions** "
"([#1144](https://github.com/adap/flower/pull/1144))"
msgstr ""

#: ../../source/ref-changelog.md:1267
msgid ""
"Custom metrics (e.g., `accuracy`) can now be aggregated without having to"
" customize the strategy. Built-in strategies support two new arguments, "
"`fit_metrics_aggregation_fn` and `evaluate_metrics_aggregation_fn`, that "
"allow passing custom metric aggregation functions."
msgstr ""

#: ../../source/ref-changelog.md:1269
msgid ""
"**User-configurable round timeout** "
"([#1162](https://github.com/adap/flower/pull/1162))"
msgstr ""

#: ../../source/ref-changelog.md:1271
msgid ""
"A new configuration value allows the round timeout to be set for "
"`start_server` and `start_simulation`. If the `config` dictionary "
"contains a `round_timeout` key (with a `float` value in seconds), the "
"server will wait *at least* `round_timeout` seconds before it closes the "
"connection."
msgstr ""

#: ../../source/ref-changelog.md:1273
msgid ""
"**Enable both federated evaluation and centralized evaluation to be used "
"at the same time in all built-in strategies** "
"([#1091](https://github.com/adap/flower/pull/1091))"
msgstr ""

#: ../../source/ref-changelog.md:1275
msgid ""
"Built-in strategies can now perform both federated evaluation (i.e., "
"client-side) and centralized evaluation (i.e., server-side) in the same "
"round. Federated evaluation can be disabled by setting `fraction_eval` to"
" `0.0`."
msgstr ""

#: ../../source/ref-changelog.md:1277
msgid ""
"**Two new Jupyter Notebook tutorials** "
"([#1141](https://github.com/adap/flower/pull/1141))"
msgstr ""

#: ../../source/ref-changelog.md:1279
msgid ""
"Two Jupyter Notebook tutorials (compatible with Google Colab) explain "
"basic and intermediate Flower features:"
msgstr ""

#: ../../source/ref-changelog.md:1281
msgid ""
"*An Introduction to Federated Learning*: [Open in "
"Colab](https://colab.research.google.com/github/adap/flower/blob/main/tutorials/Flower-1"
"-Intro-to-FL-PyTorch.ipynb)"
msgstr ""

#: ../../source/ref-changelog.md:1283
msgid ""
"*Using Strategies in Federated Learning*: [Open in "
"Colab](https://colab.research.google.com/github/adap/flower/blob/main/tutorials/Flower-2"
"-Strategies-in-FL-PyTorch.ipynb)"
msgstr ""

#: ../../source/ref-changelog.md:1285
msgid ""
"**New FedAvgM strategy (Federated Averaging with Server Momentum)** "
"([#1076](https://github.com/adap/flower/pull/1076))"
msgstr ""

#: ../../source/ref-changelog.md:1287
msgid ""
"The new `FedAvgM` strategy implements Federated Averaging with Server "
"Momentum \\[Hsu et al., 2019\\]."
msgstr ""

#: ../../source/ref-changelog.md:1289
msgid ""
"**New advanced PyTorch code example** "
"([#1007](https://github.com/adap/flower/pull/1007))"
msgstr ""

#: ../../source/ref-changelog.md:1291
msgid ""
"A new code example (`advanced_pytorch`) demonstrates advanced Flower "
"concepts with PyTorch."
msgstr ""

#: ../../source/ref-changelog.md:1293
msgid ""
"**New JAX code example** "
"([#906](https://github.com/adap/flower/pull/906), "
"[#1143](https://github.com/adap/flower/pull/1143))"
msgstr ""

#: ../../source/ref-changelog.md:1295
msgid ""
"A new code example (`jax_from_centralized_to_federated`) shows federated "
"learning with JAX and Flower."
msgstr ""

#: ../../source/ref-changelog.md:1299
msgid ""
"New option to keep Ray running if Ray was already initialized in "
"`start_simulation` ([#1177](https://github.com/adap/flower/pull/1177))"
msgstr ""

#: ../../source/ref-changelog.md:1300
msgid ""
"Add support for custom `ClientManager` as a `start_simulation` parameter "
"([#1171](https://github.com/adap/flower/pull/1171))"
msgstr ""

#: ../../source/ref-changelog.md:1301
msgid ""
"New documentation for [implementing "
"strategies](https://flower.ai/docs/framework/how-to-implement-"
"strategies.html) ([#1097](https://github.com/adap/flower/pull/1097), "
"[#1175](https://github.com/adap/flower/pull/1175))"
msgstr ""

#: ../../source/ref-changelog.md:1302
msgid ""
"New mobile-friendly documentation theme "
"([#1174](https://github.com/adap/flower/pull/1174))"
msgstr ""

#: ../../source/ref-changelog.md:1303
msgid ""
"Limit version range for (optional) `ray` dependency to include only "
"compatible releases (`>=1.9.2,<1.12.0`) "
"([#1205](https://github.com/adap/flower/pull/1205))"
msgstr ""

#: ../../source/ref-changelog.md:1307
msgid ""
"**Remove deprecated support for Python 3.6** "
"([#871](https://github.com/adap/flower/pull/871))"
msgstr ""

#: ../../source/ref-changelog.md:1308
msgid ""
"**Remove deprecated KerasClient** "
"([#857](https://github.com/adap/flower/pull/857))"
msgstr ""

#: ../../source/ref-changelog.md:1309
msgid ""
"**Remove deprecated no-op extra installs** "
"([#973](https://github.com/adap/flower/pull/973))"
msgstr ""

#: ../../source/ref-changelog.md:1310
msgid ""
"**Remove deprecated proto fields from** `FitRes` **and** `EvaluateRes` "
"([#869](https://github.com/adap/flower/pull/869))"
msgstr ""

#: ../../source/ref-changelog.md:1311
msgid ""
"**Remove deprecated QffedAvg strategy (replaced by QFedAvg)** "
"([#1107](https://github.com/adap/flower/pull/1107))"
msgstr ""

#: ../../source/ref-changelog.md:1312
msgid ""
"**Remove deprecated DefaultStrategy strategy** "
"([#1142](https://github.com/adap/flower/pull/1142))"
msgstr ""

#: ../../source/ref-changelog.md:1313
msgid ""
"**Remove deprecated support for eval_fn accuracy return value** "
"([#1142](https://github.com/adap/flower/pull/1142))"
msgstr ""

#: ../../source/ref-changelog.md:1314
msgid ""
"**Remove deprecated support for passing initial parameters as NumPy "
"ndarrays** ([#1142](https://github.com/adap/flower/pull/1142))"
msgstr ""

#: ../../source/ref-changelog.md:1316
msgid "v0.18.0 (2022-02-28)"
msgstr ""

#: ../../source/ref-changelog.md:1320
msgid ""
"**Improved Virtual Client Engine compatibility with Jupyter Notebook / "
"Google Colab** ([#866](https://github.com/adap/flower/pull/866), "
"[#872](https://github.com/adap/flower/pull/872), "
"[#833](https://github.com/adap/flower/pull/833), "
"[#1036](https://github.com/adap/flower/pull/1036))"
msgstr ""

#: ../../source/ref-changelog.md:1322
msgid ""
"Simulations (using the Virtual Client Engine through `start_simulation`) "
"now work more smoothly on Jupyter Notebooks (incl. Google Colab) after "
"installing Flower with the `simulation` extra (`pip install "
"'flwr[simulation]'`)."
msgstr ""

#: ../../source/ref-changelog.md:1324
msgid ""
"**New Jupyter Notebook code example** "
"([#833](https://github.com/adap/flower/pull/833))"
msgstr ""

#: ../../source/ref-changelog.md:1326
msgid ""
"A new code example (`quickstart_simulation`) demonstrates Flower "
"simulations using the Virtual Client Engine through Jupyter Notebook "
"(incl. Google Colab)."
msgstr ""

#: ../../source/ref-changelog.md:1328
msgid ""
"**Client properties (feature preview)** "
"([#795](https://github.com/adap/flower/pull/795))"
msgstr ""

#: ../../source/ref-changelog.md:1330
msgid ""
"Clients can implement a new method `get_properties` to enable server-side"
" strategies to query client properties."
msgstr ""

#: ../../source/ref-changelog.md:1332
msgid ""
"**Experimental Android support with TFLite** "
"([#865](https://github.com/adap/flower/pull/865))"
msgstr ""

#: ../../source/ref-changelog.md:1334
msgid ""
"Android support has finally arrived in `main`! Flower is both client-"
"agnostic and framework-agnostic by design. One can integrate arbitrary "
"client platforms and with this release, using Flower on Android has "
"become a lot easier."
msgstr ""

#: ../../source/ref-changelog.md:1336
msgid ""
"The example uses TFLite on the client side, along with a new "
"`FedAvgAndroid` strategy. The Android client and `FedAvgAndroid` are "
"still experimental, but they are a first step towards a fully-fledged "
"Android SDK and a unified `FedAvg` implementation that integrated the new"
" functionality from `FedAvgAndroid`."
msgstr ""

#: ../../source/ref-changelog.md:1338
msgid ""
"**Make gRPC keepalive time user-configurable and decrease default "
"keepalive time** ([#1069](https://github.com/adap/flower/pull/1069))"
msgstr ""

#: ../../source/ref-changelog.md:1340
msgid ""
"The default gRPC keepalive time has been reduced to increase the "
"compatibility of Flower with more cloud environments (for example, "
"Microsoft Azure). Users can configure the keepalive time to customize the"
" gRPC stack based on specific requirements."
msgstr ""

#: ../../source/ref-changelog.md:1342
msgid ""
"**New differential privacy example using Opacus and PyTorch** "
"([#805](https://github.com/adap/flower/pull/805))"
msgstr ""

#: ../../source/ref-changelog.md:1344
msgid ""
"A new code example (`opacus`) demonstrates differentially-private "
"federated learning with Opacus, PyTorch, and Flower."
msgstr ""

#: ../../source/ref-changelog.md:1346
msgid ""
"**New Hugging Face Transformers code example** "
"([#863](https://github.com/adap/flower/pull/863))"
msgstr ""

#: ../../source/ref-changelog.md:1348
msgid ""
"A new code example (`quickstart_huggingface`) demonstrates usage of "
"Hugging Face Transformers with Flower."
msgstr ""

#: ../../source/ref-changelog.md:1350
msgid ""
"**New MLCube code example** "
"([#779](https://github.com/adap/flower/pull/779), "
"[#1034](https://github.com/adap/flower/pull/1034), "
"[#1065](https://github.com/adap/flower/pull/1065), "
"[#1090](https://github.com/adap/flower/pull/1090))"
msgstr ""

#: ../../source/ref-changelog.md:1352
msgid ""
"A new code example (`quickstart_mlcube`) demonstrates usage of MLCube "
"with Flower."
msgstr ""

#: ../../source/ref-changelog.md:1354
msgid ""
"**SSL-enabled server and client** "
"([#842](https://github.com/adap/flower/pull/842),  "
"[#844](https://github.com/adap/flower/pull/844),  "
"[#845](https://github.com/adap/flower/pull/845), "
"[#847](https://github.com/adap/flower/pull/847), "
"[#993](https://github.com/adap/flower/pull/993), "
"[#994](https://github.com/adap/flower/pull/994))"
msgstr ""

#: ../../source/ref-changelog.md:1356
msgid ""
"SSL enables secure encrypted connections between clients and servers. "
"This release open-sources the Flower secure gRPC implementation to make "
"encrypted communication channels accessible to all Flower users."
msgstr ""

#: ../../source/ref-changelog.md:1358
msgid ""
"**Updated** `FedAdam` **and** `FedYogi` **strategies** "
"([#885](https://github.com/adap/flower/pull/885), "
"[#895](https://github.com/adap/flower/pull/895))"
msgstr ""

#: ../../source/ref-changelog.md:1360
msgid ""
"`FedAdam` and `FedAdam` match the latest version of the Adaptive "
"Federated Optimization paper."
msgstr ""

#: ../../source/ref-changelog.md:1362
msgid ""
"**Initialize** `start_simulation` **with a list of client IDs** "
"([#860](https://github.com/adap/flower/pull/860))"
msgstr ""

#: ../../source/ref-changelog.md:1364
msgid ""
"`start_simulation` can now be called with a list of client IDs "
"(`clients_ids`, type: `List[str]`). Those IDs will be passed to the "
"`client_fn` whenever a client needs to be initialized, which can make it "
"easier to load data partitions that are not accessible through `int` "
"identifiers."
msgstr ""

#: ../../source/ref-changelog.md:1368
msgid ""
"Update `num_examples` calculation in PyTorch code examples in "
"([#909](https://github.com/adap/flower/pull/909))"
msgstr ""

#: ../../source/ref-changelog.md:1369
msgid ""
"Expose Flower version through `flwr.__version__` "
"([#952](https://github.com/adap/flower/pull/952))"
msgstr ""

#: ../../source/ref-changelog.md:1370
msgid ""
"`start_server` in `app.py` now returns a `History` object containing "
"metrics from training ([#974](https://github.com/adap/flower/pull/974))"
msgstr ""

#: ../../source/ref-changelog.md:1371
msgid ""
"Make `max_workers` (used by `ThreadPoolExecutor`) configurable "
"([#978](https://github.com/adap/flower/pull/978))"
msgstr ""

#: ../../source/ref-changelog.md:1372
msgid ""
"Increase sleep time after server start to three seconds in all code "
"examples ([#1086](https://github.com/adap/flower/pull/1086))"
msgstr ""

#: ../../source/ref-changelog.md:1373
msgid ""
"Added a new FAQ section to the documentation "
"([#948](https://github.com/adap/flower/pull/948))"
msgstr ""

#: ../../source/ref-changelog.md:1374
msgid ""
"And many more under-the-hood changes, library updates, documentation "
"changes, and tooling improvements!"
msgstr ""

#: ../../source/ref-changelog.md:1378
msgid ""
"**Removed** `flwr_example` **and** `flwr_experimental` **from release "
"build** ([#869](https://github.com/adap/flower/pull/869))"
msgstr ""

#: ../../source/ref-changelog.md:1380
msgid ""
"The packages `flwr_example` and `flwr_experimental` have been deprecated "
"since Flower 0.12.0 and they are not longer included in Flower release "
"builds. The associated extras (`baseline`, `examples-pytorch`, `examples-"
"tensorflow`, `http-logger`, `ops`) are now no-op and will be removed in "
"an upcoming release."
msgstr ""

#: ../../source/ref-changelog.md:1382
msgid "v0.17.0 (2021-09-24)"
msgstr ""

#: ../../source/ref-changelog.md:1386
msgid ""
"**Experimental virtual client engine** "
"([#781](https://github.com/adap/flower/pull/781) "
"[#790](https://github.com/adap/flower/pull/790) "
"[#791](https://github.com/adap/flower/pull/791))"
msgstr ""

#: ../../source/ref-changelog.md:1388
msgid ""
"One of Flower's goals is to enable research at scale. This release "
"enables a first (experimental) peek at a major new feature, codenamed the"
" virtual client engine. Virtual clients enable simulations that scale to "
"a (very) large number of clients on a single machine or compute cluster. "
"The easiest way to test the new functionality is to look at the two new "
"code examples called `quickstart_simulation` and `simulation_pytorch`."
msgstr ""

#: ../../source/ref-changelog.md:1390
msgid ""
"The feature is still experimental, so there's no stability guarantee for "
"the API. It's also not quite ready for prime time and comes with a few "
"known caveats. However, those who are curious are encouraged to try it "
"out and share their thoughts."
msgstr ""

#: ../../source/ref-changelog.md:1392
msgid ""
"**New built-in strategies** "
"([#828](https://github.com/adap/flower/pull/828) "
"[#822](https://github.com/adap/flower/pull/822))"
msgstr ""

#: ../../source/ref-changelog.md:1394
msgid ""
"FedYogi - Federated learning strategy using Yogi on server-side. "
"Implementation based on https://arxiv.org/abs/2003.00295"
msgstr ""

#: ../../source/ref-changelog.md:1395
msgid ""
"FedAdam - Federated learning strategy using Adam on server-side. "
"Implementation based on https://arxiv.org/abs/2003.00295"
msgstr ""

#: ../../source/ref-changelog.md:1397
msgid ""
"**New PyTorch Lightning code example** "
"([#617](https://github.com/adap/flower/pull/617))"
msgstr ""

#: ../../source/ref-changelog.md:1399
msgid ""
"**New Variational Auto-Encoder code example** "
"([#752](https://github.com/adap/flower/pull/752))"
msgstr ""

#: ../../source/ref-changelog.md:1401
msgid ""
"**New scikit-learn code example** "
"([#748](https://github.com/adap/flower/pull/748))"
msgstr ""

#: ../../source/ref-changelog.md:1403
msgid ""
"**New experimental TensorBoard strategy** "
"([#789](https://github.com/adap/flower/pull/789))"
msgstr ""

#: ../../source/ref-changelog.md:1407
msgid ""
"Improved advanced TensorFlow code example "
"([#769](https://github.com/adap/flower/pull/769))"
msgstr ""

#: ../../source/ref-changelog.md:1408
msgid ""
"Warning when `min_available_clients` is misconfigured "
"([#830](https://github.com/adap/flower/pull/830))"
msgstr ""

#: ../../source/ref-changelog.md:1409
msgid ""
"Improved gRPC server docs "
"([#841](https://github.com/adap/flower/pull/841))"
msgstr ""

#: ../../source/ref-changelog.md:1410
msgid ""
"Improved error message in `NumPyClient` "
"([#851](https://github.com/adap/flower/pull/851))"
msgstr ""

#: ../../source/ref-changelog.md:1411
msgid ""
"Improved PyTorch quickstart code example "
"([#852](https://github.com/adap/flower/pull/852))"
msgstr ""

#: ../../source/ref-changelog.md:1415
msgid ""
"**Disabled final distributed evaluation** "
"([#800](https://github.com/adap/flower/pull/800))"
msgstr ""

#: ../../source/ref-changelog.md:1417
msgid ""
"Prior behaviour was to perform a final round of distributed evaluation on"
" all connected clients, which is often not required (e.g., when using "
"server-side evaluation). The prior behaviour can be enabled by passing "
"`force_final_distributed_eval=True` to `start_server`."
msgstr ""

#: ../../source/ref-changelog.md:1419
msgid ""
"**Renamed q-FedAvg strategy** "
"([#802](https://github.com/adap/flower/pull/802))"
msgstr ""

#: ../../source/ref-changelog.md:1421
msgid ""
"The strategy named `QffedAvg` was renamed to `QFedAvg` to better reflect "
"the notation given in the original paper (q-FFL is the optimization "
"objective, q-FedAvg is the proposed solver). Note the original (now "
"deprecated) `QffedAvg` class is still available for compatibility reasons"
" (it will be removed in a future release)."
msgstr ""

#: ../../source/ref-changelog.md:1423
msgid ""
"**Deprecated and renamed code example** `simulation_pytorch` **to** "
"`simulation_pytorch_legacy` "
"([#791](https://github.com/adap/flower/pull/791))"
msgstr ""

#: ../../source/ref-changelog.md:1425
msgid ""
"This example has been replaced by a new example. The new example is based"
" on the experimental virtual client engine, which will become the new "
"default way of doing most types of large-scale simulations in Flower. The"
" existing example was kept for reference purposes, but it might be "
"removed in the future."
msgstr ""

#: ../../source/ref-changelog.md:1427
msgid "v0.16.0 (2021-05-11)"
msgstr ""

#: ../../source/ref-changelog.md:1431
msgid ""
"**New built-in strategies** "
"([#549](https://github.com/adap/flower/pull/549))"
msgstr ""

#: ../../source/ref-changelog.md:1433
msgid "(abstract) FedOpt"
msgstr ""

#: ../../source/ref-changelog.md:1436
msgid ""
"**Custom metrics for server and strategies** "
"([#717](https://github.com/adap/flower/pull/717))"
msgstr ""

#: ../../source/ref-changelog.md:1438
msgid ""
"The Flower server is now fully task-agnostic, all remaining instances of "
"task-specific metrics (such as `accuracy`) have been replaced by custom "
"metrics dictionaries. Flower 0.15 introduced the capability to pass a "
"dictionary containing custom metrics from client to server. As of this "
"release, custom metrics replace task-specific metrics on the server."
msgstr ""

#: ../../source/ref-changelog.md:1440
msgid ""
"Custom metric dictionaries are now used in two user-facing APIs: they are"
" returned from Strategy methods `aggregate_fit`/`aggregate_evaluate` and "
"they enable evaluation functions passed to built-in strategies (via "
"`eval_fn`) to return more than two evaluation metrics. Strategies can "
"even return *aggregated* metrics dictionaries for the server to keep "
"track of."
msgstr ""

#: ../../source/ref-changelog.md:1442
msgid ""
"Strategy implementations should migrate their `aggregate_fit` and "
"`aggregate_evaluate` methods to the new return type (e.g., by simply "
"returning an empty `{}`), server-side evaluation functions should migrate"
" from `return loss, accuracy` to `return loss, {\"accuracy\": accuracy}`."
msgstr ""

#: ../../source/ref-changelog.md:1444
msgid ""
"Flower 0.15-style return types are deprecated (but still supported), "
"compatibility will be removed in a future release."
msgstr ""

#: ../../source/ref-changelog.md:1446
msgid ""
"**Migration warnings for deprecated functionality** "
"([#690](https://github.com/adap/flower/pull/690))"
msgstr ""

#: ../../source/ref-changelog.md:1448
msgid ""
"Earlier versions of Flower were often migrated to new APIs, while "
"maintaining compatibility with legacy APIs. This release introduces "
"detailed warning messages if usage of deprecated APIs is detected. The "
"new warning messages often provide details on how to migrate to more "
"recent APIs, thus easing the transition from one release to another."
msgstr ""

#: ../../source/ref-changelog.md:1450
msgid ""
"Improved docs and docstrings "
"([#691](https://github.com/adap/flower/pull/691) "
"[#692](https://github.com/adap/flower/pull/692) "
"[#713](https://github.com/adap/flower/pull/713))"
msgstr ""

#: ../../source/ref-changelog.md:1452
msgid "MXNet example and documentation"
msgstr ""

#: ../../source/ref-changelog.md:1454
msgid ""
"FedBN implementation in example PyTorch: From Centralized To Federated "
"([#696](https://github.com/adap/flower/pull/696) "
"[#702](https://github.com/adap/flower/pull/702) "
"[#705](https://github.com/adap/flower/pull/705))"
msgstr ""

#: ../../source/ref-changelog.md:1458
msgid ""
"**Serialization-agnostic server** "
"([#721](https://github.com/adap/flower/pull/721))"
msgstr ""

#: ../../source/ref-changelog.md:1460
msgid ""
"The Flower server is now fully serialization-agnostic. Prior usage of "
"class `Weights` (which represents parameters as deserialized NumPy "
"ndarrays) was replaced by class `Parameters` (e.g., in `Strategy`). "
"`Parameters` objects are fully serialization-agnostic and represents "
"parameters as byte arrays, the `tensor_type` attributes indicates how "
"these byte arrays should be interpreted (e.g., for "
"serialization/deserialization)."
msgstr ""

#: ../../source/ref-changelog.md:1462
msgid ""
"Built-in strategies implement this approach by handling serialization and"
" deserialization to/from `Weights` internally. Custom/3rd-party Strategy "
"implementations should update to the slightly changed Strategy method "
"definitions. Strategy authors can consult PR "
"[#721](https://github.com/adap/flower/pull/721) to see how strategies can"
" easily migrate to the new format."
msgstr ""

#: ../../source/ref-changelog.md:1464
msgid ""
"Deprecated `flwr.server.Server.evaluate`, use "
"`flwr.server.Server.evaluate_round` instead "
"([#717](https://github.com/adap/flower/pull/717))"
msgstr ""

#: ../../source/ref-changelog.md:1466
msgid "v0.15.0 (2021-03-12)"
msgstr ""

#: ../../source/ref-changelog.md:1470
msgid ""
"**Server-side parameter initialization** "
"([#658](https://github.com/adap/flower/pull/658))"
msgstr ""

#: ../../source/ref-changelog.md:1472
msgid ""
"Model parameters can now be initialized on the server-side. Server-side "
"parameter initialization works via a new `Strategy` method called "
"`initialize_parameters`."
msgstr ""

#: ../../source/ref-changelog.md:1474
msgid ""
"Built-in strategies support a new constructor argument called "
"`initial_parameters` to set the initial parameters. Built-in strategies "
"will provide these initial parameters to the server on startup and then "
"delete them to free the memory afterwards."
msgstr ""

#: ../../source/ref-changelog.md:1493
msgid ""
"If no initial parameters are provided to the strategy, the server will "
"continue to use the current behaviour (namely, it will ask one of the "
"connected clients for its parameters and use these as the initial global "
"parameters)."
msgstr ""

#: ../../source/ref-changelog.md:1497
msgid ""
"Deprecate `flwr.server.strategy.DefaultStrategy` (migrate to "
"`flwr.server.strategy.FedAvg`, which is equivalent)"
msgstr ""

#: ../../source/ref-changelog.md:1499
msgid "v0.14.0 (2021-02-18)"
msgstr ""

#: ../../source/ref-changelog.md:1503
msgid ""
"**Generalized** `Client.fit` **and** `Client.evaluate` **return values** "
"([#610](https://github.com/adap/flower/pull/610) "
"[#572](https://github.com/adap/flower/pull/572) "
"[#633](https://github.com/adap/flower/pull/633))"
msgstr ""

#: ../../source/ref-changelog.md:1505
msgid ""
"Clients can now return an additional dictionary mapping `str` keys to "
"values of the following types: `bool`, `bytes`, `float`, `int`, `str`. "
"This means one can return almost arbitrary values from `fit`/`evaluate` "
"and make use of them on the server side!"
msgstr ""

#: ../../source/ref-changelog.md:1507
msgid ""
"This improvement also allowed for more consistent return types between "
"`fit` and `evaluate`: `evaluate` should now return a tuple `(float, int, "
"dict)` representing the loss, number of examples, and a dictionary "
"holding arbitrary problem-specific values like accuracy."
msgstr ""

#: ../../source/ref-changelog.md:1509
msgid ""
"In case you wondered: this feature is compatible with existing projects, "
"the additional dictionary return value is optional. New code should "
"however migrate to the new return types to be compatible with upcoming "
"Flower releases (`fit`: `List[np.ndarray], int, Dict[str, Scalar]`, "
"`evaluate`: `float, int, Dict[str, Scalar]`). See the example below for "
"details."
msgstr ""

#: ../../source/ref-changelog.md:1511
msgid ""
"*Code example:* note the additional dictionary return values in both "
"`FlwrClient.fit` and `FlwrClient.evaluate`:"
msgstr ""

#: ../../source/ref-changelog.md:1526
msgid ""
"**Generalized** `config` **argument in** `Client.fit` **and** "
"`Client.evaluate` ([#595](https://github.com/adap/flower/pull/595))"
msgstr ""

#: ../../source/ref-changelog.md:1528
msgid ""
"The `config` argument used to be of type `Dict[str, str]`, which means "
"that dictionary values were expected to be strings. The new release "
"generalizes this to enable values of the following types: `bool`, "
"`bytes`, `float`, `int`, `str`."
msgstr ""

#: ../../source/ref-changelog.md:1530
msgid ""
"This means one can now pass almost arbitrary values to `fit`/`evaluate` "
"using the `config` dictionary. Yay, no more `str(epochs)` on the server-"
"side and `int(config[\"epochs\"])` on the client side!"
msgstr ""

#: ../../source/ref-changelog.md:1532
msgid ""
"*Code example:* note that the `config` dictionary now contains non-`str` "
"values in both `Client.fit` and `Client.evaluate`:"
msgstr ""

#: ../../source/ref-changelog.md:1549
msgid "v0.13.0 (2021-01-08)"
msgstr ""

#: ../../source/ref-changelog.md:1553
msgid ""
"New example: PyTorch From Centralized To Federated "
"([#549](https://github.com/adap/flower/pull/549))"
msgstr ""

#: ../../source/ref-changelog.md:1554
msgid "Improved documentation"
msgstr ""

#: ../../source/ref-changelog.md:1555
msgid "New documentation theme ([#551](https://github.com/adap/flower/pull/551))"
msgstr ""

#: ../../source/ref-changelog.md:1556
msgid "New API reference ([#554](https://github.com/adap/flower/pull/554))"
msgstr ""

#: ../../source/ref-changelog.md:1557
msgid ""
"Updated examples documentation "
"([#549](https://github.com/adap/flower/pull/549))"
msgstr ""

#: ../../source/ref-changelog.md:1558
msgid ""
"Removed obsolete documentation "
"([#548](https://github.com/adap/flower/pull/548))"
msgstr ""

#: ../../source/ref-changelog.md:1560
msgid "Bugfix:"
msgstr ""

#: ../../source/ref-changelog.md:1562
msgid ""
"`Server.fit` does not disconnect clients when finished, disconnecting the"
" clients is now handled in `flwr.server.start_server` "
"([#553](https://github.com/adap/flower/pull/553) "
"[#540](https://github.com/adap/flower/issues/540))."
msgstr ""

#: ../../source/ref-changelog.md:1564
msgid "v0.12.0 (2020-12-07)"
msgstr ""

#: ../../source/ref-changelog.md:1566 ../../source/ref-changelog.md:1582
msgid "Important changes:"
msgstr ""

#: ../../source/ref-changelog.md:1568
msgid ""
"Added an example for embedded devices "
"([#507](https://github.com/adap/flower/pull/507))"
msgstr ""

#: ../../source/ref-changelog.md:1569
msgid ""
"Added a new NumPyClient (in addition to the existing KerasClient) "
"([#504](https://github.com/adap/flower/pull/504) "
"[#508](https://github.com/adap/flower/pull/508))"
msgstr ""

#: ../../source/ref-changelog.md:1570
msgid ""
"Deprecated `flwr_example` package and started to migrate examples into "
"the top-level `examples` directory "
"([#494](https://github.com/adap/flower/pull/494) "
"[#512](https://github.com/adap/flower/pull/512))"
msgstr ""

#: ../../source/ref-changelog.md:1572
msgid "v0.11.0 (2020-11-30)"
msgstr ""

#: ../../source/ref-changelog.md:1574
msgid "Incompatible changes:"
msgstr ""

#: ../../source/ref-changelog.md:1576
msgid ""
"Renamed strategy methods "
"([#486](https://github.com/adap/flower/pull/486)) to unify the naming of "
"Flower's public APIs. Other public methods/functions (e.g., every method "
"in `Client`, but also `Strategy.evaluate`) do not use the `on_` prefix, "
"which is why we're removing it from the four methods in Strategy. To "
"migrate rename the following `Strategy` methods accordingly:"
msgstr ""

#: ../../source/ref-changelog.md:1577
msgid "`on_configure_evaluate` => `configure_evaluate`"
msgstr ""

#: ../../source/ref-changelog.md:1578
msgid "`on_aggregate_evaluate` => `aggregate_evaluate`"
msgstr ""

#: ../../source/ref-changelog.md:1579
msgid "`on_configure_fit` => `configure_fit`"
msgstr ""

#: ../../source/ref-changelog.md:1580
msgid "`on_aggregate_fit` => `aggregate_fit`"
msgstr ""

#: ../../source/ref-changelog.md:1584
msgid ""
"Deprecated `DefaultStrategy` "
"([#479](https://github.com/adap/flower/pull/479)). To migrate use "
"`FedAvg` instead."
msgstr ""

#: ../../source/ref-changelog.md:1585
msgid ""
"Simplified examples and baselines "
"([#484](https://github.com/adap/flower/pull/484))."
msgstr ""

#: ../../source/ref-changelog.md:1586
msgid ""
"Removed presently unused `on_conclude_round` from strategy interface "
"([#483](https://github.com/adap/flower/pull/483))."
msgstr ""

#: ../../source/ref-changelog.md:1587
msgid ""
"Set minimal Python version to 3.6.1 instead of 3.6.9 "
"([#471](https://github.com/adap/flower/pull/471))."
msgstr ""

#: ../../source/ref-changelog.md:1588
msgid ""
"Improved `Strategy` docstrings "
"([#470](https://github.com/adap/flower/pull/470))."
msgstr ""

#: ../../source/ref-example-projects.rst:2
msgid "Example projects"
msgstr ""

#: ../../source/ref-example-projects.rst:4
msgid ""
"Flower comes with a number of usage examples. The examples demonstrate "
"how Flower can be used to federate different kinds of existing machine "
"learning pipelines, usually leveraging popular machine learning "
"frameworks such as `PyTorch <https://pytorch.org/>`_ or `TensorFlow "
"<https://www.tensorflow.org/>`_."
msgstr ""

#: ../../source/ref-example-projects.rst:9
msgid "The following examples are available as standalone projects."
msgstr ""

#: ../../source/ref-example-projects.rst:12
msgid "Quickstart TensorFlow/Keras"
msgstr ""

#: ../../source/ref-example-projects.rst:14
msgid ""
"The TensorFlow/Keras quickstart example shows CIFAR-10 image "
"classification with MobileNetV2:"
msgstr ""

#: ../../source/ref-example-projects.rst:17
msgid ""
"`Quickstart TensorFlow (Code) "
"<https://github.com/adap/flower/tree/main/examples/quickstart-"
"tensorflow>`_"
msgstr ""

#: ../../source/ref-example-projects.rst:19
msgid ":doc:`Quickstart TensorFlow (Tutorial) <tutorial-quickstart-tensorflow>`"
msgstr ""

#: ../../source/ref-example-projects.rst:20
msgid ""
"`Quickstart TensorFlow (Blog Post) <https://flower.ai/blog/2020-12-11"
"-federated-learning-in-less-than-20-lines-of-code>`_"
msgstr ""

#: ../../source/ref-example-projects.rst:24
#: ../../source/tutorial-quickstart-pytorch.rst:4
msgid "Quickstart PyTorch"
msgstr ""

#: ../../source/ref-example-projects.rst:26
msgid ""
"The PyTorch quickstart example shows CIFAR-10 image classification with a"
" simple Convolutional Neural Network:"
msgstr ""

#: ../../source/ref-example-projects.rst:29
msgid ""
"`Quickstart PyTorch (Code) "
"<https://github.com/adap/flower/tree/main/examples/quickstart-pytorch>`_"
msgstr ""

#: ../../source/ref-example-projects.rst:31
msgid ":doc:`Quickstart PyTorch (Tutorial) <tutorial-quickstart-pytorch>`"
msgstr ""

#: ../../source/ref-example-projects.rst:34
msgid "PyTorch: From Centralized To Federated"
msgstr ""

#: ../../source/ref-example-projects.rst:36
msgid ""
"This example shows how a regular PyTorch project can be federated using "
"Flower:"
msgstr ""

#: ../../source/ref-example-projects.rst:38
msgid ""
"`PyTorch: From Centralized To Federated (Code) "
"<https://github.com/adap/flower/tree/main/examples/pytorch-from-"
"centralized-to-federated>`_"
msgstr ""

#: ../../source/ref-example-projects.rst:40
msgid ""
":doc:`PyTorch: From Centralized To Federated (Tutorial) <example-pytorch-"
"from-centralized-to-federated>`"
msgstr ""

#: ../../source/ref-example-projects.rst:44
msgid "Federated Learning on Raspberry Pi and Nvidia Jetson"
msgstr ""

#: ../../source/ref-example-projects.rst:46
msgid ""
"This example shows how Flower can be used to build a federated learning "
"system that run across Raspberry Pi and Nvidia Jetson:"
msgstr ""

#: ../../source/ref-example-projects.rst:49
msgid ""
"`Federated Learning on Raspberry Pi and Nvidia Jetson (Code) "
"<https://github.com/adap/flower/tree/main/examples/embedded-devices>`_"
msgstr ""

#: ../../source/ref-example-projects.rst:51
msgid ""
"`Federated Learning on Raspberry Pi and Nvidia Jetson (Blog Post) "
"<https://flower.ai/blog/2020-12-16-running_federated_learning_applications_on_embedded_devices_with_flower>`_"
msgstr ""

#: ../../source/ref-faq.rst:2
msgid "FAQ"
msgstr ""

#: ../../source/ref-faq.rst:4
msgid ""
"This page collects answers to commonly asked questions about Federated "
"Learning with Flower."
msgstr ""

#: ../../source/ref-faq.rst
msgid ":fa:`eye,mr-1` Can Flower run on Jupyter Notebooks / Google Colab?"
msgstr ""

#: ../../source/ref-faq.rst:9
msgid ""
"Yes, it can! Flower even comes with a few under-the-hood optimizations to"
" make it work even better on Colab. Here's a quickstart example:"
msgstr ""

#: ../../source/ref-faq.rst:11
msgid ""
"`Flower simulation PyTorch "
"<https://colab.research.google.com/github/adap/flower/blob/main/examples"
"/simulation-pytorch/sim.ipynb>`_"
msgstr ""

#: ../../source/ref-faq.rst:12
msgid ""
"`Flower simulation TensorFlow/Keras "
"<https://colab.research.google.com/github/adap/flower/blob/main/examples"
"/simulation-tensorflow/sim.ipynb>`_"
msgstr ""

#: ../../source/ref-faq.rst
msgid ":fa:`eye,mr-1` How can I run Federated Learning on a Raspberry Pi?"
msgstr ""

#: ../../source/ref-faq.rst:16
msgid ""
"Find the `blog post about federated learning on embedded device here "
"<https://flower.ai/blog/2020-12-16-running_federated_learning_applications_on_embedded_devices_with_flower>`_"
" and the corresponding `GitHub code example "
"<https://github.com/adap/flower/tree/main/examples/embedded-devices>`_."
msgstr ""

#: ../../source/ref-faq.rst
msgid ":fa:`eye,mr-1` Does Flower support federated learning on Android devices?"
msgstr ""

#: ../../source/ref-faq.rst:20
msgid ""
"Yes, it does. Please take a look at our `blog post "
"<https://flower.ai/blog/2021-12-15-federated-learning-on-android-devices-"
"with-flower>`_ or check out the code examples:"
msgstr ""

#: ../../source/ref-faq.rst:22
msgid ""
"`Android Kotlin example <https://flower.ai/docs/examples/android-"
"kotlin.html>`_"
msgstr ""

#: ../../source/ref-faq.rst:23
msgid "`Android Java example <https://flower.ai/docs/examples/android.html>`_"
msgstr ""

#: ../../source/ref-faq.rst
msgid ":fa:`eye,mr-1` Can I combine federated learning with blockchain?"
msgstr ""

#: ../../source/ref-faq.rst:27
msgid ""
"Yes, of course. A list of available examples using Flower within a "
"blockchain environment is available here:"
msgstr ""

#: ../../source/ref-faq.rst:30
msgid "`FLock: A Decentralised AI Training Platform <https://www.flock.io/#/>`_."
msgstr ""

#: ../../source/ref-faq.rst:30
msgid "Contribute to on-chain training the model and earn rewards."
msgstr ""

#: ../../source/ref-faq.rst:31
msgid "Local blockchain with federated learning simulation."
msgstr ""

#: ../../source/ref-faq.rst:32
msgid ""
"`Flower meets Nevermined GitHub Repository <https://github.com"
"/nevermined-io/fl-demo/tree/master/image-classification-flower>`_."
msgstr ""

#: ../../source/ref-faq.rst:33
msgid ""
"`Flower meets Nevermined YouTube video "
"<https://www.youtube.com/watch?v=A0A9hSlPhKI>`_."
msgstr ""

#: ../../source/ref-faq.rst:34
msgid ""
"`Flower meets KOSMoS <https://www.isw-sites.de/kosmos/wp-"
"content/uploads/sites/13/2021/05/Talk-Flower-Summit-2021.pdf>`_."
msgstr ""

#: ../../source/ref-faq.rst:35
msgid ""
"`Flower meets Talan blog post <https://www.linkedin.com/pulse/federated-"
"learning-same-mask-different-faces-imen-"
"ayari/?trackingId=971oIlxLQ9%2BA9RB0IQ73XQ%3D%3D>`_ ."
msgstr ""

#: ../../source/ref-faq.rst:36
msgid ""
"`Flower meets Talan GitHub Repository "
"<https://gitlab.com/Talan_Innovation_Factory/food-waste-prevention>`_ ."
msgstr ""

#: ../../source/ref-telemetry.md:1
msgid "Telemetry"
msgstr ""

#: ../../source/ref-telemetry.md:3
msgid ""
"The Flower open-source project collects **anonymous** usage metrics to "
"make well-informed decisions to improve Flower. Doing this enables the "
"Flower team to understand how Flower is used and what challenges users "
"might face."
msgstr ""

#: ../../source/ref-telemetry.md:5
msgid ""
"**Flower is a friendly framework for collaborative AI and data science.**"
" Staying true to this statement, Flower makes it easy to disable "
"telemetry for users that do not want to share anonymous usage metrics."
msgstr ""

#: ../../source/ref-telemetry.md:7
msgid "Principles"
msgstr ""

#: ../../source/ref-telemetry.md:9
msgid "We follow strong principles guarding anonymous usage metrics collection:"
msgstr ""

#: ../../source/ref-telemetry.md:11
msgid ""
"**Optional:** You will always be able to disable telemetry; read on to "
"learn “[How to opt-out](#how-to-opt-out)”."
msgstr ""

#: ../../source/ref-telemetry.md:12
msgid ""
"**Anonymous:** The reported usage metrics are anonymous and do not "
"contain any personally identifiable information (PII). See “[Collected "
"metrics](#collected-metrics)” to understand what metrics are being "
"reported."
msgstr ""

#: ../../source/ref-telemetry.md:13
msgid ""
"**Transparent:** You can easily inspect what anonymous metrics are being "
"reported; see the section “[How to inspect what is being reported](#how-"
"to-inspect-what-is-being-reported)”"
msgstr ""

#: ../../source/ref-telemetry.md:14
msgid ""
"**Open for feedback:** You can always reach out to us if you have "
"feedback; see the section “[How to contact us](#how-to-contact-us)” for "
"details."
msgstr ""

#: ../../source/ref-telemetry.md:16
msgid "How to opt-out"
msgstr ""

#: ../../source/ref-telemetry.md:18
msgid ""
"When Flower starts, it will check for an environment variable called "
"`FLWR_TELEMETRY_ENABLED`. Telemetry can easily be disabled by setting "
"`FLWR_TELEMETRY_ENABLED=0`. Assuming you are starting a Flower server or "
"client, simply do so by prepending your command as in:"
msgstr ""

#: ../../source/ref-telemetry.md:24
msgid ""
"Alternatively, you can export `FLWR_TELEMETRY_ENABLED=0` in, for example,"
" `.bashrc` (or whatever configuration file applies to your environment) "
"to disable Flower telemetry permanently."
msgstr ""

#: ../../source/ref-telemetry.md:26
msgid "Collected metrics"
msgstr ""

#: ../../source/ref-telemetry.md:28
msgid "Flower telemetry collects the following metrics:"
msgstr ""

#: ../../source/ref-telemetry.md:30
msgid ""
"**Flower version.** Understand which versions of Flower are currently "
"being used. This helps us to decide whether we should invest effort into "
"releasing a patch version for an older version of Flower or instead use "
"the bandwidth to build new features."
msgstr ""

#: ../../source/ref-telemetry.md:32
msgid ""
"**Operating system.** Enables us to answer questions such as: *Should we "
"create more guides for Linux, macOS, or Windows?*"
msgstr ""

#: ../../source/ref-telemetry.md:34
msgid ""
"**Python version.** Knowing the Python version helps us, for example, to "
"decide whether we should invest effort into supporting old versions of "
"Python or stop supporting them and start taking advantage of new Python "
"features."
msgstr ""

#: ../../source/ref-telemetry.md:36
msgid ""
"**Hardware properties.** Understanding the hardware environment that "
"Flower is being used in helps to decide whether we should, for example, "
"put more effort into supporting low-resource environments."
msgstr ""

#: ../../source/ref-telemetry.md:38
msgid ""
"**Execution mode.** Knowing what execution mode Flower starts in enables "
"us to understand how heavily certain features are being used and better "
"prioritize based on that."
msgstr ""

#: ../../source/ref-telemetry.md:40
msgid ""
"**Cluster.** Flower telemetry assigns a random in-memory cluster ID each "
"time a Flower workload starts. This allows us to understand which device "
"types not only start Flower workloads but also successfully complete "
"them."
msgstr ""

#: ../../source/ref-telemetry.md:42
msgid ""
"**Source.** Flower telemetry tries to store a random source ID in "
"`~/.flwr/source` the first time a telemetry event is generated. The "
"source ID is important to identify whether an issue is recurring or "
"whether an issue is triggered by multiple clusters running concurrently "
"(which often happens in simulation). For example, if a device runs "
"multiple workloads at the same time, and this results in an issue, then, "
"in order to reproduce the issue, multiple workloads must be started at "
"the same time."
msgstr ""

#: ../../source/ref-telemetry.md:44
msgid ""
"You may delete the source ID at any time. If you wish for all events "
"logged under a specific source ID to be deleted, you can send a deletion "
"request mentioning the source ID to `telemetry@flower.ai`. All events "
"related to that source ID will then be permanently deleted."
msgstr ""

#: ../../source/ref-telemetry.md:46
msgid ""
"We will not collect any personally identifiable information. If you think"
" any of the metrics collected could be misused in any way, please [get in"
" touch with us](#how-to-contact-us). We will update this page to reflect "
"any changes to the metrics collected and publish changes in the "
"changelog."
msgstr ""

#: ../../source/ref-telemetry.md:48
msgid ""
"If you think other metrics would be helpful for us to better guide our "
"decisions, please let us know! We will carefully review them; if we are "
"confident that they do not compromise user privacy, we may add them."
msgstr ""

#: ../../source/ref-telemetry.md:50
msgid "How to inspect what is being reported"
msgstr ""

#: ../../source/ref-telemetry.md:52
msgid ""
"We wanted to make it very easy for you to inspect what anonymous usage "
"metrics are reported. You can view all the reported telemetry information"
" by setting the environment variable `FLWR_TELEMETRY_LOGGING=1`. Logging "
"is disabled by default. You may use logging independently from "
"`FLWR_TELEMETRY_ENABLED` so that you can inspect the telemetry feature "
"without sending any metrics."
msgstr ""

#: ../../source/ref-telemetry.md:58
msgid ""
"The inspect Flower telemetry without sending any anonymous usage metrics,"
" use both environment variables:"
msgstr ""

#: ../../source/ref-telemetry.md:64
msgid "How to contact us"
msgstr ""

#: ../../source/ref-telemetry.md:66
msgid ""
"We want to hear from you. If you have any feedback or ideas on how to "
"improve the way we handle anonymous usage metrics, reach out to us via "
"[Slack](https://flower.ai/join-slack/) (channel `#telemetry`) or email "
"(`telemetry@flower.ai`)."
msgstr ""

#: ../../source/tutorial-quickstart-android.rst:-1
msgid ""
"Read this Federated Learning quickstart tutorial for creating an Android "
"app using Flower."
msgstr ""

#: ../../source/tutorial-quickstart-android.rst:4
msgid "Quickstart Android"
msgstr ""

#: ../../source/tutorial-quickstart-android.rst:11
msgid ""
"The experimental Flower Android SDK is not compatible with the latest "
"version of Flower. Android support is currently being reworked and will "
"be released in 2025."
msgstr ""

#: ../../source/tutorial-quickstart-android.rst:14
msgid ""
"This quickstart tutorial is kept for historical purposes and will be "
"updated once the new Android SDK is released."
msgstr ""

#: ../../source/tutorial-quickstart-android.rst:17
msgid ""
"Let's build a federated learning system using TFLite and Flower on "
"Android!"
msgstr ""

#: ../../source/tutorial-quickstart-android.rst:19
msgid ""
"Please refer to the `full code example "
"<https://github.com/adap/flower/tree/main/examples/android>`_ to learn "
"more."
msgstr ""

#: ../../source/tutorial-quickstart-fastai.rst:4
msgid "Quickstart fastai"
msgstr ""

#: ../../source/tutorial-quickstart-fastai.rst:6
msgid ""
"In this federated learning tutorial we will learn how to train a "
"SqueezeNet model on MNIST using Flower and fastai. It is recommended to "
"create a virtual environment and run everything within a :doc:`virtualenv"
" <contributor-how-to-set-up-a-virtual-env>`."
msgstr ""

#: ../../source/tutorial-quickstart-fastai.rst:10
#: ../../source/tutorial-quickstart-pytorch-lightning.rst:11
msgid "Then, clone the code example directly from GitHub:"
msgstr ""

#: ../../source/tutorial-quickstart-fastai.rst:18
msgid ""
"This will create a new directory called `quickstart-fastai` containing "
"the following files:"
msgstr ""

#: ../../source/tutorial-quickstart-fastai.rst:31
#: ../../source/tutorial-quickstart-pytorch-lightning.rst:32
msgid "Next, activate your environment, then run:"
msgstr ""

#: ../../source/tutorial-quickstart-fastai.rst:41
msgid ""
"This example by default runs the Flower Simulation Engine, creating a "
"federation of 10 nodes using `FedAvg <https://flower.ai/docs/framework"
"/ref-api/flwr.server.strategy.FedAvg.html#flwr.server.strategy.FedAvg>`_ "
"as the aggregation strategy. The dataset will be partitioned using Flower"
" Dataset's `IidPartitioner <https://flower.ai/docs/datasets/ref-"
"api/flwr_datasets.partitioner.IidPartitioner.html#flwr_datasets.partitioner.IidPartitioner>`_."
" Let's run the project:"
msgstr ""

#: ../../source/tutorial-quickstart-fastai.rst:54
#: ../../source/tutorial-quickstart-huggingface.rst:61
#: ../../source/tutorial-quickstart-jax.rst:60
#: ../../source/tutorial-quickstart-mlx.rst:60
#: ../../source/tutorial-quickstart-pytorch-lightning.rst:55
#: ../../source/tutorial-quickstart-pytorch.rst:62
#: ../../source/tutorial-quickstart-scikitlearn.rst:59
#: ../../source/tutorial-quickstart-tensorflow.rst:62
#: ../../source/tutorial-quickstart-xgboost.rst:492
msgid "With default arguments you will see an output like this one:"
msgstr ""

#: ../../source/tutorial-quickstart-fastai.rst:98
#: ../../source/tutorial-quickstart-huggingface.rst:112
#: ../../source/tutorial-quickstart-jax.rst:102
#: ../../source/tutorial-quickstart-pytorch-lightning.rst:105
#: ../../source/tutorial-quickstart-pytorch.rst:103
#: ../../source/tutorial-quickstart-scikitlearn.rst:101
#: ../../source/tutorial-quickstart-tensorflow.rst:103
#: ../../source/tutorial-quickstart-xgboost.rst:537
msgid ""
"You can also override the parameters defined in the "
"``[tool.flwr.app.config]`` section in ``pyproject.toml`` like this:"
msgstr ""

#: ../../source/tutorial-quickstart-fastai.rst:108
msgid ""
"Check the `source code <https://github.com/adap/flower/tree/main/examples"
"/quickstart-fastai>`_ of this tutorial in ``examples/quickstart-fasai`` "
"in the Flower GitHub repository."
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:-1
msgid ""
"Check out this Federating Learning quickstart tutorial for using Flower "
"with 🤗 HuggingFace Transformers in order to fine-tune an LLM."
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:4
msgid "Quickstart 🤗 Transformers"
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:6
msgid ""
"In this federated learning tutorial we will learn how to train a large "
"language model (LLM) on the `IMDB "
"<https://huggingface.co/datasets/stanfordnlp/imdb>`_ dataset using Flower"
" and the 🤗 Hugging Face Transformers library. It is recommended to create"
" a virtual environment and run everything within a :doc:`virtualenv "
"<contributor-how-to-set-up-a-virtual-env>`."
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:12
msgid ""
"Let's use ``flwr new`` to create a complete Flower+🤗 Hugging Face "
"project. It will generate all the files needed to run, by default with "
"the Flower Simulation Engine, a federation of 10 nodes using |fedavg|_ "
"The dataset will be partitioned using |flowerdatasets|_'s "
"|iidpartitioner|_."
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:17
#: ../../source/tutorial-quickstart-jax.rst:16
#: ../../source/tutorial-quickstart-mlx.rst:17
#: ../../source/tutorial-quickstart-pytorch.rst:18
#: ../../source/tutorial-quickstart-scikitlearn.rst:15
#: ../../source/tutorial-quickstart-tensorflow.rst:18
msgid ""
"Now that we have a rough idea of what this example is about, let's get "
"started. First, install Flower in your new environment:"
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:25
msgid ""
"Then, run the command below. You will be prompted to select one of the "
"available templates (choose ``HuggingFace``), give a name to your "
"project, and type in your developer name:"
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:33
#: ../../source/tutorial-quickstart-jax.rst:32
#: ../../source/tutorial-quickstart-mlx.rst:32
#: ../../source/tutorial-quickstart-pytorch.rst:34
#: ../../source/tutorial-quickstart-scikitlearn.rst:31
#: ../../source/tutorial-quickstart-tensorflow.rst:34
msgid ""
"After running it you'll notice a new directory with your project name has"
" been created. It should have the following structure:"
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:47
#: ../../source/tutorial-quickstart-jax.rst:46
#: ../../source/tutorial-quickstart-mlx.rst:46
#: ../../source/tutorial-quickstart-pytorch.rst:48
#: ../../source/tutorial-quickstart-scikitlearn.rst:45
#: ../../source/tutorial-quickstart-tensorflow.rst:48
msgid ""
"If you haven't yet installed the project and its dependencies, you can do"
" so by:"
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:54
#: ../../source/tutorial-quickstart-jax.rst:53
#: ../../source/tutorial-quickstart-pytorch.rst:55
#: ../../source/tutorial-quickstart-scikitlearn.rst:52
#: ../../source/tutorial-quickstart-tensorflow.rst:55
#: ../../source/tutorial-quickstart-xgboost.rst:485
msgid "To run the project, do:"
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:102
msgid "You can also run the project with GPU as follows:"
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:109
msgid ""
"This will use the default arguments where each ``ClientApp`` will use 2 "
"CPUs and at most 4 ``ClientApp``\\s will run in a given GPU."
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:120
#: ../../source/tutorial-quickstart-jax.rst:110
#: ../../source/tutorial-quickstart-mlx.rst:110
#: ../../source/tutorial-quickstart-pytorch.rst:111
#: ../../source/tutorial-quickstart-scikitlearn.rst:109
msgid ""
"What follows is an explanation of each component in the project you just "
"created: dataset partition, the model, defining the ``ClientApp`` and "
"defining the ``ServerApp``."
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:124
#: ../../source/tutorial-quickstart-jax.rst:114
#: ../../source/tutorial-quickstart-mlx.rst:114
#: ../../source/tutorial-quickstart-pytorch.rst:115
#: ../../source/tutorial-quickstart-scikitlearn.rst:113
#: ../../source/tutorial-quickstart-tensorflow.rst:112
#: ../../source/tutorial-quickstart-xgboost.rst:89
msgid "The Data"
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:126
msgid ""
"This tutorial uses |flowerdatasets|_ to easily download and partition the"
" `IMDB <https://huggingface.co/datasets/stanfordnlp/imdb>`_ dataset. In "
"this example you'll make use of the |iidpartitioner|_ to generate "
"``num_partitions`` partitions. You can choose |otherpartitioners|_ "
"available in Flower Datasets. To tokenize the text, we will also load the"
" tokenizer from the pre-trained Transformer model that we'll use during "
"training - more on that in the next section. Each ``ClientApp`` will call"
" this function to create dataloaders with the data that correspond to "
"their data partition."
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:171
#: ../../source/tutorial-quickstart-jax.rst:128
#: ../../source/tutorial-quickstart-mlx.rst:155
#: ../../source/tutorial-quickstart-pytorch.rst:150
#: ../../source/tutorial-quickstart-scikitlearn.rst:138
#: ../../source/tutorial-quickstart-tensorflow.rst:139
msgid "The Model"
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:173
msgid ""
"We will leverage 🤗 Hugging Face to federate the training of language "
"models over multiple clients using Flower. More specifically, we will "
"fine-tune a pre-trained Transformer model (|berttiny|_) for sequence "
"classification over the dataset of IMDB ratings. The end goal is to "
"detect if a movie rating is positive or negative. If you have access to "
"larger GPUs, feel free to use larger models!"
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:185
msgid ""
"Note that here, ``model_name`` is a string that will be loaded from the "
"``Context`` in the ClientApp and ServerApp."
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:188
msgid ""
"In addition to loading the pretrained model weights and architecture, we "
"also include two utility functions to perform both training (i.e. "
"``train()``) and evaluation (i.e. ``test()``) using the above model. "
"These functions should look fairly familiar if you have some prior "
"experience with PyTorch. Note these functions do not have anything "
"specific to Flower. That being said, the training function will normally "
"be called, as we'll see later, from a Flower client passing its own data."
" In summary, your clients can use standard training/testing functions to "
"perform local training or evaluation:"
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:228
#: ../../source/tutorial-quickstart-jax.rst:170
#: ../../source/tutorial-quickstart-mlx.rst:199
#: ../../source/tutorial-quickstart-pytorch.rst:224
#: ../../source/tutorial-quickstart-scikitlearn.rst:157
#: ../../source/tutorial-quickstart-tensorflow.rst:168
#: ../../source/tutorial-quickstart-xgboost.rst:149
msgid "The ClientApp"
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:230
msgid ""
"The main changes we have to make to use 🤗 Hugging Face with Flower will "
"be found in the ``get_weights()`` and ``set_weights()`` functions. Under "
"the hood, the ``transformers`` library uses PyTorch, which means we can "
"reuse the ``get_weights()`` and ``set_weights()`` code that we defined in"
" the :doc:`Quickstart PyTorch <tutorial-quickstart-pytorch>` tutorial. As"
" a reminder, in ``get_weights()``, PyTorch model parameters are extracted"
" and represented as a list of NumPy arrays. The ``set_weights()`` "
"function that's the opposite: given a list of NumPy arrays it applies "
"them to an existing PyTorch model. Doing this in fairly easy in PyTorch."
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:241
#: ../../source/tutorial-quickstart-pytorch.rst:234
msgid ""
"The specific implementation of ``get_weights()`` and ``set_weights()`` "
"depends on the type of models you use. The ones shown below work for a "
"wide range of PyTorch models but you might need to adjust them if you "
"have more exotic model architectures."
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:257
#: ../../source/tutorial-quickstart-jax.rst:197
#: ../../source/tutorial-quickstart-pytorch.rst:250
msgid ""
"The rest of the functionality is directly inspired by the centralized "
"case. The ``fit()`` method in the client trains the model using the local"
" dataset. Similarly, the ``evaluate()`` method is used to evaluate the "
"model received on a held-out validation set that the client might have:"
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:283
msgid ""
"Finally, we can construct a ``ClientApp`` using the ``FlowerClient`` "
"defined above by means of a ``client_fn()`` callback. Note that the "
"`context` enables you to get access to hyperparemeters defined in your "
"``pyproject.toml`` to configure the run. In this tutorial we access the "
"``local-epochs`` setting to control the number of epochs a ``ClientApp`` "
"will perform when running the ``fit()`` method. You could define "
"additional hyperparameters in ``pyproject.toml`` and access them here."
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:316
#: ../../source/tutorial-quickstart-jax.rst:246
#: ../../source/tutorial-quickstart-mlx.rst:361
#: ../../source/tutorial-quickstart-pytorch.rst:307
#: ../../source/tutorial-quickstart-scikitlearn.rst:255
#: ../../source/tutorial-quickstart-tensorflow.rst:232
#: ../../source/tutorial-quickstart-xgboost.rst:269
msgid "The ServerApp"
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:318
msgid ""
"To construct a ``ServerApp`` we define a ``server_fn()`` callback with an"
" identical signature to that of ``client_fn()`` but the return type is "
"|serverappcomponents|_ as opposed to a |client|_ In this example we use "
"the `FedAvg` strategy. To it we pass a randomly initialized model that "
"will server as the global model to federated. Note that the value of "
"``fraction_fit`` is read from the run config. You can find the default "
"value defined in the ``pyproject.toml``."
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:356
msgid ""
"Congratulations! You've successfully built and run your first federated "
"learning system for an LLM."
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:361
msgid ""
"Check the source code of the extended version of this tutorial in "
"|quickstart_hf_link|_ in the Flower GitHub repository. For a "
"comprehensive example of a federated fine-tuning of an LLM with Flower, "
"refer to the |flowertune|_ example in the Flower GitHub repository."
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:-1
msgid ""
"Read this Federated Learning quickstart tutorial for creating an iOS app "
"using Flower to train a neural network on MNIST."
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:4
msgid "Quickstart iOS"
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:11
msgid ""
"The experimental Flower iOS SDK is not compatible with the latest version"
" of Flower. iOS support is currently being reworked and will be released "
"in 2025."
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:14
msgid ""
"This quickstart tutorial is kept for historical purposes and will be "
"updated once the new iOS SDK is released."
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:17
msgid ""
"In this tutorial we will learn how to train a Neural Network on MNIST "
"using Flower and CoreML on iOS devices."
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:20
msgid ""
"First of all, for running the Flower Python server, it is recommended to "
"create a virtual environment and run everything within a :doc:`virtualenv"
" <contributor-how-to-set-up-a-virtual-env>`. For the Flower client "
"implementation in iOS, it is recommended to use Xcode as our IDE."
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:25
msgid ""
"Our example consists of one Python *server* and two iPhone *clients* that"
" all have the same model."
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:28
msgid ""
"*Clients* are responsible for generating individual weight updates for "
"the model based on their local datasets. These updates are then sent to "
"the *server* which will aggregate them to produce a better model. "
"Finally, the *server* sends this improved version of the model back to "
"each *client*. A complete cycle of weight updates is called a *round*."
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:34
msgid ""
"Now that we have a rough idea of what is going on, let's get started to "
"setup our Flower server environment. We first need to install Flower. You"
" can do this by using pip:"
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:41
msgid "Or Poetry:"
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:48
msgid "Flower Client"
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:50
msgid ""
"Now that we have all our dependencies installed, let's run a simple "
"distributed training using CoreML as our local training pipeline and "
"MNIST as our dataset. For simplicity reasons we will use the complete "
"Flower client with CoreML, that has been implemented and stored inside "
"the Swift SDK. The client implementation can be seen below:"
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:88
msgid ""
"Let's create a new application project in Xcode and add ``flwr`` as a "
"dependency in your project. For our application, we will store the logic "
"of our app in ``FLiOSModel.swift`` and the UI elements in "
"``ContentView.swift``. We will focus more on ``FLiOSModel.swift`` in this"
" quickstart. Please refer to the `full code example "
"<https://github.com/adap/flower/tree/main/examples/ios>`_ to learn more "
"about the app."
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:94
msgid "Import Flower and CoreML related packages in ``FLiOSModel.swift``:"
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:102
msgid ""
"Then add the mlmodel to the project simply by drag-and-drop, the mlmodel "
"will be bundled inside the application during deployment to your iOS "
"device. We need to pass the url to access mlmodel and run CoreML machine "
"learning processes, it can be retrieved by calling the function "
"``Bundle.main.url``. For the MNIST dataset, we need to preprocess it into"
" ``MLBatchProvider`` object. The preprocessing is done inside "
"``DataLoader.swift``."
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:120
msgid ""
"Since CoreML does not allow the model parameters to be seen before "
"training, and accessing the model parameters during or after the training"
" can only be done by specifying the layer name, we need to know this "
"information beforehand, through looking at the model specification, which"
" are written as proto files. The implementation can be seen in "
"``MLModelInspect``."
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:126
msgid ""
"After we have all of the necessary information, let's create our Flower "
"client."
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:141
msgid ""
"Then start the Flower gRPC client and start communicating to the server "
"by passing our Flower client to the function ``startFlwrGRPC``."
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:149
msgid ""
"That's it for the client. We only have to implement ``Client`` or call "
"the provided ``MLFlwrClient`` and call ``startFlwrGRPC()``. The attribute"
" ``hostname`` and ``port`` tells the client which server to connect to. "
"This can be done by entering the hostname and port in the application "
"before clicking the start button to start the federated learning process."
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:156
msgid "Flower Server"
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:158
msgid ""
"For simple workloads we can start a Flower server and leave all the "
"configuration possibilities at their default values. In a file named "
"``server.py``, import Flower and start the server:"
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:169
msgid "Train the model, federated!"
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:171
msgid ""
"With both client and server ready, we can now run everything and see "
"federated learning in action. FL systems usually have a server and "
"multiple clients. We therefore have to start the server first:"
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:179
msgid ""
"Once the server is running we can start the clients in different "
"terminals. Build and run the client through your Xcode, one through Xcode"
" Simulator and the other by deploying it to your iPhone. To see more "
"about how to deploy your app to iPhone or Simulator visit `here "
"<https://developer.apple.com/documentation/xcode/running-your-app-in-"
"simulator-or-on-a-device>`_."
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:185
msgid ""
"Congratulations! You've successfully built and run your first federated "
"learning system in your ios device. The full `source code "
"<https://github.com/adap/flower/blob/main/examples/ios>`_ for this "
"example can be found in ``examples/ios``."
msgstr ""

#: ../../source/tutorial-quickstart-jax.rst:-1
msgid ""
"Check out this Federated Learning quickstart tutorial for using Flower "
"with Jax to train a linear regression model on a scikit-learn dataset."
msgstr ""

#: ../../source/tutorial-quickstart-jax.rst:4
msgid "Quickstart JAX"
msgstr ""

#: ../../source/tutorial-quickstart-jax.rst:6
msgid ""
"In this federated learning tutorial we will learn how to train a linear "
"regression model using Flower and `JAX "
"<https://jax.readthedocs.io/en/latest/>`_. It is recommended to create a "
"virtual environment and run everything within a :doc:`virtualenv "
"<contributor-how-to-set-up-a-virtual-env>`."
msgstr ""

#: ../../source/tutorial-quickstart-jax.rst:11
msgid ""
"Let's use ``flwr new`` to create a complete Flower+JAX project. It will "
"generate all the files needed to run, by default with the Flower "
"Simulation Engine, a federation of 10 nodes using |fedavg|_. A random "
"regression dataset will be loaded from scikit-learn's |makeregression|_ "
"function."
msgstr ""

#: ../../source/tutorial-quickstart-jax.rst:24
msgid ""
"Then, run the command below. You will be prompted to select one of the "
"available templates (choose ``JAX``), give a name to your project, and "
"type in your developer name:"
msgstr ""

#: ../../source/tutorial-quickstart-jax.rst:116
msgid ""
"This tutorial uses scikit-learn's |makeregression|_ function to generate "
"a random regression problem."
msgstr ""

#: ../../source/tutorial-quickstart-jax.rst:130
msgid ""
"We defined a simple linear regression model to demonstrate how to create "
"a JAX model, but feel free to replace it with a more sophisticated JAX "
"model if you'd like, (such as with NN-based `Flax "
"<https://flax.readthedocs.io/en/latest/index.html>`_):"
msgstr ""

#: ../../source/tutorial-quickstart-jax.rst:141
msgid ""
"In addition to defining the model architecture, we also include two "
"utility functions to perform both training (i.e. ``train()``) and "
"evaluation (i.e. ``evaluation()``) using the above model."
msgstr ""

#: ../../source/tutorial-quickstart-jax.rst:172
msgid ""
"The main changes we have to make to use JAX with Flower will be found in "
"the ``get_params()`` and ``set_params()`` functions. In ``get_params()``,"
" JAX model parameters are extracted and represented as a list of NumPy "
"arrays. The ``set_params()`` function is the opposite: given a list of "
"NumPy arrays it applies them to an existing JAX model."
msgstr ""

#: ../../source/tutorial-quickstart-jax.rst:180
msgid ""
"The ``get_params()`` and ``set_params()`` functions here are conceptually"
" similar to the ``get_weights()`` and ``set_weights()`` functions that we"
" defined in the :doc:`QuickStart PyTorch <tutorial-quickstart-pytorch>` "
"tutorial."
msgstr ""

#: ../../source/tutorial-quickstart-jax.rst:227
msgid ""
"Finally, we can construct a ``ClientApp`` using the ``FlowerClient`` "
"defined above by means of a ``client_fn()`` callback. Note that the "
"`context` enables you to get access to hyperparemeters defined in your "
"``pyproject.toml`` to configure the run. In this tutorial we access the "
"``local-epochs`` setting to control the number of epochs a ``ClientApp`` "
"will perform when running the ``fit()`` method. You could define "
"additioinal hyperparameters in ``pyproject.toml`` and access them here."
msgstr ""

#: ../../source/tutorial-quickstart-jax.rst:248
msgid ""
"To construct a ``ServerApp`` we define a ``server_fn()`` callback with an"
" identical signature to that of ``client_fn()`` but the return type is "
"|serverappcomponents|_ as opposed to a |client|_ In this example we use "
"the ``FedAvg`` strategy. To it we pass a randomly initialized model that "
"will server as the global model to federated. Note that the value of "
"``input_dim`` is read from the run config. You can find the default value"
" defined in the ``pyproject.toml``."
msgstr ""

#: ../../source/tutorial-quickstart-jax.rst:276
msgid ""
"Congratulations! You've successfully built and run your first federated "
"learning system for JAX with Flower!"
msgstr ""

#: ../../source/tutorial-quickstart-jax.rst:281
msgid ""
"Check the source code of the extended version of this tutorial in "
"|quickstart_jax_link|_ in the Flower GitHub repository."
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:4
msgid "Quickstart MLX"
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:6
msgid ""
"In this federated learning tutorial we will learn how to train simple MLP"
" on MNIST using Flower and MLX. It is recommended to create a virtual "
"environment and run everything within a :doc:`virtualenv <contributor-"
"how-to-set-up-a-virtual-env>`."
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:10
msgid ""
"Let's use `flwr new` to create a complete Flower+MLX project. It will "
"generate all the files needed to run, by default with the Simulation "
"Engine, a federation of 10 nodes using `FedAvg "
"<https://flower.ai/docs/framework/ref-"
"api/flwr.server.strategy.FedAvg.html#flwr.server.strategy.FedAvg>`_. The "
"dataset will be partitioned using Flower Dataset's `IidPartitioner "
"<https://flower.ai/docs/datasets/ref-"
"api/flwr_datasets.partitioner.IidPartitioner.html#flwr_datasets.partitioner.IidPartitioner>`_."
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:25
msgid ""
"Then, run the command below. You will be prompted to select of the "
"available templates (choose ``MLX``), give a name to your project, and "
"type in your developer name:"
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:53
msgid "To run the project do:"
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:102
msgid ""
"You can also override the parameters defined in "
"``[tool.flwr.app.config]`` section in the ``pyproject.toml`` like this:"
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:116
msgid ""
"We will use `Flower Datasets <https://flower.ai/docs/datasets/>`_ to "
"easily download and partition the `MNIST` dataset. In this example you'll"
" make use of the `IidPartitioner <https://flower.ai/docs/datasets/ref-"
"api/flwr_datasets.partitioner.IidPartitioner.html#flwr_datasets.partitioner.IidPartitioner>`_"
" to generate `num_partitions` partitions. You can choose `other "
"partitioners <https://flower.ai/docs/datasets/ref-"
"api/flwr_datasets.partitioner.html>`_ available in Flower Datasets:"
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:157
msgid ""
"We define the model as in the `centralized MLX example "
"<https://github.com/ml-explore/mlx-examples/tree/main/mnist>`_, it's a "
"simple MLP:"
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:180
msgid ""
"We also define some utility functions to test our model and to iterate "
"over batches."
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:201
msgid ""
"The main changes we have to make to use `MLX` with `Flower` will be found"
" in the ``get_params()`` and ``set_params()`` functions. Indeed, MLX "
"doesn't provide an easy way to convert the model parameters into a list "
"of ``np.array`` objects (the format we need for the serialization of the "
"messages to work)."
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:206
msgid "The way MLX stores its parameters is as follows:"
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:219
msgid ""
"Therefore, to get our list of ``np.array`` objects, we need to extract "
"each array and convert them into a NumPy array:"
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:228
msgid ""
"For the ``set_params()`` function, we perform the reverse operation. We "
"receive a list of NumPy arrays and want to convert them into MLX "
"parameters. Therefore, we iterate through pairs of parameters and assign "
"them to the `weight` and `bias` keys of each layer dict:"
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:243
msgid ""
"The rest of the functionality is directly inspired by the centralized "
"case. The ``fit()`` method in the client trains the model using the local"
" dataset:"
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:259
msgid ""
"Here, after updating the parameters, we perform the training as in the "
"centralized case, and return the new parameters."
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:262
msgid "And for the ``evaluate()`` method of the client:"
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:272
msgid ""
"We also begin by updating the parameters with the ones sent by the "
"server, and then we compute the loss and accuracy using the functions "
"defined above. In the constructor of the ``FlowerClient`` we instantiate "
"the `MLP` model as well as other components such as the optimizer."
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:277
msgid "Putting everything together we have:"
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:331
msgid ""
"Finally, we can construct a ``ClientApp`` using the ``FlowerClient`` "
"defined above by means of a ``client_fn()`` callback. Note that "
"``context`` enables you to get access to hyperparemeters defined in "
"``pyproject.toml`` to configure the run. In this tutorial we access, "
"among other hyperparameters, the ``local-epochs`` setting to control the "
"number of epochs a ``ClientApp`` will perform when running the ``fit()`` "
"method."
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:363
msgid ""
"To construct a ``ServerApp``, we define a ``server_fn()`` callback with "
"an identical signature to that of ``client_fn()``, but the return type is"
" `ServerAppComponents <https://flower.ai/docs/framework/ref-"
"api/flwr.server.ServerAppComponents.html#serverappcomponents>`_ as "
"opposed to `Client <https://flower.ai/docs/framework/ref-"
"api/flwr.client.Client.html#client>`_. In this example we use the "
"``FedAvg`` strategy."
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:386
#: ../../source/tutorial-quickstart-pytorch.rst:344
#: ../../source/tutorial-quickstart-tensorflow.rst:266
msgid ""
"Congratulations! You've successfully built and run your first federated "
"learning system."
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:390
msgid ""
"Check the `source code <https://github.com/adap/flower/blob/main/examples"
"/quickstart-mlx>`_ of the extended version of this tutorial in ``examples"
"/quickstart-mlx`` in the Flower GitHub repository."
msgstr ""

#: ../../source/tutorial-quickstart-pandas.rst:-1
msgid ""
"Check out this Federated Learning quickstart tutorial for using Flower "
"with Pandas to perform Federated Analytics."
msgstr ""

#: ../../source/tutorial-quickstart-pandas.rst:4
msgid "Quickstart Pandas"
msgstr ""

#: ../../source/tutorial-quickstart-pandas.rst:9
msgid "Let's build a federated analytics system using Pandas and Flower!"
msgstr ""

#: ../../source/tutorial-quickstart-pandas.rst:11
msgid ""
"Please refer to the `full code example "
"<https://github.com/adap/flower/tree/main/examples/quickstart-pandas>`_ "
"to learn more."
msgstr ""

#: ../../source/tutorial-quickstart-pytorch.rst:-1
msgid ""
"Check out this Federated Learning quickstart tutorial for using Flower "
"with PyTorch to train a CNN model on MNIST."
msgstr ""

#: ../../source/tutorial-quickstart-pytorch.rst:6
msgid ""
"In this federated learning tutorial we will learn how to train a "
"Convolutional Neural Network on CIFAR-10 using Flower and PyTorch. It is "
"recommended to create a virtual environment and run everything within a "
":doc:`virtualenv <contributor-how-to-set-up-a-virtual-env>`."
msgstr ""

#: ../../source/tutorial-quickstart-pytorch.rst:11
msgid ""
"Let's use `flwr new` to create a complete Flower+PyTorch project. It will"
" generate all the files needed to run, by default with the Flower "
"Simulation Engine, a federation of 10 nodes using `FedAvg "
"<https://flower.ai/docs/framework/ref-"
"api/flwr.server.strategy.FedAvg.html#flwr.server.strategy.FedAvg>`_. The "
"dataset will be partitioned using Flower Dataset's `IidPartitioner "
"<https://flower.ai/docs/datasets/ref-"
"api/flwr_datasets.partitioner.IidPartitioner.html#flwr_datasets.partitioner.IidPartitioner>`_."
msgstr ""

#: ../../source/tutorial-quickstart-pytorch.rst:26
msgid ""
"Then, run the command below. You will be prompted to select one of the "
"available templates (choose ``PyTorch``), give a name to your project, "
"and type in your developer name:"
msgstr ""

#: ../../source/tutorial-quickstart-pytorch.rst:117
msgid ""
"This tutorial uses `Flower Datasets <https://flower.ai/docs/datasets/>`_ "
"to easily download and partition the `CIFAR-10` dataset. In this example "
"you'll make use of the `IidPartitioner <https://flower.ai/docs/datasets"
"/ref-"
"api/flwr_datasets.partitioner.IidPartitioner.html#flwr_datasets.partitioner.IidPartitioner>`_"
" to generate `num_partitions` partitions. You can choose `other "
"partitioners <https://flower.ai/docs/datasets/ref-"
"api/flwr_datasets.partitioner.html>`_ available in Flower Datasets. Each "
"``ClientApp`` will call this function to create dataloaders with the data"
" that correspond to their data partition."
msgstr ""

#: ../../source/tutorial-quickstart-pytorch.rst:152
msgid ""
"We defined a simple Convolutional Neural Network (CNN), but feel free to "
"replace it with a more sophisticated model if you'd like:"
msgstr ""

#: ../../source/tutorial-quickstart-pytorch.rst:177
msgid ""
"In addition to defining the model architecture, we also include two "
"utility functions to perform both training (i.e. ``train()``) and "
"evaluation (i.e. ``test()``) using the above model. These functions "
"should look fairly familiar if you have some prior experience with "
"PyTorch. Note these functions do not have anything specific to Flower. "
"That being said, the training function will normally be called, as we'll "
"see later, from a Flower client passing its own data. In summary, your "
"clients can use standard training/testing functions to perform local "
"training or evaluation:"
msgstr ""

#: ../../source/tutorial-quickstart-pytorch.rst:226
msgid ""
"The main changes we have to make to use `PyTorch` with `Flower` will be "
"found in the ``get_weights()`` and ``set_weights()`` functions. In "
"``get_weights()`` PyTorch model parameters are extracted and represented "
"as a list of NumPy arrays. The ``set_weights()`` function that's the "
"oposite: given a list of NumPy arrays it applies them to an existing "
"PyTorch model. Doing this in fairly easy in PyTorch."
msgstr ""

#: ../../source/tutorial-quickstart-pytorch.rst:282
msgid ""
"Finally, we can construct a ``ClientApp`` using the ``FlowerClient`` "
"defined above by means of a ``client_fn()`` callback. Note that the "
"`context` enables you to get access to hyperparemeters defined in your "
"``pyproject.toml`` to configure the run. In this tutorial we access the "
"`local-epochs` setting to control the number of epochs a ``ClientApp`` "
"will perform when running the ``fit()`` method. You could define "
"additioinal hyperparameters in ``pyproject.toml`` and access them here."
msgstr ""

#: ../../source/tutorial-quickstart-pytorch.rst:309
msgid ""
"To construct a ``ServerApp`` we define a ``server_fn()`` callback with an"
" identical signature to that of ``client_fn()`` but the return type is "
"`ServerAppComponents <https://flower.ai/docs/framework/ref-"
"api/flwr.server.ServerAppComponents.html#serverappcomponents>`_ as "
"opposed to a `Client <https://flower.ai/docs/framework/ref-"
"api/flwr.client.Client.html#client>`_. In this example we use the "
"`FedAvg`. To it we pass a randomly initialized model that will server as "
"the global model to federated. Note that the value of ``fraction_fit`` is"
" read from the run config. You can find the default value defined in the "
"``pyproject.toml``."
msgstr ""

#: ../../source/tutorial-quickstart-pytorch.rst:348
msgid ""
"Check the `source code <https://github.com/adap/flower/blob/main/examples"
"/quickstart-pytorch>`_ of the extended version of this tutorial in "
"``examples/quickstart-pytorch`` in the Flower GitHub repository."
msgstr ""

#: ../../source/tutorial-quickstart-pytorch.rst:354
#: ../../source/tutorial-quickstart-tensorflow.rst:278
msgid "Video tutorial"
msgstr ""

#: ../../source/tutorial-quickstart-pytorch.rst:358
msgid ""
"The video shown below shows how to setup a PyTorch + Flower project using"
" our previously recommended APIs. A new video tutorial will be released "
"that shows the new APIs (as the content above does)"
msgstr ""

#: ../../source/tutorial-quickstart-pytorch-lightning.rst:4
msgid "Quickstart PyTorch Lightning"
msgstr ""

#: ../../source/tutorial-quickstart-pytorch-lightning.rst:6
msgid ""
"In this federated learning tutorial we will learn how to train an "
"AutoEncoder model on MNIST using Flower and PyTorch Lightning. It is "
"recommended to create a virtual environment and run everything within a "
":doc:`virtualenv <contributor-how-to-set-up-a-virtual-env>`."
msgstr ""

#: ../../source/tutorial-quickstart-pytorch-lightning.rst:19
msgid ""
"This will create a new directory called `quickstart-pytorch-lightning` "
"containing the following files:"
msgstr ""

#: ../../source/tutorial-quickstart-pytorch-lightning.rst:42
msgid ""
"By default, Flower Simulation Engine will be started and it will create a"
" federation of 4 nodes using `FedAvg <https://flower.ai/docs/framework"
"/ref-api/flwr.server.strategy.FedAvg.html#flwr.server.strategy.FedAvg>`_ "
"as the aggregation strategy. The dataset will be partitioned using Flower"
" Dataset's `IidPartitioner <https://flower.ai/docs/datasets/ref-"
"api/flwr_datasets.partitioner.IidPartitioner.html#flwr_datasets.partitioner.IidPartitioner>`_."
" To run the project, do:"
msgstr ""

#: ../../source/tutorial-quickstart-pytorch-lightning.rst:93
msgid ""
"Each simulated `ClientApp` (two per round) will also log a summary of "
"their local training process. Expect this output to be similar to:"
msgstr ""

#: ../../source/tutorial-quickstart-pytorch-lightning.rst:115
msgid ""
"Check the `source code <https://github.com/adap/flower/tree/main/examples"
"/quickstart-pytorch-lightning>`_ of this tutorial in ``examples"
"/quickstart-pytorch-lightning`` in the Flower GitHub repository."
msgstr ""

#: ../../source/tutorial-quickstart-scikitlearn.rst:-1
msgid ""
"Check out this Federated Learning quickstart tutorial for using Flower "
"with scikit-learn to train a linear regression model."
msgstr ""

#: ../../source/tutorial-quickstart-scikitlearn.rst:4
msgid "Quickstart scikit-learn"
msgstr ""

#: ../../source/tutorial-quickstart-scikitlearn.rst:6
msgid ""
"In this federated learning tutorial we will learn how to train a Logistic"
" Regression on MNIST using Flower and scikit-learn. It is recommended to "
"create a virtual environment and run everything within a :doc:`virtualenv"
" <contributor-how-to-set-up-a-virtual-env>`."
msgstr ""

#: ../../source/tutorial-quickstart-scikitlearn.rst:10
msgid ""
"Let's use ``flwr new`` to create a complete Flower+scikit-learn project. "
"It will generate all the files needed to run, by default with the Flower "
"Simulation Engine, a federation of 10 nodes using |fedavg|_ The dataset "
"will be partitioned using |flowerdatasets|_'s |iidpartitioner|_"
msgstr ""

#: ../../source/tutorial-quickstart-scikitlearn.rst:23
msgid ""
"Then, run the command below. You will be prompted to select one of the "
"available templates (choose ``sklearn``), give a name to your project, "
"and type in your developer name:"
msgstr ""

#: ../../source/tutorial-quickstart-scikitlearn.rst:115
msgid ""
"This tutorial uses |flowerdatasets|_ to easily download and partition the"
" `MNIST <https://huggingface.co/datasets/ylecun/mnist>`_ dataset. In this"
" example you'll make use of the |iidpartitioner|_ to generate "
"``num_partitions`` partitions. You can choose |otherpartitioners|_ "
"available in Flower Datasets. Each ``ClientApp`` will call this function "
"to create dataloaders with the data that correspond to their data "
"partition."
msgstr ""

#: ../../source/tutorial-quickstart-scikitlearn.rst:140
msgid ""
"We define the |logisticregression|_ model from scikit-learn in the "
"``get_model()`` function:"
msgstr ""

#: ../../source/tutorial-quickstart-scikitlearn.rst:153
msgid ""
"To perform the training and evaluation, we will make use of the "
"``.fit()`` and ``.score()`` methods available in the "
"``LogisticRegression`` class."
msgstr ""

#: ../../source/tutorial-quickstart-scikitlearn.rst:159
msgid ""
"The main changes we have to make to use scikit-learn with Flower will be "
"found in the ``get_model_params()``, ``set_model_params()``, and "
"``set_initial_params()`` functions. In ``get_model_params()``, the "
"coefficients and intercept of the logistic regression model are extracted"
" and represented as a list of NumPy arrays. In ``set_model_params()``, "
"that's the opposite: given a list of NumPy arrays it applies them to an "
"existing ``LogisticRegression`` model. Finally, in "
"``set_initial_params()``, we initialize the model parameters based on the"
" MNIST dataset, which has 10 classes (corresponding to the 10 digits) and"
" 784 features (corresponding to the size of the MNIST image array, which "
"is 28 × 28). Doing this is fairly easy in scikit-learn."
msgstr ""

#: ../../source/tutorial-quickstart-scikitlearn.rst:198
msgid ""
"The rest of the functionality is directly inspired by the centralized "
"case:"
msgstr ""

#: ../../source/tutorial-quickstart-scikitlearn.rst:226
msgid ""
"Finally, we can construct a ``ClientApp`` using the ``FlowerClient`` "
"defined above by means of a ``client_fn()`` callback. Note that the "
"``context`` enables you to get access to hyperparemeters defined in your "
"``pyproject.toml`` to configure the run. In this tutorial we access the "
"`local-epochs` setting to control the number of epochs a ``ClientApp`` "
"will perform when running the ``fit()`` method. You could define "
"additioinal hyperparameters in ``pyproject.toml`` and access them here."
msgstr ""

#: ../../source/tutorial-quickstart-scikitlearn.rst:257
msgid ""
"To construct a ``ServerApp`` we define a ``server_fn()`` callback with an"
" identical signature to that of ``client_fn()`` but the return type is "
"|serverappcomponents|_ as opposed to a |client|_ In this example we use "
"the `FedAvg` strategy. To it we pass a zero-initialized model that will "
"server as the global model to be federated. Note that the values of "
"``num-server-rounds``, ``penalty``, and ``local-epochs`` are read from "
"the run config. You can find the default values defined in the "
"``pyproject.toml``."
msgstr ""

#: ../../source/tutorial-quickstart-scikitlearn.rst:295
msgid ""
"Congratulations! You've successfully built and run your first federated "
"learning system in scikit-learn."
msgstr ""

#: ../../source/tutorial-quickstart-scikitlearn.rst:300
msgid ""
"Check the source code of the extended version of this tutorial in "
"|quickstart_sklearn_link|_ in the Flower GitHub repository."
msgstr ""

#: ../../source/tutorial-quickstart-tensorflow.rst:-1
msgid ""
"Check out this Federated Learning quickstart tutorial for using Flower "
"with TensorFlow to train a CNN model on CIFAR-10."
msgstr ""

#: ../../source/tutorial-quickstart-tensorflow.rst:4
msgid "Quickstart TensorFlow"
msgstr ""

#: ../../source/tutorial-quickstart-tensorflow.rst:6
msgid ""
"In this tutorial we will learn how to train a Convolutional Neural "
"Network on CIFAR-10 using the Flower framework and TensorFlow. First of "
"all, it is recommended to create a virtual environment and run everything"
" within a :doc:`virtualenv <contributor-how-to-set-up-a-virtual-env>`."
msgstr ""

#: ../../source/tutorial-quickstart-tensorflow.rst:11
msgid ""
"Let's use `flwr new` to create a complete Flower+TensorFlow project. It "
"will generate all the files needed to run, by default with the Flower "
"Simulation Engine, a federation of 10 nodes using `FedAvg "
"<https://flower.ai/docs/framework/ref-"
"api/flwr.server.strategy.FedAvg.html#flwr.server.strategy.FedAvg>`_. The "
"dataset will be partitioned using Flower Dataset's `IidPartitioner "
"<https://flower.ai/docs/datasets/ref-"
"api/flwr_datasets.partitioner.IidPartitioner.html#flwr_datasets.partitioner.IidPartitioner>`_."
msgstr ""

#: ../../source/tutorial-quickstart-tensorflow.rst:26
msgid ""
"Then, run the command below. You will be prompted to select one of the "
"available templates (choose ``TensorFlow``), give a name to your project,"
" and type in your developer name:"
msgstr ""

#: ../../source/tutorial-quickstart-tensorflow.rst:114
msgid ""
"This tutorial uses `Flower Datasets <https://flower.ai/docs/datasets/>`_ "
"to easily download and partition the `CIFAR-10` dataset. In this example "
"you'll make use of the `IidPartitioner <https://flower.ai/docs/datasets"
"/ref-"
"api/flwr_datasets.partitioner.IidPartitioner.html#flwr_datasets.partitioner.IidPartitioner>`_"
" to generate `num_partitions` partitions. You can choose `other "
"partitioners <https://flower.ai/docs/datasets/ref-"
"api/flwr_datasets.partitioner.html>`_ available in Flower Datasets. Each "
"``ClientApp`` will call this function to create the ``NumPy`` arrays that"
" correspond to their data partition."
msgstr ""

#: ../../source/tutorial-quickstart-tensorflow.rst:141
msgid ""
"Next, we need a model. We defined a simple Convolutional Neural Network "
"(CNN), but feel free to replace it with a more sophisticated model if "
"you'd like:"
msgstr ""

#: ../../source/tutorial-quickstart-tensorflow.rst:170
msgid ""
"With `TensorFlow`, we can use the built-in ``get_weights()`` and "
"``set_weights()`` functions, which simplifies the implementation with "
"`Flower`. The rest of the functionality in the ClientApp is directly "
"inspired by the centralized case. The ``fit()`` method in the client "
"trains the model using the local dataset. Similarly, the ``evaluate()`` "
"method is used to evaluate the model received on a held-out validation "
"set that the client might have:"
msgstr ""

#: ../../source/tutorial-quickstart-tensorflow.rst:203
msgid ""
"Finally, we can construct a ``ClientApp`` using the ``FlowerClient`` "
"defined above by means of a ``client_fn()`` callback. Note that the "
"`context` enables you to get access to hyperparameters defined in your "
"``pyproject.toml`` to configure the run. For example, in this tutorial we"
" access the `local-epochs` setting to control the number of epochs a "
"``ClientApp`` will perform when running the ``fit()`` method, in addition"
" to `batch-size`. You could define additional hyperparameters in "
"``pyproject.toml`` and access them here."
msgstr ""

#: ../../source/tutorial-quickstart-tensorflow.rst:234
msgid ""
"To construct a ``ServerApp`` we define a ``server_fn()`` callback with an"
" identical signature to that of ``client_fn()`` but the return type is "
"`ServerAppComponents <https://flower.ai/docs/framework/ref-"
"api/flwr.server.ServerAppComponents.html#serverappcomponents>`_ as "
"opposed to a `Client <https://flower.ai/docs/framework/ref-"
"api/flwr.client.Client.html#client>`_. In this example we use the "
"`FedAvg`. To it we pass a randomly initialized model that will serve as "
"the global model to federate."
msgstr ""

#: ../../source/tutorial-quickstart-tensorflow.rst:270
msgid ""
"Check the source code of the extended version of this tutorial in "
"|quickstart_tf_link|_ in the Flower GitHub repository."
msgstr ""

#: ../../source/tutorial-quickstart-tensorflow.rst:282
msgid ""
"The video shown below shows how to setup a TensorFlow + Flower project "
"using our previously recommended APIs. A new video tutorial will be "
"released that shows the new APIs (as the content above does)"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:-1
msgid ""
"Check out this Federated Learning quickstart tutorial for using Flower "
"with XGBoost to train classification models on trees."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:4
msgid "Quickstart XGBoost"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:7
msgid "XGBoost"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:9
msgid ""
"EXtreme Gradient Boosting (**XGBoost**) is a robust and efficient "
"implementation of gradient-boosted decision tree (**GBDT**), that "
"maximises the computational boundaries for boosted tree methods. It's "
"primarily designed to enhance both the performance and computational "
"speed of machine learning models. In XGBoost, trees are constructed "
"concurrently, unlike the sequential approach taken by GBDT."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:15
msgid ""
"Often, for tabular data on medium-sized datasets with fewer than 10k "
"training examples, XGBoost surpasses the results of deep learning "
"techniques."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:19
msgid "Why Federated XGBoost?"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:21
msgid ""
"As the demand for data privacy and decentralized learning grows, there's "
"an increasing requirement to implement federated XGBoost systems for "
"specialised applications, like survival analysis and financial fraud "
"detection."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:25
msgid ""
"Federated learning ensures that raw data remains on the local device, "
"making it an attractive approach for sensitive domains where data privacy"
" is paramount. Given the robustness and efficiency of XGBoost, combining "
"it with federated learning offers a promising solution for these specific"
" challenges."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:31
msgid "Environment Setup"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:33
msgid ""
"In this tutorial, we learn how to train a federated XGBoost model on the "
"HIGGS dataset using Flower and the ``xgboost`` package to perform a "
"binary classification task. We use a simple example (`full code xgboost-"
"quickstart <https://github.com/adap/flower/tree/main/examples/xgboost-"
"quickstart>`_) to demonstrate how federated XGBoost works, and then we "
"dive into a more complex comprehensive example (`full code xgboost-"
"comprehensive <https://github.com/adap/flower/tree/main/examples/xgboost-"
"comprehensive>`_) to run various experiments."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:42
msgid ""
"It is recommended to create a virtual environment and run everything "
"within a :doc:`virtualenv <contributor-how-to-set-up-a-virtual-env>`."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:45
msgid ""
"We first need to install Flower and Flower Datasets. You can do this by "
"running :"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:52
msgid ""
"Since we want to use ``xgboost`` package to build up XGBoost trees, let's"
" go ahead and install ``xgboost``:"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:60
msgid "The Configurations"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:62
msgid ""
"We define all required configurations / hyper-parameters inside the "
"``pyproject.toml`` file:"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:84
msgid ""
"The ``local-epochs`` represents the number of iterations for local tree "
"boost. We use CPU for the training in default. One can assign it to a GPU"
" by setting ``tree_method`` to ``gpu_hist``. We use AUC as evaluation "
"metric."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:91
msgid ""
"This tutorial uses `Flower Datasets <https://flower.ai/docs/datasets/>`_ "
"to easily download and partition the `HIGGS` dataset."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:105
msgid ""
"In this example, we split the dataset into 20 partitions with uniform "
"distribution (`IidPartitioner <https://flower.ai/docs/datasets/ref-"
"api/flwr_datasets.partitioner.IidPartitioner.html#flwr_datasets.partitioner.IidPartitioner>`_)."
" Then, we load the partition for the given client based on "
"``partition_id``."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:110
msgid ""
"Subsequently, we train/test split using the given partition (client's "
"local data), and reformat data to DMatrix for the ``xgboost`` package."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:124
msgid ""
"The functions of ``train_test_split`` and "
"``transform_dataset_to_dmatrix`` are defined as below:"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:151
msgid ""
"*Clients* are responsible for generating individual weight-updates for "
"the model based on their local datasets. Let's first see how we define "
"Flower client for XGBoost. We follow the general rule to define "
"``FlowerClient`` class inherited from ``fl.client.Client``."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:176
msgid ""
"All required parameters defined above are passed to ``FlowerClient``'s "
"constructor."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:178
msgid ""
"Then, we override ``fit`` and ``evaluate`` methods insides "
"``FlowerClient`` class as follows."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:217
msgid ""
"In ``fit``, at the first round, we call ``xgb.train()`` to build up the "
"first set of trees. From the second round, we load the global model sent "
"from server to new build Booster object, and then update model weights on"
" local training data with function ``_local_boost`` as follows:"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:237
msgid ""
"Given ``num_local_round``, we update trees by calling "
"``bst_input.update`` method. After training, the last "
"``N=num_local_round`` trees will be extracted to send to the server."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:265
msgid ""
"In ``evaluate``, after loading the global model, we call ``bst.eval_set``"
" function to conduct evaluation on valid set. The AUC value will be "
"returned."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:271
msgid ""
"After the local training on clients, clients' model updates are sent to "
"the *server*, which aggregates them to produce a better model. Finally, "
"the *server* sends this improved model version back to each *client* to "
"complete a federated round."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:275
msgid ""
"In the file named ``server_app.py``, we define a strategy for XGBoost "
"bagging aggregation:"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:308
msgid ""
"An ``evaluate_metrics_aggregation`` function is defined to collect and "
"wighted average the AUC values from clients. The ``config_func`` function"
" is to return the current FL round number to client's ``fit()`` and "
"``evaluate()`` methods."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:313
msgid "Tree-based Bagging Aggregation"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:315
msgid ""
"You must be curious about how bagging aggregation works. Let's look into "
"the details."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:317
msgid ""
"In file ``flwr.server.strategy.fedxgb_bagging.py``, we define "
"``FedXgbBagging`` inherited from ``flwr.server.strategy.FedAvg``. Then, "
"we override the ``aggregate_fit``, ``aggregate_evaluate`` and "
"``evaluate`` methods as follows:"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:414
msgid ""
"In ``aggregate_fit``, we sequentially aggregate the clients' XGBoost "
"trees by calling ``aggregate()`` function:"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:474
msgid ""
"In this function, we first fetch the number of trees and the number of "
"parallel trees for the current and previous model by calling "
"``_get_tree_nums``. Then, the fetched information will be aggregated. "
"After that, the trees (containing model weights) are aggregated to "
"generate a new tree model."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:479
msgid ""
"After traversal of all clients' models, a new global model is generated, "
"followed by serialisation, and sending the global model back to each "
"client."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:483
msgid "Launch Federated XGBoost!"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:533
msgid ""
"Congratulations! You've successfully built and run your first federated "
"XGBoost system. The AUC values can be checked in ``History (metrics, "
"distributed, evaluate)``. One can see that the average AUC increases over"
" FL rounds."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:547
msgid ""
"Check the full `source code "
"<https://github.com/adap/flower/blob/main/examples/xgboost-quickstart>`_ "
"for this example in ``examples/xgboost-quickstart`` in the Flower GitHub "
"repository."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:552
msgid "Comprehensive Federated XGBoost"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:554
msgid ""
"Now that you know how federated XGBoost works with Flower, it's time to "
"run some more comprehensive experiments by customising the experimental "
"settings. In the xgboost-comprehensive example (`full code "
"<https://github.com/adap/flower/tree/main/examples/xgboost-"
"comprehensive>`_), we provide more options to define various experimental"
" setups, including aggregation strategies, data partitioning and "
"centralised / distributed evaluation. Let's take a look!"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:562
msgid "Cyclic Training"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:564
msgid ""
"In addition to bagging aggregation, we offer a cyclic training scheme, "
"which performs FL in a client-by-client fashion. Instead of aggregating "
"multiple clients, there is only one single client participating in the "
"training per round in the cyclic training scenario. The trained local "
"XGBoost trees will be passed to the next client as an initialised model "
"for next round's boosting."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:570
msgid "To do this, we first customise a ``ClientManager`` in ``server_app.py``:"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:610
msgid ""
"The customised ``ClientManager`` samples all available clients in each FL"
" round based on the order of connection to the server. Then, we define a "
"new strategy ``FedXgbCyclic`` in "
"``flwr.server.strategy.fedxgb_cyclic.py``, in order to sequentially "
"select only one client in given round and pass the received model to the "
"next client."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:652
msgid ""
"Unlike the original ``FedAvg``, we don't perform aggregation here. "
"Instead, we just make a copy of the received client model as global model"
" by overriding ``aggregate_fit``."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:655
msgid ""
"Also, the customised ``configure_fit`` and ``configure_evaluate`` methods"
" ensure the clients to be sequentially selected given FL round:"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:685
msgid "Customised Data Partitioning"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:687
msgid ""
"In ``task.py``, we use the ``instantiate_fds`` function to instantiate "
"Flower Datasets and the data partitioner based on the given "
"``partitioner_type`` and ``num_partitions``. Currently, we provide four "
"supported partitioner type to simulate the uniformity/non-uniformity in "
"data quantity (uniform, linear, square, exponential)."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:726
msgid "Customised Centralised / Distributed Evaluation"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:728
msgid ""
"To facilitate centralised evaluation, we define a function in "
"``server_app.py``:"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:759
msgid ""
"This function returns an evaluation function, which instantiates a "
"``Booster`` object and loads the global model weights to it. The "
"evaluation is conducted by calling ``eval_set()`` method, and the tested "
"AUC value is reported."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:763
msgid ""
"As for distributed evaluation on the clients, it's same as the quick-"
"start example by overriding the ``evaluate()`` method insides the "
"``XgbClient`` class in ``client_app.py``."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:768
#, fuzzy
msgid "Arguments Explainer"
msgstr "Argumento de compilação"

#: ../../source/tutorial-quickstart-xgboost.rst:770
msgid ""
"We define all hyper-parameters under ``[tool.flwr.app.config]`` entry in "
"``pyproject.toml``:"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:799
msgid ""
"On the server side, we allow user to specify training strategies / FL "
"rounds / participating clients / clients for evaluation, and evaluation "
"fashion. Note that with ``centralised-eval = true``, the sever will do "
"centralised evaluation and all functionalities for client evaluation will"
" be disabled."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:804
msgid ""
"On the client side, we can define various options for client data "
"partitioning. Besides, clients also have an option to conduct evaluation "
"on centralised test set by setting ``centralised-eval = true``, as well "
"as an option to perform scaled learning rate based on the number of "
"clients by setting ``scaled-lr = true``."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:810
#, fuzzy
msgid "Example Commands"
msgstr "Exemplo"

#: ../../source/tutorial-quickstart-xgboost.rst:812
msgid "To run bagging aggregation for 5 rounds evaluated on centralised test set:"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:818
msgid ""
"To run cyclic training with linear partitioner type evaluated on "
"centralised test set:"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:827
msgid ""
"The full `code <https://github.com/adap/flower/blob/main/examples"
"/xgboost-comprehensive/>`_ for this comprehensive example can be found in"
" ``examples/xgboost-comprehensive`` in the Flower GitHub repository."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:833
msgid "Video Tutorial"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:837
msgid ""
"The video shown below shows how to setup a XGBoost + Flower project using"
" our previously recommended APIs. A new video tutorial will be released "
"that shows the new APIs (as the content above does)"
msgstr ""

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:9
msgid "Build a strategy from scratch"
msgstr ""

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:11
msgid ""
"Welcome to the third part of the Flower federated learning tutorial. In "
"previous parts of this tutorial, we introduced federated learning with "
"PyTorch and the Flower framework (`part 1 "
"<https://flower.ai/docs/framework/tutorial-get-started-with-flower-"
"pytorch.html>`__) and we learned how strategies can be used to customize "
"the execution on both the server and the clients (`part 2 "
"<https://flower.ai/docs/framework/tutorial-use-a-federated-learning-"
"strategy-pytorch.html>`__)."
msgstr ""

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:13
msgid ""
"In this notebook, we'll continue to customize the federated learning "
"system we built previously by creating a custom version of FedAvg using "
"the Flower framework, Flower Datasets, and PyTorch."
msgstr ""

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:15
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:16
#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:15
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:15
msgid ""
"`Star Flower on GitHub <https://github.com/adap/flower>`__ ⭐️ and join "
"the Flower community on Flower Discuss and the Flower Slack to connect, "
"ask questions, and get help: - `Join Flower Discuss "
"<https://discuss.flower.ai/>`__ We'd love to hear from you in the "
"``Introduction`` topic! If anything is unclear, post in ``Flower Help - "
"Beginners``. - `Join Flower Slack <https://flower.ai/join-slack>`__ We'd "
"love to hear from you in the ``#introductions`` channel! If anything is "
"unclear, head over to the ``#questions`` channel."
msgstr ""

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:18
msgid "Let's build a new ``Strategy`` from scratch! 🌼"
msgstr ""

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:30
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:30
msgid "Preparation"
msgstr ""

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:32
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:33
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:32
msgid ""
"Before we begin with the actual code, let's make sure that we have "
"everything we need."
msgstr ""

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:44
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:45
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:44
msgid "Installing dependencies"
msgstr ""

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:46
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:47
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:46
msgid "First, we install the necessary packages:"
msgstr ""

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:66
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:67
#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:66
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:66
msgid ""
"Now that we have all dependencies installed, we can import everything we "
"need for this tutorial:"
msgstr ""

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:106
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:106
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:106
msgid ""
"It is possible to switch to a runtime that has GPU acceleration enabled "
"(on Google Colab: ``Runtime > Change runtime type > Hardware acclerator: "
"GPU > Save``). Note, however, that Google Colab is not always able to "
"offer GPU acceleration. If you see an error related to GPU availability "
"in one of the following sections, consider switching back to CPU-based "
"execution by setting ``DEVICE = torch.device(\"cpu\")``. If the runtime "
"has GPU acceleration enabled, you should see the output ``Training on "
"cuda``, otherwise it'll say ``Training on cpu``."
msgstr ""

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:119
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:119
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:119
msgid "Data loading"
msgstr ""

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:121
msgid ""
"Let's now load the CIFAR-10 training and test set, partition them into "
"ten smaller datasets (each split into training and validation set), and "
"wrap everything in their own ``DataLoader``."
msgstr ""

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:163
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:163
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:169
msgid "Model training/evaluation"
msgstr ""

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:165
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:165
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:171
msgid ""
"Let's continue with the usual model definition (including "
"``set_parameters`` and ``get_parameters``), training and test functions:"
msgstr ""

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:256
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:262
msgid "Flower client"
msgstr ""

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:258
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:264
msgid ""
"To implement the Flower client, we (again) create a subclass of "
"``flwr.client.NumPyClient`` and implement the three methods "
"``get_parameters``, ``fit``, and ``evaluate``. Here, we also pass the "
"``partition_id`` to the client and use it log additional details. We then"
" create an instance of ``ClientApp`` and pass it the ``client_fn``."
msgstr ""

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:311
msgid "Let's test what we have so far before we continue:"
msgstr ""

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:357
msgid "Build a Strategy from scratch"
msgstr ""

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:359
msgid ""
"Let’s overwrite the ``configure_fit`` method such that it passes a higher"
" learning rate (potentially also other hyperparameters) to the optimizer "
"of a fraction of the clients. We will keep the sampling of the clients as"
" it is in ``FedAvg`` and then change the configuration dictionary (one of"
" the ``FitIns`` attributes)."
msgstr ""

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:523
msgid ""
"The only thing left is to use the newly created custom Strategy "
"``FedCustom`` when starting the experiment:"
msgstr ""

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:559
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:998
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:841
msgid "Recap"
msgstr ""

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:561
msgid ""
"In this notebook, we’ve seen how to implement a custom strategy. A custom"
" strategy enables granular control over client node configuration, result"
" aggregation, and more. To define a custom strategy, you only have to "
"overwrite the abstract methods of the (abstract) base class ``Strategy``."
" To make custom strategies even more powerful, you can pass custom "
"functions to the constructor of your new class (``__init__``) and then "
"call these functions whenever needed."
msgstr ""

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:575
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:1014
#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:813
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:859
msgid ""
"Before you continue, make sure to join the Flower community on Flower "
"Discuss (`Join Flower Discuss <https://discuss.flower.ai>`__) and on "
"Slack (`Join Slack <https://flower.ai/join-slack/>`__)."
msgstr ""

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:577
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:1016
#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:815
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:861
#: ../../source/tutorial-series-what-is-federated-learning.ipynb:371
msgid ""
"There's a dedicated ``#questions`` channel if you need help, but we'd "
"also love to hear who you are in ``#introductions``!"
msgstr ""

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:579
msgid ""
"The `Flower Federated Learning Tutorial - Part 4 "
"<https://flower.ai/docs/framework/tutorial-customize-the-client-"
"pytorch.html>`__ introduces ``Client``, the flexible API underlying "
"``NumPyClient``."
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:9
msgid "Customize the client"
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:11
msgid ""
"Welcome to the fourth part of the Flower federated learning tutorial. In "
"the previous parts of this tutorial, we introduced federated learning "
"with PyTorch and Flower (`part 1 <https://flower.ai/docs/framework"
"/tutorial-get-started-with-flower-pytorch.html>`__), we learned how "
"strategies can be used to customize the execution on both the server and "
"the clients (`part 2 <https://flower.ai/docs/framework/tutorial-use-a"
"-federated-learning-strategy-pytorch.html>`__), and we built our own "
"custom strategy from scratch (`part 3 <https://flower.ai/docs/framework"
"/tutorial-build-a-strategy-from-scratch-pytorch.html>`__)."
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:14
msgid ""
"In this notebook, we revisit ``NumPyClient`` and introduce a new "
"baseclass for building clients, simply named ``Client``. In previous "
"parts of this tutorial, we've based our client on ``NumPyClient``, a "
"convenience class which makes it easy to work with machine learning "
"libraries that have good NumPy interoperability. With ``Client``, we gain"
" a lot of flexibility that we didn't have before, but we'll also have to "
"do a few things the we didn't have to do before."
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:19
msgid ""
"Let's go deeper and see what it takes to move from ``NumPyClient`` to "
"``Client``! 🌼"
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:31
#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:30
msgid "Step 0: Preparation"
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:121
msgid ""
"Let's now define a loading function for the CIFAR-10 training and test "
"set, partition them into ``num_partitions`` smaller datasets (each split "
"into training and validation set), and wrap everything in their own "
"``DataLoader``."
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:256
msgid "Step 1: Revisiting NumPyClient"
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:258
msgid ""
"So far, we've implemented our client by subclassing "
"``flwr.client.NumPyClient``. The three methods we implemented are "
"``get_parameters``, ``fit``, and ``evaluate``."
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:299
msgid ""
"Then, we define the function ``numpyclient_fn`` that is used by Flower to"
" create the ``FlowerNumpyClient`` instances on demand. Finally, we create"
" the ``ClientApp`` and pass the ``numpyclient_fn`` to it."
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:328
msgid ""
"We've seen this before, there's nothing new so far. The only *tiny* "
"difference compared to the previous notebook is naming, we've changed "
"``FlowerClient`` to ``FlowerNumPyClient`` and ``client_fn`` to "
"``numpyclient_fn``. Next, we configure the number of federated learning "
"rounds using ``ServerConfig`` and create the ``ServerApp`` with this "
"config:"
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:355
msgid ""
"Finally, we specify the resources for each client and run the simulation "
"to see the output we get:"
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:389
msgid ""
"This works as expected, ten clients are training for three rounds of "
"federated learning."
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:391
msgid ""
"Let's dive a little bit deeper and discuss how Flower executes this "
"simulation. Whenever a client is selected to do some work, "
"``run_simulation`` launches the ``ClientApp`` object which in turn calls "
"the function ``numpyclient_fn`` to create an instance of our "
"``FlowerNumPyClient`` (along with loading the model and the data)."
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:393
msgid ""
"But here's the perhaps surprising part: Flower doesn't actually use the "
"``FlowerNumPyClient`` object directly. Instead, it wraps the object to "
"makes it look like a subclass of ``flwr.client.Client``, not "
"``flwr.client.NumPyClient``. In fact, the Flower core framework doesn't "
"know how to handle ``NumPyClient``'s, it only knows how to handle "
"``Client``'s. ``NumPyClient`` is just a convenience abstraction built on "
"top of ``Client``."
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:395
msgid ""
"Instead of building on top of ``NumPyClient``, we can directly build on "
"top of ``Client``."
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:407
msgid "Step 2: Moving from ``NumPyClient`` to ``Client``"
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:409
msgid ""
"Let's try to do the same thing using ``Client`` instead of "
"``NumPyClient``."
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:519
msgid ""
"Before we discuss the code in more detail, let's try to run it! Gotta "
"make sure our new ``Client``-based client works, right?"
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:545
msgid ""
"That's it, we're now using ``Client``. It probably looks similar to what "
"we've done with ``NumPyClient``. So what's the difference?"
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:547
msgid ""
"First of all, it's more code. But why? The difference comes from the fact"
" that ``Client`` expects us to take care of parameter serialization and "
"deserialization. For Flower to be able to send parameters over the "
"network, it eventually needs to turn these parameters into ``bytes``. "
"Turning parameters (e.g., NumPy ``ndarray``'s) into raw bytes is called "
"serialization. Turning raw bytes into something more useful (like NumPy "
"``ndarray``'s) is called deserialization. Flower needs to do both: it "
"needs to serialize parameters on the server-side and send them to the "
"client, the client needs to deserialize them to use them for local "
"training, and then serialize the updated parameters again to send them "
"back to the server, which (finally!) deserializes them again in order to "
"aggregate them with the updates received from other clients."
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:550
msgid ""
"The only *real* difference between Client and NumPyClient is that "
"NumPyClient takes care of serialization and deserialization for you. It "
"can do so because it expects you to return parameters as NumPy ndarray's,"
" and it knows how to handle these. This makes working with machine "
"learning libraries that have good NumPy support (most of them) a breeze."
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:552
msgid ""
"In terms of API, there's one major difference: all methods in Client take"
" exactly one argument (e.g., ``FitIns`` in ``Client.fit``) and return "
"exactly one value (e.g., ``FitRes`` in ``Client.fit``). The methods in "
"``NumPyClient`` on the other hand have multiple arguments (e.g., "
"``parameters`` and ``config`` in ``NumPyClient.fit``) and multiple return"
" values (e.g., ``parameters``, ``num_example``, and ``metrics`` in "
"``NumPyClient.fit``) if there are multiple things to handle. These "
"``*Ins`` and ``*Res`` objects in ``Client`` wrap all the individual "
"values you're used to from ``NumPyClient``."
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:565
msgid "Step 3: Custom serialization"
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:567
msgid ""
"Here we will explore how to implement custom serialization with a simple "
"example."
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:569
msgid ""
"But first what is serialization? Serialization is just the process of "
"converting an object into raw bytes, and equally as important, "
"deserialization is the process of converting raw bytes back into an "
"object. This is very useful for network communication. Indeed, without "
"serialization, you could not just a Python object through the internet."
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:571
msgid ""
"Federated Learning relies heavily on internet communication for training "
"by sending Python objects back and forth between the clients and the "
"server. This means that serialization is an essential part of Federated "
"Learning."
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:573
msgid ""
"In the following section, we will write a basic example where instead of "
"sending a serialized version of our ``ndarray``\\ s containing our "
"parameters, we will first convert the ``ndarray`` into sparse matrices, "
"before sending them. This technique can be used to save bandwidth, as in "
"certain cases where the weights of a model are sparse (containing many 0 "
"entries), converting them to a sparse matrix can greatly improve their "
"bytesize."
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:576
msgid "Our custom serialization/deserialization functions"
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:578
msgid ""
"This is where the real serialization/deserialization will happen, "
"especially in ``ndarray_to_sparse_bytes`` for serialization and "
"``sparse_bytes_to_ndarray`` for deserialization."
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:580
msgid ""
"Note that we imported the ``scipy.sparse`` library in order to convert "
"our arrays."
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:668
msgid "Client-side"
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:670
msgid ""
"To be able to serialize our ``ndarray``\\ s into sparse parameters, we "
"will just have to call our custom functions in our "
"``flwr.client.Client``."
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:672
msgid ""
"Indeed, in ``get_parameters`` we need to serialize the parameters we got "
"from our network using our custom ``ndarrays_to_sparse_parameters`` "
"defined above."
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:674
msgid ""
"In ``fit``, we first need to deserialize the parameters coming from the "
"server using our custom ``sparse_parameters_to_ndarrays`` and then we "
"need to serialize our local results with "
"``ndarrays_to_sparse_parameters``."
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:676
msgid ""
"In ``evaluate``, we will only need to deserialize the global parameters "
"with our custom function."
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:781
msgid "Server-side"
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:783
msgid ""
"For this example, we will just use ``FedAvg`` as a strategy. To change "
"the serialization and deserialization here, we only need to reimplement "
"the ``evaluate`` and ``aggregate_fit`` functions of ``FedAvg``. The other"
" functions of the strategy will be inherited from the super class "
"``FedAvg``."
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:785
msgid "As you can see only one line as change in ``evaluate``:"
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:791
msgid ""
"And for ``aggregate_fit``, we will first deserialize every result we "
"received:"
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:800
msgid "And then serialize the aggregated result:"
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:959
msgid "We can now run our custom serialization example!"
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:1000
msgid ""
"In this part of the tutorial, we've seen how we can build clients by "
"subclassing either ``NumPyClient`` or ``Client``. ``NumPyClient`` is a "
"convenience abstraction that makes it easier to work with machine "
"learning libraries that have good NumPy interoperability. ``Client`` is a"
" more flexible abstraction that allows us to do things that are not "
"possible in ``NumPyClient``. In order to do so, it requires us to handle "
"parameter serialization and deserialization ourselves."
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:1018
msgid ""
"This is the final part of the Flower tutorial (for now!), "
"congratulations! You're now well equipped to understand the rest of the "
"documentation. There are many topics we didn't cover in the tutorial, we "
"recommend the following resources:"
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:1020
msgid "`Read Flower Docs <https://flower.ai/docs/>`__"
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:1021
msgid "`Check out Flower Code Examples <https://flower.ai/docs/examples/>`__"
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:1022
msgid ""
"`Use Flower Baselines for your research "
"<https://flower.ai/docs/baselines/>`__"
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:1023
msgid ""
"`Watch Flower AI Summit 2024 videos <https://flower.ai/conf/flower-ai-"
"summit-2024/>`__"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:9
msgid "Get started with Flower"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:11
#: ../../source/tutorial-series-what-is-federated-learning.ipynb:11
msgid "Welcome to the Flower federated learning tutorial!"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:13
msgid ""
"In this notebook, we'll build a federated learning system using the "
"Flower framework, Flower Datasets and PyTorch. In part 1, we use PyTorch "
"for the model training pipeline and data loading. In part 2, we federate "
"the PyTorch project using Flower."
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:18
msgid "Let's get started! 🌼"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:32
msgid ""
"Before we begin with any actual code, let's make sure that we have "
"everything we need."
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:44
msgid "Install dependencies"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:46
msgid ""
"Next, we install the necessary packages for PyTorch (``torch`` and "
"``torchvision``), Flower Datasets (``flwr-datasets``) and Flower "
"(``flwr``):"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:109
msgid ""
"It is possible to switch to a runtime that has GPU acceleration enabled "
"(on Google Colab: ``Runtime > Change runtime type > Hardware accelerator:"
" GPU > Save``). Note, however, that Google Colab is not always able to "
"offer GPU acceleration. If you see an error related to GPU availability "
"in one of the following sections, consider switching back to CPU-based "
"execution by setting ``DEVICE = torch.device(\"cpu\")``. If the runtime "
"has GPU acceleration enabled, you should see the output ``Training on "
"cuda``, otherwise it'll say ``Training on cpu``."
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:122
msgid "Load the data"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:124
msgid ""
"Federated learning can be applied to many different types of tasks across"
" different domains. In this tutorial, we introduce federated learning by "
"training a simple convolutional neural network (CNN) on the popular "
"CIFAR-10 dataset. CIFAR-10 can be used to train image classifiers that "
"distinguish between images from ten different classes: 'airplane', "
"'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', and "
"'truck'."
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:135
msgid ""
"We simulate having multiple datasets from multiple organizations (also "
"called the \"cross-silo\" setting in federated learning) by splitting the"
" original CIFAR-10 dataset into multiple partitions. Each partition will "
"represent the data from a single organization. We're doing this purely "
"for experimentation purposes, in the real world there's no need for data "
"splitting because each organization already has their own data (the data "
"is naturally partitioned)."
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:137
msgid ""
"Each organization will act as a client in the federated learning system. "
"Having ten organizations participate in a federation means having ten "
"clients connected to the federated learning server."
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:148
msgid ""
"We use the Flower Datasets library (``flwr-datasets``) to partition "
"CIFAR-10 into ten partitions using ``FederatedDataset``. We will create a"
" small training and test set for each of the ten organizations and wrap "
"each of these into a PyTorch ``DataLoader``:"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:196
msgid ""
"We now have a function that can return a training set and validation set "
"(``trainloader`` and ``valloader``) representing one dataset from one of "
"ten different organizations. Each ``trainloader``/``valloader`` pair "
"contains 4000 training examples and 1000 validation examples. There's "
"also a single ``testloader`` (we did not split the test set). Again, this"
" is only necessary for building research or educational systems, actual "
"federated learning systems have their data naturally distributed across "
"multiple partitions."
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:199
msgid ""
"Let's take a look at the first batch of images and labels in the first "
"training set (i.e., ``trainloader`` from ``partition_id=0``) before we "
"move on:"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:241
msgid ""
"The output above shows a random batch of images from the ``trainloader`` "
"from the first of ten partitions. It also prints the labels associated "
"with each image (i.e., one of the ten possible labels we've seen above). "
"If you run the cell again, you should see another batch of images."
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:253
msgid "Step 1: Centralized Training with PyTorch"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:264
msgid ""
"Next, we're going to use PyTorch to define a simple convolutional neural "
"network. This introduction assumes basic familiarity with PyTorch, so it "
"doesn't cover the PyTorch-related aspects in full detail. If you want to "
"dive deeper into PyTorch, we recommend `DEEP LEARNING WITH PYTORCH: A 60 "
"MINUTE BLITZ "
"<https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html>`__."
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:276
msgid "Define the model"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:278
msgid ""
"We use the simple CNN described in the `PyTorch tutorial "
"<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#define-a"
"-convolutional-neural-network>`__:"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:315
msgid "Let's continue with the usual training and test functions:"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:375
msgid "Train the model"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:377
msgid ""
"We now have all the basic building blocks we need: a dataset, a model, a "
"training function, and a test function. Let's put them together to train "
"the model on the dataset of one of our organizations "
"(``partition_id=0``). This simulates the reality of most machine learning"
" projects today: each organization has their own data and trains models "
"only on this internal data:"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:406
msgid ""
"Training the simple CNN on our CIFAR-10 split for 5 epochs should result "
"in a test set accuracy of about 41%, which is not good, but at the same "
"time, it doesn't really matter for the purposes of this tutorial. The "
"intent was just to show a simple centralized training pipeline that sets "
"the stage for what comes next - federated learning!"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:418
msgid "Step 2: Federated Learning with Flower"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:420
msgid ""
"Step 1 demonstrated a simple centralized training pipeline. All data was "
"in one place (i.e., a single ``trainloader`` and a single ``valloader``)."
" Next, we'll simulate a situation where we have multiple datasets in "
"multiple organizations and where we train a model over these "
"organizations using federated learning."
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:432
msgid "Update model parameters"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:434
msgid ""
"In federated learning, the server sends global model parameters to the "
"client, and the client updates the local model with parameters received "
"from the server. It then trains the model on the local data (which "
"changes the model parameters locally) and sends the updated/changed model"
" parameters back to the server (or, alternatively, it sends just the "
"gradients back to the server, not the full model parameters)."
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:436
msgid ""
"We need two helper functions to update the local model with parameters "
"received from the server and to get the updated model parameters from the"
" local model: ``set_parameters`` and ``get_parameters``. The following "
"two functions do just that for the PyTorch model above."
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:438
msgid ""
"The details of how this works are not really important here (feel free to"
" consult the PyTorch documentation if you want to learn more). In "
"essence, we use ``state_dict`` to access PyTorch model parameter tensors."
" The parameter tensors are then converted to/from a list of NumPy "
"ndarray's (which the Flower ``NumPyClient`` knows how to "
"serialize/deserialize):"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:466
msgid "Define the Flower ClientApp"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:468
msgid ""
"With that out of the way, let's move on to the interesting part. "
"Federated learning systems consist of a server and multiple clients. In "
"Flower, we create a ``ServerApp`` and a ``ClientApp`` to run the server-"
"side and client-side code, respectively."
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:470
msgid ""
"The first step toward creating a ``ClientApp`` is to implement a "
"subclasses of ``flwr.client.Client`` or ``flwr.client.NumPyClient``. We "
"use ``NumPyClient`` in this tutorial because it is easier to implement "
"and requires us to write less boilerplate. To implement ``NumPyClient``, "
"we create a subclass that implements the three methods "
"``get_parameters``, ``fit``, and ``evaluate``:"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:472
msgid "``get_parameters``: Return the current local model parameters"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:473
msgid ""
"``fit``: Receive model parameters from the server, train the model on the"
" local data, and return the updated model parameters to the server"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:474
msgid ""
"``evaluate``: Receive model parameters from the server, evaluate the "
"model on the local data, and return the evaluation result to the server"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:476
msgid ""
"We mentioned that our clients will use the previously defined PyTorch "
"components for model training and evaluation. Let's see a simple Flower "
"client implementation that brings everything together:"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:513
msgid ""
"Our class ``FlowerClient`` defines how local training/evaluation will be "
"performed and allows Flower to call the local training/evaluation through"
" ``fit`` and ``evaluate``. Each instance of ``FlowerClient`` represents a"
" *single client* in our federated learning system. Federated learning "
"systems have multiple clients (otherwise, there's not much to federate), "
"so each client will be represented by its own instance of "
"``FlowerClient``. If we have, for example, three clients in our workload,"
" then we'd have three instances of ``FlowerClient`` (one on each of the "
"machines we'd start the client on). Flower calls ``FlowerClient.fit`` on "
"the respective instance when the server selects a particular client for "
"training (and ``FlowerClient.evaluate`` for evaluation)."
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:516
msgid ""
"In this notebook, we want to simulate a federated learning system with 10"
" clients *on a single machine*. This means that the server and all 10 "
"clients will live on a single machine and share resources such as CPU, "
"GPU, and memory. Having 10 clients would mean having 10 instances of "
"``FlowerClient`` in memory. Doing this on a single machine can quickly "
"exhaust the available memory resources, even if only a subset of these "
"clients participates in a single round of federated learning."
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:518
msgid ""
"In addition to the regular capabilities where server and clients run on "
"multiple machines, Flower, therefore, provides special simulation "
"capabilities that create ``FlowerClient`` instances only when they are "
"actually necessary for training or evaluation. To enable the Flower "
"framework to create clients when necessary, we need to implement a "
"function that creates a ``FlowerClient`` instance on demand. We typically"
" call this function ``client_fn``. Flower calls ``client_fn`` whenever it"
" needs an instance of one particular client to call ``fit`` or "
"``evaluate`` (those instances are usually discarded after use, so they "
"should not keep any local state). In federated learning experiments using"
" Flower, clients are identified by a partition ID, or ``partition-id``. "
"This ``partition-id`` is used to load different local data partitions for"
" different clients, as can be seen below. The value of ``partition-id`` "
"is retrieved from the ``node_config`` dictionary in the ``Context`` "
"object, which holds the information that persists throughout each "
"training round."
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:522
msgid ""
"With this, we have the class ``FlowerClient`` which defines client-side "
"training/evaluation and ``client_fn`` which allows Flower to create "
"``FlowerClient`` instances whenever it needs to call ``fit`` or "
"``evaluate`` on one particular client. Last, but definitely not least, we"
" create an instance of ``ClientApp`` and pass it the ``client_fn``. "
"``ClientApp`` is the entrypoint that a running Flower client uses to call"
" your code (as defined in, for example, ``FlowerClient.fit``)."
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:563
#, fuzzy
msgid "Define the Flower ServerApp"
msgstr "Clone o repositório do flower."

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:565
msgid ""
"On the server side, we need to configure a strategy which encapsulates "
"the federated learning approach/algorithm, for example, *Federated "
"Averaging* (FedAvg). Flower has a number of built-in strategies, but we "
"can also use our own strategy implementations to customize nearly all "
"aspects of the federated learning approach. For this example, we use the "
"built-in ``FedAvg`` implementation and customize it using a few basic "
"parameters:"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:592
msgid ""
"Similar to ``ClientApp``, we create a ``ServerApp`` using a utility "
"function ``server_fn``. In ``server_fn``, we pass an instance of "
"``ServerConfig`` for defining the number of federated learning rounds "
"(``num_rounds``) and we also pass the previously created ``strategy``. "
"The ``server_fn`` returns a ``ServerAppComponents`` object containing the"
" settings that define the ``ServerApp`` behaviour. ``ServerApp`` is the "
"entrypoint that Flower uses to call all your server-side code (for "
"example, the strategy)."
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:629
msgid "Run the training"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:631
msgid ""
"In simulation, we often want to control the amount of resources each "
"client can use. In the next cell, we specify a ``backend_config`` "
"dictionary with the ``client_resources`` key (required) for defining the "
"amount of CPU and GPU resources each client can access."
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:659
msgid ""
"The last step is the actual call to ``run_simulation`` which - you "
"guessed it - runs the simulation. ``run_simulation`` accepts a number of "
"arguments: - ``server_app`` and ``client_app``: the previously created "
"``ServerApp`` and ``ClientApp`` objects, respectively - "
"``num_supernodes``: the number of ``SuperNodes`` to simulate which equals"
" the number of clients for Flower simulation - ``backend_config``: the "
"resource allocation used in this simulation"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:686
msgid "Behind the scenes"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:688
msgid "So how does this work? How does Flower execute this simulation?"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:690
#, python-format
msgid ""
"When we call ``run_simulation``, we tell Flower that there are 10 clients"
" (``num_supernodes=10``, where 1 ``SuperNode`` launches 1 ``ClientApp``)."
" Flower then goes ahead an asks the ``ServerApp`` to issue an "
"instructions to those nodes using the ``FedAvg`` strategy. ``FedAvg`` "
"knows that it should select 100% of the available clients "
"(``fraction_fit=1.0``), so it goes ahead and selects 10 random clients "
"(i.e., 100% of 10)."
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:692
msgid ""
"Flower then asks the selected 10 clients to train the model. Each of the "
"10 ``ClientApp`` instances receives a message, which causes it to call "
"``client_fn`` to create an instance of ``FlowerClient``. It then calls "
"``.fit()`` on each the ``FlowerClient`` instances and returns the "
"resulting model parameter updates to the ``ServerApp``. When the "
"``ServerApp`` receives the model parameter updates from the clients, it "
"hands those updates over to the strategy (*FedAvg*) for aggregation. The "
"strategy aggregates those updates and returns the new global model, which"
" then gets used in the next round of federated learning."
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:705
msgid "Where's the accuracy?"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:707
msgid ""
"You may have noticed that all metrics except for ``losses_distributed`` "
"are empty. Where did the ``{\"accuracy\": float(accuracy)}`` go?"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:709
msgid ""
"Flower can automatically aggregate losses returned by individual clients,"
" but it cannot do the same for metrics in the generic metrics dictionary "
"(the one with the ``accuracy`` key). Metrics dictionaries can contain "
"very different kinds of metrics and even key/value pairs that are not "
"metrics at all, so the framework does not (and can not) know how to "
"handle these automatically."
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:711
msgid ""
"As users, we need to tell the framework how to handle/aggregate these "
"custom metrics, and we do so by passing metric aggregation functions to "
"the strategy. The strategy will then call these functions whenever it "
"receives fit or evaluate metrics from clients. The two possible functions"
" are ``fit_metrics_aggregation_fn`` and "
"``evaluate_metrics_aggregation_fn``."
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:713
msgid ""
"Let's create a simple weighted averaging function to aggregate the "
"``accuracy`` metric we return from ``evaluate``:"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:781
msgid ""
"We now have a full system that performs federated training and federated "
"evaluation. It uses the ``weighted_average`` function to aggregate custom"
" evaluation metrics and calculates a single ``accuracy`` metric across "
"all clients on the server side."
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:783
msgid ""
"The other two categories of metrics (``losses_centralized`` and "
"``metrics_centralized``) are still empty because they only apply when "
"centralized evaluation is being used. Part two of the Flower tutorial "
"will cover centralized evaluation."
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:795
msgid "Final remarks"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:797
msgid ""
"Congratulations, you just trained a convolutional neural network, "
"federated over 10 clients! With that, you understand the basics of "
"federated learning with Flower. The same approach you've seen can be used"
" with other machine learning frameworks (not just PyTorch) and tasks (not"
" just CIFAR-10 images classification), for example NLP with Hugging Face "
"Transformers or speech with SpeechBrain."
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:799
msgid ""
"In the next notebook, we're going to cover some more advanced concepts. "
"Want to customize your strategy? Initialize parameters on the server "
"side? Or evaluate the aggregated model on the server side? We'll cover "
"all this and more in the next tutorial."
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:817
msgid ""
"The `Flower Federated Learning Tutorial - Part 2 "
"<https://flower.ai/docs/framework/tutorial-use-a-federated-learning-"
"strategy-pytorch.html>`__ goes into more depth about strategies and all "
"the advanced things you can build with them."
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:9
msgid "Use a federated learning strategy"
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:11
msgid ""
"Welcome to the next part of the federated learning tutorial. In previous "
"parts of this tutorial, we introduced federated learning with PyTorch and"
" Flower (`part 1 <https://flower.ai/docs/framework/tutorial-get-started-"
"with-flower-pytorch.html>`__)."
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:13
msgid ""
"In this notebook, we'll begin to customize the federated learning system "
"we built in the introductory notebook again, using the Flower framework, "
"Flower Datasets, and PyTorch."
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:18
msgid "Let's move beyond FedAvg with Flower strategies! 🌼"
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:121
msgid ""
"Let's now load the CIFAR-10 training and test set, partition them into "
"ten smaller datasets (each split into training and validation set), and "
"wrap everything in their own ``DataLoader``. We introduce a new parameter"
" ``num_partitions`` which allows us to call ``load_datasets`` with "
"different numbers of partitions."
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:321
msgid "Strategy customization"
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:323
msgid ""
"So far, everything should look familiar if you've worked through the "
"introductory notebook. With that, we're ready to introduce a number of "
"new features."
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:335
msgid "Server-side parameter **initialization**"
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:337
msgid ""
"Flower, by default, initializes the global model by asking one random "
"client for the initial parameters. In many cases, we want more control "
"over parameter initialization though. Flower therefore allows you to "
"directly pass the initial parameters to the Strategy. We create an "
"instance of ``Net()`` and get the paramaters as follows:"
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:358
msgid ""
"Next, we create a ``server_fn`` that returns the components needed for "
"the server. Within ``server_fn``, we create a Strategy that uses the "
"initial parameters."
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:393
msgid ""
"Passing ``initial_parameters`` to the ``FedAvg`` strategy prevents Flower"
" from asking one of the clients for the initial parameters. In "
"``server_fn``, we pass this new ``strategy`` and a ``ServerConfig`` for "
"defining the number of federated learning rounds (``num_rounds``)."
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:395
msgid ""
"Similar to the ``ClientApp``, we now create the ``ServerApp`` using the "
"``server_fn``:"
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:416
msgid ""
"Last but not least, we specify the resources for each client and run the "
"simulation."
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:448
msgid ""
"If we look closely, we can see that the logs do not show any calls to the"
" ``FlowerClient.get_parameters`` method."
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:460
msgid "Starting with a customized strategy"
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:462
msgid ""
"We've seen the function ``run_simulation`` before. It accepts a number of"
" arguments, amongst them the ``server_app`` which wraps around the "
"strategy and number of training rounds, ``client_app`` which wraps around"
" the ``client_fn`` used to create ``FlowerClient`` instances, and the "
"number of clients to simulate which equals ``num_supernodes``."
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:464
msgid ""
"The strategy encapsulates the federated learning approach/algorithm, for "
"example, ``FedAvg`` or ``FedAdagrad``. Let's try to use a different "
"strategy this time:"
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:509
msgid "Server-side parameter **evaluation**"
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:511
msgid ""
"Flower can evaluate the aggregated model on the server-side or on the "
"client-side. Client-side and server-side evaluation are similar in some "
"ways, but different in others."
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:513
msgid ""
"**Centralized Evaluation** (or *server-side evaluation*) is conceptually "
"simple: it works the same way that evaluation in centralized machine "
"learning does. If there is a server-side dataset that can be used for "
"evaluation purposes, then that's great. We can evaluate the newly "
"aggregated model after each round of training without having to send the "
"model to clients. We're also fortunate in the sense that our entire "
"evaluation dataset is available at all times."
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:515
msgid ""
"**Federated Evaluation** (or *client-side evaluation*) is more complex, "
"but also more powerful: it doesn't require a centralized dataset and "
"allows us to evaluate models over a larger set of data, which often "
"yields more realistic evaluation results. In fact, many scenarios require"
" us to use **Federated Evaluation** if we want to get representative "
"evaluation results at all. But this power comes at a cost: once we start "
"to evaluate on the client side, we should be aware that our evaluation "
"dataset can change over consecutive rounds of learning if those clients "
"are not always available. Moreover, the dataset held by each client can "
"also change over consecutive rounds. This can lead to evaluation results "
"that are not stable, so even if we would not change the model, we'd see "
"our evaluation results fluctuate over consecutive rounds."
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:518
msgid ""
"We've seen how federated evaluation works on the client side (i.e., by "
"implementing the ``evaluate`` method in ``FlowerClient``). Now let's see "
"how we can evaluate aggregated model parameters on the server-side:"
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:549
msgid ""
"We create a ``FedAvg`` strategy and pass ``evaluate_fn`` to it. Then, we "
"create a ``ServerApp`` that uses this strategy."
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:586
msgid "Finally, we run the simulation."
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:613
msgid "Sending/receiving arbitrary values to/from clients"
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:615
msgid ""
"In some situations, we want to configure client-side execution (training,"
" evaluation) from the server-side. One example for that is the server "
"asking the clients to train for a certain number of local epochs. Flower "
"provides a way to send configuration values from the server to the "
"clients using a dictionary. Let's look at an example where the clients "
"receive values from the server through the ``config`` parameter in "
"``fit`` (``config`` is also available in ``evaluate``). The ``fit`` "
"method receives the configuration dictionary through the ``config`` "
"parameter and can then read values from this dictionary. In this example,"
" it reads ``server_round`` and ``local_epochs`` and uses those values to "
"improve the logging and configure the number of local training epochs:"
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:674
msgid ""
"So how can we send this config dictionary from server to clients? The "
"built-in Flower Strategies provide way to do this, and it works similarly"
" to the way server-side evaluation works. We provide a function to the "
"strategy, and the strategy calls this function for every round of "
"federated learning:"
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:704
msgid ""
"Next, we'll pass this function to the FedAvg strategy before starting the"
" simulation:"
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:749
msgid ""
"As we can see, the client logs now include the current round of federated"
" learning (which they read from the ``config`` dictionary). We can also "
"configure local training to run for one epoch during the first and second"
" round of federated learning, and then for two epochs during the third "
"round."
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:751
msgid ""
"Clients can also return arbitrary values to the server. To do so, they "
"return a dictionary from ``fit`` and/or ``evaluate``. We have seen and "
"used this concept throughout this notebook without mentioning it "
"explicitly: our ``FlowerClient`` returns a dictionary containing a custom"
" key/value pair as the third return value in ``evaluate``."
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:763
msgid "Scaling federated learning"
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:765
msgid ""
"As a last step in this notebook, let's see how we can use Flower to "
"experiment with a large number of clients."
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:785
msgid ""
"Note that we can reuse the ``ClientApp`` for different ``num-partitions``"
" since the Context is defined by the ``num_supernodes`` argument in "
"``run_simulation()``."
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:787
#, python-format
msgid ""
"We now have 1000 partitions, each holding 45 training and 5 validation "
"examples. Given that the number of training examples on each client is "
"quite small, we should probably train the model a bit longer, so we "
"configure the clients to perform 3 local training epochs. We should also "
"adjust the fraction of clients selected for training during each round "
"(we don't want all 1000 clients participating in every round), so we "
"adjust ``fraction_fit`` to ``0.025``, which means that only 2.5% of "
"available clients (so 25 clients) will be selected for training each "
"round:"
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:843
msgid ""
"In this notebook, we've seen how we can gradually enhance our system by "
"customizing the strategy, initializing parameters on the server side, "
"choosing a different strategy, and evaluating models on the server-side. "
"That's quite a bit of flexibility with so little code, right?"
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:845
msgid ""
"In the later sections, we've seen how we can communicate arbitrary values"
" between server and clients to fully customize client-side execution. "
"With that capability, we built a large-scale Federated Learning "
"simulation using the Flower Virtual Client Engine and ran an experiment "
"involving 1000 clients in the same workload - all in a Jupyter Notebook!"
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:863
msgid ""
"The `Flower Federated Learning Tutorial - Part 3 "
"<https://flower.ai/docs/framework/tutorial-build-a-strategy-from-scratch-"
"pytorch.html>`__ shows how to build a fully custom ``Strategy`` from "
"scratch."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:9
msgid "What is Federated Learning?"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:13
msgid ""
"In this tutorial, you will learn what federated learning is, build your "
"first system in Flower, and gradually extend it. If you work through all "
"parts of the tutorial, you will be able to build advanced federated "
"learning systems that approach the current state of the art in the field."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:15
msgid ""
"🧑‍🏫 This tutorial starts from zero and expects no familiarity with "
"federated learning. Only a basic understanding of data science and Python"
" programming is assumed."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:17
msgid ""
"`Star Flower on GitHub <https://github.com/adap/flower>`__ ⭐️ and join "
"the open-source Flower community on Slack to connect, ask questions, and "
"get help: `Join Slack <https://flower.ai/join-slack>`__ 🌼 We'd love to "
"hear from you in the ``#introductions`` channel! And if anything is "
"unclear, head over to the ``#questions`` channel."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:19
msgid "Let's get started!"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:31
msgid "Classical Machine Learning"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:33
msgid ""
"Before we begin discussing federated learning, let us quickly recap how "
"most machine learning works today."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:35
msgid ""
"In machine learning, we have a model, and we have data. The model could "
"be a neural network (as depicted here), or something else, like classical"
" linear regression."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:41
msgid "|dbd9718fb89b4e219a54b72b6eecf502|"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:109
msgid "Model and data"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:47
msgid ""
"We train the model using the data to perform a useful task. A task could "
"be to detect objects in images, transcribe an audio recording, or play a "
"game like Go."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:53
msgid "|18916394e69e4fdaafbb56f7bba690d3|"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:111
msgid "Train model using data"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:59
msgid ""
"In practice, the training data we work with doesn't originate on the "
"machine we train the model on."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:61
msgid ""
"This data gets created \"somewhere else\". For instance, the data can "
"originate on a smartphone by the user interacting with an app, a car "
"collecting sensor data, a laptop receiving input via the keyboard, or a "
"smart speaker listening to someone trying to sing a song."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:67
msgid "|20988fac7e2e497ea15f786730279299|"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:113
msgid "Data on a phone"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:73
msgid ""
"What's also important to mention, this \"somewhere else\" is usually not "
"just one place, it's many places. It could be several devices all running"
" the same app. But it could also be several organizations, all generating"
" data for the same task."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:79
msgid "|5d612ca92b074af4a034bf4c0f498d2e|"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:115
msgid "Data is on many devices"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:85
msgid ""
"So to use machine learning, or any kind of data analysis, the approach "
"that has been used in the past was to collect all this data on a central "
"server. This server can be located somewhere in a data center, or "
"somewhere in the cloud."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:91
msgid "|6721ae86e3f348e2bce58d358a2ee79c|"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:117
msgid "Central data collection"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:97
msgid ""
"Once all the data is collected in one place, we can finally use machine "
"learning algorithms to train our model on the data. This is the machine "
"learning approach that we've basically always relied on."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:103
msgid "|d255f931abb44ca8a7eba0d90dfcf6a1|"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:119
msgid "Central model training"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:130
msgid "Challenges of classical machine learning"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:132
msgid ""
"This classical machine learning approach we've just seen can be used in "
"some cases. Great examples include categorizing holiday photos, or "
"analyzing web traffic. Cases, where all the data is naturally available "
"on a centralized server."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:138
msgid "|f98da3b55eca452390fb33429a7d7ebe|"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:173
msgid "Centralized possible"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:144
msgid ""
"But the approach can not be used in many other cases. Cases, where the "
"data is not available on a centralized server, or cases where the data "
"available on one server is not enough to train a good model."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:150
msgid "|10dc1f84d36b432e95d7f61fcd25a701|"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:175
msgid "Centralized impossible"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:156
msgid ""
"There are many reasons why the classical centralized machine learning "
"approach does not work for a large number of highly important real-world "
"use cases. Those reasons include:"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:158
msgid ""
"**Regulations**: GDPR (Europe), CCPA (California), PIPEDA (Canada), LGPD "
"(Brazil), PDPL (Argentina), KVKK (Turkey), POPI (South Africa), FSS "
"(Russia), CDPR (China), PDPB (India), PIPA (Korea), APPI (Japan), PDP "
"(Indonesia), PDPA (Singapore), APP (Australia), and other regulations "
"protect sensitive data from being moved. In fact, those regulations "
"sometimes even prevent single organizations from combining their own "
"users' data for machine learning training because those users live in "
"different parts of the world, and their data is governed by different "
"data protection regulations."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:160
msgid ""
"**User preference**: In addition to regulation, there are use cases where"
" users just expect that no data leaves their device, ever. If you type "
"your passwords and credit card info into the digital keyboard of your "
"phone, you don't expect those passwords to end up on the server of the "
"company that developed that keyboard, do you? In fact, that use case was "
"the reason federated learning was invented in the first place."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:161
msgid ""
"**Data volume**: Some sensors, like cameras, produce such a high data "
"volume that it is neither feasible nor economic to collect all the data "
"(due to, for example, bandwidth or communication efficiency). Think about"
" a national rail service with hundreds of train stations across the "
"country. If each of these train stations is outfitted with a number of "
"security cameras, the volume of raw on-device data they produce requires "
"incredibly powerful and exceedingly expensive infrastructure to process "
"and store. And most of the data isn't even useful."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:164
msgid "Examples where centralized machine learning does not work include:"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:166
msgid ""
"Sensitive healthcare records from multiple hospitals to train cancer "
"detection models."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:167
msgid ""
"Financial information from different organizations to detect financial "
"fraud."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:168
msgid "Location data from your electric car to make better range prediction."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:169
msgid "End-to-end encrypted messages to train better auto-complete models."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:171
msgid ""
"The popularity of privacy-enhancing systems like the `Brave "
"<https://brave.com/>`__ browser or the `Signal <https://signal.org/>`__ "
"messenger shows that users care about privacy. In fact, they choose the "
"privacy-enhancing version over other alternatives, if such an alternative"
" exists. But what can we do to apply machine learning and data science to"
" these cases to utilize private data? After all, these are all areas that"
" would benefit significantly from recent advances in AI."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:186
msgid "Federated Learning"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:188
msgid ""
"Federated Learning simply reverses this approach. It enables machine "
"learning on distributed data by moving the training to the data, instead "
"of moving the data to the training. Here's a one-liner explanation:"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:190
msgid "Centralized machine learning: move the data to the computation"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:191
msgid "Federated (machine) Learning: move the computation to the data"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:193
msgid ""
"By doing so, Federated Learning enables us to use machine learning (and "
"other data science approaches) in areas where it wasn't possible before. "
"We can now train excellent medical AI models by enabling different "
"hospitals to work together. We can solve financial fraud by training AI "
"models on the data of different financial institutions. We can build "
"novel privacy-enhancing applications (such as secure messaging) that have"
" better built-in AI than their non-privacy-enhancing alternatives. And "
"those are just a few of the examples that come to mind. As we deploy "
"Federated Learning, we discover more and more areas that can suddenly be "
"reinvented because they now have access to vast amounts of previously "
"inaccessible data."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:196
msgid ""
"So how does Federated Learning work, exactly? Let's start with an "
"intuitive explanation."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:199
msgid "Federated learning in five steps"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:202
msgid "Step 0: Initialize global model"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:204
msgid ""
"We start by initializing the model on the server. This is exactly the "
"same in classic centralized learning: we initialize the model parameters,"
" either randomly or from a previously saved checkpoint."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:210
msgid "|f963159664b54e40a64a7f1c19414349|"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:307
msgid "Initialize global model"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:217
msgid ""
"Step 1: Send model to a number of connected organizations/devices (client"
" nodes)"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:219
msgid ""
"Next, we send the parameters of the global model to the connected client "
"nodes (think: edge devices like smartphones or servers belonging to "
"organizations). This is to ensure that each participating node starts its"
" local training using the same model parameters. We often use only a few "
"of the connected nodes instead of all nodes. The reason for this is that "
"selecting more and more client nodes has diminishing returns."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:225
msgid "|3647c3b36916415ab40c1597a3ddd4b0|"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:309
msgid "Send global model"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:232
msgid ""
"Step 2: Train model locally on the data of each organization/device "
"(client node)"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:234
msgid ""
"Now that all (selected) client nodes have the latest version of the "
"global model parameters, they start the local training. They use their "
"own local dataset to train their own local model. They don't train the "
"model until full convergence, but they only train for a little while. "
"This could be as little as one epoch on the local data, or even just a "
"few steps (mini-batches)."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:240
msgid "|a3c07b2cf1214488a99267b3757d9426|"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:311
msgid "Train on local data"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:247
msgid "Step 3: Return model updates back to the server"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:249
msgid ""
"After local training, each client node has a slightly different version "
"of the model parameters they originally received. The parameters are all "
"different because each client node has different examples in its local "
"dataset. The client nodes then send those model updates back to the "
"server. The model updates they send can either be the full model "
"parameters or just the gradients that were accumulated during local "
"training."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:255
msgid "|2f6bce3bfacf4c85ac3a7e0fd1d5aa84|"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:313
msgid "Send model updates"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:262
msgid "Step 4: Aggregate model updates into a new global model"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:264
msgid ""
"The server receives model updates from the selected client nodes. If it "
"selected 100 client nodes, it now has 100 slightly different versions of "
"the original global model, each trained on the local data of one client. "
"But didn't we want to have one model that contains the learnings from the"
" data of all 100 client nodes?"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:266
msgid ""
"In order to get one single model, we have to combine all the model "
"updates we received from the client nodes. This process is called "
"*aggregation*, and there are many different ways to do it. The most basic"
" way is called *Federated Averaging* (`McMahan et al., 2016 "
"<https://arxiv.org/abs/1602.05629>`__), often abbreviated as *FedAvg*. "
"*FedAvg* takes the 100 model updates and, as the name suggests, averages "
"them. To be more precise, it takes the *weighted average* of the model "
"updates, weighted by the number of examples each client used for "
"training. The weighting is important to make sure that each data example "
"has the same \"influence\" on the resulting global model. If one client "
"has 10 examples, and another client has 100 examples, then - without "
"weighting - each of the 10 examples would influence the global model ten "
"times as much as each of the 100 examples."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:273
msgid "|19ebdce05cab40d791a2117f743290c3|"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:315
msgid "Aggregate model updates"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:280
msgid "Step 5: Repeat steps 1 to 4 until the model converges"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:282
msgid ""
"Steps 1 to 4 are what we call a single round of federated learning. The "
"global model parameters get sent to the participating client nodes (step "
"1), the client nodes train on their local data (step 2), they send their "
"updated models to the server (step 3), and the server then aggregates the"
" model updates to get a new version of the global model (step 4)."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:284
msgid ""
"During a single round, each client node that participates in that "
"iteration only trains for a little while. This means that after the "
"aggregation step (step 4), we have a model that has been trained on all "
"the data of all participating client nodes, but only for a little while. "
"We then have to repeat this training process over and over again to "
"eventually arrive at a fully trained model that performs well across the "
"data of all client nodes."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:289
msgid ""
"Congratulations, you now understand the basics of federated learning. "
"There's a lot more to discuss, of course, but that was federated learning"
" in a nutshell. In later parts of this tutorial, we will go into more "
"detail. Interesting questions include: How can we select the best client "
"nodes that should participate in the next round? What's the best way to "
"aggregate model updates? How can we handle failing client nodes "
"(stragglers)?"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:294
msgid ""
"Just like we can train a model on the decentralized data of different "
"client nodes, we can also evaluate the model on that data to receive "
"valuable metrics. This is called federated evaluation, sometimes "
"abbreviated as FE. In fact, federated evaluation is an integral part of "
"most federated learning systems."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:297
msgid "Federated Analytics"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:299
msgid ""
"In many cases, machine learning isn't necessary to derive value from "
"data. Data analysis can yield valuable insights, but again, there's often"
" not enough data to get a clear answer. What's the average age at which "
"people develop a certain type of health condition? Federated analytics "
"enables such queries over multiple client nodes. It is usually used in "
"conjunction with other privacy-enhancing technologies like secure "
"aggregation to prevent the server from seeing the results submitted by "
"individual client nodes."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:305
msgid ""
"Differential privacy (DP) is often mentioned in the context of Federated "
"Learning. It is a privacy-preserving method used when analyzing and "
"sharing statistical data, ensuring the privacy of individual "
"participants. DP achieves this by adding statistical noise to the model "
"updates, ensuring any individual participants’ information cannot be "
"distinguished or re-identified. This technique can be considered an "
"optimization that provides a quantifiable privacy protection measure."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:326
msgid "Flower"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:328
msgid ""
"Federated learning, federated evaluation, and federated analytics require"
" infrastructure to move machine learning models back and forth, train and"
" evaluate them on local data, and then aggregate the updated models. "
"Flower provides the infrastructure to do exactly that in an easy, "
"scalable, and secure way. In short, Flower presents a unified approach to"
" federated learning, analytics, and evaluation. It allows the user to "
"federate any workload, any ML framework, and any programming language."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:334
msgid "|dd729f8776d640ffb136545f3f26210f|"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:340
msgid ""
"Flower federated learning server and client nodes (car, scooter, personal"
" computer, roomba, and phone)"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:351
msgid "Final Remarks"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:353
msgid ""
"Congratulations, you just learned the basics of federated learning and "
"how it relates to the classic (centralized) machine learning!"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:355
msgid ""
"In the next part of this tutorial, we are going to build a first "
"federated learning system with Flower."
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:369
msgid ""
"Before you continue, make sure to join the Flower community on Slack: "
"`Join Slack <https://flower.ai/join-slack/>`__"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:373
msgid ""
"The `Flower Federated Learning Tutorial - Part 1 "
"<https://flower.ai/docs/framework/tutorial-get-started-with-flower-"
"pytorch.html>`__ shows how to build a simple federated learning system "
"with PyTorch and Flower."
msgstr ""

#~ msgid ""
#~ "Configuring and setting up the "
#~ ":code:`Dockerfile` as well the configuration"
#~ " for the devcontainer can be a "
#~ "bit more involved. The good thing "
#~ "is you want have to do it. "
#~ "Usually it should be enough to "
#~ "install Docker on your system and "
#~ "ensure its available on your command "
#~ "line. Additionally, install the `VSCode "
#~ "Containers Extension <vscode:extension/ms-vscode-"
#~ "remote.remote-containers>`_."
#~ msgstr ""

#~ msgid ""
#~ "``flwr = { path = "
#~ "\"../../dist/flwr-1.0.0-py3-none-any.whl\" }`` "
#~ "(without extras)"
#~ msgstr ""

#~ msgid ""
#~ "``flwr = { path = "
#~ "\"../../dist/flwr-1.0.0-py3-none-any.whl\", extras ="
#~ " [\"simulation\"] }`` (with extras)"
#~ msgstr ""

#~ msgid "Upload the whl (e.g., ``flwr-1.7.0-py3-none-any.whl``)"
#~ msgstr ""

#~ msgid ""
#~ "Change ``!pip install -q 'flwr[simulation]'"
#~ " torch torchvision matplotlib`` to ``!pip"
#~ " install -q 'flwr-1.7.0-py3-none-"
#~ "any.whl[simulation]' torch torchvision matplotlib``"
#~ msgstr ""

#~ msgid "Before the release"
#~ msgstr ""

#~ msgid ""
#~ "Update the changelog (``changelog.md``) with"
#~ " all relevant changes that happened "
#~ "after the last release. If the "
#~ "last release was tagged ``v1.2.0``, you"
#~ " can use the following URL to "
#~ "see all commits that got merged "
#~ "into ``main`` since then:"
#~ msgstr ""

#~ msgid ""
#~ "`GitHub: Compare v1.2.0...main "
#~ "<https://github.com/adap/flower/compare/v1.2.0...main>`_"
#~ msgstr ""

#~ msgid ""
#~ "Thank the authors who contributed since"
#~ " the last release. This can be "
#~ "done by running the ``./dev/add-"
#~ "shortlog.sh`` convenience script (it can "
#~ "be ran multiple times and will "
#~ "update the names in the list if"
#~ " new contributors were added in the"
#~ " meantime)."
#~ msgstr ""

#~ msgid ""
#~ "Update the ``changelog.md`` section header "
#~ "``Unreleased`` to contain the version "
#~ "number and date for the release "
#~ "you are building. Create a pull "
#~ "request with the change."
#~ msgstr ""

#~ msgid ""
#~ "Tag the release commit with the "
#~ "version number as soon as the PR"
#~ " is merged: ``git tag v0.12.3``, then"
#~ " ``git push --tags``. This will "
#~ "create a draft release on GitHub "
#~ "containing the correct artifacts and the"
#~ " relevant part of the changelog."
#~ msgstr ""

#~ msgid ""
#~ "Note that, in order to build the"
#~ " documentation locally (with ``poetry run"
#~ " make html``, like described below), "
#~ "`Pandoc <https://pandoc.org/installing.html>_` needs "
#~ "to be installed on the system."
#~ msgstr ""

#~ msgid ""
#~ "If you're familiar with how contributing"
#~ " on GitHub works, you can directly"
#~ " checkout our `getting started guide "
#~ "for contributors <https://flower.ai/docs/getting-"
#~ "started-for-contributors.html>`_ and examples "
#~ "of `good first contributions "
#~ "<https://flower.ai/docs/good-first-contributions.html>`_."
#~ msgstr ""

#~ msgid ""
#~ "This will create a `flower/` (or "
#~ "the name of your fork if you "
#~ "renamed it) folder in the current "
#~ "working directory."
#~ msgstr ""

#~ msgid "Otherwise you can always find this option in the `Branches` page."
#~ msgstr ""

#~ msgid ""
#~ "Once you click the `Compare & pull"
#~ " request` button, you should see "
#~ "something similar to this:"
#~ msgstr ""

#~ msgid "Find the source file in `doc/source`"
#~ msgstr ""

#~ msgid ""
#~ "Make the change in the `.rst` file"
#~ " (beware, the dashes under the title"
#~ " should be the same length as "
#~ "the title itself)"
#~ msgstr ""

#~ msgid "Change the file name to `save-progress.rst`"
#~ msgstr ""

#~ msgid "Add a redirect rule to `doc/source/conf.py`"
#~ msgstr ""

#~ msgid ""
#~ "This will cause a redirect from "
#~ "`saving-progress.html` to `save-progress.html`,"
#~ " old links will continue to work."
#~ msgstr ""

#~ msgid ""
#~ "For the lateral navigation bar to "
#~ "work properly, it is very important "
#~ "to update the `index.rst` file as "
#~ "well. This is where we define the"
#~ " whole arborescence of the navbar."
#~ msgstr ""

#~ msgid "Find and modify the file name in `index.rst`"
#~ msgstr ""

#~ msgid "Add CI job to deploy the staging system when the `main` branch changes"
#~ msgstr ""

#~ msgid "`Python 3.7 <https://docs.python.org/3.7/>`_ or above"
#~ msgstr ""

#~ msgid ""
#~ "First, clone the `Flower repository "
#~ "<https://github.com/adap/flower>`_ from GitHub::"
#~ msgstr ""

#~ msgid ""
#~ "Second, create a virtual environment "
#~ "(and activate it). If you chose to"
#~ " use :code:`pyenv` (with the :code"
#~ ":`pyenv-virtualenv` plugin) and already "
#~ "have it installed , you can use"
#~ " the following convenience script (by "
#~ "default it will use :code:`Python "
#~ "3.8.17`, but you can change it by"
#~ " providing a specific :code:`<version>`)::"
#~ msgstr ""

#~ msgid ""
#~ "If you don't have :code:`pyenv` "
#~ "installed, you can use the following "
#~ "script that will install pyenv, set "
#~ "it up and create the virtual "
#~ "environment (with :code:`Python 3.8.17` by "
#~ "default)::"
#~ msgstr ""

#~ msgid ""
#~ "Third, install the Flower package in "
#~ "development mode (think :code:`pip install "
#~ "-e`) along with all necessary "
#~ "dependencies::"
#~ msgstr ""

#~ msgid ""
#~ "Developers could run the full set "
#~ "of Github Actions workflows under their"
#~ " local environment by using `Act "
#~ "<https://github.com/nektos/act>_`. Please refer to"
#~ " the installation instructions under the"
#~ " linked repository and run the next"
#~ " command under Flower main cloned "
#~ "repository folder::"
#~ msgstr ""

#~ msgid ""
#~ "Please note that these components are"
#~ " still experimental, the correct "
#~ "configuration of DP for a specific "
#~ "task is still an unsolved problem."
#~ msgstr ""

#~ msgid ""
#~ "The distribution of the update norm "
#~ "has been shown to vary from "
#~ "task-to-task and to evolve as "
#~ "training progresses. Therefore, we use "
#~ "an adaptive approach [andrew]_ that "
#~ "continuously adjusts the clipping threshold"
#~ " to track a prespecified quantile of"
#~ " the update norm distribution."
#~ msgstr ""

#~ msgid ""
#~ "We make (and attempt to enforce) a"
#~ " number of assumptions that must be"
#~ " satisfied to ensure that the "
#~ "training process actually realises the "
#~ ":math:`(\\epsilon, \\delta)` guarantees the "
#~ "user has in mind when configuring "
#~ "the setup."
#~ msgstr ""

#~ msgid ""
#~ "The first two are useful for "
#~ "eliminating a multitude of complications "
#~ "associated with calibrating the noise to"
#~ " the clipping threshold while the "
#~ "third one is required to comply "
#~ "with the assumptions of the privacy "
#~ "analysis."
#~ msgstr ""

#~ msgid ""
#~ "The first version of our solution "
#~ "was to define a decorator whose "
#~ "constructor accepted, among other things, "
#~ "a boolean valued variable indicating "
#~ "whether adaptive clipping was to be "
#~ "enabled or not. We quickly realized "
#~ "that this would clutter its "
#~ ":code:`__init__()` function with variables "
#~ "corresponding to hyperparameters of adaptive"
#~ " clipping that would remain unused "
#~ "when it was disabled. A cleaner "
#~ "implementation could be achieved by "
#~ "splitting the functionality into two "
#~ "decorators, :code:`DPFedAvgFixed` and "
#~ ":code:`DPFedAvgAdaptive`, with the latter sub-"
#~ " classing the former. The constructors "
#~ "for both classes accept a boolean "
#~ "parameter :code:`server_side_noising`, which, as "
#~ "the name suggests, determines where "
#~ "noising is to be performed."
#~ msgstr ""

#~ msgid ""
#~ ":code:`aggregate_fit()`: We check whether any"
#~ " of the sampled clients dropped out"
#~ " or failed to upload an update "
#~ "before the round timed out. In "
#~ "that case, we need to abort the"
#~ " current round, discarding any successful"
#~ " updates that were received, and move"
#~ " on to the next one. On the "
#~ "other hand, if all clients responded "
#~ "successfully, we must force the "
#~ "averaging of the updates to happen "
#~ "in an unweighted manner by intercepting"
#~ " the :code:`parameters` field of "
#~ ":code:`FitRes` for each received update "
#~ "and setting it to 1. Furthermore, "
#~ "if :code:`server_side_noising=true`, each update "
#~ "is perturbed with an amount of "
#~ "noise equal to what it would have"
#~ " been subjected to had client-side"
#~ " noising being enabled.  This entails "
#~ "*pre*-processing of the arguments to "
#~ "this method before passing them on "
#~ "to the wrappee's implementation of "
#~ ":code:`aggregate_fit()`."
#~ msgstr ""

#~ msgid ""
#~ "McMahan, H. Brendan, et al. \"Learning"
#~ " differentially private recurrent language "
#~ "models.\" arXiv preprint arXiv:1710.06963 "
#~ "(2017)."
#~ msgstr ""

#~ msgid ""
#~ "Andrew, Galen, et al. \"Differentially "
#~ "private learning with adaptive clipping.\" "
#~ "Advances in Neural Information Processing "
#~ "Systems 34 (2021): 17455-17466."
#~ msgstr ""

#~ msgid ""
#~ "The following command can be used "
#~ "to verfiy if Flower was successfully "
#~ "installed. If everything worked, it "
#~ "should print the version of Flower "
#~ "to the command line::"
#~ msgstr ""

#~ msgid "flwr (Python API reference)"
#~ msgstr ""

#~ msgid "start_client"
#~ msgstr ""

#~ msgid "start_numpy_client"
#~ msgstr ""

#~ msgid "start_simulation"
#~ msgstr ""

#~ msgid "server.start_server"
#~ msgstr ""

#~ msgid "server.strategy"
#~ msgstr ""

#~ msgid "server.strategy.Strategy"
#~ msgstr ""

#~ msgid "server.strategy.FedAvg"
#~ msgstr ""

#~ msgid "server.strategy.FedAvgM"
#~ msgstr ""

#~ msgid "server.strategy.FedMedian"
#~ msgstr ""

#~ msgid "server.strategy.QFedAvg"
#~ msgstr ""

#~ msgid "server.strategy.FaultTolerantFedAvg"
#~ msgstr ""

#~ msgid "server.strategy.FedOpt"
#~ msgstr ""

#~ msgid "server.strategy.FedProx"
#~ msgstr ""

#~ msgid "server.strategy.FedAdagrad"
#~ msgstr ""

#~ msgid "server.strategy.FedAdam"
#~ msgstr ""

#~ msgid "server.strategy.FedYogi"
#~ msgstr ""

#~ msgid "server.strategy.FedTrimmedAvg"
#~ msgstr ""

#~ msgid "server.strategy.Krum"
#~ msgstr ""

#~ msgid "server.strategy.FedXgbNnAvg"
#~ msgstr ""

#~ msgid "server.strategy.DPFedAvgAdaptive"
#~ msgstr ""

#~ msgid "server.strategy.DPFedAvgFixed"
#~ msgstr ""

#~ msgid ""
#~ "**Fix the incorrect return types of "
#~ "Strategy** "
#~ "([#2432](https://github.com/adap/flower/pull/2432/files))"
#~ msgstr ""

#~ msgid ""
#~ "The types of the return values in"
#~ " the docstrings in two methods "
#~ "(`aggregate_fit` and `aggregate_evaluate`) now "
#~ "match the hint types in the code."
#~ msgstr ""

#~ msgid ""
#~ "Using the `client_fn`, Flower clients "
#~ "can interchangeably run as standalone "
#~ "processes (i.e. via `start_client`) or "
#~ "in simulation (i.e. via `start_simulation`)"
#~ " without requiring changes to how the"
#~ " client class is defined and "
#~ "instantiated. Calling `start_numpy_client` is "
#~ "now deprecated."
#~ msgstr ""

#~ msgid ""
#~ "**Update Flower Examples** "
#~ "([#2384](https://github.com/adap/flower/pull/2384)), "
#~ "([#2425](https://github.com/adap/flower/pull/2425))"
#~ msgstr ""

#~ msgid ""
#~ "**General updates to baselines** "
#~ "([#2301](https://github.com/adap/flower/pull/2301), "
#~ "[#2305](https://github.com/adap/flower/pull/2305), "
#~ "[#2307](https://github.com/adap/flower/pull/2307), "
#~ "[#2327](https://github.com/adap/flower/pull/2327), "
#~ "[#2435](https://github.com/adap/flower/pull/2435))"
#~ msgstr ""

#~ msgid ""
#~ "**General updates to the simulation "
#~ "engine** ([#2331](https://github.com/adap/flower/pull/2331), "
#~ "[#2447](https://github.com/adap/flower/pull/2447), "
#~ "[#2448](https://github.com/adap/flower/pull/2448))"
#~ msgstr ""

#~ msgid ""
#~ "**General improvements** "
#~ "([#2309](https://github.com/adap/flower/pull/2309), "
#~ "[#2310](https://github.com/adap/flower/pull/2310), "
#~ "[2313](https://github.com/adap/flower/pull/2313), "
#~ "[#2316](https://github.com/adap/flower/pull/2316), "
#~ "[2317](https://github.com/adap/flower/pull/2317),[#2349](https://github.com/adap/flower/pull/2349),"
#~ " [#2360](https://github.com/adap/flower/pull/2360), "
#~ "[#2402](https://github.com/adap/flower/pull/2402), "
#~ "[#2446](https://github.com/adap/flower/pull/2446))"
#~ msgstr ""

#~ msgid ""
#~ "`flower-superlink --driver-api-address "
#~ "\"0.0.0.0:8081\" --fleet-api-address "
#~ "\"0.0.0.0:8086\"`"
#~ msgstr ""

#~ msgid ""
#~ "That's it for the client. We only"
#~ " have to implement :code:`Client` or "
#~ ":code:`NumPyClient` and call "
#~ ":code:`fl.client.start_client()`. The string "
#~ ":code:`\"0.0.0.0:8080\"` tells the client "
#~ "which server to connect to. In our"
#~ " case we can run the server and"
#~ " the client on the same machine, "
#~ "therefore we use :code:`\"0.0.0.0:8080\"`. If"
#~ " we run a truly federated workload"
#~ " with the server and clients running"
#~ " on different machines, all that "
#~ "needs to change is the "
#~ ":code:`server_address` we pass to the "
#~ "client."
#~ msgstr ""

#~ msgid ""
#~ "That's it for the client. We only"
#~ " have to implement :code:`Client` or "
#~ ":code:`NumPyClient` and call "
#~ ":code:`fl.client.start_client()`. The string "
#~ ":code:`\"[::]:8080\"` tells the client which"
#~ " server to connect to. In our "
#~ "case we can run the server and "
#~ "the client on the same machine, "
#~ "therefore we use :code:`\"[::]:8080\"`. If "
#~ "we run a truly federated workload "
#~ "with the server and clients running "
#~ "on different machines, all that needs"
#~ " to change is the :code:`server_address`"
#~ " we point the client at."
#~ msgstr ""

#~ msgid ""
#~ "Let's build a horizontal federated "
#~ "learning system using XGBoost and "
#~ "Flower!"
#~ msgstr ""

#~ msgid ""
#~ "Please refer to the `full code "
#~ "example <https://github.com/adap/flower/tree/main/examples"
#~ "/quickstart-xgboost-horizontal>`_ to learn "
#~ "more."
#~ msgstr ""

#~ msgid ""
#~ "In this notebook, we'll build a "
#~ "federated learning system using Flower "
#~ "and PyTorch. In part 1, we use "
#~ "PyTorch for the model training pipeline"
#~ " and data loading. In part 2, "
#~ "we continue to federate the PyTorch-"
#~ "based pipeline using Flower."
#~ msgstr ""

#~ msgid ""
#~ "Next, we install the necessary packages"
#~ " for PyTorch (``torch`` and "
#~ "``torchvision``) and Flower (``flwr``):"
#~ msgstr ""

#~ msgid ""
#~ "Federated learning can be applied to "
#~ "many different types of tasks across "
#~ "different domains. In this tutorial, we"
#~ " introduce federated learning by training"
#~ " a simple convolutional neural network "
#~ "(CNN) on the popular CIFAR-10 dataset."
#~ " CIFAR-10 can be used to train "
#~ "image classifiers that distinguish between "
#~ "images from ten different classes:"
#~ msgstr ""

#~ msgid ""
#~ "Each organization will act as a "
#~ "client in the federated learning system."
#~ " So having ten organizations participate"
#~ " in a federation means having ten "
#~ "clients connected to the federated "
#~ "learning server:"
#~ msgstr ""

#~ msgid ""
#~ "Let's now load the CIFAR-10 training "
#~ "and test set, partition them into "
#~ "ten smaller datasets (each split into"
#~ " training and validation set), and "
#~ "wrap the resulting partitions by "
#~ "creating a PyTorch ``DataLoader`` for "
#~ "each of them:"
#~ msgstr ""

#~ msgid "|ed6498a023f2477a9ccd57ee4514bda4|"
#~ msgstr ""

#~ msgid "|5a4f742489ac4f819afefdd4dc9ab272|"
#~ msgstr ""

#~ msgid "|3331c80cd05045f6a56524d8e3e76d0c|"
#~ msgstr ""

#~ msgid "|4987b26884ec4b2c8f06c1264bcebe60|"
#~ msgstr ""

#~ msgid "|ec8ae2d778aa493a986eb2fa29c220e5|"
#~ msgstr ""

#~ msgid "|b8949d0669fe4f8eadc9a4932f4e9c57|"
#~ msgstr ""

#~ msgid "|94ff30bdcd09443e8488b5f29932a541|"
#~ msgstr ""

#~ msgid "|48dccf1d6d0544bba8917d2783a47719|"
#~ msgstr ""

#~ msgid "|0366618db96b4f329f0d4372d1150fde|"
#~ msgstr ""

#~ msgid "|ac80eddc76e6478081b1ca35eed029c0|"
#~ msgstr ""

#~ msgid "|1ac94140c317450e89678db133c7f3c2|"
#~ msgstr ""

#~ msgid "|f8850c6e96fc4430b55e53bba237a7c0|"
#~ msgstr ""

#~ msgid "|4a368fdd3fc34adabd20a46752a68582|"
#~ msgstr ""

#~ msgid "|40f69c17bb444652a7c8dfe577cd120e|"
#~ msgstr ""

#~ msgid ""
#~ "Please follow the first section on "
#~ "`Run Flower using Docker "
#~ "<https://flower.ai/docs/framework/how-to-run-"
#~ "flower-using-docker>`_ which covers this"
#~ " step in more detail."
#~ msgstr ""

#~ msgid ""
#~ "Since `Flower 1.5 <https://flower.ai/docs/framework"
#~ "/ref-changelog.html#v1-5-0-2023-08-31>`_ we have "
#~ "introduced translations to our doc "
#~ "pages, but, as you might have "
#~ "noticed, the translations are often "
#~ "imperfect. If you speak languages other"
#~ " than English, you might be able "
#~ "to help us in our effort to "
#~ "make Federated Learning accessible to as"
#~ " many people as possible by "
#~ "contributing to those translations! This "
#~ "might also be a great opportunity "
#~ "for those wanting to become open "
#~ "source contributors with little prerequistes."
#~ msgstr ""

#~ msgid ""
#~ "You input your translation in the "
#~ "textbox at the top and then, once"
#~ " you are happy with it, you "
#~ "either press ``Save and continue`` (to"
#~ " save the translation and go to "
#~ "the next untranslated string), ``Save "
#~ "and stay`` (to save the translation "
#~ "and stay on the same page), "
#~ "``Suggest`` (to add your translation to"
#~ " suggestions for other users to "
#~ "view), or ``Skip`` (to go to the"
#~ " next untranslated string without saving"
#~ " anything)."
#~ msgstr ""

#~ msgid ""
#~ "The first thing we need to do "
#~ "is to define a message type for"
#~ " the RPC system in :code:`transport.proto`."
#~ " Note that we have to do it "
#~ "for both the request and response "
#~ "messages. For more details on the "
#~ "syntax of proto3, please see the  "
#~ "`official documentation <https://developers.google.com"
#~ "/protocol-buffers/docs/proto3>`_."
#~ msgstr ""

#~ msgid ""
#~ "Source: `Official VSCode documentation "
#~ "<https://code.visualstudio.com/docs/remote/containers>`_"
#~ msgstr ""

#~ msgid ""
#~ "`Developing inside a Container "
#~ "<https://code.visualstudio.com/docs/remote/containers#_system-"
#~ "requirements>`_"
#~ msgstr ""

#~ msgid ""
#~ "`Remote development in Containers "
#~ "<https://code.visualstudio.com/docs/remote/containers-"
#~ "tutorial>`_"
#~ msgstr ""

#~ msgid ""
#~ "If you are not familiar with "
#~ "Flower Baselines, you should probably "
#~ "check-out our `contributing guide for "
#~ "baselines <https://flower.ai/docs/contributing-"
#~ "baselines.html>`_."
#~ msgstr ""

#~ msgid ""
#~ "You should then check out the open"
#~ " `issues "
#~ "<https://github.com/adap/flower/issues?q=is%3Aopen+is%3Aissue+label%3A%22new+baseline%22>`_"
#~ " for baseline requests. If you find"
#~ " a baseline that you'd like to "
#~ "work on and that has no assignes,"
#~ " feel free to assign it to "
#~ "yourself and start working on it!"
#~ msgstr ""

#~ msgid ""
#~ "If you're familiar with how contributing"
#~ " on GitHub works, you can directly"
#~ " checkout our `getting started guide "
#~ "for contributors <https://flower.ai/docs/contributor-"
#~ "tutorial-get-started-as-a-contributor.html>`_."
#~ msgstr ""

#~ msgid ""
#~ "Git is a distributed version control "
#~ "tool. This allows for an entire "
#~ "codebase's history to be stored and "
#~ "every developer's machine. It is a "
#~ "software that will need to be "
#~ "installed on your local machine, you "
#~ "can follow this `guide "
#~ "<https://docs.github.com/en/get-started/quickstart/set-"
#~ "up-git>`_ to set it up."
#~ msgstr ""

#~ msgid ""
#~ "A fork is a personal copy of "
#~ "a GitHub repository. To create one "
#~ "for Flower, you must navigate to "
#~ "https://github.com/adap/flower (while connected to"
#~ " your GitHub account) and click the"
#~ " ``Fork`` button situated on the top"
#~ " right of the page."
#~ msgstr ""

#~ msgid ""
#~ "Now we will add an upstream "
#~ "address to our repository. Still in "
#~ "the same directroy, we must run "
#~ "the following command:"
#~ msgstr ""

#~ msgid ""
#~ "This can be achieved by following "
#~ "this `getting started guide for "
#~ "contributors`_ (note that you won't need"
#~ " to clone the repository). Once you"
#~ " are able to write code and "
#~ "test it, you can finally start "
#~ "making changes!"
#~ msgstr ""

#~ msgid ""
#~ "For our documentation, we’ve started to"
#~ " use the `Diàtaxis framework "
#~ "<https://diataxis.fr/>`_."
#~ msgstr ""

#~ msgid ""
#~ "Our “How to” guides should have "
#~ "titles that continue the sencence “How"
#~ " to …”, for example, “How to "
#~ "upgrade to Flower 1.0”."
#~ msgstr ""

#~ msgid ""
#~ "This issue is about changing the "
#~ "title of a doc from present "
#~ "continious to present simple."
#~ msgstr ""

#~ msgid ""
#~ "Let's take the example of “Saving "
#~ "Progress” which we changed to “Save "
#~ "Progress”. Does this pass our check?"
#~ msgstr ""

#~ msgid "Before: ”How to saving progress” ❌"
#~ msgstr ""

#~ msgid "After: ”How to save progress” ✅"
#~ msgstr ""

#~ msgid ""
#~ "This is a tiny change, but it’ll"
#~ " allow us to test your end-"
#~ "to-end setup. After cloning and "
#~ "setting up the Flower repo, here’s "
#~ "what you should do:"
#~ msgstr ""

#~ msgid ""
#~ "Build the docs and check the "
#~ "result: `<https://flower.ai/docs/writing-"
#~ "documentation.html#edit-an-existing-page>`_"
#~ msgstr ""

#~ msgid "Here’s how to change the file name:"
#~ msgstr ""

#~ msgid ""
#~ "Commit the changes (commit messages are"
#~ " always imperative: “Do something”, in "
#~ "this case “Change …”)"
#~ msgstr ""

#~ msgid ""
#~ "`Good first contributions "
#~ "<https://flower.ai/docs/framework/contributor-ref-good-"
#~ "first-contributions.html>`_, where you should"
#~ " particularly look into the "
#~ ":code:`baselines` contributions."
#~ msgstr ""

#~ msgid ""
#~ "If the section is completely empty "
#~ "(without any token) or non-existant, "
#~ "the changelog will just contain the "
#~ "title of the PR for the changelog"
#~ " entry, without any description."
#~ msgstr ""

#~ msgid ""
#~ "Flower uses :code:`pyproject.toml` to manage"
#~ " dependencies and configure development "
#~ "tools (the ones which support it). "
#~ "Poetry is a build tool which "
#~ "supports `PEP 517 "
#~ "<https://www.python.org/dev/peps/pep-0517/>`_."
#~ msgstr ""

#~ msgid ""
#~ "This tutorial will show you how to"
#~ " use Flower to build a federated "
#~ "version of an existing machine learning"
#~ " workload with `FedBN <https://github.com/med-"
#~ "air/FedBN>`_, a federated training strategy"
#~ " designed for non-iid data. We "
#~ "are using PyTorch to train a "
#~ "Convolutional Neural Network(with Batch "
#~ "Normalization layers) on the CIFAR-10 "
#~ "dataset. When applying FedBN, only few"
#~ " changes needed compared to `Example: "
#~ "PyTorch - From Centralized To Federated"
#~ " <https://flower.ai/docs/examples/pytorch-from-"
#~ "centralized-to-federated.html>`_."
#~ msgstr ""

#~ msgid ""
#~ "All files are revised based on "
#~ "`Example: PyTorch - From Centralized To"
#~ " Federated <https://flower.ai/docs/examples/pytorch-"
#~ "from-centralized-to-federated.html>`_. The "
#~ "only thing to do is modifying the"
#~ " file called :code:`cifar.py`, revised part"
#~ " is shown below:"
#~ msgstr ""

#~ msgid ""
#~ "So far this should all look fairly"
#~ " familiar if you've used PyTorch "
#~ "before. Let's take the next step "
#~ "and use what we've built to create"
#~ " a federated learning system within "
#~ "FedBN, the sytstem consists of one "
#~ "server and two clients."
#~ msgstr ""

#~ msgid ""
#~ "If you have read `Example: PyTorch "
#~ "- From Centralized To Federated "
#~ "<https://flower.ai/docs/examples/pytorch-from-"
#~ "centralized-to-federated.html>`_, the following"
#~ " parts are easy to follow, onyl "
#~ ":code:`get_parameters` and :code:`set_parameters` "
#~ "function in :code:`client.py` needed to "
#~ "revise. If not, please read the "
#~ "`Example: PyTorch - From Centralized To"
#~ " Federated <https://flower.ai/docs/examples/pytorch-"
#~ "from-centralized-to-federated.html>`_. first."
#~ msgstr ""

#~ msgid "Example: Walk-Through PyTorch & MNIST"
#~ msgstr ""

#~ msgid ""
#~ "In this tutorial we will learn, "
#~ "how to train a Convolutional Neural "
#~ "Network on MNIST using Flower and "
#~ "PyTorch."
#~ msgstr ""

#~ msgid ""
#~ "Since we want to use PyTorch to"
#~ " solve a computer vision task, let's"
#~ " go ahead an install PyTorch and "
#~ "the **torchvision** library:"
#~ msgstr ""

#~ msgid "Ready... Set... Train!"
#~ msgstr ""

#~ msgid ""
#~ "Now that we have all our "
#~ "dependencies installed, let's run a "
#~ "simple distributed training with two "
#~ "clients and one server. Our training "
#~ "procedure and network architecture are "
#~ "based on PyTorch's `Basic MNIST Example"
#~ " <https://github.com/pytorch/examples/tree/master/mnist>`_. "
#~ "This will allow you see how easy"
#~ " it is to wrap your code with"
#~ " Flower and begin training in a "
#~ "federated way. We provide you with "
#~ "two helper scripts, namely *run-"
#~ "server.sh*, and *run-clients.sh*. Don't "
#~ "be afraid to look inside, they are"
#~ " simple enough =)."
#~ msgstr ""

#~ msgid ""
#~ "Go ahead and launch on a terminal"
#~ " the *run-server.sh* script first as"
#~ " follows:"
#~ msgstr ""

#~ msgid "Now that the server is up and running, go ahead and launch the clients."
#~ msgstr ""

#~ msgid ""
#~ "Et voilà! You should be seeing the"
#~ " training procedure and, after a few"
#~ " iterations, the test accuracy for "
#~ "each client."
#~ msgstr ""

#~ msgid "Now, let's see what is really happening inside."
#~ msgstr ""

#~ msgid ""
#~ "Inside the server helper script *run-"
#~ "server.sh* you will find the following"
#~ " code that basically runs the "
#~ ":code:`server.py`"
#~ msgstr ""

#~ msgid ""
#~ "We can go a bit deeper and "
#~ "see that :code:`server.py` simply launches "
#~ "a server that will coordinate three "
#~ "rounds of training. Flower Servers are"
#~ " very customizable, but for simple "
#~ "workloads, we can start a server "
#~ "using the :ref:`start_server <flwr-server-"
#~ "start_server-apiref>` function and leave "
#~ "all the configuration possibilities at "
#~ "their default values, as seen below."
#~ msgstr ""

#~ msgid ""
#~ "Next, let's take a look at the "
#~ "*run-clients.sh* file. You will see "
#~ "that it contains the main loop "
#~ "that starts a set of *clients*."
#~ msgstr ""

#~ msgid ""
#~ "**cid**: is the client ID. It is"
#~ " an integer that uniquely identifies "
#~ "client identifier."
#~ msgstr ""

#~ msgid "**sever_address**: String that identifies IP and port of the server."
#~ msgstr ""

#~ msgid ""
#~ "**nb_clients**: This defines the number "
#~ "of clients being created. This piece "
#~ "of information is not required by "
#~ "the client, but it helps us "
#~ "partition the original MNIST dataset to"
#~ " make sure that every client is "
#~ "working on unique subsets of both "
#~ "*training* and *test* sets."
#~ msgstr ""

#~ msgid ""
#~ "Again, we can go deeper and look"
#~ " inside :code:`flwr_example/quickstart-"
#~ "pytorch/client.py`. After going through the"
#~ " argument parsing code at the "
#~ "beginning of our :code:`main` function, "
#~ "you will find a call to "
#~ ":code:`mnist.load_data`. This function is "
#~ "responsible for partitioning the original "
#~ "MNIST datasets (*training* and *test*) "
#~ "and returning a :code:`torch.utils.data.DataLoader`"
#~ " s for each of them. We then"
#~ " instantiate a :code:`PytorchMNISTClient` object"
#~ " with our client ID, our DataLoaders,"
#~ " the number of epochs in each "
#~ "round, and which device we want to"
#~ " use for training (CPU or GPU)."
#~ msgstr ""

#~ msgid ""
#~ "The :code:`PytorchMNISTClient` object when "
#~ "finally passed to :code:`fl.client.start_client` "
#~ "along with the server's address as "
#~ "the training process begins."
#~ msgstr ""

#~ msgid "A Closer Look"
#~ msgstr ""

#~ msgid ""
#~ "Now, let's look closely into the "
#~ ":code:`PytorchMNISTClient` inside :code:`flwr_example"
#~ ".quickstart-pytorch.mnist` and see what it"
#~ " is doing:"
#~ msgstr ""

#~ msgid ""
#~ "The first thing to notice is that"
#~ " :code:`PytorchMNISTClient` instantiates a CNN"
#~ " model inside its constructor"
#~ msgstr ""

#~ msgid ""
#~ "The code for the CNN is available"
#~ " under :code:`quickstart-pytorch.mnist` and "
#~ "it is reproduced below. It is the"
#~ " same network found in `Basic MNIST"
#~ " Example "
#~ "<https://github.com/pytorch/examples/tree/master/mnist>`_."
#~ msgstr ""

#~ msgid ""
#~ "The second thing to notice is that"
#~ " :code:`PytorchMNISTClient` class inherits from"
#~ " the :code:`fl.client.Client`, and hence it"
#~ " must implement the following methods:"
#~ msgstr ""

#~ msgid ""
#~ "When comparing the abstract class to "
#~ "its derived class :code:`PytorchMNISTClient` "
#~ "you will notice that :code:`fit` calls"
#~ " a :code:`train` function and that "
#~ ":code:`evaluate` calls a :code:`test`: "
#~ "function."
#~ msgstr ""

#~ msgid ""
#~ "These functions can both be found "
#~ "inside the same :code:`quickstart-"
#~ "pytorch.mnist` module:"
#~ msgstr ""

#~ msgid ""
#~ "Observe that these functions encapsulate "
#~ "regular training and test loops and "
#~ "provide :code:`fit` and :code:`evaluate` with"
#~ " final statistics for each round. You"
#~ " could substitute them with your "
#~ "custom train and test loops and "
#~ "change the network architecture, and the"
#~ " entire example would still work "
#~ "flawlessly. As a matter of fact, "
#~ "why not try and modify the code"
#~ " to an example of your liking?"
#~ msgstr ""

#~ msgid "Give It a Try"
#~ msgstr ""

#~ msgid ""
#~ "Looking through the quickstart code "
#~ "description above will have given a "
#~ "good understanding of how *clients* and"
#~ " *servers* work in Flower, how to "
#~ "run a simple experiment, and the "
#~ "internals of a client wrapper. Here "
#~ "are a few things you could try "
#~ "on your own and get more "
#~ "experience with Flower:"
#~ msgstr ""

#~ msgid ""
#~ "Try and change :code:`PytorchMNISTClient` so"
#~ " it can accept different architectures."
#~ msgstr ""

#~ msgid ""
#~ "Modify the :code:`train` function so "
#~ "that it accepts different optimizers"
#~ msgstr ""

#~ msgid ""
#~ "Modify the :code:`test` function so that"
#~ " it proves not only the top-1 "
#~ "(regular accuracy) but also the top-5"
#~ " accuracy?"
#~ msgstr ""

#~ msgid ""
#~ "Go larger! Try to adapt the code"
#~ " to larger images and datasets. Why"
#~ " not try training on ImageNet with"
#~ " a ResNet-50?"
#~ msgstr ""

#~ msgid "You are ready now. Enjoy learning in a federated way!"
#~ msgstr ""

#~ msgid "Differential privacy"
#~ msgstr ""

#~ msgid ""
#~ "Flower provides differential privacy (DP) "
#~ "wrapper classes for the easy integration"
#~ " of the central DP guarantees "
#~ "provided by DP-FedAvg into training "
#~ "pipelines defined in any of the "
#~ "various ML frameworks that Flower is "
#~ "compatible with."
#~ msgstr ""

#~ msgid ""
#~ "Please note that these components are"
#~ " still experimental; the correct "
#~ "configuration of DP for a specific "
#~ "task is still an unsolved problem."
#~ msgstr ""

#~ msgid ""
#~ "The name DP-FedAvg is misleading "
#~ "since it can be applied on top "
#~ "of any FL algorithm that conforms "
#~ "to the general structure prescribed by"
#~ " the FedOpt family of algorithms."
#~ msgstr ""

#~ msgid "DP-FedAvg"
#~ msgstr ""

#~ msgid ""
#~ "DP-FedAvg, originally proposed by "
#~ "McMahan et al. [mcmahan]_ and extended"
#~ " by Andrew et al. [andrew]_, is "
#~ "essentially FedAvg with the following "
#~ "modifications."
#~ msgstr ""

#~ msgid ""
#~ "**Clipping** : The influence of each "
#~ "client's update is bounded by clipping"
#~ " it. This is achieved by enforcing"
#~ " a cap on the L2 norm of "
#~ "the update, scaling it down if "
#~ "needed."
#~ msgstr ""

#~ msgid ""
#~ "**Noising** :  Gaussian noise, calibrated "
#~ "to the clipping threshold, is added "
#~ "to the average computed at the "
#~ "server."
#~ msgstr ""

#~ msgid ""
#~ "The distribution of the update norm "
#~ "has been shown to vary from "
#~ "task-to-task and to evolve as "
#~ "training progresses. This variability is "
#~ "crucial in understanding its impact on"
#~ " differential privacy guarantees, emphasizing "
#~ "the need for an adaptive approach "
#~ "[andrew]_ that continuously adjusts the "
#~ "clipping threshold to track a "
#~ "prespecified quantile of the update norm"
#~ " distribution."
#~ msgstr ""

#~ msgid "Simplifying Assumptions"
#~ msgstr ""

#~ msgid ""
#~ "We make (and attempt to enforce) a"
#~ " number of assumptions that must be"
#~ " satisfied to ensure that the "
#~ "training process actually realizes the "
#~ ":math:`(\\epsilon, \\delta)` guarantees the "
#~ "user has in mind when configuring "
#~ "the setup."
#~ msgstr ""

#~ msgid ""
#~ "**Fixed-size subsampling** :Fixed-size "
#~ "subsamples of the clients must be "
#~ "taken at each round, as opposed to"
#~ " variable-sized Poisson subsamples."
#~ msgstr ""

#~ msgid ""
#~ "**Unweighted averaging** : The contributions"
#~ " from all the clients must weighted"
#~ " equally in the aggregate to "
#~ "eliminate the requirement for the server"
#~ " to know in advance the sum of"
#~ " the weights of all clients available"
#~ " for selection."
#~ msgstr ""

#~ msgid ""
#~ "**No client failures** : The set "
#~ "of available clients must stay constant"
#~ " across all rounds of training. In"
#~ " other words, clients cannot drop out"
#~ " or fail."
#~ msgstr ""

#~ msgid ""
#~ "The first two are useful for "
#~ "eliminating a multitude of complications "
#~ "associated with calibrating the noise to"
#~ " the clipping threshold, while the "
#~ "third one is required to comply "
#~ "with the assumptions of the privacy "
#~ "analysis."
#~ msgstr ""

#~ msgid ""
#~ "These restrictions are in line with "
#~ "constraints imposed by Andrew et al. "
#~ "[andrew]_."
#~ msgstr ""

#~ msgid "Customizable Responsibility for Noise injection"
#~ msgstr ""

#~ msgid ""
#~ "In contrast to other implementations "
#~ "where the addition of noise is "
#~ "performed at the server, you can "
#~ "configure the site of noise injection"
#~ " to better match your threat model."
#~ " We provide users with the "
#~ "flexibility to set up the training "
#~ "such that each client independently adds"
#~ " a small amount of noise to the"
#~ " clipped update, with the result that"
#~ " simply aggregating the noisy updates "
#~ "is equivalent to the explicit addition"
#~ " of noise to the non-noisy "
#~ "aggregate at the server."
#~ msgstr ""

#~ msgid ""
#~ "To be precise, if we let :math:`m`"
#~ " be the number of clients sampled "
#~ "each round and :math:`\\sigma_\\Delta` be "
#~ "the scale of the total Gaussian "
#~ "noise that needs to be added to"
#~ " the sum of the model updates, "
#~ "we can use simple maths to show"
#~ " that this is equivalent to each "
#~ "client adding noise with scale "
#~ ":math:`\\sigma_\\Delta/\\sqrt{m}`."
#~ msgstr ""

#~ msgid "Wrapper-based approach"
#~ msgstr ""

#~ msgid ""
#~ "Introducing DP to an existing workload"
#~ " can be thought of as adding an"
#~ " extra layer of security around it."
#~ " This inspired us to provide the "
#~ "additional server and client-side logic"
#~ " needed to make the training process"
#~ " differentially private as wrappers for "
#~ "instances of the :code:`Strategy` and "
#~ ":code:`NumPyClient` abstract classes respectively."
#~ " This wrapper-based approach has the"
#~ " advantage of being easily composable "
#~ "with other wrappers that someone might"
#~ " contribute to the Flower library in"
#~ " the future, e.g., for secure "
#~ "aggregation. Using Inheritance instead can "
#~ "be tedious because that would require"
#~ " the creation of new sub- classes "
#~ "every time a new class implementing "
#~ ":code:`Strategy` or :code:`NumPyClient` is "
#~ "defined."
#~ msgstr ""

#~ msgid "Server-side logic"
#~ msgstr ""

#~ msgid ""
#~ "The first version of our solution "
#~ "was to define a decorator whose "
#~ "constructor accepted, among other things, "
#~ "a boolean-valued variable indicating "
#~ "whether adaptive clipping was to be "
#~ "enabled or not. We quickly realized "
#~ "that this would clutter its "
#~ ":code:`__init__()` function with variables "
#~ "corresponding to hyperparameters of adaptive"
#~ " clipping that would remain unused "
#~ "when it was disabled. A cleaner "
#~ "implementation could be achieved by "
#~ "splitting the functionality into two "
#~ "decorators, :code:`DPFedAvgFixed` and "
#~ ":code:`DPFedAvgAdaptive`, with the latter sub-"
#~ " classing the former. The constructors "
#~ "for both classes accept a boolean "
#~ "parameter :code:`server_side_noising`, which, as "
#~ "the name suggests, determines where "
#~ "noising is to be performed."
#~ msgstr ""

#~ msgid ""
#~ "The server-side capabilities required "
#~ "for the original version of DP-"
#~ "FedAvg, i.e., the one which performed"
#~ " fixed clipping, can be completely "
#~ "captured with the help of wrapper "
#~ "logic for just the following two "
#~ "methods of the :code:`Strategy` abstract "
#~ "class."
#~ msgstr ""

#~ msgid ""
#~ ":code:`configure_fit()` : The config "
#~ "dictionary being sent by the wrapped "
#~ ":code:`Strategy` to each client needs to"
#~ " be augmented with an additional "
#~ "value equal to the clipping threshold"
#~ " (keyed under :code:`dpfedavg_clip_norm`) and,"
#~ " if :code:`server_side_noising=true`, another one"
#~ " equal to the scale of the "
#~ "Gaussian noise that needs to be "
#~ "added at the client (keyed under "
#~ ":code:`dpfedavg_noise_stddev`). This entails "
#~ "*post*-processing of the results returned "
#~ "by the wrappee's implementation of "
#~ ":code:`configure_fit()`."
#~ msgstr ""

#~ msgid ""
#~ ":code:`aggregate_fit()`: We check whether any"
#~ " of the sampled clients dropped out"
#~ " or failed to upload an update "
#~ "before the round timed out. In "
#~ "that case, we need to abort the"
#~ " current round, discarding any successful"
#~ " updates that were received, and move"
#~ " on to the next one. On the "
#~ "other hand, if all clients responded "
#~ "successfully, we must force the "
#~ "averaging of the updates to happen "
#~ "in an unweighted manner by intercepting"
#~ " the :code:`parameters` field of "
#~ ":code:`FitRes` for each received update "
#~ "and setting it to 1. Furthermore, "
#~ "if :code:`server_side_noising=true`, each update "
#~ "is perturbed with an amount of "
#~ "noise equal to what it would have"
#~ " been subjected to had client-side"
#~ " noising being enabled. This entails "
#~ "*pre*-processing of the arguments to "
#~ "this method before passing them on "
#~ "to the wrappee's implementation of "
#~ ":code:`aggregate_fit()`."
#~ msgstr ""

#~ msgid ""
#~ "We can't directly change the aggregation"
#~ " function of the wrapped strategy to"
#~ " force it to add noise to the"
#~ " aggregate, hence we simulate client-"
#~ "side noising to implement server-side"
#~ " noising."
#~ msgstr ""

#~ msgid ""
#~ "These changes have been put together "
#~ "into a class called :code:`DPFedAvgFixed`, "
#~ "whose constructor accepts the strategy "
#~ "being decorated, the clipping threshold "
#~ "and the number of clients sampled "
#~ "every round as compulsory arguments. The"
#~ " user is expected to specify the "
#~ "clipping threshold since the order of"
#~ " magnitude of the update norms is "
#~ "highly dependent on the model being "
#~ "trained and providing a default value"
#~ " would be misleading. The number of"
#~ " clients sampled at every round is"
#~ " required to calculate the amount of"
#~ " noise that must be added to "
#~ "each individual update, either by the"
#~ " server or the clients."
#~ msgstr ""

#~ msgid ""
#~ "The additional functionality required to "
#~ "facilitate adaptive clipping has been "
#~ "provided in :code:`DPFedAvgAdaptive`, a "
#~ "subclass of :code:`DPFedAvgFixed`. It "
#~ "overrides the above-mentioned methods to"
#~ " do the following."
#~ msgstr ""

#~ msgid ""
#~ ":code:`configure_fit()` : It intercepts the"
#~ " config dict returned by "
#~ ":code:`super.configure_fit()` to add the "
#~ "key-value pair "
#~ ":code:`dpfedavg_adaptive_clip_enabled:True` to it, "
#~ "which the client interprets as an "
#~ "instruction to include an indicator bit"
#~ " (1 if update norm <= clipping "
#~ "threshold, 0 otherwise) in the results"
#~ " returned by it."
#~ msgstr ""

#~ msgid ""
#~ ":code:`aggregate_fit()` : It follows a "
#~ "call to :code:`super.aggregate_fit()` with one"
#~ " to :code:`__update_clip_norm__()`, a procedure"
#~ " which adjusts the clipping threshold "
#~ "on the basis of the indicator bits"
#~ " received from the sampled clients."
#~ msgstr ""

#~ msgid "Client-side logic"
#~ msgstr ""

#~ msgid ""
#~ "The client-side capabilities required "
#~ "can be completely captured through "
#~ "wrapper logic for just the :code:`fit()`"
#~ " method of the :code:`NumPyClient` abstract"
#~ " class. To be precise, we need "
#~ "to *post-process* the update computed"
#~ " by the wrapped client to clip "
#~ "it, if necessary, to the threshold "
#~ "value supplied by the server as "
#~ "part of the config dictionary. In "
#~ "addition to this, it may need to"
#~ " perform some extra work if either"
#~ " (or both) of the following keys "
#~ "are also present in the dict."
#~ msgstr ""

#~ msgid ""
#~ ":code:`dpfedavg_noise_stddev` : Generate and "
#~ "add the specified amount of noise "
#~ "to the clipped update."
#~ msgstr ""

#~ msgid ""
#~ ":code:`dpfedavg_adaptive_clip_enabled` : Augment the"
#~ " metrics dict in the :code:`FitRes` "
#~ "object being returned to the server "
#~ "with an indicator bit, calculated as "
#~ "described earlier."
#~ msgstr ""

#~ msgid "Performing the :math:`(\\epsilon, \\delta)` analysis"
#~ msgstr ""

#~ msgid ""
#~ "Assume you have trained for :math:`n`"
#~ " rounds with sampling fraction :math:`q`"
#~ " and noise multiplier :math:`z`. In "
#~ "order to calculate the :math:`\\epsilon` "
#~ "value this would result in for a"
#~ " particular :math:`\\delta`, the following "
#~ "script may be used."
#~ msgstr ""

#~ msgid ""
#~ "McMahan et al. \"Learning Differentially "
#~ "Private Recurrent Language Models.\" "
#~ "International Conference on Learning "
#~ "Representations (ICLR), 2017."
#~ msgstr ""

#~ msgid ""
#~ "Andrew, Galen, et al. \"Differentially "
#~ "Private Learning with Adaptive Clipping.\" "
#~ "Advances in Neural Information Processing "
#~ "Systems (NeurIPS), 2021."
#~ msgstr ""

#~ msgid ""
#~ "This can be achieved by customizing "
#~ "an existing strategy or by `implementing"
#~ " a custom strategy from scratch "
#~ "<https://flower.ai/docs/framework/how-to-implement-"
#~ "strategies.html>`_. Here's a nonsensical "
#~ "example that customizes :code:`FedAvg` by "
#~ "adding a custom ``\"hello\": \"world\"`` "
#~ "configuration key/value pair to the "
#~ "config dict of a *single client* "
#~ "(only the first client in the "
#~ "list, the other clients in this "
#~ "round to not receive this \"special\""
#~ " config value):"
#~ msgstr ""

#~ msgid ""
#~ "More sophisticated implementations can use "
#~ ":code:`configure_fit` to implement custom "
#~ "client selection logic. A client will"
#~ " only participate in a round if "
#~ "the corresponding :code:`ClientProxy` is "
#~ "included in the the list returned "
#~ "from :code:`configure_fit`."
#~ msgstr ""

#~ msgid ""
#~ "More sophisticated implementations can use "
#~ ":code:`configure_evaluate` to implement custom "
#~ "client selection logic. A client will"
#~ " only participate in a round if "
#~ "the corresponding :code:`ClientProxy` is "
#~ "included in the the list returned "
#~ "from :code:`configure_evaluate`."
#~ msgstr ""

#~ msgid ""
#~ "`How to run Flower using Docker "
#~ "<https://flower.ai/docs/framework/how-to-run-"
#~ "flower-using-docker.html>`_"
#~ msgstr ""

#~ msgid ""
#~ "Ray Dashboard: `<https://docs.ray.io/en/latest/ray-"
#~ "core/ray-dashboard.html>`_"
#~ msgstr ""

#~ msgid ""
#~ "Ray Metrics: `<https://docs.ray.io/en/latest/ray-"
#~ "observability/ray-metrics.html>`_"
#~ msgstr ""

#~ msgid "Enjoy building more robust and flexible ``ClientApp``s with mods!"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`ClientApp <flwr.client.ClientApp>`\\ "
#~ "\\(client\\_fn\\[\\, mods\\]\\)"
#~ msgstr ""

#~ msgid ":py:obj:`flwr.server.driver <flwr.server.driver>`\\"
#~ msgstr ""

#~ msgid "Flower driver SDK."
#~ msgstr ""

#~ msgid "driver"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`start_driver <flwr.server.driver.start_driver>`\\ "
#~ "\\(\\*\\[\\, server\\_address\\, server\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`Driver <flwr.server.driver.Driver>`\\ "
#~ "\\(\\[driver\\_service\\_address\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`GrpcDriver <flwr.server.driver.GrpcDriver>`\\ "
#~ "\\(\\[driver\\_service\\_address\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "`GrpcDriver` provides access to the gRPC Driver API/service."
#~ msgstr ""

#~ msgid ":py:obj:`get_nodes <flwr.server.driver.Driver.get_nodes>`\\ \\(\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`pull_task_res "
#~ "<flwr.server.driver.Driver.pull_task_res>`\\ \\(task\\_ids\\)"
#~ msgstr ""

#~ msgid "Get task results."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`push_task_ins "
#~ "<flwr.server.driver.Driver.push_task_ins>`\\ "
#~ "\\(task\\_ins\\_list\\)"
#~ msgstr ""

#~ msgid "Schedule tasks."
#~ msgstr ""

#~ msgid "GrpcDriver"
#~ msgstr ""

#~ msgid ":py:obj:`connect <flwr.server.driver.GrpcDriver.connect>`\\ \\(\\)"
#~ msgstr ""

#~ msgid "Connect to the Driver API."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`create_run "
#~ "<flwr.server.driver.GrpcDriver.create_run>`\\ \\(req\\)"
#~ msgstr ""

#~ msgid "Request for run ID."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`disconnect "
#~ "<flwr.server.driver.GrpcDriver.disconnect>`\\ \\(\\)"
#~ msgstr ""

#~ msgid "Disconnect from the Driver API."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`get_nodes <flwr.server.driver.GrpcDriver.get_nodes>`\\"
#~ " \\(req\\)"
#~ msgstr ""

#~ msgid "Get client IDs."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`pull_task_res "
#~ "<flwr.server.driver.GrpcDriver.pull_task_res>`\\ \\(req\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`push_task_ins "
#~ "<flwr.server.driver.GrpcDriver.push_task_ins>`\\ \\(req\\)"
#~ msgstr ""

#~ msgid ""
#~ "Optionally specify the type of actor "
#~ "to use. The actor object, which "
#~ "persists throughout the simulation, will "
#~ "be the process in charge of "
#~ "running the clients' jobs (i.e. their"
#~ " `fit()` method)."
#~ msgstr ""

#~ msgid ""
#~ "Much effort went into a completely "
#~ "restructured Flower docs experience. The "
#~ "documentation on [flower.ai/docs](flower.ai/docs) is"
#~ " now divided into Flower Framework, "
#~ "Flower Baselines, Flower Android SDK, "
#~ "Flower iOS SDK, and code example "
#~ "projects."
#~ msgstr ""

#~ msgid ""
#~ "The first preview release of Flower "
#~ "Baselines has arrived! We're kickstarting "
#~ "Flower Baselines with implementations of "
#~ "FedOpt (FedYogi, FedAdam, FedAdagrad), FedBN,"
#~ " and FedAvgM. Check the documentation "
#~ "on how to use [Flower "
#~ "Baselines](https://flower.ai/docs/using-baselines.html). "
#~ "With this first preview release we're"
#~ " also inviting the community to "
#~ "[contribute their own "
#~ "baselines](https://flower.ai/docs/contributing-baselines.html)."
#~ msgstr ""

#~ msgid ""
#~ "Flower usage examples used to be "
#~ "bundled with Flower in a package "
#~ "called ``flwr_example``. We are migrating "
#~ "those examples to standalone projects to"
#~ " make them easier to use. All "
#~ "new examples are based in the "
#~ "directory `examples "
#~ "<https://github.com/adap/flower/tree/main/examples>`_."
#~ msgstr ""

#~ msgid "The following examples are available as standalone projects."
#~ msgstr ""

#~ msgid "Quickstart TensorFlow/Keras"
#~ msgstr ""

#~ msgid ""
#~ "`Quickstart TensorFlow (Tutorial) "
#~ "<https://flower.ai/docs/framework/tutorial-quickstart-"
#~ "tensorflow.html>`_"
#~ msgstr ""

#~ msgid ""
#~ "`Quickstart PyTorch (Tutorial) "
#~ "<https://flower.ai/docs/framework/tutorial-quickstart-"
#~ "pytorch.html>`_"
#~ msgstr ""

#~ msgid ""
#~ "`PyTorch: From Centralized To Federated "
#~ "(Tutorial) <https://flower.ai/docs/framework/example-"
#~ "pytorch-from-centralized-to-federated.html>`_"
#~ msgstr ""

#~ msgid "Legacy Examples (`flwr_example`)"
#~ msgstr ""

#~ msgid ""
#~ "The useage examples in `flwr_example` "
#~ "are deprecated and will be removed "
#~ "in the future. New examples are "
#~ "provided as standalone projects in "
#~ "`examples <https://github.com/adap/flower/tree/main/examples>`_."
#~ msgstr ""

#~ msgid "Extra Dependencies"
#~ msgstr ""

#~ msgid ""
#~ "The core Flower framework keeps a "
#~ "minimal set of dependencies. The "
#~ "examples demonstrate Flower in the "
#~ "context of different machine learning "
#~ "frameworks, so additional dependencies need"
#~ " to be installed before an example"
#~ " can be run."
#~ msgstr ""

#~ msgid "For PyTorch examples::"
#~ msgstr ""

#~ msgid "For TensorFlow examples::"
#~ msgstr ""

#~ msgid "For both PyTorch and TensorFlow examples::"
#~ msgstr ""

#~ msgid ""
#~ "Please consult :code:`pyproject.toml` for a"
#~ " full list of possible extras "
#~ "(section :code:`[tool.poetry.extras]`)."
#~ msgstr ""

#~ msgid "PyTorch Examples"
#~ msgstr ""

#~ msgid ""
#~ "Our PyTorch examples are based on "
#~ "PyTorch 1.7. They should work with "
#~ "other releases as well. So far, we"
#~ " provide the following examples."
#~ msgstr ""

#~ msgid "CIFAR-10 Image Classification"
#~ msgstr ""

#~ msgid ""
#~ "`CIFAR-10 and CIFAR-100 "
#~ "<https://www.cs.toronto.edu/~kriz/cifar.html>`_ are "
#~ "popular RGB image datasets. The Flower"
#~ " CIFAR-10 example uses PyTorch to "
#~ "train a simple CNN classifier in a"
#~ " federated learning setup with two "
#~ "clients."
#~ msgstr ""

#~ msgid "First, start a Flower server:"
#~ msgstr ""

#~ msgid "$ ./src/py/flwr_example/pytorch_cifar/run-server.sh"
#~ msgstr ""

#~ msgid "Then, start the two clients in a new terminal window:"
#~ msgstr ""

#~ msgid "$ ./src/py/flwr_example/pytorch_cifar/run-clients.sh"
#~ msgstr ""

#~ msgid "For more details, see :code:`src/py/flwr_example/pytorch_cifar`."
#~ msgstr ""

#~ msgid "ImageNet-2012 Image Classification"
#~ msgstr ""

#~ msgid ""
#~ "`ImageNet-2012 <http://www.image-net.org/>`_ is "
#~ "one of the major computer vision "
#~ "datasets. The Flower ImageNet example "
#~ "uses PyTorch to train a ResNet-18 "
#~ "classifier in a federated learning setup"
#~ " with ten clients."
#~ msgstr ""

#~ msgid "$ ./src/py/flwr_example/pytorch_imagenet/run-server.sh"
#~ msgstr ""

#~ msgid "$ ./src/py/flwr_example/pytorch_imagenet/run-clients.sh"
#~ msgstr ""

#~ msgid "For more details, see :code:`src/py/flwr_example/pytorch_imagenet`."
#~ msgstr ""

#~ msgid "TensorFlow Examples"
#~ msgstr ""

#~ msgid ""
#~ "Our TensorFlow examples are based on "
#~ "TensorFlow 2.0 or newer. So far, "
#~ "we provide the following examples."
#~ msgstr ""

#~ msgid "Fashion-MNIST Image Classification"
#~ msgstr ""

#~ msgid ""
#~ "`Fashion-MNIST <https://github.com/zalandoresearch"
#~ "/fashion-mnist>`_ is often used as "
#~ "the \"Hello, world!\" of machine "
#~ "learning. We follow this tradition and"
#~ " provide an example which samples "
#~ "random local datasets from Fashion-MNIST"
#~ " and trains a simple image "
#~ "classification model over those partitions."
#~ msgstr ""

#~ msgid "$ ./src/py/flwr_example/tensorflow_fashion_mnist/run-server.sh"
#~ msgstr ""

#~ msgid "$ ./src/py/flwr_example/tensorflow_fashion_mnist/run-clients.sh"
#~ msgstr ""

#~ msgid ""
#~ "For more details, see "
#~ ":code:`src/py/flwr_example/tensorflow_fashion_mnist`."
#~ msgstr ""

#~ msgid ":fa:`eye,mr-1` Can Flower run on Juptyter Notebooks / Google Colab?"
#~ msgstr ""

#~ msgid ""
#~ "`Flower meets KOSMoS <https://www.kosmos-"
#~ "bmbf.de/wp-content/uploads/sites/13/2021/05/Talk-"
#~ "Flower-Summit-2021.pdf>`_."
#~ msgstr ""

#~ msgid ""
#~ "If you want to check out "
#~ "everything put together, you should "
#~ "check out the full code example: "
#~ "[https://github.com/adap/flower/tree/main/examples/quickstart-"
#~ "huggingface](https://github.com/adap/flower/tree/main/examples"
#~ "/quickstart-huggingface)."
#~ msgstr ""

#~ msgid ""
#~ "First of all, for running the "
#~ "Flower Python server, it is recommended"
#~ " to create a virtual environment and"
#~ " run everything within a `virtualenv "
#~ "<https://flower.ai/docs/recommended-env-setup.html>`_. "
#~ "For the Flower client implementation in"
#~ " iOS, it is recommended to use "
#~ "Xcode as our IDE."
#~ msgstr ""

#~ msgid ""
#~ "Since CoreML does not allow the "
#~ "model parameters to be seen before "
#~ "training, and accessing the model "
#~ "parameters during or after the training"
#~ " can only be done by specifying "
#~ "the layer name, we need to know"
#~ " this informations beforehand, through "
#~ "looking at the model specification, "
#~ "which are written as proto files. "
#~ "The implementation can be seen in "
#~ ":code:`MLModelInspect`."
#~ msgstr ""

#~ msgid ""
#~ "After we have all of the necessary"
#~ " informations, let's create our Flower "
#~ "client."
#~ msgstr ""

#~ msgid ""
#~ "MXNet is no longer maintained and "
#~ "has been moved into `Attic "
#~ "<https://attic.apache.org/projects/mxnet.html>`_. As a "
#~ "result, we would encourage you to "
#~ "use other ML frameworks alongise Flower,"
#~ " for example, PyTorch. This tutorial "
#~ "might be removed in future versions "
#~ "of Flower."
#~ msgstr ""

#~ msgid ""
#~ "It is recommended to create a "
#~ "virtual environment and run everything "
#~ "within this `virtualenv <https://flower.ai/docs"
#~ "/recommended-env-setup.html>`_."
#~ msgstr ""

#~ msgid ""
#~ "First of all, it is recommended to"
#~ " create a virtual environment and run"
#~ " everything within a `virtualenv "
#~ "<https://flower.ai/docs/recommended-env-setup.html>`_."
#~ msgstr ""

#~ msgid "Since we want to use scikt-learn, let's go ahead and install it:"
#~ msgstr ""

#~ msgid ""
#~ "We load the MNIST dataset from "
#~ "`OpenML <https://www.openml.org/d/554>`_, a popular"
#~ " image classification dataset of "
#~ "handwritten digits for machine learning. "
#~ "The utility :code:`utils.load_mnist()` downloads "
#~ "the training and test data. The "
#~ "training set is split afterwards into"
#~ " 10 partitions with :code:`utils.partition()`."
#~ msgstr ""

#~ msgid ""
#~ "Now that you have known how "
#~ "federated XGBoost work with Flower, it's"
#~ " time to run some more comprehensive"
#~ " experiments by customising the "
#~ "experimental settings. In the xgboost-"
#~ "comprehensive example (`full code "
#~ "<https://github.com/adap/flower/tree/main/examples/xgboost-"
#~ "comprehensive>`_), we provide more options "
#~ "to define various experimental setups, "
#~ "including aggregation strategies, data "
#~ "partitioning and centralised/distributed evaluation."
#~ " We also support `Flower simulation "
#~ "<https://flower.ai/docs/framework/how-to-run-"
#~ "simulations.html>`_ making it easy to "
#~ "simulate large client cohorts in a "
#~ "resource-aware manner. Let's take a "
#~ "look!"
#~ msgstr ""

#~ msgid "|31e4b1afa87c4b968327bbeafbf184d4|"
#~ msgstr ""

#~ msgid "|c9d935b4284e4c389a33d86b33e07c0a|"
#~ msgstr ""

#~ msgid "|00727b5faffb468f84dd1b03ded88638|"
#~ msgstr ""

#~ msgid "|daf0cf0ff4c24fd29439af78416cf47b|"
#~ msgstr ""

#~ msgid "|9f093007080d471d94ca90d3e9fde9b6|"
#~ msgstr ""

#~ msgid "|46a26e6150e0479fbd3dfd655f36eb13|"
#~ msgstr ""

#~ msgid "|3daba297595c4c7fb845d90404a6179a|"
#~ msgstr ""

#~ msgid "|5769874fa9c4455b80b2efda850d39d7|"
#~ msgstr ""

#~ msgid "|ba47ffb421814b0f8f9fa5719093d839|"
#~ msgstr ""

#~ msgid "|aeac5bf79cbf497082e979834717e01b|"
#~ msgstr ""

#~ msgid "|ce27ed4bbe95459dba016afc42486ba2|"
#~ msgstr ""

#~ msgid "|ae94a7f71dda443cbec2385751427d41|"
#~ msgstr ""

#~ msgid "|e61fce4d43d243e7bb08bdde97d81ce6|"
#~ msgstr ""

#~ msgid "|08cb60859b07461588fe44e55810b050|"
#~ msgstr ""

#~ msgid "``BASE_IMAGE_TAG``"
#~ msgstr "``BASE_IMAGE_TAG``"

#~ msgid "The image tag of the base image."
#~ msgstr "A tag da imagem da imagem base."

#~ msgid ""
#~ "Open the notebook ``doc/source/tutorial-"
#~ "get-started-with-flower-pytorch.ipynb``:"
#~ msgstr ""

#~ msgid ""
#~ "https://colab.research.google.com/github/adap/flower/blob/main/doc/source"
#~ "/tutorial-get-started-with-flower-"
#~ "pytorch.ipynb"
#~ msgstr ""

#~ msgid ""
#~ "https://colab.research.google.com/github/adap/flower/blob/branch-"
#~ "name/doc/source/tutorial-get-started-with-"
#~ "flower-pytorch.ipynb"
#~ msgstr ""

#~ msgid "Virutualenv with Pyenv/Virtualenv"
#~ msgstr ""

#~ msgid ""
#~ "It is important to follow the "
#~ "instructions described in comments. For "
#~ "instance, in order to not break "
#~ "how our changelog system works, you "
#~ "should read the information above the"
#~ " ``Changelog entry`` section carefully. You"
#~ " can also checkout some examples and"
#~ " details in the :ref:`changelogentry` "
#~ "appendix."
#~ msgstr ""

#~ msgid "Open a PR (as shown above)"
#~ msgstr ""

#~ msgid "How to write a good PR title"
#~ msgstr ""

#~ msgid ""
#~ "A well-crafted PR title helps team"
#~ " members quickly understand the purpose "
#~ "and scope of the changes being "
#~ "proposed. Here's a guide to help "
#~ "you write a good GitHub PR title:"
#~ msgstr ""

#~ msgid ""
#~ "1. Be Clear and Concise: Provide a"
#~ " clear summary of the changes in "
#~ "a concise manner. 1. Use Actionable "
#~ "Verbs: Start with verbs like \"Add,\""
#~ " \"Update,\" or \"Fix\" to indicate "
#~ "the purpose. 1. Include Relevant "
#~ "Information: Mention the affected feature "
#~ "or module for context. 1. Keep it"
#~ " Short: Avoid lengthy titles for easy"
#~ " readability. 1. Use Proper Capitalization"
#~ " and Punctuation: Follow grammar rules "
#~ "for clarity."
#~ msgstr ""

#~ msgid ""
#~ "Let's start with a few examples "
#~ "for titles that should be avoided "
#~ "because they do not provide meaningful"
#~ " information:"
#~ msgstr ""

#~ msgid "Implement Algorithm"
#~ msgstr ""

#~ msgid "Database"
#~ msgstr ""

#~ msgid "Add my_new_file.py to codebase"
#~ msgstr ""

#~ msgid "Improve code in module"
#~ msgstr ""

#~ msgid "Change SomeModule"
#~ msgstr ""

#~ msgid ""
#~ "Here are a few positive examples "
#~ "which provide helpful information without "
#~ "repeating how they do it, as that"
#~ " is already visible in the \"Files"
#~ " changed\" section of the PR:"
#~ msgstr ""

#~ msgid "Update docs banner to mention Flower Summit 2023"
#~ msgstr ""

#~ msgid "Remove unnecessary XGBoost dependency"
#~ msgstr ""

#~ msgid "Remove redundant attributes in strategies subclassing FedAvg"
#~ msgstr ""

#~ msgid ""
#~ "Add CI job to deploy the staging"
#~ " system when the ``main`` branch "
#~ "changes"
#~ msgstr ""

#~ msgid ""
#~ "Add new amazing library which will "
#~ "be used to improve the simulation "
#~ "engine"
#~ msgstr ""

#~ msgid "Changelog entry"
#~ msgstr ""

#~ msgid ""
#~ "When opening a new PR, inside its"
#~ " description, there should be a "
#~ "``Changelog entry`` header."
#~ msgstr ""

#~ msgid ""
#~ "Above this header you should see "
#~ "the following comment that explains how"
#~ " to write your changelog entry:"
#~ msgstr ""

#~ msgid ""
#~ "Inside the following 'Changelog entry' "
#~ "section, you should put the description"
#~ " of your changes that will be "
#~ "added to the changelog alongside your"
#~ " PR title."
#~ msgstr ""

#~ msgid ""
#~ "If the section is completely empty "
#~ "(without any token) or non-existent, "
#~ "the changelog will just contain the "
#~ "title of the PR for the changelog"
#~ " entry, without any description."
#~ msgstr ""

#~ msgid ""
#~ "If the section contains some text "
#~ "other than tokens, it will use it"
#~ " to add a description to the "
#~ "change."
#~ msgstr ""

#~ msgid ""
#~ "If the section contains one of the"
#~ " following tokens it will ignore any"
#~ " other text and put the PR "
#~ "under the corresponding section of the"
#~ " changelog:"
#~ msgstr ""

#~ msgid "<general> is for classifying a PR as a general improvement."
#~ msgstr ""

#~ msgid "<skip> is to not add the PR to the changelog"
#~ msgstr ""

#~ msgid "<baselines> is to add a general baselines change to the PR"
#~ msgstr ""

#~ msgid "<examples> is to add a general examples change to the PR"
#~ msgstr ""

#~ msgid "<sdk> is to add a general sdk change to the PR"
#~ msgstr ""

#~ msgid "<simulations> is to add a general simulations change to the PR"
#~ msgstr ""

#~ msgid "Note that only one token should be used."
#~ msgstr ""

#~ msgid ""
#~ "Its content must have a specific "
#~ "format. We will break down what "
#~ "each possibility does:"
#~ msgstr ""

#~ msgid ""
#~ "If the ``### Changelog entry`` section"
#~ " contains nothing or doesn't exist, "
#~ "the following text will be added "
#~ "to the changelog::"
#~ msgstr ""

#~ msgid ""
#~ "If the ``### Changelog entry`` section"
#~ " contains a description (and no "
#~ "token), the following text will be "
#~ "added to the changelog::"
#~ msgstr ""

#~ msgid ""
#~ "If the ``### Changelog entry`` section"
#~ " contains ``<skip>``, nothing will change"
#~ " in the changelog."
#~ msgstr ""

#~ msgid ""
#~ "If the ``### Changelog entry`` section"
#~ " contains ``<general>``, the following text"
#~ " will be added to the changelog::"
#~ msgstr ""

#~ msgid ""
#~ "If the ``### Changelog entry`` section"
#~ " contains ``<baselines>``, the following "
#~ "text will be added to the "
#~ "changelog::"
#~ msgstr ""

#~ msgid ""
#~ "If the ``### Changelog entry`` section"
#~ " contains ``<examples>``, the following "
#~ "text will be added to the "
#~ "changelog::"
#~ msgstr ""

#~ msgid ""
#~ "If the ``### Changelog entry`` section"
#~ " contains ``<sdk>``, the following text "
#~ "will be added to the changelog::"
#~ msgstr ""

#~ msgid ""
#~ "If the ``### Changelog entry`` section"
#~ " contains ``<simulations>``, the following "
#~ "text will be added to the "
#~ "changelog::"
#~ msgstr ""

#~ msgid ""
#~ "Note that only one token must be"
#~ " provided, otherwise, only the first "
#~ "action (in the order listed above), "
#~ "will be performed."
#~ msgstr ""

#~ msgid "Example: MXNet - Run MXNet Federated"
#~ msgstr ""

#~ msgid ""
#~ "This tutorial will show you how to"
#~ " use Flower to build a federated "
#~ "version of an existing MXNet workload."
#~ " We are using MXNet to train a"
#~ " Sequential model on the MNIST "
#~ "dataset. We will structure the example"
#~ " similar to our `PyTorch - From "
#~ "Centralized To Federated "
#~ "<https://github.com/adap/flower/blob/main/examples/pytorch-"
#~ "from-centralized-to-federated>`_ walkthrough. "
#~ "MXNet and PyTorch are very similar "
#~ "and a very good comparison between "
#~ "MXNet and PyTorch is given `here "
#~ "<https://mxnet.apache.org/versions/1.7.0/api/python/docs/tutorials"
#~ "/getting-started/to-mxnet/pytorch.html>`_. First, "
#~ "we build a centralized training approach"
#~ " based on the `Handwritten Digit "
#~ "Recognition "
#~ "<https://mxnet.apache.org/versions/1.7.0/api/python/docs/tutorials/packages/gluon/image/mnist.html>`_"
#~ " tutorial. Then, we build upon the"
#~ " centralized training code to run the"
#~ " training in a federated fashion."
#~ msgstr ""

#~ msgid ""
#~ "Before we start setting up our "
#~ "MXNet example, we install the "
#~ ":code:`mxnet` and :code:`flwr` packages:"
#~ msgstr ""

#~ msgid "MNIST Training with MXNet"
#~ msgstr ""

#~ msgid ""
#~ "We begin with a brief description "
#~ "of the centralized training code based"
#~ " on a :code:`Sequential` model. If "
#~ "you want a more in-depth "
#~ "explanation of what's going on then "
#~ "have a look at the official `MXNet"
#~ " tutorial "
#~ "<https://mxnet.apache.org/versions/1.7.0/api/python/docs/tutorials/>`_."
#~ msgstr ""

#~ msgid ""
#~ "Let's create a new file "
#~ "called:code:`mxnet_mnist.py` with all the "
#~ "components required for a traditional "
#~ "(centralized) MNIST training. First, the "
#~ "MXNet package :code:`mxnet` needs to be"
#~ " imported. You can see that we "
#~ "do not yet import the :code:`flwr` "
#~ "package for federated learning. This "
#~ "will be done later."
#~ msgstr ""

#~ msgid ""
#~ "The :code:`load_data()` function loads the "
#~ "MNIST training and test sets."
#~ msgstr ""

#~ msgid ""
#~ "As already mentioned, we will use "
#~ "the MNIST dataset for this machine "
#~ "learning workload. The model architecture "
#~ "(a very simple :code:`Sequential` model) "
#~ "is defined in :code:`model()`."
#~ msgstr ""

#~ msgid ""
#~ "We now need to define the training"
#~ " (function :code:`train()`) which loops "
#~ "over the training set and measures "
#~ "the loss for each batch of "
#~ "training examples."
#~ msgstr ""

#~ msgid ""
#~ "The evaluation of the model is "
#~ "defined in function :code:`test()`. The "
#~ "function loops over all test samples "
#~ "and measures the loss and accuracy "
#~ "of the model based on the test "
#~ "dataset."
#~ msgstr ""

#~ msgid ""
#~ "Having defined the data loading, model"
#~ " architecture, training, and evaluation we"
#~ " can put everything together and "
#~ "train our model on MNIST. Note "
#~ "that the GPU/CPU device for the "
#~ "training and testing is defined within"
#~ " the :code:`ctx` (context)."
#~ msgstr ""

#~ msgid "You can now run your (centralized) MXNet machine learning workload:"
#~ msgstr ""

#~ msgid ""
#~ "So far this should all look fairly"
#~ " familiar if you've used MXNet (or"
#~ " even PyTorch) before. Let's take the"
#~ " next step and use what we've "
#~ "built to create a simple federated "
#~ "learning system consisting of one server"
#~ " and two clients."
#~ msgstr ""

#~ msgid "MXNet meets Flower"
#~ msgstr ""

#~ msgid ""
#~ "So far, it was not easily possible"
#~ " to use MXNet workloads for federated"
#~ " learning because federated learning is "
#~ "not supported in MXNet. Since Flower "
#~ "is fully agnostic towards the underlying"
#~ " machine learning framework, it can "
#~ "be used to federated arbitrary machine"
#~ " learning workloads. This section will "
#~ "show you how Flower can be used"
#~ " to federate our centralized MXNet "
#~ "workload."
#~ msgstr ""

#~ msgid ""
#~ "The concept to federate an existing "
#~ "workload is always the same and "
#~ "easy to understand. We have to "
#~ "start a *server* and then use the"
#~ " code in :code:`mxnet_mnist.py` for the "
#~ "*clients* that are connected to the "
#~ "*server*. The *server* sends model "
#~ "parameters to the clients. The *clients*"
#~ " run the training and update the "
#~ "parameters. The updated parameters are "
#~ "sent back to the *server* which "
#~ "averages all received parameter updates. "
#~ "This describes one round of the "
#~ "federated learning process and we repeat"
#~ " this for multiple rounds."
#~ msgstr ""

#~ msgid ""
#~ "Finally, we will define our *client* "
#~ "logic in :code:`client.py` and build "
#~ "upon the previously defined MXNet "
#~ "training in :code:`mxnet_mnist.py`. Our "
#~ "*client* needs to import :code:`flwr`, "
#~ "but also :code:`mxnet` to update the "
#~ "parameters on our MXNet model:"
#~ msgstr ""

#~ msgid ""
#~ "Implementing a Flower *client* basically "
#~ "means implementing a subclass of either"
#~ " :code:`flwr.client.Client` or "
#~ ":code:`flwr.client.NumPyClient`. Our implementation "
#~ "will be based on "
#~ ":code:`flwr.client.NumPyClient` and we'll call "
#~ "it :code:`MNISTClient`. :code:`NumPyClient` is "
#~ "slightly easier to implement than "
#~ ":code:`Client` if you use a framework"
#~ " with good NumPy interoperability (like "
#~ "PyTorch or MXNet) because it avoids "
#~ "some of the boilerplate that would "
#~ "otherwise be necessary. :code:`MNISTClient` "
#~ "needs to implement four methods, two "
#~ "methods for getting/setting model parameters,"
#~ " one method for training the model,"
#~ " and one method for testing the "
#~ "model:"
#~ msgstr ""

#~ msgid "transform MXNet :code:`NDArray`'s to NumPy :code:`ndarray`'s"
#~ msgstr ""

#~ msgid ""
#~ "The challenging part is to transform "
#~ "the MXNet parameters from :code:`NDArray` "
#~ "to :code:`NumPy Arrays` to make it "
#~ "readable for Flower."
#~ msgstr ""

#~ msgid ""
#~ "The two :code:`NumPyClient` methods "
#~ ":code:`fit` and :code:`evaluate` make use "
#~ "of the functions :code:`train()` and "
#~ ":code:`test()` previously defined in "
#~ ":code:`mxnet_mnist.py`. So what we really "
#~ "do here is we tell Flower through"
#~ " our :code:`NumPyClient` subclass which of"
#~ " our already defined functions to "
#~ "call for training and evaluation. We "
#~ "included type annotations to give you"
#~ " a better understanding of the data"
#~ " types that get passed around."
#~ msgstr ""

#~ msgid ""
#~ "Having defined data loading, model "
#~ "architecture, training, and evaluation we "
#~ "can put everything together and train"
#~ " our :code:`Sequential` model on MNIST."
#~ msgstr ""

#~ msgid ""
#~ "in each window (make sure that the"
#~ " server is still running before you"
#~ " do so) and see your MXNet "
#~ "project run federated learning across "
#~ "two clients. Congratulations!"
#~ msgstr ""

#~ msgid ""
#~ "The full source code for this "
#~ "example: `MXNet: From Centralized To "
#~ "Federated (Code) "
#~ "<https://github.com/adap/flower/blob/main/examples/mxnet-"
#~ "from-centralized-to-federated>`_. Our "
#~ "example is of course somewhat over-"
#~ "simplified because both clients load the"
#~ " exact same dataset, which isn't "
#~ "realistic. You're now prepared to "
#~ "explore this topic further. How about"
#~ " using a CNN or using a "
#~ "different dataset? How about adding more"
#~ " clients?"
#~ msgstr ""

#~ msgid ""
#~ "This guide describes how to a "
#~ "SSL-enabled secure Flower server can "
#~ "be started and how a Flower client"
#~ " can establish a secure connections "
#~ "to it."
#~ msgstr ""

#~ msgid ""
#~ "The code example comes with a "
#~ "README.md file which will explain how"
#~ " to start it. Although it is "
#~ "already SSL-enabled, it might be "
#~ "less descriptive on how. Stick to "
#~ "this guide for a deeper introduction "
#~ "to the topic."
#~ msgstr ""

#~ msgid ""
#~ "Using SSL-enabled connections requires "
#~ "certificates to be passed to the "
#~ "server and client. For the purpose "
#~ "of this guide we are going to "
#~ "generate self-signed certificates. As "
#~ "this can become quite complex we "
#~ "are going to ask you to run "
#~ "the script in :code:`examples/advanced-"
#~ "tensorflow/certificates/generate.sh`"
#~ msgstr ""

#~ msgid "with the following command sequence:"
#~ msgstr ""

#~ msgid ""
#~ "The approach how the SSL certificates"
#~ " are generated in this example can"
#~ " serve as an inspiration and starting"
#~ " point but should not be taken "
#~ "as complete for production environments. "
#~ "Please refer to other sources regarding"
#~ " the issue of correctly generating "
#~ "certificates for production environments."
#~ msgstr ""

#~ msgid ""
#~ "In case you are a researcher you"
#~ " might be just fine using the "
#~ "self-signed certificates generated using "
#~ "the scripts which are part of this"
#~ " guide."
#~ msgstr ""

#~ msgid ""
#~ "We are now going to show how "
#~ "to write a sever which uses the"
#~ " previously generated scripts."
#~ msgstr ""

#~ msgid ""
#~ "When providing certificates, the server "
#~ "expects a tuple of three certificates."
#~ " :code:`Path` can be used to easily"
#~ " read the contents of those files "
#~ "into byte strings, which is the "
#~ "data type :code:`start_server` expects."
#~ msgstr ""

#~ msgid ""
#~ "We are now going to show how "
#~ "to write a client which uses the"
#~ " previously generated scripts:"
#~ msgstr ""

#~ msgid ""
#~ "When setting :code:`root_certificates`, the "
#~ "client expects the PEM-encoded root "
#~ "certificates as a byte string. We "
#~ "are again using :code:`Path` to simplify"
#~ " reading those as byte strings."
#~ msgstr ""

#~ msgid ""
#~ "You should now have learned how to"
#~ " generate self-signed certificates using"
#~ " the given script, start a SSL-"
#~ "enabled server, and have a client "
#~ "establish a secure connection to it."
#~ msgstr ""

#~ msgid ""
#~ "The simplest way to get started "
#~ "with Flower is by using the "
#~ "pre-made Docker images, which you can"
#~ " find on `Docker Hub "
#~ "<https://hub.docker.com/r/flwr/server/tags>`_."
#~ msgstr ""

#~ msgid "Flower server"
#~ msgstr ""

#~ msgid ""
#~ "The command will pull the Docker "
#~ "image with the tag "
#~ "``1.7.0-py3.11-ubuntu22.04`` from Docker Hub. "
#~ "The tag contains the information which"
#~ " Flower, Python and Ubuntu is used."
#~ " In this case, it uses Flower "
#~ "1.7.0, Python 3.11 and Ubuntu 22.04. "
#~ "The ``--rm`` flag tells Docker to "
#~ "remove the container after it exits."
#~ msgstr ""

#~ msgid ""
#~ "By default, the Flower server keeps "
#~ "state in-memory. When using the "
#~ "Docker flag ``--rm``, the state is "
#~ "not persisted between container starts. "
#~ "We will show below how to save "
#~ "the state in a file on your "
#~ "host system."
#~ msgstr ""

#~ msgid ""
#~ "The ``-p <host>:<container>`` flag tells "
#~ "Docker to map the ports "
#~ "``9091``/``9092`` of the host to "
#~ "``9091``/``9092`` of the container, allowing"
#~ " you to access the Driver API "
#~ "on ``http://localhost:9091`` and the Fleet "
#~ "API on ``http://localhost:9092``. Lastly, any"
#~ " flag that comes after the tag "
#~ "is passed to the Flower server. "
#~ "Here, we are passing the flag "
#~ "``--insecure``."
#~ msgstr ""

#~ msgid ""
#~ "The ``--insecure`` flag enables insecure "
#~ "communication (using HTTP, not HTTPS) "
#~ "and should only be used for "
#~ "testing purposes. We strongly recommend "
#~ "enabling `SSL <https://flower.ai/docs/framework/how-"
#~ "to-run-flower-using-docker.html#enabling-"
#~ "ssl-for-secure-connections>`_ when "
#~ "deploying to a production environment."
#~ msgstr ""

#~ msgid ""
#~ "You can use ``--help`` to view all"
#~ " available flags that the server "
#~ "supports:"
#~ msgstr ""

#~ msgid ""
#~ "If you want to persist the state"
#~ " of the server on your host "
#~ "system, all you need to do is "
#~ "specify a path where you want to"
#~ " save the file on your host "
#~ "system and a name for the database"
#~ " file. In the example below, we "
#~ "tell Docker via the flag ``-v`` to"
#~ " mount the user's home directory "
#~ "(``~/`` on your host) into the "
#~ "``/app/`` directory of the container. "
#~ "Furthermore, we use the flag "
#~ "``--database`` to specify the name of"
#~ " the database file."
#~ msgstr ""

#~ msgid ""
#~ "As soon as the server starts, the"
#~ " file ``state.db`` is created in the"
#~ " user's home directory on your host"
#~ " system. If the file already exists,"
#~ " the server tries to restore the "
#~ "state from the file. To start the"
#~ " server with an empty database, "
#~ "simply remove the ``state.db`` file."
#~ msgstr ""

#~ msgid ""
#~ "To enable SSL, you will need a "
#~ "CA certificate, a server certificate and"
#~ " a server private key."
#~ msgstr ""

#~ msgid ""
#~ "For testing purposes, you can generate"
#~ " your own self-signed certificates. "
#~ "The `Enable SSL connections "
#~ "<https://flower.ai/docs/framework/how-to-enable-"
#~ "ssl-connections.html#certificates>`_ page contains "
#~ "a section that will guide you "
#~ "through the process."
#~ msgstr ""

#~ msgid ""
#~ "Assuming all files we need are in"
#~ " the local ``certificates`` directory, we"
#~ " can use the flag ``-v`` to "
#~ "mount the local directory into the "
#~ "``/app/`` directory of the container. "
#~ "This allows the server to access "
#~ "the files within the container. Finally,"
#~ " we pass the names of the "
#~ "certificates to the server with the "
#~ "``--certificates`` flag."
#~ msgstr ""

#~ msgid "Using a different Flower or Python version"
#~ msgstr ""

#~ msgid ""
#~ "If you want to use a different "
#~ "version of Flower or Python, you "
#~ "can do so by changing the tag. "
#~ "All versions we provide are available"
#~ " on `Docker Hub "
#~ "<https://hub.docker.com/r/flwr/server/tags>`_."
#~ msgstr ""

#~ msgid ""
#~ "The following command returns the "
#~ "current image hash referenced by the "
#~ "``server:1.7.0-py3.11-ubuntu22.04`` tag:"
#~ msgstr ""

#~ msgid "Next, we can pin the hash when running a new server container:"
#~ msgstr ""

#~ msgid ""
#~ "QUICKSTART TUTORIALS: :doc:`PyTorch <tutorial-"
#~ "quickstart-pytorch>` | :doc:`TensorFlow "
#~ "<tutorial-quickstart-tensorflow>` | :doc:`🤗 "
#~ "Transformers <tutorial-quickstart-huggingface>` "
#~ "| :doc:`JAX <tutorial-quickstart-jax>` |"
#~ " :doc:`Pandas <tutorial-quickstart-pandas>` "
#~ "| :doc:`fastai <tutorial-quickstart-fastai>`"
#~ " | :doc:`PyTorch Lightning <tutorial-"
#~ "quickstart-pytorch-lightning>` | :doc:`MXNet "
#~ "<tutorial-quickstart-mxnet>` | :doc"
#~ ":`scikit-learn <tutorial-quickstart-scikitlearn>`"
#~ " | :doc:`XGBoost <tutorial-quickstart-"
#~ "xgboost>` | :doc:`Android <tutorial-"
#~ "quickstart-android>` | :doc:`iOS <tutorial-"
#~ "quickstart-ios>`"
#~ msgstr ""

#~ msgid "flower-driver-api"
#~ msgstr ""

#~ msgid "flower-fleet-api"
#~ msgstr ""

#~ msgid ""
#~ "Bases: :py:class:`~flwr.common.record.typeddict.TypedDict`\\ "
#~ "[:py:class:`str`, :py:obj:`~typing.Union`\\ "
#~ "[:py:class:`int`, :py:class:`float`, :py:class:`str`, "
#~ ":py:class:`bytes`, :py:class:`bool`, "
#~ ":py:class:`~typing.List`\\ [:py:class:`int`], "
#~ ":py:class:`~typing.List`\\ [:py:class:`float`], "
#~ ":py:class:`~typing.List`\\ [:py:class:`str`], "
#~ ":py:class:`~typing.List`\\ [:py:class:`bytes`], "
#~ ":py:class:`~typing.List`\\ [:py:class:`bool`]]]"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`create_error_reply "
#~ "<flwr.common.Message.create_error_reply>`\\ \\(error\\, "
#~ "ttl\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`create_reply <flwr.common.Message.create_reply>`\\ "
#~ "\\(content\\, ttl\\)"
#~ msgstr ""

#~ msgid ""
#~ "Bases: :py:class:`~flwr.common.record.typeddict.TypedDict`\\ "
#~ "[:py:class:`str`, :py:obj:`~typing.Union`\\ "
#~ "[:py:class:`int`, :py:class:`float`, "
#~ ":py:class:`~typing.List`\\ [:py:class:`int`], "
#~ ":py:class:`~typing.List`\\ [:py:class:`float`]]]"
#~ msgstr ""

#~ msgid "Run Flower server (Driver API and Fleet API)."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`start_driver <flwr.server.start_driver>`\\ "
#~ "\\(\\*\\[\\, server\\_address\\, server\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "Start a Flower Driver API server."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`Driver <flwr.server.Driver>`\\ "
#~ "\\(\\[driver\\_service\\_address\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "`Driver` class provides an interface to the Driver API."
#~ msgstr ""

#~ msgid ""
#~ "The IPv4 or IPv6 address of the"
#~ " Driver API server. Defaults to "
#~ "`\"[::]:9091\"`."
#~ msgstr ""

#~ msgid ":py:obj:`close <flwr.server.Driver.close>`\\ \\(\\)"
#~ msgstr ""

#~ msgid "Disconnect from the SuperLink if connected."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`create_message <flwr.server.Driver.create_message>`\\"
#~ " \\(content\\, message\\_type\\, ...\\)"
#~ msgstr ""

#~ msgid ""
#~ "Time-to-live for the round trip"
#~ " of this message, i.e., the time "
#~ "from sending this message to receiving"
#~ " a reply. It specifies the duration"
#~ " for which the message and its "
#~ "potential reply are considered valid."
#~ msgstr ""

#~ msgid "start\\_driver"
#~ msgstr ""

#~ msgid ""
#~ "The IPv4 or IPv6 address of the"
#~ " Driver API server. Defaults to "
#~ "`\"[::]:8080\"`."
#~ msgstr ""

#~ msgid ""
#~ "A server implementation, either "
#~ "`flwr.server.Server` or a subclass thereof."
#~ " If no instance is provided, then "
#~ "`start_driver` will create one."
#~ msgstr ""

#~ msgid ""
#~ "An implementation of the class "
#~ "`flwr.server.ClientManager`. If no implementation"
#~ " is provided, then `start_driver` will "
#~ "use `flwr.server.SimpleClientManager`."
#~ msgstr ""

#~ msgid "The Driver object to use."
#~ msgstr ""

#~ msgid "Starting a driver that connects to an insecure server:"
#~ msgstr ""

#~ msgid "Starting a driver that connects to an SSL-enabled server:"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`run_simulation_from_cli "
#~ "<flwr.simulation.run_simulation_from_cli>`\\ \\(\\)"
#~ msgstr ""

#~ msgid "Run Simulation Engine from the CLI."
#~ msgstr ""

#~ msgid "run\\_simulation\\_from\\_cli"
#~ msgstr ""

#~ msgid ""
#~ "Check out this Federated Learning "
#~ "quickstart tutorial for using Flower "
#~ "with MXNet to train a Sequential "
#~ "model on MNIST."
#~ msgstr ""

#~ msgid "Quickstart MXNet"
#~ msgstr ""

#~ msgid ""
#~ "MXNet is no longer maintained and "
#~ "has been moved into `Attic "
#~ "<https://attic.apache.org/projects/mxnet.html>`_. As a "
#~ "result, we would encourage you to "
#~ "use other ML frameworks alongside "
#~ "Flower, for example, PyTorch. This "
#~ "tutorial might be removed in future "
#~ "versions of Flower."
#~ msgstr ""

#~ msgid ""
#~ "In this tutorial, we will learn "
#~ "how to train a :code:`Sequential` model"
#~ " on MNIST using Flower and MXNet."
#~ msgstr ""

#~ msgid "Since we want to use MXNet, let's go ahead and install it:"
#~ msgstr ""

#~ msgid ""
#~ "Now that we have all our "
#~ "dependencies installed, let's run a "
#~ "simple distributed training with two "
#~ "clients and one server. Our training "
#~ "procedure and network architecture are "
#~ "based on MXNet´s `Hand-written Digit "
#~ "Recognition tutorial "
#~ "<https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/image/mnist.html>`_."
#~ msgstr ""

#~ msgid ""
#~ "In a file called :code:`client.py`, "
#~ "import Flower and MXNet related "
#~ "packages:"
#~ msgstr ""

#~ msgid "In addition, define the device allocation in MXNet with:"
#~ msgstr ""

#~ msgid ""
#~ "We use MXNet to load MNIST, a "
#~ "popular image classification dataset of "
#~ "handwritten digits for machine learning. "
#~ "The MXNet utility :code:`mx.test_utils.get_mnist()`"
#~ " downloads the training and test "
#~ "data."
#~ msgstr ""

#~ msgid ""
#~ "Define the training and loss with "
#~ "MXNet. We train the model by "
#~ "looping over the dataset, measure the"
#~ " corresponding loss, and optimize it."
#~ msgstr ""

#~ msgid ""
#~ "Next, we define the validation of "
#~ "our machine learning model. We loop "
#~ "over the test set and measure both"
#~ " loss and accuracy on the test "
#~ "set."
#~ msgstr ""

#~ msgid ""
#~ "After defining the training and testing"
#~ " of a MXNet machine learning model,"
#~ " we use these functions to implement"
#~ " a Flower client."
#~ msgstr ""

#~ msgid "Our Flower clients will use a simple :code:`Sequential` model:"
#~ msgstr ""

#~ msgid ""
#~ "After loading the dataset with "
#~ ":code:`load_data()` we perform one forward "
#~ "propagation to initialize the model and"
#~ " model parameters with :code:`model(init)`. "
#~ "Next, we implement a Flower client."
#~ msgstr ""

#~ msgid ""
#~ "Flower provides a convenience class "
#~ "called :code:`NumPyClient` which makes it "
#~ "easier to implement the :code:`Client` "
#~ "interface when your workload uses MXNet."
#~ " Implementing :code:`NumPyClient` usually means"
#~ " defining the following methods "
#~ "(:code:`set_parameters` is optional though):"
#~ msgstr ""

#~ msgid "They can be implemented in the following way:"
#~ msgstr ""

#~ msgid ""
#~ "We can now create an instance of"
#~ " our class :code:`MNISTClient` and add "
#~ "one line to actually run this "
#~ "client:"
#~ msgstr ""

#~ msgid ""
#~ "That's it for the client. We only"
#~ " have to implement :code:`Client` or "
#~ ":code:`NumPyClient` and call "
#~ ":code:`fl.client.start_client()` or "
#~ ":code:`fl.client.start_numpy_client()`. The string "
#~ ":code:`\"0.0.0.0:8080\"` tells the client "
#~ "which server to connect to. In our"
#~ " case we can run the server and"
#~ " the client on the same machine, "
#~ "therefore we use :code:`\"0.0.0.0:8080\"`. If"
#~ " we run a truly federated workload"
#~ " with the server and clients running"
#~ " on different machines, all that "
#~ "needs to change is the "
#~ ":code:`server_address` we pass to the "
#~ "client."
#~ msgstr ""

#~ msgid ""
#~ "With both client and server ready, "
#~ "we can now run everything and see"
#~ " federated learning in action. Federated"
#~ " learning systems usually have a "
#~ "server and multiple clients. We "
#~ "therefore have to start the server "
#~ "first:"
#~ msgstr ""

#~ msgid ""
#~ "Congratulations! You've successfully built and"
#~ " run your first federated learning "
#~ "system. The full `source code "
#~ "<https://github.com/adap/flower/blob/main/examples/quickstart-"
#~ "mxnet/client.py>`_ for this example can "
#~ "be found in :code:`examples/quickstart-mxnet`."
#~ msgstr ""

#~ msgid "Sets the parameters of a :code:`sklean` LogisticRegression model"
#~ msgstr ""

#~ msgid ":code:`load_mnist()`"
#~ msgstr ""

#~ msgid "Loads the MNIST dataset using OpenML"
#~ msgstr ""

#~ msgid ":code:`shuffle()`"
#~ msgstr ""

#~ msgid "Shuffles data and its label"
#~ msgstr ""

#~ msgid ":code:`partition()`"
#~ msgstr ""

#~ msgid "Splits datasets into a number of partitions"
#~ msgstr ""

#~ msgid ""
#~ "We load the MNIST dataset from "
#~ "`OpenML "
#~ "<https://www.openml.org/search?type=data&sort=runs&id=554>`_, a"
#~ " popular image classification dataset of"
#~ " handwritten digits for machine learning."
#~ " The utility :code:`utils.load_mnist()` downloads"
#~ " the training and test data. The "
#~ "training set is split afterwards into"
#~ " 10 partitions with :code:`utils.partition()`."
#~ msgstr ""

#~ msgid ""
#~ "The number of federated learning rounds"
#~ " is set in :code:`fit_round()` and "
#~ "the evaluation is defined in "
#~ ":code:`get_evaluate_fn()`. The evaluation function"
#~ " is called after each federated "
#~ "learning round and gives you information"
#~ " about loss and accuracy."
#~ msgstr ""

#~ msgid "Let's get stated!"
#~ msgstr ""

#~ msgid ""
#~ "We now have a list of ten "
#~ "training sets and ten validation sets"
#~ " (``trainloaders`` and ``valloaders``) "
#~ "representing the data of ten different"
#~ " organizations. Each ``trainloader``/``valloader`` "
#~ "pair contains 4500 training examples and"
#~ " 500 validation examples. There's also "
#~ "a single ``testloader`` (we did not "
#~ "split the test set). Again, this "
#~ "is only necessary for building research"
#~ " or educational systems, actual federated"
#~ " learning systems have their data "
#~ "naturally distributed across multiple "
#~ "partitions."
#~ msgstr ""

#~ msgid "|2b5c62c529f6416f840c594cce062fbb|"
#~ msgstr ""

#~ msgid "|90b334680cb7467d9a04d39b8e8dca9f|"
#~ msgstr ""

#~ msgid "|65764ceee89f4335bfd93fd0b115e831|"
#~ msgstr ""

#~ msgid "|d97319ec28bb407ea0ab9705e38f3bcf|"
#~ msgstr ""

#~ msgid "|11e95ac83a8548d8b3505b4663187d07|"
#~ msgstr ""

#~ msgid "|1dab2f3a23674abc8a6731f20fa10730|"
#~ msgstr ""

#~ msgid "|7f0ee162da38450788493a21627306f7|"
#~ msgstr ""

#~ msgid "|296a1fb72c514b23b3d8905ff0ff98c6|"
#~ msgstr ""

#~ msgid "|5b1408eec0d746cdb91162a9107b6089|"
#~ msgstr ""

#~ msgid "|aef19f4b122c4e8d9f4c57f99bcd5dd2|"
#~ msgstr ""

#~ msgid "|2881a86d8fc54ba29d96b29fc2819f4a|"
#~ msgstr ""

#~ msgid "|ec1fe880237247e0975f52766775ab84|"
#~ msgstr ""

#~ msgid "|9fdf048ed58d4467b2718cdf4aaf1ec3|"
#~ msgstr ""

#~ msgid "|ff726bc5505e432388ee2fdd6ef420b9|"
#~ msgstr ""

#~ msgid ""
#~ "Currently, Flower provides two images, a"
#~ " ``base`` image and a ``superlink`` "
#~ "image. The base image, as the name"
#~ " suggests, contains basic dependencies that"
#~ " the SuperLink needs. This includes "
#~ "system dependencies, Python and Python "
#~ "tools. The SuperLink image is based "
#~ "on the base image, but it "
#~ "additionally installs the SuperLink using "
#~ "``pip``."
#~ msgstr ""
#~ "Atualmente, Flower fornece duas imagens, "
#~ "uma imagem base e uma imagem de"
#~ " servidor. Também haverá uma imagem "
#~ "de cliente em breve. A imagem "
#~ "base, como o nome sugere, contém "
#~ "dependências básicas que tanto o "
#~ "servidor quanto o cliente precisam. Isso"
#~ " inclui dependências do sistema, Python "
#~ "e ferramentas Python. A imagem do "
#~ "servidor é baseada na imagem base, "
#~ "mas também instala o servidor Flower "
#~ "usando ``pip```."

#~ msgid "``3.11``"
#~ msgstr "``3.11``"

#~ msgid "Defaults to ``22.04``."
#~ msgstr "Como padrão ``22.04``."

#~ msgid "Building the SuperLink image"
#~ msgstr "Construindo a imagem do servidor"

#~ msgid "Defaults to ``flwr/base``."
#~ msgstr "Pré-definido para ``flwr/server``."

#~ msgid "The Python version of the base image."
#~ msgstr "O nome do repositório da imagem base."

#~ msgid "Defaults to ``py3.11``."
#~ msgstr "Como padrão ``22.04``."

#~ msgid "Defaults to ``ubuntu22.04``."
#~ msgstr "Pré-definido para ``py3.11-ubuntu22.04``."

#~ msgid "The PyPI package to install."
#~ msgstr ""

#~ msgid "Defaults to ``flwr``."
#~ msgstr "Pré-definido para ``flwr/server``."

#~ msgid ""
#~ "The name of image is ``flwr_superlink``"
#~ " and the tag ``0.1.0``. Remember that"
#~ " the build arguments as well as "
#~ "the name and tag can be adapted"
#~ " to your needs. These values serve"
#~ " as examples only."
#~ msgstr ""
#~ "O nome da imagem é ``flwr_server`` "
#~ "e a tag ``0.1.0``. Lembre-se que"
#~ " os argumentos de compilação, bem "
#~ "como o nome e a tag podem "
#~ "ser adaptados às suas necessidades. "
#~ "Esses valores servem apenas como "
#~ "exemplos."

#~ msgid "Creating New Messages"
#~ msgstr "Criando novas mensagens"

#~ msgid ""
#~ "This is a simple guide for "
#~ "creating a new type of message "
#~ "between the server and clients in "
#~ "Flower."
#~ msgstr ""

#~ msgid ""
#~ "Let's suppose we have the following "
#~ "example functions in :code:`server.py` and "
#~ ":code:`numpy_client.py`..."
#~ msgstr ""

#~ msgid "Server's side:"
#~ msgstr ""

#~ msgid "Client's side:"
#~ msgstr ""

#~ msgid ""
#~ "Let's now see what we need to "
#~ "implement in order to get this "
#~ "simple function between the server and"
#~ " client to work!"
#~ msgstr ""

#~ msgid "Message Types for Protocol Buffers"
#~ msgstr ""

#~ msgid ""
#~ "The first thing we need to do "
#~ "is to define a message type for"
#~ " the RPC system in :code:`transport.proto`."
#~ " Note that we have to do it "
#~ "for both the request and response "
#~ "messages. For more details on the "
#~ "syntax of proto3, please see the  "
#~ "`official documentation <https://protobuf.dev"
#~ "/programming-guides/proto3/>`_."
#~ msgstr ""

#~ msgid "Within the :code:`ServerMessage` block:"
#~ msgstr ""

#~ msgid "Within the ClientMessage block:"
#~ msgstr ""

#~ msgid ""
#~ "Make sure to also add a field "
#~ "of the newly created message type "
#~ "in :code:`oneof msg`."
#~ msgstr ""

#~ msgid "Once that is done, we will compile the file with:"
#~ msgstr ""

#~ msgid "If it compiles successfully, you should see the following message:"
#~ msgstr ""

#~ msgid "Serialization and Deserialization Functions"
#~ msgstr ""

#~ msgid ""
#~ "Our next step is to add functions"
#~ " to serialize and deserialize Python "
#~ "datatypes to or from our defined "
#~ "RPC message types. You should add "
#~ "these functions in :code:`serde.py`."
#~ msgstr ""

#~ msgid "The four functions:"
#~ msgstr ""

#~ msgid "Sending the Message from the Server"
#~ msgstr ""

#~ msgid ""
#~ "Now write the request function in "
#~ "your Client Proxy class (e.g., "
#~ ":code:`grpc_client_proxy.py`) using the serde "
#~ "functions you just created:"
#~ msgstr ""

#~ msgid "Receiving the Message by the Client"
#~ msgstr ""

#~ msgid ""
#~ "Last step! Modify the code in "
#~ ":code:`message_handler.py` to check the field"
#~ " of your message and call the "
#~ ":code:`example_response` function. Remember to "
#~ "use the serde functions!"
#~ msgstr ""

#~ msgid "Within the handle function:"
#~ msgstr ""

#~ msgid "And add a new function:"
#~ msgstr ""

#~ msgid "Hopefully, when you run your program you will get the intended result!"
#~ msgstr ""

#~ msgid ""
#~ "The simplest way to get started "
#~ "with Flower is by using the "
#~ "pre-made Docker images, which you can"
#~ " find on `Docker Hub "
#~ "<https://hub.docker.com/u/flwr>`__."
#~ msgstr ""

#~ msgid ""
#~ "If you want to persist the state"
#~ " of the SuperLink on your host "
#~ "system, all you need to do is "
#~ "specify a path where you want to"
#~ " save the file on your host "
#~ "system and a name for the database"
#~ " file. In the example below, we "
#~ "tell Docker via the flag ``--volume``"
#~ " to mount the user's home directory"
#~ " (``~/`` on your host) into the "
#~ "``/app/`` directory of the container. "
#~ "Furthermore, we use the flag "
#~ "``--database`` to specify the name of"
#~ " the database file."
#~ msgstr ""

#~ msgid ""
#~ "As soon as the SuperLink starts, "
#~ "the file ``state.db`` is created in "
#~ "the user's home directory on your "
#~ "host system. If the file already "
#~ "exists, the SuperLink tries to restore"
#~ " the state from the file. To "
#~ "start the SuperLink with an empty "
#~ "database, simply remove the ``state.db`` "
#~ "file."
#~ msgstr ""

#~ msgid ""
#~ "Assuming all files we need are in"
#~ " the local ``certificates`` directory, we"
#~ " can use the flag ``--volume`` to "
#~ "mount the local directory into the "
#~ "``/app/`` directory of the container. "
#~ "This allows the SuperLink to access "
#~ "the files within the container. Finally,"
#~ " we pass the names of the "
#~ "certificates to the SuperLink with the"
#~ " ``--certificates`` flag."
#~ msgstr ""

#~ msgid ""
#~ "``--server 192.168.1.100:9092``: This option "
#~ "specifies the address of the SuperLinks"
#~ " Fleet"
#~ msgstr ""

#~ msgid ""
#~ "Assuming the certificate already exists "
#~ "locally, we can use the flag "
#~ "``--volume`` to mount the local "
#~ "certificate into the container's ``/app/`` "
#~ "directory. This allows the SuperNode to"
#~ " access the certificate within the "
#~ "container. Use the ``--certificates`` flag "
#~ "when starting the container."
#~ msgstr ""

#~ msgid ""
#~ "``--server 192.168.1.100:9091``: This option "
#~ "specifies the address of the SuperLinks"
#~ " Driver"
#~ msgstr ""

#~ msgid ""
#~ "Assuming the certificate already exists "
#~ "locally, we can use the flag "
#~ "``--volume`` to mount the local "
#~ "certificate into the container's ``/app/`` "
#~ "directory. This allows the ServerApp to"
#~ " access the certificate within the "
#~ "container. Use the ``--certificates`` flag "
#~ "when starting the container."
#~ msgstr ""

#~ msgid ""
#~ "If you want to use a different "
#~ "version of Flower, for example Flower"
#~ " nightly, you can do so by "
#~ "changing the tag. All available versions"
#~ " are on `Docker Hub "
#~ "<https://hub.docker.com/r/flwr/superlink/tags>`__."
#~ msgstr ""

#~ msgid ""
#~ "Here's another example to start with "
#~ "HTTPS. Use the ``--certificates`` command "
#~ "line argument to pass paths to (CA"
#~ " certificate, server certificate, and "
#~ "server private key)."
#~ msgstr ""

#~ msgid ":py:obj:`run_driver_api <flwr.server.run_driver_api>`\\ \\(\\)"
#~ msgstr ""

#~ msgid "Run Flower server (Driver API)."
#~ msgstr ""

#~ msgid ":py:obj:`run_fleet_api <flwr.server.run_fleet_api>`\\ \\(\\)"
#~ msgstr ""

#~ msgid "Run Flower server (Fleet API)."
#~ msgstr ""

#~ msgid "Unreleased"
#~ msgstr ""

#~ msgid "|d8bf04f23d9b46d8a23cc6f4887d7873|"
#~ msgstr ""

#~ msgid "|5aa1711387d74d0f8b9c499e1a51627e|"
#~ msgstr ""

#~ msgid "|2bc8e069228d4873804061ff4a95048c|"
#~ msgstr ""

#~ msgid "|c258488766324dc9a6807f0e7c4fd5f4|"
#~ msgstr ""

#~ msgid "|d5f962c3f4ec48529efda980868c14b0|"
#~ msgstr ""

#~ msgid "|a5eccea18d4c43a68b54b65043cabef8|"
#~ msgstr ""

#~ msgid "|f17662f7df2d42f68cac70a1fdeda8a7|"
#~ msgstr ""

#~ msgid "|241fc906441a4f038c625a19d30d01b2|"
#~ msgstr ""

#~ msgid "|0aa5aa05810b44b6a835cecce28f3137|"
#~ msgstr ""

#~ msgid "|c742940dd4bf4de09d8d0d5e8d179638|"
#~ msgstr ""

#~ msgid "|1f169ab4601a47e1a226f1628f4ebddb|"
#~ msgstr ""

#~ msgid "|12cfa9cde14440ecb8c8f6c1d7185bec|"
#~ msgstr ""

#~ msgid "|72939caf6e294b0986fee6dde96614d7|"
#~ msgstr ""

#~ msgid "|83a8daee45da4a98b8d6f24ae098fc50|"
#~ msgstr ""

#~ msgid "Edge Client Engine"
#~ msgstr "Engine do Edge Client"

#~ msgid ""
#~ "`Flower <https://flower.ai>`_ core framework "
#~ "architecture with Edge Client Engine"
#~ msgstr ""
#~ "`Flower <https://flower.ai>`_ arquitetura principal"
#~ " do framework com Engine do Edge "
#~ "Client"

#~ msgid "Virtual Client Engine"
#~ msgstr "Engine do Virtual Client"

#~ msgid ""
#~ "`Flower <https://flower.ai>`_ core framework "
#~ "architecture with Virtual Client Engine"
#~ msgstr ""
#~ "`Flower <https://flower.ai>`_ arquitetura principal"
#~ " do framework com Engine do Virtual"
#~ " Client"

#~ msgid "Virtual Client Engine and Edge Client Engine in the same workload"
#~ msgstr ""
#~ "Engine do Virtual Client e do Edge"
#~ " Client no mesma carga de trabalho"
#~ " (workload)"

#~ msgid ""
#~ "`Flower <https://flower.ai>`_ core framework "
#~ "architecture with both Virtual Client "
#~ "Engine and Edge Client Engine"
#~ msgstr ""
#~ "`Flower <https://flower.ai>`_ arquitetura principal"
#~ " do framework com ambas engines do"
#~ " Virtual Client e do Edge Client"

#~ msgid "Clone the flower repository."
#~ msgstr "Clone o repositório do flower."

#~ msgid ""
#~ "Please follow the first section on "
#~ ":doc:`Run Flower using Docker <how-"
#~ "to-run-flower-using-docker>` which "
#~ "covers this step in more detail."
#~ msgstr ""
#~ "Por favor, siga a primeira seção "
#~ "em :doc:`Execute o Flower usando Docker"
#~ " <how-to-run-flower-using-docker>`"
#~ " que cobre este passo em mais "
#~ "detalhes."

#~ msgid "``22.04``"
#~ msgstr "``23.0.1``"

#~ msgid "``23.0.1``"
#~ msgstr "``23.0.1``"

#~ msgid "``69.0.2``"
#~ msgstr "``69.0.2``"

#~ msgid "``1.8.0``"
#~ msgstr "``1.7.0``"

#~ msgid "Building the SuperLink/SuperNode or ServerApp image"
#~ msgstr "Construindo a imagem do servidor"

#~ msgid "``1.8.0-py3.10-ubuntu22.04``"
#~ msgstr ""

#~ msgid ""
#~ "The following example creates a "
#~ "SuperLink/SuperNode or ServerApp image with"
#~ " the official Flower base image:"
#~ msgstr ""
#~ "O exemplo a seguir cria uma imagem"
#~ " de servidor com a imagem base "
#~ "oficial do Flower py3.11-ubuntu22.04 e "
#~ "Flower 1.7.0:"

#~ msgid "Trigger the CI for building the Docker images."
#~ msgstr "Versão da imagem Docker oficial do Ubuntu."

#~ msgid ""
#~ "To trigger the workflow, a collaborator"
#~ " must create a ``workflow_dispatch`` event"
#~ " in the GitHub CI. This can be"
#~ " done either through the UI or "
#~ "via the GitHub CLI. The event "
#~ "requires only one input, the Flower "
#~ "version, to be released."
#~ msgstr ""

#~ msgid "**Via the UI**"
#~ msgstr ""

#~ msgid ""
#~ "Go to the ``Build docker images`` "
#~ "workflow `page "
#~ "<https://github.com/adap/flower/actions/workflows/docker-"
#~ "images.yml>`_."
#~ msgstr ""

#~ msgid ""
#~ "Click on the ``Run workflow`` button "
#~ "and type the new version of Flower"
#~ " in the ``Version of Flower`` input"
#~ " field."
#~ msgstr ""

#~ msgid "Click on the **green** ``Run workflow`` button."
#~ msgstr ""

#~ msgid "**Via the GitHub CI**"
#~ msgstr ""

#~ msgid ""
#~ "Make sure you are logged in via"
#~ " ``gh auth login`` and that the "
#~ "current working directory is the root"
#~ " of the Flower repository."
#~ msgstr ""

#~ msgid ""
#~ "Trigger the workflow via ``gh workflow"
#~ " run docker-images.yml -f flwr-"
#~ "version=<NEW_VERSION>``."
#~ msgstr ""

#~ msgid "Preliminarities"
#~ msgstr ""

#~ msgid "Example: JAX - Run JAX Federated"
#~ msgstr ""

#~ msgid ""
#~ "\\small\n"
#~ "P[M(D_{1} \\in A)] \\leq e^{\\delta} P[M(D_{2} \\in A)] + \\delta"
#~ msgstr ""

#~ msgid ""
#~ "The following command can be used "
#~ "to verify if Flower was successfully "
#~ "installed. If everything worked, it "
#~ "should print the version of Flower "
#~ "to the command line::"
#~ msgstr ""

#~ msgid ":doc:`How to run Flower using Docker <how-to-run-flower-using-docker>`"
#~ msgstr ""

#~ msgid ""
#~ "The simplest way to get started "
#~ "with Flower is by using the "
#~ "pre-made Docker images, which you can"
#~ " find on `Docker Hub "
#~ "<https://hub.docker.com/u/flwr>`__. Supported "
#~ "architectures include ``amd64`` and "
#~ "``arm64v8``."
#~ msgstr ""

#~ msgid "Before you start, make sure that the Docker daemon is running:"
#~ msgstr ""

#~ msgid ""
#~ "If you do not see the version "
#~ "of Docker but instead get an error"
#~ " saying that the command was not "
#~ "found, you will need to install "
#~ "Docker first. You can find installation"
#~ " instruction `here <https://docs.docker.com/get-"
#~ "docker/>`_."
#~ msgstr ""

#~ msgid ""
#~ "On Linux, Docker commands require "
#~ "``sudo`` privilege. If you want to "
#~ "avoid using ``sudo``, you can follow "
#~ "the `Post-installation steps "
#~ "<https://docs.docker.com/engine/install/linux-postinstall/>`_"
#~ " on the official Docker website."
#~ msgstr ""

#~ msgid ""
#~ "To ensure optimal performance and "
#~ "compatibility, the SuperLink, SuperNode and"
#~ " ServerApp image must have the same"
#~ " version when running together. This "
#~ "guarantees seamless integration and avoids "
#~ "potential conflicts or issues that may"
#~ " arise from using different versions."
#~ msgstr ""

#~ msgid "Flower SuperLink"
#~ msgstr ""

#~ msgid "Quickstart"
#~ msgstr ""

#~ msgid "If you're looking to try out Flower, you can use the following command:"
#~ msgstr ""

#~ msgid ""
#~ "The command pulls the Docker image "
#~ "with the tag ``1.8.0`` from Docker "
#~ "Hub. The tag specifies the Flower "
#~ "version. In this case, Flower 1.8.0. "
#~ "The ``--rm`` flag tells Docker to "
#~ "remove the container after it exits."
#~ msgstr ""

#~ msgid ""
#~ "By default, the Flower SuperLink keeps"
#~ " state in-memory. When using the "
#~ "Docker flag ``--rm``, the state is "
#~ "not persisted between container starts. "
#~ "We will show below how to save "
#~ "the state in a file on your "
#~ "host system."
#~ msgstr ""

#~ msgid ""
#~ "The ``-p <host>:<container>`` flag tells "
#~ "Docker to map the ports "
#~ "``9091``/``9092`` of the host to "
#~ "``9091``/``9092`` of the container, allowing"
#~ " you to access the Driver API "
#~ "on ``http://localhost:9091`` and the Fleet "
#~ "API on ``http://localhost:9092``. Lastly, any"
#~ " flag that comes after the tag "
#~ "is passed to the Flower SuperLink. "
#~ "Here, we are passing the flag "
#~ "``--insecure``."
#~ msgstr ""

#~ msgid ""
#~ "The ``--insecure`` flag enables insecure "
#~ "communication (using HTTP, not HTTPS) "
#~ "and should only be used for "
#~ "testing purposes. We strongly recommend "
#~ "enabling `SSL <https://flower.ai/docs/framework/how-"
#~ "to-run-flower-using-docker.html#enabling-"
#~ "ssl-for-secure-connections>`__ when "
#~ "deploying to a production environment."
#~ msgstr ""

#~ msgid ""
#~ "You can use ``--help`` to view all"
#~ " available flags that the SuperLink "
#~ "supports:"
#~ msgstr ""

#~ msgid "Mounting a volume to store the state on the host system"
#~ msgstr ""

#~ msgid ""
#~ "If you want to persist the state"
#~ " of the SuperLink on your host "
#~ "system, all you need to do is "
#~ "specify a directory where you want "
#~ "to save the file on your host "
#~ "system and a name for the database"
#~ " file. By default, the SuperLink "
#~ "container runs with a non-root "
#~ "user called ``app`` with the user "
#~ "ID ``49999``. It is recommended to "
#~ "create new directory and change the "
#~ "user ID of the directory to "
#~ "``49999`` to ensure the mounted "
#~ "directory has the proper permissions. If"
#~ " you later want to delete the "
#~ "directory, you can change the user "
#~ "ID back to the current user ID "
#~ "by running ``sudo chown -R $USER:$(id"
#~ " -gn) state``."
#~ msgstr ""

#~ msgid ""
#~ "In the example below, we create a"
#~ " new directory, change the user ID"
#~ " and tell Docker via the flag "
#~ "``--volume`` to mount the local "
#~ "``state`` directory into the ``/app/state``"
#~ " directory of the container. Furthermore,"
#~ " we use the flag ``--database`` to"
#~ " specify the name of the database "
#~ "file."
#~ msgstr ""

#~ msgid ""
#~ "As soon as the SuperLink starts, "
#~ "the file ``state.db`` is created in "
#~ "the ``state`` directory on your host "
#~ "system. If the file already exists, "
#~ "the SuperLink tries to restore the "
#~ "state from the file. To start the"
#~ " SuperLink with an empty database, "
#~ "simply remove the ``state.db`` file."
#~ msgstr ""

#~ msgid "Enabling SSL for secure connections"
#~ msgstr ""

#~ msgid ""
#~ "To enable SSL, you will need a "
#~ "PEM-encoded root certificate, a PEM-"
#~ "encoded private key and a PEM-"
#~ "encoded certificate chain."
#~ msgstr ""

#~ msgid ""
#~ "Assuming all files we need are in"
#~ " the local ``certificates`` directory, we"
#~ " can use the flag ``--volume`` to "
#~ "mount the local directory into the "
#~ "``/app/certificates/`` directory of the "
#~ "container. This allows the SuperLink to"
#~ " access the files within the "
#~ "container. The ``ro`` stands for "
#~ "``read-only``. Docker volumes default to"
#~ " ``read-write``; that option tells "
#~ "Docker to make the volume ``read-"
#~ "only`` instead. Finally, we pass the "
#~ "names of the certificates and key "
#~ "file to the SuperLink with the "
#~ "``--ssl-ca-certfile``, ``--ssl-certfile`` "
#~ "and ``--ssl-keyfile`` flag."
#~ msgstr ""

#~ msgid ""
#~ "Because Flower containers, by default, "
#~ "run with a non-root user ``app``,"
#~ " the mounted files and directories "
#~ "must have the proper permissions for "
#~ "the user ID ``49999``. For example, "
#~ "to change the user ID of all "
#~ "files in the ``certificates/`` directory, "
#~ "you can run ``sudo chown -R "
#~ "49999:49999 certificates/*``."
#~ msgstr ""

#~ msgid "Flower SuperNode"
#~ msgstr ""

#~ msgid ""
#~ "The SuperNode Docker image comes with"
#~ " a pre-installed version of Flower"
#~ " and serves as a base for "
#~ "building your own SuperNode image."
#~ msgstr ""

#~ msgid ""
#~ "The SuperNode Docker image currently "
#~ "works only with the 1.9.0-nightly "
#~ "release. A stable version will be "
#~ "available when Flower 1.9.0 (stable) "
#~ "gets released (ETA: May). A SuperNode"
#~ " nightly image must be paired with"
#~ " the corresponding SuperLink and ServerApp"
#~ " nightly images released on the same"
#~ " day. To ensure the versions are "
#~ "in sync, using the concrete tag, "
#~ "e.g., ``1.9.0.dev20240501`` instead of "
#~ "``nightly`` is recommended."
#~ msgstr ""

#~ msgid ""
#~ "We will use the ``quickstart-pytorch``"
#~ " example, which you can find in "
#~ "the Flower repository, to illustrate how"
#~ " you can dockerize your ClientApp."
#~ msgstr ""

#~ msgid ""
#~ "Before we can start, we need to"
#~ " meet a few prerequisites in our "
#~ "local development environment. You can "
#~ "skip the first part if you want"
#~ " to run your ClientApp instead of "
#~ "the ``quickstart-pytorch`` example."
#~ msgstr ""
#~ "Antes de começarmos, precisamos encontrar "
#~ "alguns pré-requisitos em nosso ambiente "
#~ "de desenvolvimento local."

#~ msgid "Creating a SuperNode Dockerfile"
#~ msgstr ""

#~ msgid "Let's assume the following project layout:"
#~ msgstr ""

#~ msgid ""
#~ "First, we need to create a "
#~ "``requirements.txt`` file in the directory "
#~ "where the ``ClientApp`` code is located."
#~ " In the file, we list all the"
#~ " dependencies that the ClientApp requires."
#~ msgstr ""

#~ msgid ""
#~ "Note that `flwr <https://pypi.org/project/flwr/>`__"
#~ " is already installed in the "
#~ "``flwr/supernode`` base image, so you "
#~ "only need to include other package "
#~ "dependencies in your ``requirements.txt``, "
#~ "such as ``torch``, ``tensorflow``, etc."
#~ msgstr ""

#~ msgid ""
#~ "Next, we create a Dockerfile. If "
#~ "you use the ``quickstart-pytorch`` "
#~ "example, create a new file called "
#~ "``Dockerfile.supernode`` in ``examples/quickstart-"
#~ "pytorch``."
#~ msgstr ""

#~ msgid ""
#~ "The ``Dockerfile.supernode`` contains the "
#~ "instructions that assemble the SuperNode "
#~ "image."
#~ msgstr ""

#~ msgid ""
#~ "In the first two lines, we "
#~ "instruct Docker to use the SuperNode "
#~ "image tagged ``nightly`` as a base "
#~ "image and set our working directory "
#~ "to ``/app``. The following instructions "
#~ "will now be executed in the "
#~ "``/app`` directory. Next, we install the"
#~ " ClientApp dependencies by copying the "
#~ "``requirements.txt`` file into the image "
#~ "and run ``pip install``. In the "
#~ "last two lines, we copy the "
#~ "``client.py`` module into the image and"
#~ " set the entry point to ``flower-"
#~ "client-app`` with the argument "
#~ "``client:app``. The argument is the "
#~ "object reference of the ClientApp "
#~ "(``<module>:<attribute>``) that will be run"
#~ " inside the ClientApp."
#~ msgstr ""

#~ msgid "Building the SuperNode Docker image"
#~ msgstr "Construindo a imagem do servidor"

#~ msgid ""
#~ "Next, we build the SuperNode Docker "
#~ "image by running the following command"
#~ " in the directory where Dockerfile "
#~ "and ClientApp code are located."
#~ msgstr ""

#~ msgid ""
#~ "We gave the image the name "
#~ "``flwr_supernode``, and the tag ``0.0.1``. "
#~ "Remember that the here chosen values "
#~ "only serve as an example. You can"
#~ " change them to your needs."
#~ msgstr ""

#~ msgid "Now that we have built the SuperNode image, we can finally run it."
#~ msgstr ""

#~ msgid "Let's break down each part of this command:"
#~ msgstr ""

#~ msgid "``docker run``: This is the command to run a new Docker container."
#~ msgstr ""

#~ msgid ""
#~ "``--rm``: This option specifies that the"
#~ " container should be automatically removed"
#~ " when it stops."
#~ msgstr ""

#~ msgid "``flwr_supernode:0.0.1``: The name the tag of the Docker image to use."
#~ msgstr ""

#~ msgid "``--insecure``: This option enables insecure communication."
#~ msgstr ""

#~ msgid ""
#~ "``--superlink 192.168.1.100:9092``: This option "
#~ "specifies the address of the SuperLinks"
#~ " Fleet"
#~ msgstr ""

#~ msgid "API to connect to. Remember to update it with your SuperLink IP."
#~ msgstr ""

#~ msgid ""
#~ "To test running Flower locally, you "
#~ "can create a `bridge network "
#~ "<https://docs.docker.com/network/network-tutorial-"
#~ "standalone/#use-user-defined-bridge-"
#~ "networks>`__, use the ``--network`` argument"
#~ " and pass the name of the "
#~ "Docker network to run your SuperNodes."
#~ msgstr ""

#~ msgid ""
#~ "Any argument that comes after the "
#~ "tag is passed to the Flower "
#~ "SuperNode binary. To see all available"
#~ " flags that the SuperNode supports, "
#~ "run:"
#~ msgstr ""

#~ msgid ""
#~ "To enable SSL, we will need to "
#~ "mount a PEM-encoded root certificate "
#~ "into your SuperNode container."
#~ msgstr ""

#~ msgid ""
#~ "Assuming the certificate already exists "
#~ "locally, we can use the flag "
#~ "``--volume`` to mount the local "
#~ "certificate into the container's ``/app/`` "
#~ "directory. This allows the SuperNode to"
#~ " access the certificate within the "
#~ "container. Use the ``--root-certificates`` "
#~ "flag when starting the container."
#~ msgstr ""

#~ msgid "Flower ServerApp"
#~ msgstr ""

#~ msgid ""
#~ "The procedure for building and running"
#~ " a ServerApp image is almost "
#~ "identical to the SuperNode image."
#~ msgstr ""

#~ msgid ""
#~ "Similar to the SuperNode image, the "
#~ "ServerApp Docker image comes with a "
#~ "pre-installed version of Flower and "
#~ "serves as a base for building your"
#~ " own ServerApp image."
#~ msgstr ""

#~ msgid ""
#~ "We will use the same ``quickstart-"
#~ "pytorch`` example as we do in the"
#~ " Flower SuperNode section. If you "
#~ "have not already done so, please "
#~ "follow the `SuperNode Prerequisites`_ before"
#~ " proceeding."
#~ msgstr ""

#~ msgid "Creating a ServerApp Dockerfile"
#~ msgstr ""

#~ msgid ""
#~ "First, we need to create a "
#~ "Dockerfile in the directory where the"
#~ " ``ServerApp`` code is located. If "
#~ "you use the ``quickstart-pytorch`` "
#~ "example, create a new file called "
#~ "``Dockerfile.serverapp`` in ``examples/quickstart-"
#~ "pytorch``."
#~ msgstr ""

#~ msgid ""
#~ "The ``Dockerfile.serverapp`` contains the "
#~ "instructions that assemble the ServerApp "
#~ "image."
#~ msgstr ""

#~ msgid ""
#~ "In the first two lines, we "
#~ "instruct Docker to use the ServerApp "
#~ "image tagged ``1.8.0`` as a base "
#~ "image and set our working directory "
#~ "to ``/app``. The following instructions "
#~ "will now be executed in the "
#~ "``/app`` directory. In the last two "
#~ "lines, we copy the ``server.py`` module"
#~ " into the image and set the "
#~ "entry point to ``flower-server-app`` "
#~ "with the argument ``server:app``. The "
#~ "argument is the object reference of "
#~ "the ServerApp (``<module>:<attribute>``) that "
#~ "will be run inside the ServerApp "
#~ "container."
#~ msgstr ""

#~ msgid "Building the ServerApp Docker image"
#~ msgstr "Construindo a imagem do servidor"

#~ msgid ""
#~ "Next, we build the ServerApp Docker "
#~ "image by running the following command"
#~ " in the directory where Dockerfile "
#~ "and ServerApp code are located."
#~ msgstr ""

#~ msgid ""
#~ "We gave the image the name "
#~ "``flwr_serverapp``, and the tag ``0.0.1``. "
#~ "Remember that the here chosen values "
#~ "only serve as an example. You can"
#~ " change them to your needs."
#~ msgstr ""

#~ msgid "Running the ServerApp Docker image"
#~ msgstr "Construindo a imagem do servidor"

#~ msgid "Now that we have built the ServerApp image, we can finally run it."
#~ msgstr ""

#~ msgid "``flwr_serverapp:0.0.1``: The name the tag of the Docker image to use."
#~ msgstr ""

#~ msgid ""
#~ "``--superlink 192.168.1.100:9091``: This option "
#~ "specifies the address of the SuperLinks"
#~ " Driver"
#~ msgstr ""

#~ msgid ""
#~ "To test running Flower locally, you "
#~ "can create a `bridge network "
#~ "<https://docs.docker.com/network/network-tutorial-"
#~ "standalone/#use-user-defined-bridge-"
#~ "networks>`__, use the ``--network`` argument"
#~ " and pass the name of the "
#~ "Docker network to run your ServerApps."
#~ msgstr ""

#~ msgid ""
#~ "Any argument that comes after the "
#~ "tag is passed to the Flower "
#~ "ServerApp binary. To see all available"
#~ " flags that the ServerApp supports, "
#~ "run:"
#~ msgstr ""

#~ msgid ""
#~ "To enable SSL, we will need to "
#~ "mount a PEM-encoded root certificate "
#~ "into your ServerApp container."
#~ msgstr ""

#~ msgid ""
#~ "Assuming the certificate already exists "
#~ "locally, we can use the flag "
#~ "``--volume`` to mount the local "
#~ "certificate into the container's ``/app/`` "
#~ "directory. This allows the ServerApp to"
#~ " access the certificate within the "
#~ "container. Use the ``--root-certificates`` "
#~ "flags when starting the container."
#~ msgstr ""

#~ msgid "Advanced Docker options"
#~ msgstr ""

#~ msgid "Run with root user privileges"
#~ msgstr ""

#~ msgid ""
#~ "Flower Docker images, by default, run"
#~ " with a non-root user "
#~ "(username/groupname: ``app``, UID/GID: ``49999``)."
#~ " Using root user is not recommended"
#~ " unless it is necessary for specific"
#~ " tasks during the build process. "
#~ "Always make sure to run the "
#~ "container as a non-root user in"
#~ " production to maintain security best "
#~ "practices."
#~ msgstr ""

#~ msgid "**Run a container with root user privileges**"
#~ msgstr ""

#~ msgid "**Run the build process with root user privileges**"
#~ msgstr ""

#~ msgid "Using a different Flower version"
#~ msgstr ""

#~ msgid "Pinning a Docker image to a specific version"
#~ msgstr ""

#~ msgid ""
#~ "It may happen that we update the"
#~ " images behind the tags. Such updates"
#~ " usually include security updates of "
#~ "system dependencies that should not "
#~ "change the functionality of Flower. "
#~ "However, if you want to ensure "
#~ "that you always use the same "
#~ "image, you can specify the hash of"
#~ " the image instead of the tag."
#~ msgstr ""

#~ msgid ""
#~ "The following command returns the "
#~ "current image hash referenced by the "
#~ "``superlink:1.8.0`` tag:"
#~ msgstr ""

#~ msgid "Next, we can pin the hash when running a new SuperLink container:"
#~ msgstr ""

#~ msgid "Setting environment variables"
#~ msgstr ""

#~ msgid ""
#~ "To set a variable inside a Docker"
#~ " container, you can use the ``-e "
#~ "<name>=<value>`` flag."
#~ msgstr ""

#~ msgid ""
#~ "This approach consists of two seprate"
#~ " phases: clipping of the updates and"
#~ " adding noise to the aggregated "
#~ "model. For the clipping phase, Flower"
#~ " framework has made it possible to"
#~ " decide whether to perform clipping "
#~ "on the server side or the client"
#~ " side."
#~ msgstr ""

#~ msgid ""
#~ "The :code:`on_fit_config_fn` can be used "
#~ "to pass arbitrary configuration values "
#~ "from server to client, and poetentially"
#~ " change these values each round, for"
#~ " example, to adjust the learning "
#~ "rate. The client will receive the "
#~ "dictionary returned by the "
#~ ":code:`on_fit_config_fn` in its own "
#~ ":code:`client.fit()` function."
#~ msgstr ""

#~ msgid ""
#~ "QUICKSTART TUTORIALS: :doc:`PyTorch <tutorial-"
#~ "quickstart-pytorch>` | :doc:`TensorFlow "
#~ "<tutorial-quickstart-tensorflow>` | :doc:`🤗 "
#~ "Transformers <tutorial-quickstart-huggingface>` "
#~ "| :doc:`JAX <tutorial-quickstart-jax>` |"
#~ " :doc:`Pandas <tutorial-quickstart-pandas>` "
#~ "| :doc:`fastai <tutorial-quickstart-fastai>`"
#~ " | :doc:`PyTorch Lightning <tutorial-"
#~ "quickstart-pytorch-lightning>` | :doc:`scikit-"
#~ "learn <tutorial-quickstart-scikitlearn>` | "
#~ ":doc:`XGBoost <tutorial-quickstart-xgboost>` |"
#~ " :doc:`Android <tutorial-quickstart-android>` "
#~ "| :doc:`iOS <tutorial-quickstart-ios>`"
#~ msgstr ""

#~ msgid "flower-client-app"
#~ msgstr ""

#~ msgid ":py:obj:`flwr.client <flwr.client>`\\"
#~ msgstr ""

#~ msgid ":py:obj:`flwr.common <flwr.common>`\\"
#~ msgstr ""

#~ msgid ":py:obj:`flwr.server <flwr.server>`\\"
#~ msgstr ""

#~ msgid ":py:obj:`flwr.simulation <flwr.simulation>`\\"
#~ msgstr ""

#~ msgid ":py:obj:`run_client_app <flwr.client.run_client_app>`\\ \\(\\)"
#~ msgstr ""

#~ msgid "Run Flower client app."
#~ msgstr ""

#~ msgid ":py:obj:`run_supernode <flwr.client.run_supernode>`\\ \\(\\)"
#~ msgstr ""

#~ msgid "Run Flower SuperNode."
#~ msgstr ""

#~ msgid ":py:obj:`flwr.client.mod <flwr.client.mod>`\\"
#~ msgstr ""

#~ msgid ":py:obj:`Context <flwr.common.Context>`\\ \\(state\\)"
#~ msgstr ""

#~ msgid "State of your run."
#~ msgstr ""

#~ msgid "Metrics record."
#~ msgstr ""

#~ msgid ""
#~ "Bases: :py:class:`~flwr.common.record.typeddict.TypedDict`\\ "
#~ "[:py:class:`str`, :py:class:`int` | "
#~ ":py:class:`float` | :py:class:`str` | "
#~ ":py:class:`bytes` | :py:class:`bool` | "
#~ ":py:class:`~typing.List`\\ [:py:class:`int`] | "
#~ ":py:class:`~typing.List`\\ [:py:class:`float`] | "
#~ ":py:class:`~typing.List`\\ [:py:class:`str`] | "
#~ ":py:class:`~typing.List`\\ [:py:class:`bytes`] | "
#~ ":py:class:`~typing.List`\\ [:py:class:`bool`]]"
#~ msgstr ""

#~ msgid "Remove all items from R."
#~ msgstr ""

#~ msgid ":py:obj:`get <flwr.common.ConfigsRecord.get>`\\ \\(k\\[\\,d\\]\\)"
#~ msgstr ""

#~ msgid "d defaults to None."
#~ msgstr ""

#~ msgid "Update R from dict/iterable E and F."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`RUN_DRIVER_API_ENTER "
#~ "<flwr.common.EventType.RUN_DRIVER_API_ENTER>`\\"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`RUN_DRIVER_API_LEAVE "
#~ "<flwr.common.EventType.RUN_DRIVER_API_LEAVE>`\\"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`RUN_FLEET_API_ENTER "
#~ "<flwr.common.EventType.RUN_FLEET_API_ENTER>`\\"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`RUN_FLEET_API_LEAVE "
#~ "<flwr.common.EventType.RUN_FLEET_API_LEAVE>`\\"
#~ msgstr ""

#~ msgid ":py:obj:`DRIVER_CONNECT <flwr.common.EventType.DRIVER_CONNECT>`\\"
#~ msgstr ""

#~ msgid ":py:obj:`DRIVER_DISCONNECT <flwr.common.EventType.DRIVER_DISCONNECT>`\\"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`START_DRIVER_ENTER "
#~ "<flwr.common.EventType.START_DRIVER_ENTER>`\\"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`START_DRIVER_LEAVE "
#~ "<flwr.common.EventType.START_DRIVER_LEAVE>`\\"
#~ msgstr ""

#~ msgid ""
#~ "An identifier that can be used "
#~ "when loading a particular data partition"
#~ " for a ClientApp. Making use of "
#~ "this identifier is more relevant when"
#~ " conducting simulations."
#~ msgstr ""

#~ msgid ":py:obj:`partition_id <flwr.common.Metadata.partition_id>`\\"
#~ msgstr ""

#~ msgid "An identifier telling which data partition a ClientApp should use."
#~ msgstr ""

#~ msgid ""
#~ "Bases: :py:class:`~flwr.common.record.typeddict.TypedDict`\\ "
#~ "[:py:class:`str`, :py:class:`int` | "
#~ ":py:class:`float` | :py:class:`~typing.List`\\ "
#~ "[:py:class:`int`] | :py:class:`~typing.List`\\ "
#~ "[:py:class:`float`]]"
#~ msgstr ""

#~ msgid ":py:obj:`get <flwr.common.MetricsRecord.get>`\\ \\(k\\[\\,d\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ "A dataclass storing named Arrays in "
#~ "order. This means that it holds "
#~ "entries as an OrderedDict[str, Array]. "
#~ "ParametersRecord objects can be viewed "
#~ "as an equivalent to PyTorch's "
#~ "state_dict, but holding serialised tensors "
#~ "instead."
#~ msgstr ""

#~ msgid ":py:obj:`get <flwr.common.ParametersRecord.get>`\\ \\(k\\[\\,d\\]\\)"
#~ msgstr ""

#~ msgid ":py:obj:`run_server_app <flwr.server.run_server_app>`\\ \\(\\)"
#~ msgstr ""

#~ msgid "Run Flower server app."
#~ msgstr ""

#~ msgid ":py:obj:`run_superlink <flwr.server.run_superlink>`\\ \\(\\)"
#~ msgstr ""

#~ msgid "Run Flower SuperLink (Driver API and Fleet API)."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`LegacyContext <flwr.server.LegacyContext>`\\ "
#~ "\\(state\\[\\, config\\, strategy\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ":py:obj:`flwr.server.strategy <flwr.server.strategy>`\\"
#~ msgstr ""

#~ msgid ":py:obj:`flwr.server.workflow <flwr.server.workflow>`\\"
#~ msgstr ""

#~ msgid "run\\_driver\\_api"
#~ msgstr ""

#~ msgid "run\\_fleet\\_api"
#~ msgstr ""

#~ msgid ""
#~ "The protocol involves four main stages:"
#~ " - 'setup': Send SecAgg+ configuration "
#~ "to clients and collect their public "
#~ "keys. - 'share keys': Broadcast public"
#~ " keys among clients and collect "
#~ "encrypted secret"
#~ msgstr ""

#~ msgid "key shares."
#~ msgstr ""

#~ msgid ""
#~ "The protocol involves four main stages:"
#~ " - 'setup': Send SecAgg configuration "
#~ "to clients and collect their public "
#~ "keys. - 'share keys': Broadcast public"
#~ " keys among clients and collect "
#~ "encrypted secret"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`start_simulation <flwr.simulation.start_simulation>`\\"
#~ " \\(\\*\\, client\\_fn\\[\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ "'A dictionary, e.g {\"<keyA>\": <value>, "
#~ "\"<keyB>\": <value>} to configure a "
#~ "backend. Values supported in <value> are"
#~ " those included by "
#~ "`flwr.common.typing.ConfigsRecordValues`."
#~ msgstr ""

#~ msgid ""
#~ "When diabled, only INFO, WARNING and "
#~ "ERROR log messages will be shown. "
#~ "If enabled, DEBUG-level logs will "
#~ "be displayed."
#~ msgstr ""

#~ msgid ""
#~ "A function creating client instances. "
#~ "The function must take a single "
#~ "`str` argument called `cid`. It should"
#~ " return a single client instance of"
#~ " type Client. Note that the created"
#~ " client instances are ephemeral and "
#~ "will often be destroyed after a "
#~ "single method invocation. Since client "
#~ "instances are not long-lived, they "
#~ "should not attempt to carry state "
#~ "over method invocations. Any state "
#~ "required by the instance (model, "
#~ "dataset, hyperparameters, ...) should be "
#~ "(re-)created in either the call to "
#~ "`client_fn` or the call to any of"
#~ " the client methods (e.g., load "
#~ "evaluation data in the `evaluate` method"
#~ " itself)."
#~ msgstr ""

#~ msgid ""
#~ "The total number of clients in "
#~ "this simulation. This must be set "
#~ "if `clients_ids` is not set and "
#~ "vice-versa."
#~ msgstr ""

#~ msgid ""
#~ "List `client_id`s for each client. This"
#~ " is only required if `num_clients` is"
#~ " not set. Setting both `num_clients` "
#~ "and `clients_ids` with `len(clients_ids)` not"
#~ " equal to `num_clients` generates an "
#~ "error."
#~ msgstr ""

#~ msgid ""
#~ "In this tutorial we will learn how"
#~ " to train a Convolutional Neural "
#~ "Network on CIFAR10 using Flower and "
#~ "PyTorch."
#~ msgstr ""

#~ msgid ""
#~ "*Clients* are responsible for generating "
#~ "individual weight-updates for the model"
#~ " based on their local datasets. These"
#~ " updates are then sent to the "
#~ "*server* which will aggregate them to"
#~ " produce a better model. Finally, the"
#~ " *server* sends this improved version "
#~ "of the model back to each "
#~ "*client*. A complete cycle of weight "
#~ "updates is called a *round*."
#~ msgstr ""

#~ msgid ""
#~ "Now that we have a rough idea "
#~ "of what is going on, let's get "
#~ "started. We first need to install "
#~ "Flower. You can do this by running"
#~ " :"
#~ msgstr ""

#~ msgid ""
#~ "Since we want to use PyTorch to"
#~ " solve a computer vision task, let's"
#~ " go ahead and install PyTorch and "
#~ "the **torchvision** library:"
#~ msgstr ""

#~ msgid ""
#~ "Now that we have all our "
#~ "dependencies installed, let's run a "
#~ "simple distributed training with two "
#~ "clients and one server. Our training "
#~ "procedure and network architecture are "
#~ "based on PyTorch's `Deep Learning with"
#~ " PyTorch "
#~ "<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_."
#~ msgstr ""

#~ msgid ""
#~ "In a file called :code:`client.py`, "
#~ "import Flower and PyTorch related "
#~ "packages:"
#~ msgstr ""

#~ msgid "In addition, we define the device allocation in PyTorch with:"
#~ msgstr ""

#~ msgid ""
#~ "We use PyTorch to load CIFAR10, a"
#~ " popular colored image classification "
#~ "dataset for machine learning. The "
#~ "PyTorch :code:`DataLoader()` downloads the "
#~ "training and test data that are "
#~ "then normalized."
#~ msgstr ""

#~ msgid ""
#~ "Define the loss and optimizer with "
#~ "PyTorch. The training of the dataset "
#~ "is done by looping over the "
#~ "dataset, measure the corresponding loss "
#~ "and optimize it."
#~ msgstr ""

#~ msgid ""
#~ "Define then the validation of the  "
#~ "machine learning network. We loop over"
#~ " the test set and measure the "
#~ "loss and accuracy of the test set."
#~ msgstr ""

#~ msgid ""
#~ "After defining the training and testing"
#~ " of a PyTorch machine learning model,"
#~ " we use the functions for the "
#~ "Flower clients."
#~ msgstr ""

#~ msgid ""
#~ "The Flower clients will use a "
#~ "simple CNN adapted from 'PyTorch: A "
#~ "60 Minute Blitz':"
#~ msgstr ""

#~ msgid ""
#~ "After loading the data set with "
#~ ":code:`load_data()` we define the Flower "
#~ "interface."
#~ msgstr ""

#~ msgid ""
#~ "Flower provides a convenience class "
#~ "called :code:`NumPyClient` which makes it "
#~ "easier to implement the :code:`Client` "
#~ "interface when your workload uses "
#~ "PyTorch. Implementing :code:`NumPyClient` usually"
#~ " means defining the following methods "
#~ "(:code:`set_parameters` is optional though):"
#~ msgstr ""

#~ msgid "receive the updated local model weights"
#~ msgstr ""

#~ msgid "which can be implemented in the following way:"
#~ msgstr ""

#~ msgid ""
#~ "Congratulations! You've successfully built and"
#~ " run your first federated learning "
#~ "system. The full `source code "
#~ "<https://github.com/adap/flower/blob/main/examples/quickstart-"
#~ "pytorch/client.py>`_ for this example can "
#~ "be found in :code:`examples/quickstart-"
#~ "pytorch`."
#~ msgstr ""

#~ msgid ""
#~ "In this example, we split the "
#~ "dataset into two partitions with uniform"
#~ " distribution (:code:`IidPartitioner(num_partitions=2)`). "
#~ "Then, we load the partition for "
#~ "the given client based on "
#~ ":code:`node_id`:"
#~ msgstr ""

#~ msgid ""
#~ "The :code:`self.bst` is used to keep "
#~ "the Booster objects that remain "
#~ "consistent across rounds, allowing them "
#~ "to store predictions from trees "
#~ "integrated in earlier rounds and "
#~ "maintain other essential data structures "
#~ "for training."
#~ msgstr ""

#~ msgid ""
#~ "In :code:`fit`, at the first round, "
#~ "we call :code:`xgb.train()` to build up"
#~ " the first set of trees. the "
#~ "returned Booster object and config are"
#~ " stored in :code:`self.bst` and "
#~ ":code:`self.config`, respectively. From the "
#~ "second round, we load the global "
#~ "model sent from server to "
#~ ":code:`self.bst`, and then update model "
#~ "weights on local training data with "
#~ "function :code:`local_boost` as follows:"
#~ msgstr ""

#~ msgid ""
#~ "Given :code:`num_local_round`, we update trees"
#~ " by calling :code:`self.bst.update` method. "
#~ "After training, the last "
#~ ":code:`N=num_local_round` trees will be "
#~ "extracted to send to the server."
#~ msgstr ""

#~ msgid ""
#~ "In :code:`evaluate`, we call "
#~ ":code:`self.bst.eval_set` function to conduct "
#~ "evaluation on valid set. The AUC "
#~ "value will be returned."
#~ msgstr ""

#~ msgid ""
#~ "That's it for the client. We only"
#~ " have to implement :code:`Client`and call"
#~ " :code:`fl.client.start_client()`. The string "
#~ ":code:`\"[::]:8080\"` tells the client which"
#~ " server to connect to. In our "
#~ "case we can run the server and "
#~ "the client on the same machine, "
#~ "therefore we use :code:`\"[::]:8080\"`. If "
#~ "we run a truly federated workload "
#~ "with the server and clients running "
#~ "on different machines, all that needs"
#~ " to change is the :code:`server_address`"
#~ " we point the client at."
#~ msgstr ""

#~ msgid ""
#~ "We use two clients for this "
#~ "example. An :code:`evaluate_metrics_aggregation` "
#~ "function is defined to collect and "
#~ "wighted average the AUC values from "
#~ "clients."
#~ msgstr ""

#~ msgid ""
#~ "Welcome to the third part of the"
#~ " Flower federated learning tutorial. In "
#~ "previous parts of this tutorial, we "
#~ "introduced federated learning with PyTorch "
#~ "and Flower (`part 1 "
#~ "<https://flower.ai/docs/framework/tutorial-get-started-"
#~ "with-flower-pytorch.html>`__) and we "
#~ "learned how strategies can be used "
#~ "to customize the execution on both "
#~ "the server and the clients (`part "
#~ "2 <https://flower.ai/docs/framework/tutorial-use-a"
#~ "-federated-learning-strategy-pytorch.html>`__)."
#~ msgstr ""

#~ msgid ""
#~ "In this notebook, we'll continue to "
#~ "customize the federated learning system "
#~ "we built previously by creating a "
#~ "custom version of FedAvg (again, using"
#~ " `Flower <https://flower.ai/>`__ and `PyTorch "
#~ "<https://pytorch.org/>`__)."
#~ msgstr ""

#~ msgid ""
#~ "`Star Flower on GitHub "
#~ "<https://github.com/adap/flower>`__ ⭐️ and join "
#~ "the Flower community on Slack to "
#~ "connect, ask questions, and get help:"
#~ " `Join Slack <https://flower.ai/join-slack>`__"
#~ " 🌼 We'd love to hear from you"
#~ " in the ``#introductions`` channel! And "
#~ "if anything is unclear, head over "
#~ "to the ``#questions`` channel."
#~ msgstr ""

#~ msgid "Let's build a new ``Strategy`` from scratch!"
#~ msgstr ""

#~ msgid ""
#~ "Let's now load the CIFAR-10 training "
#~ "and test set, partition them into "
#~ "ten smaller datasets (each split into"
#~ " training and validation set), and "
#~ "wrap everything in their own "
#~ "``DataLoader``. We introduce a new "
#~ "parameter ``num_clients`` which allows us "
#~ "to call ``load_datasets`` with different "
#~ "numbers of clients."
#~ msgstr ""

#~ msgid ""
#~ "To implement the Flower client, we "
#~ "(again) create a subclass of "
#~ "``flwr.client.NumPyClient`` and implement the "
#~ "three methods ``get_parameters``, ``fit``, and"
#~ " ``evaluate``. Here, we also pass the"
#~ " ``cid`` to the client and use "
#~ "it log additional details:"
#~ msgstr ""

#~ msgid ""
#~ "Let's go deeper and see what it"
#~ " takes to move from ``NumPyClient`` "
#~ "to ``Client``!"
#~ msgstr ""

#~ msgid ""
#~ "So far, we've implemented our client "
#~ "by subclassing ``flwr.client.NumPyClient``. The "
#~ "three methods we implemented are "
#~ "``get_parameters``, ``fit``, and ``evaluate``. "
#~ "Finally, we wrap the creation of "
#~ "instances of this class in a "
#~ "function called ``client_fn``:"
#~ msgstr ""

#~ msgid ""
#~ "We've seen this before, there's nothing"
#~ " new so far. The only *tiny* "
#~ "difference compared to the previous "
#~ "notebook is naming, we've changed "
#~ "``FlowerClient`` to ``FlowerNumPyClient`` and "
#~ "``client_fn`` to ``numpyclient_fn``. Let's run"
#~ " it to see the output we get:"
#~ msgstr ""

#~ msgid ""
#~ "This works as expected, two clients "
#~ "are training for three rounds of "
#~ "federated learning."
#~ msgstr ""

#~ msgid ""
#~ "Let's dive a little bit deeper and"
#~ " discuss how Flower executes this "
#~ "simulation. Whenever a client is "
#~ "selected to do some work, "
#~ "``start_simulation`` calls the function "
#~ "``numpyclient_fn`` to create an instance "
#~ "of our ``FlowerNumPyClient`` (along with "
#~ "loading the model and the data)."
#~ msgstr ""

#~ msgid ""
#~ "`Check out Flower Code Examples "
#~ "<https://github.com/adap/flower/tree/main/examples>`__"
#~ msgstr ""

#~ msgid ""
#~ "`Watch Flower Summit 2023 videos "
#~ "<https://flower.ai/conf/flower-summit-2023/>`__"
#~ msgstr ""

#~ msgid ""
#~ "In this notebook, we'll build a "
#~ "federated learning system using Flower, "
#~ "`Flower Datasets <https://flower.ai/docs/datasets/>`__ "
#~ "and PyTorch. In part 1, we use "
#~ "PyTorch for the model training pipeline"
#~ " and data loading. In part 2, "
#~ "we continue to federate the PyTorch-"
#~ "based pipeline using Flower."
#~ msgstr ""

#~ msgid "Loading the data"
#~ msgstr ""

#~ msgid ""
#~ "We simulate having multiple datasets "
#~ "from multiple organizations (also called "
#~ "the \"cross-silo\" setting in federated"
#~ " learning) by splitting the original "
#~ "CIFAR-10 dataset into multiple partitions. "
#~ "Each partition will represent the data"
#~ " from a single organization. We're "
#~ "doing this purely for experimentation "
#~ "purposes, in the real world there's "
#~ "no need for data splitting because "
#~ "each organization already has their own"
#~ " data (so the data is naturally "
#~ "partitioned)."
#~ msgstr ""

#~ msgid ""
#~ "Each organization will act as a "
#~ "client in the federated learning system."
#~ " So having ten organizations participate"
#~ " in a federation means having ten "
#~ "clients connected to the federated "
#~ "learning server."
#~ msgstr ""

#~ msgid ""
#~ "Let's now create the Federated Dataset"
#~ " abstraction that from ``flwr-datasets``"
#~ " that partitions the CIFAR-10. We "
#~ "will create small training and test "
#~ "set for each edge device and wrap"
#~ " each of them into a PyTorch "
#~ "``DataLoader``:"
#~ msgstr ""

#~ msgid ""
#~ "We now have a list of ten "
#~ "training sets and ten validation sets"
#~ " (``trainloaders`` and ``valloaders``) "
#~ "representing the data of ten different"
#~ " organizations. Each ``trainloader``/``valloader`` "
#~ "pair contains 4000 training examples and"
#~ " 1000 validation examples. There's also "
#~ "a single ``testloader`` (we did not "
#~ "split the test set). Again, this "
#~ "is only necessary for building research"
#~ " or educational systems, actual federated"
#~ " learning systems have their data "
#~ "naturally distributed across multiple "
#~ "partitions."
#~ msgstr ""

#~ msgid ""
#~ "Let's take a look at the first "
#~ "batch of images and labels in the"
#~ " first training set (i.e., "
#~ "``trainloaders[0]``) before we move on:"
#~ msgstr ""

#~ msgid ""
#~ "The output above shows a random "
#~ "batch of images from the first "
#~ "``trainloader`` in our list of ten "
#~ "``trainloaders``. It also prints the "
#~ "labels associated with each image (i.e.,"
#~ " one of the ten possible labels "
#~ "we've seen above). If you run the"
#~ " cell again, you should see another"
#~ " batch of images."
#~ msgstr ""

#~ msgid "Defining the model"
#~ msgstr ""

#~ msgid "Training the model"
#~ msgstr ""

#~ msgid ""
#~ "We now have all the basic building"
#~ " blocks we need: a dataset, a "
#~ "model, a training function, and a "
#~ "test function. Let's put them together"
#~ " to train the model on the "
#~ "dataset of one of our organizations "
#~ "(``trainloaders[0]``). This simulates the "
#~ "reality of most machine learning "
#~ "projects today: each organization has "
#~ "their own data and trains models "
#~ "only on this internal data:"
#~ msgstr ""

#~ msgid ""
#~ "Training the simple CNN on our "
#~ "CIFAR-10 split for 5 epochs should "
#~ "result in a test set accuracy of"
#~ " about 41%, which is not good, "
#~ "but at the same time, it doesn't"
#~ " really matter for the purposes of"
#~ " this tutorial. The intent was just"
#~ " to show a simplistic centralized "
#~ "training pipeline that sets the stage"
#~ " for what comes next - federated "
#~ "learning!"
#~ msgstr ""

#~ msgid "Updating model parameters"
#~ msgstr ""

#~ msgid ""
#~ "In federated learning, the server sends"
#~ " the global model parameters to the"
#~ " client, and the client updates the"
#~ " local model with the parameters "
#~ "received from the server. It then "
#~ "trains the model on the local data"
#~ " (which changes the model parameters "
#~ "locally) and sends the updated/changed "
#~ "model parameters back to the server "
#~ "(or, alternatively, it sends just the"
#~ " gradients back to the server, not"
#~ " the full model parameters)."
#~ msgstr ""

#~ msgid ""
#~ "The details of how this works are"
#~ " not really important here (feel free"
#~ " to consult the PyTorch documentation "
#~ "if you want to learn more). In "
#~ "essence, we use ``state_dict`` to access"
#~ " PyTorch model parameter tensors. The "
#~ "parameter tensors are then converted "
#~ "to/from a list of NumPy ndarray's "
#~ "(which Flower knows how to "
#~ "serialize/deserialize):"
#~ msgstr ""

#~ msgid "Implementing a Flower client"
#~ msgstr ""

#~ msgid ""
#~ "With that out of the way, let's"
#~ " move on to the interesting part. "
#~ "Federated learning systems consist of a"
#~ " server and multiple clients. In "
#~ "Flower, we create clients by "
#~ "implementing subclasses of ``flwr.client.Client``"
#~ " or ``flwr.client.NumPyClient``. We use "
#~ "``NumPyClient`` in this tutorial because "
#~ "it is easier to implement and "
#~ "requires us to write less boilerplate."
#~ msgstr ""

#~ msgid ""
#~ "To implement the Flower client, we "
#~ "create a subclass of "
#~ "``flwr.client.NumPyClient`` and implement the "
#~ "three methods ``get_parameters``, ``fit``, and"
#~ " ``evaluate``:"
#~ msgstr ""

#~ msgid ""
#~ "``fit``: Receive model parameters from "
#~ "the server, train the model parameters"
#~ " on the local data, and return "
#~ "the (updated) model parameters to the"
#~ " server"
#~ msgstr ""

#~ msgid ""
#~ "``evaluate``: Receive model parameters from"
#~ " the server, evaluate the model "
#~ "parameters on the local data, and "
#~ "return the evaluation result to the "
#~ "server"
#~ msgstr ""

#~ msgid ""
#~ "Our class ``FlowerClient`` defines how "
#~ "local training/evaluation will be performed"
#~ " and allows Flower to call the "
#~ "local training/evaluation through ``fit`` and"
#~ " ``evaluate``. Each instance of "
#~ "``FlowerClient`` represents a *single client*"
#~ " in our federated learning system. "
#~ "Federated learning systems have multiple "
#~ "clients (otherwise, there's not much to"
#~ " federate), so each client will be"
#~ " represented by its own instance of"
#~ " ``FlowerClient``. If we have, for "
#~ "example, three clients in our workload,"
#~ " then we'd have three instances of"
#~ " ``FlowerClient``. Flower calls "
#~ "``FlowerClient.fit`` on the respective "
#~ "instance when the server selects a "
#~ "particular client for training (and "
#~ "``FlowerClient.evaluate`` for evaluation)."
#~ msgstr ""

#~ msgid "Using the Virtual Client Engine"
#~ msgstr ""

#~ msgid ""
#~ "In this notebook, we want to "
#~ "simulate a federated learning system "
#~ "with 10 clients on a single "
#~ "machine. This means that the server "
#~ "and all 10 clients will live on"
#~ " a single machine and share resources"
#~ " such as CPU, GPU, and memory. "
#~ "Having 10 clients would mean having "
#~ "10 instances of ``FlowerClient`` in "
#~ "memory. Doing this on a single "
#~ "machine can quickly exhaust the "
#~ "available memory resources, even if only"
#~ " a subset of these clients "
#~ "participates in a single round of "
#~ "federated learning."
#~ msgstr ""

#~ msgid ""
#~ "In addition to the regular capabilities"
#~ " where server and clients run on "
#~ "multiple machines, Flower, therefore, provides"
#~ " special simulation capabilities that "
#~ "create ``FlowerClient`` instances only when"
#~ " they are actually necessary for "
#~ "training or evaluation. To enable the"
#~ " Flower framework to create clients "
#~ "when necessary, we need to implement "
#~ "a function called ``client_fn`` that "
#~ "creates a ``FlowerClient`` instance on "
#~ "demand. Flower calls ``client_fn`` whenever"
#~ " it needs an instance of one "
#~ "particular client to call ``fit`` or "
#~ "``evaluate`` (those instances are usually "
#~ "discarded after use, so they should "
#~ "not keep any local state). Clients "
#~ "are identified by a client ID, or"
#~ " short ``cid``. The ``cid`` can be"
#~ " used, for example, to load different"
#~ " local data partitions for different "
#~ "clients, as can be seen below:"
#~ msgstr ""

#~ msgid "Starting the training"
#~ msgstr ""

#~ msgid ""
#~ "We now have the class ``FlowerClient``"
#~ " which defines client-side "
#~ "training/evaluation and ``client_fn`` which "
#~ "allows Flower to create ``FlowerClient`` "
#~ "instances whenever it needs to call "
#~ "``fit`` or ``evaluate`` on one "
#~ "particular client. The last step is "
#~ "to start the actual simulation using "
#~ "``flwr.simulation.start_simulation``."
#~ msgstr ""

#~ msgid ""
#~ "The function ``start_simulation`` accepts a"
#~ " number of arguments, amongst them "
#~ "the ``client_fn`` used to create "
#~ "``FlowerClient`` instances, the number of "
#~ "clients to simulate (``num_clients``), the "
#~ "number of federated learning rounds "
#~ "(``num_rounds``), and the strategy. The "
#~ "strategy encapsulates the federated learning"
#~ " approach/algorithm, for example, *Federated "
#~ "Averaging* (FedAvg)."
#~ msgstr ""

#~ msgid ""
#~ "Flower has a number of built-in"
#~ " strategies, but we can also use "
#~ "our own strategy implementations to "
#~ "customize nearly all aspects of the "
#~ "federated learning approach. For this "
#~ "example, we use the built-in "
#~ "``FedAvg`` implementation and customize it "
#~ "using a few basic parameters. The "
#~ "last step is the actual call to"
#~ " ``start_simulation`` which - you guessed"
#~ " it - starts the simulation:"
#~ msgstr ""

#~ msgid ""
#~ "When we call ``start_simulation``, we "
#~ "tell Flower that there are 10 "
#~ "clients (``num_clients=10``). Flower then goes"
#~ " ahead an asks the ``FedAvg`` "
#~ "strategy to select clients. ``FedAvg`` "
#~ "knows that it should select 100% "
#~ "of the available clients "
#~ "(``fraction_fit=1.0``), so it goes ahead "
#~ "and selects 10 random clients (i.e., "
#~ "100% of 10)."
#~ msgstr ""

#~ msgid ""
#~ "Flower then asks the selected 10 "
#~ "clients to train the model. When "
#~ "the server receives the model parameter"
#~ " updates from the clients, it hands"
#~ " those updates over to the strategy"
#~ " (*FedAvg*) for aggregation. The strategy"
#~ " aggregates those updates and returns "
#~ "the new global model, which then "
#~ "gets used in the next round of "
#~ "federated learning."
#~ msgstr ""

#~ msgid ""
#~ "The only thing left to do is "
#~ "to tell the strategy to call this"
#~ " function whenever it receives evaluation"
#~ " metric dictionaries from the clients:"
#~ msgstr ""

#~ msgid ""
#~ "In this notebook, we'll begin to "
#~ "customize the federated learning system "
#~ "we built in the introductory notebook"
#~ " (again, using `Flower <https://flower.ai/>`__"
#~ " and `PyTorch <https://pytorch.org/>`__)."
#~ msgstr ""

#~ msgid "Let's move beyond FedAvg with Flower strategies!"
#~ msgstr ""

#~ msgid ""
#~ "Flower, by default, initializes the "
#~ "global model by asking one random "
#~ "client for the initial parameters. In"
#~ " many cases, we want more control "
#~ "over parameter initialization though. Flower"
#~ " therefore allows you to directly "
#~ "pass the initial parameters to the "
#~ "Strategy:"
#~ msgstr ""

#~ msgid ""
#~ "Passing ``initial_parameters`` to the "
#~ "``FedAvg`` strategy prevents Flower from "
#~ "asking one of the clients for the"
#~ " initial parameters. If we look "
#~ "closely, we can see that the logs"
#~ " do not show any calls to the"
#~ " ``FlowerClient.get_parameters`` method."
#~ msgstr ""

#~ msgid ""
#~ "We've seen the function ``start_simulation``"
#~ " before. It accepts a number of "
#~ "arguments, amongst them the ``client_fn`` "
#~ "used to create ``FlowerClient`` instances, "
#~ "the number of clients to simulate "
#~ "``num_clients``, the number of rounds "
#~ "``num_rounds``, and the strategy."
#~ msgstr ""

#~ msgid ""
#~ "Next, we'll just pass this function "
#~ "to the FedAvg strategy before starting"
#~ " the simulation:"
#~ msgstr ""

#~ msgid ""
#~ "We now have 1000 partitions, each "
#~ "holding 45 training and 5 validation "
#~ "examples. Given that the number of "
#~ "training examples on each client is "
#~ "quite small, we should probably train"
#~ " the model a bit longer, so we"
#~ " configure the clients to perform 3"
#~ " local training epochs. We should "
#~ "also adjust the fraction of clients "
#~ "selected for training during each round"
#~ " (we don't want all 1000 clients "
#~ "participating in every round), so we "
#~ "adjust ``fraction_fit`` to ``0.05``, which "
#~ "means that only 5% of available "
#~ "clients (so 50 clients) will be "
#~ "selected for training each round:"
#~ msgstr ""

#~ msgid "|93b02017c78049bbbd5ae456dcb2c91b|"
#~ msgstr ""

#~ msgid "|01471150fd5144c080a176b43e92a3ff|"
#~ msgstr ""

#~ msgid "|9bc21c7dbd17444a8f070c60786e3484|"
#~ msgstr ""

#~ msgid "|3047bbce54b34099ae559963d0420d79|"
#~ msgstr ""

#~ msgid "|e9f8ce948593444fb838d2f354c7ec5d|"
#~ msgstr ""

#~ msgid "|c24c1478b30e4f74839208628a842d1e|"
#~ msgstr ""

#~ msgid "|1b3613d7a58847b59e1d3180802dbc09|"
#~ msgstr ""

#~ msgid "|9980b5213db547d0b8024a50992b9e3f|"
#~ msgstr ""

#~ msgid "|c7afb4c92d154bfaa5e8cb9a150e17f1|"
#~ msgstr ""

#~ msgid "|032eb6fed6924ac387b9f13854919196|"
#~ msgstr ""

#~ msgid "|fbf225add7fd4df5a9bf25a95597d954|"
#~ msgstr ""

#~ msgid "|7efbe3d29d8349b89594e8947e910525|"
#~ msgstr ""

#~ msgid "|329fb3c04c744eda83bb51fa444c2266|"
#~ msgstr ""

#~ msgid "|c00bf2750bc24d229737a0fe1395f0fc|"
#~ msgstr ""

#~ msgid ":py:obj:`client <flwr.client>`\\"
#~ msgstr ""

#~ msgid ":py:obj:`common <flwr.common>`\\"
#~ msgstr ""

#~ msgid ":py:obj:`server <flwr.server>`\\"
#~ msgstr ""

#~ msgid ":py:obj:`simulation <flwr.simulation>`\\"
#~ msgstr ""

#~ msgid ":py:obj:`mod <flwr.client.mod>`\\"
#~ msgstr ""

#~ msgid "run\\_client\\_app"
#~ msgstr ""

#~ msgid "run\\_supernode"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`get <flwr.common.ConfigsRecord.get>`\\ "
#~ "\\(key\\[\\, default\\]\\)"
#~ msgstr ""

#~ msgid "Retrieve the corresponding layout by the string key."
#~ msgstr ""

#~ msgid ""
#~ "When there isn't an exact match, "
#~ "all the existing keys in the "
#~ "layout map will be treated as a"
#~ " regex and map against the input "
#~ "key again. The first match will be"
#~ " returned, based on the key insertion"
#~ " order. Return None if there isn't"
#~ " any match found."
#~ msgstr ""

#~ msgid "the string key as the query for the layout."
#~ msgstr ""

#~ msgid "Corresponding layout based on the query."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`get <flwr.common.MetricsRecord.get>`\\ "
#~ "\\(key\\[\\, default\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`get <flwr.common.ParametersRecord.get>`\\ "
#~ "\\(key\\[\\, default\\]\\)"
#~ msgstr ""

#~ msgid ":py:obj:`strategy <flwr.server.strategy>`\\"
#~ msgstr ""

#~ msgid ":py:obj:`workflow <flwr.server.workflow>`\\"
#~ msgstr ""

#~ msgid "run\\_server\\_app"
#~ msgstr ""

#~ msgid "run\\_superlink"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`start_simulation <flwr.simulation.start_simulation>`\\"
#~ " \\(\\*\\, client\\_fn\\, num\\_clients\\)"
#~ msgstr ""

#~ msgid "Start a Ray-based Flower simulation server."
#~ msgstr ""

#~ msgid ""
#~ "A function creating `Client` instances. "
#~ "The function must have the signature "
#~ "`client_fn(context: Context). It should return"
#~ " a single client instance of type "
#~ "`Client`. Note that the created client"
#~ " instances are ephemeral and will "
#~ "often be destroyed after a single "
#~ "method invocation. Since client instances "
#~ "are not long-lived, they should "
#~ "not attempt to carry state over "
#~ "method invocations. Any state required "
#~ "by the instance (model, dataset, "
#~ "hyperparameters, ...) should be (re-)created"
#~ " in either the call to `client_fn`"
#~ " or the call to any of the "
#~ "client methods (e.g., load evaluation "
#~ "data in the `evaluate` method itself)."
#~ msgstr ""

#~ msgid "The total number of clients in this simulation."
#~ msgstr ""

#~ msgid ""
#~ "UNSUPPORTED, WILL BE REMOVED. USE "
#~ "`num_clients` INSTEAD. List `client_id`s for"
#~ " each client. This is only required"
#~ " if `num_clients` is not set. Setting"
#~ " both `num_clients` and `clients_ids` with"
#~ " `len(clients_ids)` not equal to "
#~ "`num_clients` generates an error. Using "
#~ "this argument will raise an error."
#~ msgstr ""

#~ msgid ""
#~ "CPU and GPU resources for a single"
#~ " client. Supported keys are `num_cpus` "
#~ "and `num_gpus`. To understand the GPU"
#~ " utilization caused by `num_gpus`, as "
#~ "well as using custom resources, please"
#~ " consult the Ray documentation."
#~ msgstr ""

#~ msgid ""
#~ "An implementation of the abstract base"
#~ " class `flwr.server.Server`. If no instance"
#~ " is provided, then `start_server` will "
#~ "create one."
#~ msgstr ""

#~ msgid ""
#~ "An implementation of the abstract base"
#~ " class `flwr.server.Strategy`. If no "
#~ "strategy is provided, then `start_server` "
#~ "will use `flwr.server.strategy.FedAvg`."
#~ msgstr ""

#~ msgid ""
#~ "An implementation of the abstract base"
#~ " class `flwr.server.ClientManager`. If no "
#~ "implementation is provided, then "
#~ "`start_simulation` will use "
#~ "`flwr.server.client_manager.SimpleClientManager`."
#~ msgstr ""

#~ msgid ""
#~ "Optional dictionary containing arguments for"
#~ " the call to `ray.init`. If "
#~ "ray_init_args is None (the default), Ray"
#~ " will be initialized with the "
#~ "following default args:  { "
#~ "\"ignore_reinit_error\": True, \"include_dashboard\": "
#~ "False }  An empty dictionary can "
#~ "be used (ray_init_args={}) to prevent "
#~ "any arguments from being passed to "
#~ "ray.init."
#~ msgstr ""

#~ msgid ""
#~ "Optional dictionary containing arguments for"
#~ " the call to `ray.init`. If "
#~ "ray_init_args is None (the default), Ray"
#~ " will be initialized with the "
#~ "following default args:"
#~ msgstr ""

#~ msgid "{ \"ignore_reinit_error\": True, \"include_dashboard\": False }"
#~ msgstr ""

#~ msgid ""
#~ "An empty dictionary can be used "
#~ "(ray_init_args={}) to prevent any arguments"
#~ " from being passed to ray.init."
#~ msgstr ""

#~ msgid ""
#~ "Set to True to prevent `ray.shutdown()`"
#~ " in case `ray.is_initialized()=True`."
#~ msgstr ""

#~ msgid ""
#~ "Optionally specify the type of actor "
#~ "to use. The actor object, which "
#~ "persists throughout the simulation, will "
#~ "be the process in charge of "
#~ "executing a ClientApp wrapping input "
#~ "argument `client_fn`."
#~ msgstr ""

#~ msgid ""
#~ "If you want to create your own "
#~ "Actor classes, you might need to "
#~ "pass some input argument. You can "
#~ "use this dictionary for such purpose."
#~ msgstr ""

#~ msgid ""
#~ "(default: \"DEFAULT\") Optional string "
#~ "(\"DEFAULT\" or \"SPREAD\") for the VCE"
#~ " to choose in which node the "
#~ "actor is placed. If you are an "
#~ "advanced user needed more control you"
#~ " can use lower-level scheduling "
#~ "strategies to pin actors to specific "
#~ "compute nodes (e.g. via "
#~ "NodeAffinitySchedulingStrategy). Please note this"
#~ " is an advanced feature. For all "
#~ "details, please refer to the Ray "
#~ "documentation: https://docs.ray.io/en/latest/ray-"
#~ "core/scheduling/index.html"
#~ msgstr ""

#~ msgid "**hist** -- Object containing metrics from training."
#~ msgstr ""

#~ msgid ""
#~ "Check out this Federated Learning "
#~ "quickstart tutorial for using Flower "
#~ "with FastAI to train a vision "
#~ "model on CIFAR-10."
#~ msgstr ""

#~ msgid "Let's build a federated learning system using fastai and Flower!"
#~ msgstr ""

#~ msgid ""
#~ "Please refer to the `full code "
#~ "example <https://github.com/adap/flower/tree/main/examples"
#~ "/quickstart-fastai>`_ to learn more."
#~ msgstr ""

#~ msgid ""
#~ "Check out this Federating Learning "
#~ "quickstart tutorial for using Flower "
#~ "with HuggingFace Transformers in order "
#~ "to fine-tune an LLM."
#~ msgstr ""

#~ msgid ""
#~ "Let's build a federated learning system"
#~ " using Hugging Face Transformers and "
#~ "Flower!"
#~ msgstr ""

#~ msgid ""
#~ "We will leverage Hugging Face to "
#~ "federate the training of language models"
#~ " over multiple clients using Flower. "
#~ "More specifically, we will fine-tune "
#~ "a pre-trained Transformer model "
#~ "(distilBERT) for sequence classification over"
#~ " a dataset of IMDB ratings. The "
#~ "end goal is to detect if a "
#~ "movie rating is positive or negative."
#~ msgstr ""

#~ msgid "Dependencies"
#~ msgstr ""

#~ msgid ""
#~ "To follow along this tutorial you "
#~ "will need to install the following "
#~ "packages: :code:`datasets`, :code:`evaluate`, "
#~ ":code:`flwr`, :code:`torch`, and "
#~ ":code:`transformers`. This can be done "
#~ "using :code:`pip`:"
#~ msgstr ""

#~ msgid "Standard Hugging Face workflow"
#~ msgstr ""

#~ msgid "Handling the data"
#~ msgstr ""

#~ msgid ""
#~ "To fetch the IMDB dataset, we will"
#~ " use Hugging Face's :code:`datasets` "
#~ "library. We then need to tokenize "
#~ "the data and create :code:`PyTorch` "
#~ "dataloaders, this is all done in "
#~ "the :code:`load_data` function:"
#~ msgstr ""

#~ msgid "Training and testing the model"
#~ msgstr ""

#~ msgid ""
#~ "Once we have a way of creating "
#~ "our trainloader and testloader, we can"
#~ " take care of the training and "
#~ "testing. This is very similar to "
#~ "any :code:`PyTorch` training or testing "
#~ "loop:"
#~ msgstr ""

#~ msgid "Creating the model itself"
#~ msgstr ""

#~ msgid ""
#~ "To create the model itself, we "
#~ "will just load the pre-trained "
#~ "distillBERT model using Hugging Face’s "
#~ ":code:`AutoModelForSequenceClassification` :"
#~ msgstr ""

#~ msgid "Federating the example"
#~ msgstr ""

#~ msgid "Creating the IMDBClient"
#~ msgstr ""

#~ msgid ""
#~ "To federate our example to multiple "
#~ "clients, we first need to write "
#~ "our Flower client class (inheriting from"
#~ " :code:`flwr.client.NumPyClient`). This is very"
#~ " easy, as our model is a "
#~ "standard :code:`PyTorch` model:"
#~ msgstr ""

#~ msgid ""
#~ "The :code:`get_parameters` function lets the"
#~ " server get the client's parameters. "
#~ "Inversely, the :code:`set_parameters` function "
#~ "allows the server to send its "
#~ "parameters to the client. Finally, the"
#~ " :code:`fit` function trains the model "
#~ "locally for the client, and the "
#~ ":code:`evaluate` function tests the model "
#~ "locally and returns the relevant "
#~ "metrics."
#~ msgstr ""

#~ msgid "Starting the server"
#~ msgstr ""

#~ msgid ""
#~ "Now that we have a way to "
#~ "instantiate clients, we need to create"
#~ " our server in order to aggregate "
#~ "the results. Using Flower, this can "
#~ "be done very easily by first "
#~ "choosing a strategy (here, we are "
#~ "using :code:`FedAvg`, which will define "
#~ "the global weights as the average "
#~ "of all the clients' weights at "
#~ "each round) and then using the "
#~ ":code:`flwr.server.start_server` function:"
#~ msgstr ""

#~ msgid ""
#~ "The :code:`weighted_average` function is there"
#~ " to provide a way to aggregate "
#~ "the metrics distributed amongst the "
#~ "clients (basically this allows us to "
#~ "display a nice average accuracy and "
#~ "loss for every round)."
#~ msgstr ""

#~ msgid "Putting everything together"
#~ msgstr ""

#~ msgid "We can now start client instances using:"
#~ msgstr ""

#~ msgid ""
#~ "And they will be able to connect"
#~ " to the server and start the "
#~ "federated training."
#~ msgstr ""

#~ msgid ""
#~ "If you want to check out "
#~ "everything put together, you should "
#~ "check out the `full code example "
#~ "<https://github.com/adap/flower/tree/main/examples/quickstart-"
#~ "huggingface>`_ ."
#~ msgstr ""

#~ msgid ""
#~ "Of course, this is a very basic"
#~ " example, and a lot can be "
#~ "added or modified, it was just to"
#~ " showcase how simply we could "
#~ "federate a Hugging Face workflow using"
#~ " Flower."
#~ msgstr ""

#~ msgid ""
#~ "Note that in this example we used"
#~ " :code:`PyTorch`, but we could have "
#~ "very well used :code:`TensorFlow`."
#~ msgstr ""

#~ msgid ""
#~ "Check out this Federated Learning "
#~ "quickstart tutorial for using Flower "
#~ "with PyTorch Lightning to train an "
#~ "Auto Encoder model on MNIST."
#~ msgstr ""

#~ msgid ""
#~ "Let's build a horizontal federated "
#~ "learning system using PyTorch Lightning "
#~ "and Flower!"
#~ msgstr ""

#~ msgid ""
#~ "Please refer to the `full code "
#~ "example <https://github.com/adap/flower/tree/main/examples"
#~ "/quickstart-pytorch-lightning>`_ to learn "
#~ "more."
#~ msgstr ""

#~ msgid ""
#~ "Check out this Federated Learning "
#~ "quickstart tutorial for using Flower "
#~ "with TensorFlow to train a MobilNetV2"
#~ " model on CIFAR-10."
#~ msgstr ""

#~ msgid "Let's build a federated learning system in less than 20 lines of code!"
#~ msgstr ""

#~ msgid "Before Flower can be imported we have to install it:"
#~ msgstr ""

#~ msgid ""
#~ "Since we want to use the Keras "
#~ "API of TensorFlow (TF), we have to"
#~ " install TF as well:"
#~ msgstr ""

#~ msgid "Next, in a file called :code:`client.py`, import Flower and TensorFlow:"
#~ msgstr ""

#~ msgid ""
#~ "We use the Keras utilities of TF"
#~ " to load CIFAR10, a popular colored"
#~ " image classification dataset for machine"
#~ " learning. The call to "
#~ ":code:`tf.keras.datasets.cifar10.load_data()` downloads "
#~ "CIFAR10, caches it locally, and then "
#~ "returns the entire training and test "
#~ "set as NumPy ndarrays."
#~ msgstr ""

#~ msgid ""
#~ "Next, we need a model. For the "
#~ "purpose of this tutorial, we use "
#~ "MobilNetV2 with 10 output classes:"
#~ msgstr ""

#~ msgid ""
#~ "The Flower server interacts with clients"
#~ " through an interface called "
#~ ":code:`Client`. When the server selects "
#~ "a particular client for training, it "
#~ "sends training instructions over the "
#~ "network. The client receives those "
#~ "instructions and calls one of the "
#~ ":code:`Client` methods to run your code"
#~ " (i.e., to train the neural network"
#~ " we defined earlier)."
#~ msgstr ""

#~ msgid ""
#~ "Flower provides a convenience class "
#~ "called :code:`NumPyClient` which makes it "
#~ "easier to implement the :code:`Client` "
#~ "interface when your workload uses Keras."
#~ " The :code:`NumPyClient` interface defines "
#~ "three methods which can be implemented"
#~ " in the following way:"
#~ msgstr ""

#~ msgid ""
#~ "We can now create an instance of"
#~ " our class :code:`CifarClient` and add "
#~ "one line to actually run this "
#~ "client:"
#~ msgstr ""

#~ msgid ""
#~ "That's it for the client. We only"
#~ " have to implement :code:`Client` or "
#~ ":code:`NumPyClient` and call "
#~ ":code:`fl.client.start_client()`. If you implement"
#~ " a client of type :code:`NumPyClient` "
#~ "you'll need to first call its "
#~ ":code:`to_client()` method. The string "
#~ ":code:`\"[::]:8080\"` tells the client which"
#~ " server to connect to. In our "
#~ "case we can run the server and "
#~ "the client on the same machine, "
#~ "therefore we use :code:`\"[::]:8080\"`. If "
#~ "we run a truly federated workload "
#~ "with the server and clients running "
#~ "on different machines, all that needs"
#~ " to change is the :code:`server_address`"
#~ " we point the client at."
#~ msgstr ""

#~ msgid "Each client will have its own dataset."
#~ msgstr ""

#~ msgid ""
#~ "You should now see how the "
#~ "training does in the very first "
#~ "terminal (the one that started the "
#~ "server):"
#~ msgstr ""

#~ msgid ""
#~ "Congratulations! You've successfully built and"
#~ " run your first federated learning "
#~ "system. The full `source code "
#~ "<https://github.com/adap/flower/blob/main/examples/quickstart-"
#~ "tensorflow/client.py>`_ for this can be "
#~ "found in :code:`examples/quickstart-"
#~ "tensorflow/client.py`."
#~ msgstr ""

#~ msgid "|e5918c1c06a4434bbe4bf49235e40059|"
#~ msgstr ""

#~ msgid "|c0165741bd1944f09ec55ce49032377d|"
#~ msgstr ""

#~ msgid "|0a0ac9427ac7487b8e52d75ed514f04e|"
#~ msgstr ""

#~ msgid "|5defee3ea4ca40d99fcd3e4ea045be25|"
#~ msgstr ""

#~ msgid "|74f26ca701254d3db57d7899bd91eb55|"
#~ msgstr ""

#~ msgid "|bda79f21f8154258a40e5766b2634ad7|"
#~ msgstr ""

#~ msgid "|89d30862e62e4f9989e193483a08680a|"
#~ msgstr ""

#~ msgid "|77e9918671c54b4f86e01369c0785ce8|"
#~ msgstr ""

#~ msgid "|7e4ccef37cc94148a067107b34eb7447|"
#~ msgstr ""

#~ msgid "|28e47e4cded14479a0846c8e5f22c872|"
#~ msgstr ""

#~ msgid "|4b8c5d1afa144294b76ffc76e4658a38|"
#~ msgstr ""

#~ msgid "|9dbdb3a0f6cb4a129fac863eaa414c17|"
#~ msgstr ""

#~ msgid "|81749d0ac0834c36a83bd38f433fea31|"
#~ msgstr ""

#~ msgid "|ed9aae51da70428eab7eef32f21e819e|"
#~ msgstr ""

#~ msgid "|e87b69b2ada74ea49412df16f4a0b9cc|"
#~ msgstr ""

#~ msgid "|33cacb7d985c4906b348515c1a5cd993|"
#~ msgstr ""

#~ msgid "|cc080a555947492fa66131dc3a967603|"
#~ msgstr ""

#~ msgid "|085c3e0fb8664c6aa06246636524b20b|"
#~ msgstr ""

#~ msgid "|bfe69c74e48c45d49b50251c38c2a019|"
#~ msgstr ""

#~ msgid "|ebbecd651f0348d99c6511ea859bf4ca|"
#~ msgstr ""

#~ msgid "|163117eb654a4273babba413cf8065f5|"
#~ msgstr ""

#~ msgid "|452ac3ba453b4cd1be27be1ba7560d64|"
#~ msgstr ""

#~ msgid "|f403fcd69e4e44409627e748b404c086|"
#~ msgstr ""

#~ msgid "|4b00fe63870145968f8443619a792a42|"
#~ msgstr ""

#~ msgid "|368378731066486fa4397e89bc6b870c|"
#~ msgstr ""

#~ msgid "|a66aa83d85bf4ffba7ed660b718066da|"
#~ msgstr ""

#~ msgid "|82324b9af72a4582a81839d55caab767|"
#~ msgstr ""

#~ msgid "|fbf2da0da3cc4f8ab3b3eff852d80c41|"
#~ msgstr ""

#~ msgid ""
#~ "The Visual Studio Code Remote - "
#~ "Containers extension lets you use a "
#~ "Docker container as a fully-featured "
#~ "development environment. It allows you "
#~ "to open any folder inside (or "
#~ "mounted into) a container and take "
#~ "advantage of Visual Studio Code's full"
#~ " feature set. A :code:`devcontainer.json` "
#~ "file in your project tells VS Code"
#~ " how to access (or create) a "
#~ "development container with a well-"
#~ "defined tool and runtime stack. This "
#~ "container can be used to run an"
#~ " application or to separate tools, "
#~ "libraries, or runtimes needed for "
#~ "working with a codebase."
#~ msgstr ""

#~ msgid ""
#~ "Configuring and setting up the "
#~ ":code:`Dockerfile` as well the configuration"
#~ " for the devcontainer can be a "
#~ "bit more involved. The good thing "
#~ "is you don't have to do it. "
#~ "Usually it should be enough to "
#~ "install `Docker "
#~ "<https://docs.docker.com/engine/install/>`_ on your "
#~ "system and ensure its available on "
#~ "your command line. Additionally, install "
#~ "the `VSCode Containers Extension "
#~ "<vscode:extension/ms-vscode-remote.remote-"
#~ "containers>`_."
#~ msgstr ""

#~ msgid ""
#~ "If you prefer to use Anaconda for"
#~ " your virtual environment then install "
#~ "and setup the `conda "
#~ "<https://docs.conda.io/projects/conda/en/latest/user-"
#~ "guide/install/index.html>`_  package. After setting"
#~ " it up you can create a virtual"
#~ " environment with:"
#~ msgstr ""

#~ msgid "The :code:`SecAgg+` abstraction"
#~ msgstr ""

#~ msgid "The :code:`LightSecAgg` abstraction"
#~ msgstr ""

#~ msgid ""
#~ "A fork is a personal copy of "
#~ "a GitHub repository. To create one "
#~ "for Flower, you must navigate to "
#~ "`<https://github.com/adap/flower>`_ (while connected "
#~ "to your GitHub account) and click "
#~ "the ``Fork`` button situated on the "
#~ "top right of the page."
#~ msgstr ""

#~ msgid ""
#~ "To check which files have been "
#~ "modified compared to the last version"
#~ " (last commit) and to see which "
#~ "files are staged for commit, you "
#~ "can use the :code:`git status` command."
#~ msgstr ""

#~ msgid ""
#~ "Once you have added all the files"
#~ " you wanted to commit using "
#~ ":code:`git add`, you can finally create"
#~ " your commit using this command:"
#~ msgstr ""

#~ msgid ""
#~ "The \\<commit_message\\> is there to "
#~ "explain to others what the commit "
#~ "does. It should be written in an"
#~ " imperative style and be concise. An"
#~ " example would be :code:`git commit "
#~ "-m \"Add images to README\"`."
#~ msgstr ""

#~ msgid ""
#~ ":doc:`Good first contributions <contributor-"
#~ "ref-good-first-contributions>`, where you"
#~ " should particularly look into the "
#~ ":code:`baselines` contributions."
#~ msgstr ""

#~ msgid ""
#~ "Flower uses :code:`pyproject.toml` to manage"
#~ " dependencies and configure development "
#~ "tools (the ones which support it). "
#~ "Poetry is a build tool which "
#~ "supports `PEP 517 "
#~ "<https://peps.python.org/pep-0517/>`_."
#~ msgstr ""

#~ msgid ""
#~ "Install `xz` (to install different "
#~ "Python versions) and `pandoc` to build"
#~ " the docs::"
#~ msgstr ""

#~ msgid ""
#~ "Ensure you system (Ubuntu 22.04+) is "
#~ "up-to-date, and you have all "
#~ "necessary packages::"
#~ msgstr ""

#~ msgid ""
#~ "1. Clone the `Flower repository "
#~ "<https://github.com/adap/flower>`_ from GitHub::"
#~ msgstr ""

#~ msgid ""
#~ "Let's create the Python environment for"
#~ " all-things Flower. If you wish "
#~ "to use :code:`pyenv`, we provide two "
#~ "convenience scripts that you can use."
#~ " If you prefer using something else"
#~ " than :code:`pyenv`, create a new "
#~ "environment, activate and skip to the"
#~ " last point where all packages are"
#~ " installed."
#~ msgstr ""

#~ msgid ""
#~ "If you don't have :code:`pyenv` "
#~ "installed, the following script that "
#~ "will install it, set it up, and"
#~ " create the virtual environment (with "
#~ ":code:`Python 3.9.20` by default)::"
#~ msgstr ""

#~ msgid ""
#~ "If you already have :code:`pyenv` "
#~ "installed (along with the :code:`pyenv-"
#~ "virtualenv` plugin), you can use the "
#~ "following convenience script (with "
#~ ":code:`Python 3.9.20` by default)::"
#~ msgstr ""

#~ msgid ""
#~ "3. Install the Flower package in "
#~ "development mode (think :code:`pip install "
#~ "-e`) along with all necessary "
#~ "dependencies::"
#~ msgstr ""

#~ msgid ""
#~ "The Flower repository contains a number"
#~ " of convenience scripts to make "
#~ "recurring development tasks easier and "
#~ "less error-prone. See the :code:`/dev`"
#~ " subdirectory for a full list. The"
#~ " following scripts are amongst the "
#~ "most important ones:"
#~ msgstr ""

#~ msgid ""
#~ "If in a hurry, bypass the hook "
#~ "using ``--no-verify`` with the ``git "
#~ "commit`` command. ::"
#~ msgstr ""

#~ msgid ""
#~ "Developers could run the full set "
#~ "of Github Actions workflows under their"
#~ " local environment by using `Act "
#~ "<https://github.com/nektos/act>`_. Please refer to"
#~ " the installation instructions under the"
#~ " linked repository and run the next"
#~ " command under Flower main cloned "
#~ "repository folder::"
#~ msgstr ""

#~ msgid ""
#~ "Flower uses Poetry to build releases."
#~ " The necessary command is wrapped in"
#~ " a simple script::"
#~ msgstr ""

#~ msgid ""
#~ "The resulting :code:`.whl` and :code:`.tar.gz`"
#~ " releases will be stored in the "
#~ ":code:`/dist` subdirectory."
#~ msgstr ""

#~ msgid ""
#~ "Flower's documentation uses `Sphinx "
#~ "<https://www.sphinx-doc.org/>`_. There's no "
#~ "convenience script to re-build the "
#~ "documentation yet, but it's pretty "
#~ "easy::"
#~ msgstr ""

#~ msgid ""
#~ "Some quickstart examples may have "
#~ "limitations or requirements that prevent "
#~ "them from running on every environment."
#~ " For more information, please see "
#~ "`Limitations`_."
#~ msgstr ""

#~ msgid ""
#~ "Change the application code. For "
#~ "example, change the  ``seed`` in "
#~ "``quickstart_docker/task.py`` to ``43`` and "
#~ "save it:"
#~ msgstr ""

#~ msgid ""
#~ "All files are revised based on "
#~ ":doc:`Example: PyTorch - From Centralized "
#~ "To Federated <example-pytorch-from-"
#~ "centralized-to-federated>`. The only thing"
#~ " to do is modifying the file "
#~ "called :code:`cifar.py`, revised part is "
#~ "shown below:"
#~ msgstr ""

#~ msgid ""
#~ "If you have read :doc:`Example: PyTorch"
#~ " - From Centralized To Federated "
#~ "<example-pytorch-from-centralized-to-"
#~ "federated>`, the following parts are "
#~ "easy to follow, only :code:`get_parameters`"
#~ " and :code:`set_parameters` function in "
#~ ":code:`client.py` needed to revise. If "
#~ "not, please read the :doc:`Example: "
#~ "PyTorch - From Centralized To Federated"
#~ " <example-pytorch-from-centralized-to-"
#~ "federated>`. first."
#~ msgstr ""

#~ msgid ""
#~ "Our example consists of one *server* "
#~ "and two *clients*. In FedBN, "
#~ ":code:`server.py` keeps unchanged, we can "
#~ "start the server directly."
#~ msgstr ""

#~ msgid ""
#~ "Finally, we will revise our *client* "
#~ "logic by changing :code:`get_parameters` and"
#~ " :code:`set_parameters` in :code:`client.py`, we"
#~ " will exclude batch normalization "
#~ "parameters from model parameter list "
#~ "when sending to or receiving from "
#~ "the server."
#~ msgstr ""

#~ msgid ""
#~ "Let's create a new file called "
#~ ":code:`cifar.py` with all the components "
#~ "required for a traditional (centralized) "
#~ "training on CIFAR-10. First, all "
#~ "required packages (such as :code:`torch` "
#~ "and :code:`torchvision`) need to be "
#~ "imported. You can see that we do"
#~ " not import any package for federated"
#~ " learning. You can keep all these "
#~ "imports as they are even when we"
#~ " add the federated learning components "
#~ "at a later point."
#~ msgstr ""

#~ msgid ""
#~ "As already mentioned we will use "
#~ "the CIFAR-10 dataset for this machine"
#~ " learning workload. The model architecture"
#~ " (a very simple Convolutional Neural "
#~ "Network) is defined in :code:`class "
#~ "Net()`."
#~ msgstr ""

#~ msgid ""
#~ "The :code:`load_data()` function loads the "
#~ "CIFAR-10 training and test sets. The "
#~ ":code:`transform` normalized the data after"
#~ " loading."
#~ msgstr ""

#~ msgid ""
#~ "We now need to define the training"
#~ " (function :code:`train()`) which loops "
#~ "over the training set, measures the "
#~ "loss, backpropagates it, and then takes"
#~ " one optimizer step for each batch"
#~ " of training examples."
#~ msgstr ""

#~ msgid ""
#~ "The evaluation of the model is "
#~ "defined in the function :code:`test()`. "
#~ "The function loops over all test "
#~ "samples and measures the loss of "
#~ "the model based on the test "
#~ "dataset."
#~ msgstr ""

#~ msgid ""
#~ "The concept is easy to understand. "
#~ "We have to start a *server* and"
#~ " then use the code in "
#~ ":code:`cifar.py` for the *clients* that "
#~ "are connected to the *server*. The "
#~ "*server* sends model parameters to the"
#~ " clients. The *clients* run the "
#~ "training and update the parameters. The"
#~ " updated parameters are sent back to"
#~ " the *server* which averages all "
#~ "received parameter updates. This describes "
#~ "one round of the federated learning "
#~ "process and we repeat this for "
#~ "multiple rounds."
#~ msgstr ""

#~ msgid ""
#~ "Our example consists of one *server* "
#~ "and two *clients*. Let's set up "
#~ ":code:`server.py` first. The *server* needs"
#~ " to import the Flower package "
#~ ":code:`flwr`. Next, we use the "
#~ ":code:`start_server` function to start a "
#~ "server and tell it to perform "
#~ "three rounds of federated learning."
#~ msgstr ""

#~ msgid ""
#~ "Finally, we will define our *client* "
#~ "logic in :code:`client.py` and build "
#~ "upon the previously defined centralized "
#~ "training in :code:`cifar.py`. Our *client* "
#~ "needs to import :code:`flwr`, but also"
#~ " :code:`torch` to update the parameters "
#~ "on our PyTorch model:"
#~ msgstr ""

#~ msgid ""
#~ "Implementing a Flower *client* basically "
#~ "means implementing a subclass of either"
#~ " :code:`flwr.client.Client` or "
#~ ":code:`flwr.client.NumPyClient`. Our implementation "
#~ "will be based on "
#~ ":code:`flwr.client.NumPyClient` and we'll call "
#~ "it :code:`CifarClient`. :code:`NumPyClient` is "
#~ "slightly easier to implement than "
#~ ":code:`Client` if you use a framework"
#~ " with good NumPy interoperability (like "
#~ "PyTorch or TensorFlow/Keras) because it "
#~ "avoids some of the boilerplate that "
#~ "would otherwise be necessary. "
#~ ":code:`CifarClient` needs to implement four"
#~ " methods, two methods for getting/setting"
#~ " model parameters, one method for "
#~ "training the model, and one method "
#~ "for testing the model:"
#~ msgstr ""

#~ msgid ":code:`set_parameters`"
#~ msgstr ""

#~ msgid ""
#~ "loop over the list of model "
#~ "parameters received as NumPy :code:`ndarray`'s"
#~ " (think list of neural network "
#~ "layers)"
#~ msgstr ""

#~ msgid ":code:`get_parameters`"
#~ msgstr ""

#~ msgid ""
#~ "get the model parameters and return "
#~ "them as a list of NumPy "
#~ ":code:`ndarray`'s (which is what "
#~ ":code:`flwr.client.NumPyClient` expects)"
#~ msgstr ""

#~ msgid ":code:`fit`"
#~ msgstr ""

#~ msgid ":code:`evaluate`"
#~ msgstr ""

#~ msgid ""
#~ "The two :code:`NumPyClient` methods "
#~ ":code:`fit` and :code:`evaluate` make use "
#~ "of the functions :code:`train()` and "
#~ ":code:`test()` previously defined in "
#~ ":code:`cifar.py`. So what we really do"
#~ " here is we tell Flower through "
#~ "our :code:`NumPyClient` subclass which of "
#~ "our already defined functions to call"
#~ " for training and evaluation. We "
#~ "included type annotations to give you"
#~ " a better understanding of the data"
#~ " types that get passed around."
#~ msgstr ""

#~ msgid ""
#~ "All that's left to do it to "
#~ "define a function that loads both "
#~ "model and data, creates a "
#~ ":code:`CifarClient`, and starts this client."
#~ " You load your data and model "
#~ "by using :code:`cifar.py`. Start "
#~ ":code:`CifarClient` with the function "
#~ ":code:`fl.client.start_client()` by pointing it "
#~ "at the same IP address we used "
#~ "in :code:`server.py`:"
#~ msgstr ""

#~ msgid ""
#~ "\\small\n"
#~ "\\frac{∆ \\times \\sqrt{2 \\times "
#~ "\\log\\left(\\frac{1.25}{\\delta}\\right)}}{\\epsilon}\n"
#~ "\n"
#~ msgstr ""

#~ msgid ""
#~ "The :code:`Strategy` abstraction provides a"
#~ " method called :code:`evaluate` that can"
#~ " directly be used to evaluate the "
#~ "current global model parameters. The "
#~ "current server implementation calls "
#~ ":code:`evaluate` after parameter aggregation "
#~ "and before federated evaluation (see "
#~ "next paragraph)."
#~ msgstr ""

#~ msgid ""
#~ "Client-side evaluation happens in the"
#~ " :code:`Client.evaluate` method and can be"
#~ " configured from the server side."
#~ msgstr ""

#~ msgid ""
#~ ":code:`fraction_evaluate`: a :code:`float` defining"
#~ " the fraction of clients that will"
#~ " be selected for evaluation. If "
#~ ":code:`fraction_evaluate` is set to "
#~ ":code:`0.1` and :code:`100` clients are "
#~ "connected to the server, then :code:`10`"
#~ " will be randomly selected for "
#~ "evaluation. If :code:`fraction_evaluate` is "
#~ "set to :code:`0.0`, federated evaluation "
#~ "will be disabled."
#~ msgstr ""

#~ msgid ""
#~ ":code:`min_evaluate_clients`: an :code:`int`: the"
#~ " minimum number of clients to be "
#~ "selected for evaluation. If "
#~ ":code:`fraction_evaluate` is set to "
#~ ":code:`0.1`, :code:`min_evaluate_clients` is set "
#~ "to 20, and :code:`100` clients are "
#~ "connected to the server, then :code:`20`"
#~ " clients will be selected for "
#~ "evaluation."
#~ msgstr ""

#~ msgid ""
#~ ":code:`min_available_clients`: an :code:`int` that"
#~ " defines the minimum number of "
#~ "clients which need to be connected "
#~ "to the server before a round of"
#~ " federated evaluation can start. If "
#~ "fewer than :code:`min_available_clients` are "
#~ "connected to the server, the server "
#~ "will wait until more clients are "
#~ "connected before it continues to sample"
#~ " clients for evaluation."
#~ msgstr ""

#~ msgid ""
#~ ":code:`on_evaluate_config_fn`: a function that "
#~ "returns a configuration dictionary which "
#~ "will be sent to the selected "
#~ "clients. The function will be called "
#~ "during each round and provides a "
#~ "convenient way to customize client-side"
#~ " evaluation from the server side, for"
#~ " example, to configure the number of"
#~ " validation steps performed."
#~ msgstr ""

#~ msgid ""
#~ "Model parameters can also be evaluated"
#~ " during training. :code:`Client.fit` can "
#~ "return arbitrary evaluation results as a"
#~ " dictionary:"
#~ msgstr ""

#~ msgid ""
#~ "The same :code:`Strategy`-customization approach "
#~ "can be used to aggregate custom "
#~ "evaluation results coming from individual "
#~ "clients. Clients can return custom "
#~ "metrics to the server by returning "
#~ "a dictionary:"
#~ msgstr ""

#~ msgid "Enable node authentication in :code:`SuperLink`"
#~ msgstr ""

#~ msgid ""
#~ "To enable node authentication, first you"
#~ " need to configure SSL/TLS connections "
#~ "to secure the SuperLink<>SuperNode "
#~ "communication. You can find the complete"
#~ " guide `here <https://flower.ai/docs/framework/how-"
#~ "to-enable-ssl-connections.html>`_. After "
#~ "configuring secure connections, you can "
#~ "enable client authentication in a "
#~ "long-running Flower :code:`SuperLink`. Use "
#~ "the following terminal command to start"
#~ " a Flower :code:`SuperNode` that has "
#~ "both secure connections and node "
#~ "authentication enabled:"
#~ msgstr ""

#~ msgid ""
#~ "The first flag :code:`--auth-list-"
#~ "public-keys` expects a path to a "
#~ "CSV file storing all known node "
#~ "public keys. You need to store all"
#~ " known node public keys that are "
#~ "allowed to participate in a federation"
#~ " in one CSV file (:code:`.csv`)."
#~ msgstr ""

#~ msgid ""
#~ "The second and third flags :code"
#~ ":`--auth-superlink-private-key` and :code"
#~ ":`--auth-superlink-public-key` expect paths"
#~ " to the server's private and public"
#~ " keys. For development purposes, you "
#~ "can generate a private and public "
#~ "key pair using :code:`ssh-keygen -t "
#~ "ecdsa -b 384`."
#~ msgstr ""

#~ msgid "Enable node authentication in :code:`SuperNode`"
#~ msgstr ""

#~ msgid ""
#~ "Similar to the long-running Flower "
#~ "server (:code:`SuperLink`), you can easily "
#~ "enable node authentication in the "
#~ "long-running Flower client (:code:`SuperNode`)."
#~ " Use the following terminal command "
#~ "to start an authenticated :code:`SuperNode`:"
#~ msgstr ""

#~ msgid ""
#~ "The :code:`--auth-supernode-private-key` "
#~ "flag expects a path to the node's"
#~ " private key file and the :code"
#~ ":`--auth-supernode-public-key` flag expects"
#~ " a path to the node's public "
#~ "key file. For development purposes, you"
#~ " can generate a private and public"
#~ " key pair using :code:`ssh-keygen -t"
#~ " ecdsa -b 384`."
#~ msgstr ""

#~ msgid ""
#~ "You should now have learned how to"
#~ " start a long-running Flower server"
#~ " (:code:`SuperLink`) and client "
#~ "(:code:`SuperNode`) with node authentication "
#~ "enabled. You should also know the "
#~ "significance of the private key and "
#~ "store it safely to minimize security "
#~ "risks."
#~ msgstr ""

#~ msgid ""
#~ "The easiest way to send configuration"
#~ " values to clients is to use a"
#~ " built-in strategy like :code:`FedAvg`. "
#~ "Built-in strategies support so-called"
#~ " configuration functions. A configuration "
#~ "function is a function that the "
#~ "built-in strategy calls to get the"
#~ " configuration dictionary for the current"
#~ " round. It then forwards the "
#~ "configuration dictionary to all the "
#~ "clients selected during that round."
#~ msgstr ""

#~ msgid ""
#~ "To make the built-in strategies "
#~ "use this function, we can pass it"
#~ " to ``FedAvg`` during initialization using"
#~ " the parameter :code:`on_fit_config_fn`:"
#~ msgstr ""

#~ msgid "The :code:`FedAvg` strategy will call this function *every round*."
#~ msgstr ""

#~ msgid ""
#~ "This can be achieved by customizing "
#~ "an existing strategy or by "
#~ ":doc:`implementing a custom strategy from "
#~ "scratch <how-to-implement-strategies>`. "
#~ "Here's a nonsensical example that "
#~ "customizes :code:`FedAvg` by adding a "
#~ "custom ``\"hello\": \"world\"`` configuration "
#~ "key/value pair to the config dict "
#~ "of a *single client* (only the "
#~ "first client in the list, the "
#~ "other clients in this round to not"
#~ " receive this \"special\" config value):"
#~ msgstr ""

#~ msgid ""
#~ "containing relevant information including: log"
#~ " message level (e.g. :code:`INFO`, "
#~ ":code:`DEBUG`), a timestamp, the line "
#~ "where the logging took place from, "
#~ "as well as the log message itself."
#~ " In this way, the logger would "
#~ "typically display information on your "
#~ "terminal as follows:"
#~ msgstr ""

#~ msgid ""
#~ "By default, the Flower log is "
#~ "outputted to the terminal where you "
#~ "launch your Federated Learning workload "
#~ "from. This applies for both gRPC-"
#~ "based federation (i.e. when you do "
#~ ":code:`fl.server.start_server`) and when using "
#~ "the :code:`VirtualClientEngine` (i.e. when you"
#~ " do :code:`fl.simulation.start_simulation`). In "
#~ "some situations you might want to "
#~ "save this log to disk. You can "
#~ "do so by calling the "
#~ "`fl.common.logger.configure() "
#~ "<https://github.com/adap/flower/blob/main/src/py/flwr/common/logger.py>`_"
#~ " function. For example:"
#~ msgstr ""

#~ msgid ""
#~ "With the above, Flower will record "
#~ "the log you see on your terminal"
#~ " to :code:`log.txt`. This file will "
#~ "be created in the same directory "
#~ "as were you are running the code"
#~ " from. If we inspect we see the"
#~ " log above is also recorded but "
#~ "prefixing with :code:`identifier` each line:"
#~ msgstr ""

#~ msgid ""
#~ "The :code:`fl.common.logger.configure` function, "
#~ "also allows specifying a host to "
#~ "which logs can be pushed (via "
#~ ":code:`POST`) through a native Python "
#~ ":code:`logging.handler.HTTPHandler`. This is a "
#~ "particularly useful feature in "
#~ ":code:`gRPC`-based Federated Learning workloads "
#~ "where otherwise gathering logs from all"
#~ " entities (i.e. the server and the"
#~ " clients) might be cumbersome. Note "
#~ "that in Flower simulation, the server"
#~ " automatically displays all logs. You "
#~ "can still specify a :code:`HTTPHandler` "
#~ "should you wish to backup or "
#~ "analyze the logs somewhere else."
#~ msgstr ""

#~ msgid ""
#~ "This guide describes how to a "
#~ "SSL-enabled secure Flower server "
#~ "(:code:`SuperLink`) can be started and "
#~ "how a Flower client (:code:`SuperNode`) "
#~ "can establish a secure connections to"
#~ " it."
#~ msgstr ""

#~ msgid ""
#~ "The code example comes with a "
#~ ":code:`README.md` file which explains how "
#~ "to start it. Although it is "
#~ "already SSL-enabled, it might be "
#~ "less descriptive on how it does "
#~ "so. Stick to this guide for a "
#~ "deeper introduction to the topic."
#~ msgstr ""

#~ msgid ""
#~ "Using SSL-enabled connections requires "
#~ "certificates to be passed to the "
#~ "server and client. For the purpose "
#~ "of this guide we are going to "
#~ "generate self-signed certificates. As "
#~ "this can become quite complex we "
#~ "are going to ask you to run "
#~ "the script in :code:`examples/advanced-"
#~ "tensorflow/certificates/generate.sh` with the "
#~ "following command sequence:"
#~ msgstr ""

#~ msgid ""
#~ "This will generate the certificates in"
#~ " :code:`examples/advanced-tensorflow/.cache/certificates`."
#~ msgstr ""

#~ msgid ""
#~ "When setting :code:`root_certificates`, the "
#~ "client expects a file path to "
#~ "PEM-encoded root certificates."
#~ msgstr ""

#~ msgid "The :code:`Strategy` abstraction"
#~ msgstr ""

#~ msgid ""
#~ "All strategy implementation are derived "
#~ "from the abstract base class "
#~ ":code:`flwr.server.strategy.Strategy`, both built-in"
#~ " implementations and third party "
#~ "implementations. This means that custom "
#~ "strategy implementations have the exact "
#~ "same capabilities at their disposal as"
#~ " built-in ones."
#~ msgstr ""

#~ msgid ""
#~ "Creating a new strategy means "
#~ "implementing a new :code:`class` (derived "
#~ "from the abstract base class "
#~ ":code:`Strategy`) that implements for the "
#~ "previously shown abstract methods:"
#~ msgstr ""

#~ msgid "The :code:`initialize_parameters` method"
#~ msgstr ""

#~ msgid ""
#~ ":code:`initialize_parameters` is called only "
#~ "once, at the very beginning of an"
#~ " execution. It is responsible for "
#~ "providing the initial global model "
#~ "parameters in a serialized form (i.e.,"
#~ " as a :code:`Parameters` object)."
#~ msgstr ""

#~ msgid ""
#~ "Built-in strategies return user-provided"
#~ " initial parameters. The following example"
#~ " shows how initial parameters can be"
#~ " passed to :code:`FedAvg`:"
#~ msgstr ""

#~ msgid ""
#~ "The Flower server will call "
#~ ":code:`initialize_parameters`, which either returns"
#~ " the parameters that were passed to"
#~ " :code:`initial_parameters`, or :code:`None`. If"
#~ " no parameters are returned from "
#~ ":code:`initialize_parameters` (i.e., :code:`None`), "
#~ "the server will randomly select one "
#~ "client and ask it to provide its"
#~ " parameters. This is a convenience "
#~ "feature and not recommended in practice,"
#~ " but it can be useful for "
#~ "prototyping. In practice, it is "
#~ "recommended to always use server-side"
#~ " parameter initialization."
#~ msgstr ""

#~ msgid "The :code:`configure_fit` method"
#~ msgstr ""

#~ msgid ""
#~ ":code:`configure_fit` is responsible for "
#~ "configuring the upcoming round of "
#~ "training. What does *configure* mean in"
#~ " this context? Configuring a round "
#~ "means selecting clients and deciding "
#~ "what instructions to send to these "
#~ "clients. The signature of "
#~ ":code:`configure_fit` makes this clear:"
#~ msgstr ""

#~ msgid ""
#~ "The return value is a list of "
#~ "tuples, each representing the instructions "
#~ "that will be sent to a particular"
#~ " client. Strategy implementations usually "
#~ "perform the following steps in "
#~ ":code:`configure_fit`:"
#~ msgstr ""

#~ msgid ""
#~ "Use the :code:`client_manager` to randomly "
#~ "sample all (or a subset of) "
#~ "available clients (each represented as a"
#~ " :code:`ClientProxy` object)"
#~ msgstr ""

#~ msgid ""
#~ "Pair each :code:`ClientProxy` with the "
#~ "same :code:`FitIns` holding the current "
#~ "global model :code:`parameters` and "
#~ ":code:`config` dict"
#~ msgstr ""

#~ msgid ""
#~ "More sophisticated implementations can use "
#~ ":code:`configure_fit` to implement custom "
#~ "client selection logic. A client will"
#~ " only participate in a round if "
#~ "the corresponding :code:`ClientProxy` is "
#~ "included in the list returned from "
#~ ":code:`configure_fit`."
#~ msgstr ""

#~ msgid ""
#~ "The structure of this return value "
#~ "provides a lot of flexibility to "
#~ "the user. Since instructions are defined"
#~ " on a per-client basis, different "
#~ "instructions can be sent to each "
#~ "client. This enables custom strategies "
#~ "to train, for example, different models"
#~ " on different clients, or use "
#~ "different hyperparameters on different clients"
#~ " (via the :code:`config` dict)."
#~ msgstr ""

#~ msgid "The :code:`aggregate_fit` method"
#~ msgstr ""

#~ msgid ""
#~ ":code:`aggregate_fit` is responsible for "
#~ "aggregating the results returned by the"
#~ " clients that were selected and asked"
#~ " to train in :code:`configure_fit`."
#~ msgstr ""

#~ msgid ""
#~ "Of course, failures can happen, so "
#~ "there is no guarantee that the "
#~ "server will get results from all "
#~ "the clients it sent instructions to "
#~ "(via :code:`configure_fit`). :code:`aggregate_fit` "
#~ "therefore receives a list of "
#~ ":code:`results`, but also a list of "
#~ ":code:`failures`."
#~ msgstr ""

#~ msgid ""
#~ ":code:`aggregate_fit` returns an optional "
#~ ":code:`Parameters` object and a dictionary "
#~ "of aggregated metrics. The :code:`Parameters`"
#~ " return value is optional because "
#~ ":code:`aggregate_fit` might decide that the"
#~ " results provided are not sufficient "
#~ "for aggregation (e.g., too many "
#~ "failures)."
#~ msgstr ""

#~ msgid "The :code:`configure_evaluate` method"
#~ msgstr ""

#~ msgid ""
#~ ":code:`configure_evaluate` is responsible for "
#~ "configuring the upcoming round of "
#~ "evaluation. What does *configure* mean "
#~ "in this context? Configuring a round "
#~ "means selecting clients and deciding "
#~ "what instructions to send to these "
#~ "clients. The signature of "
#~ ":code:`configure_evaluate` makes this clear:"
#~ msgstr ""

#~ msgid ""
#~ "The return value is a list of "
#~ "tuples, each representing the instructions "
#~ "that will be sent to a particular"
#~ " client. Strategy implementations usually "
#~ "perform the following steps in "
#~ ":code:`configure_evaluate`:"
#~ msgstr ""

#~ msgid ""
#~ "Pair each :code:`ClientProxy` with the "
#~ "same :code:`EvaluateIns` holding the current"
#~ " global model :code:`parameters` and "
#~ ":code:`config` dict"
#~ msgstr ""

#~ msgid ""
#~ "More sophisticated implementations can use "
#~ ":code:`configure_evaluate` to implement custom "
#~ "client selection logic. A client will"
#~ " only participate in a round if "
#~ "the corresponding :code:`ClientProxy` is "
#~ "included in the list returned from "
#~ ":code:`configure_evaluate`."
#~ msgstr ""

#~ msgid ""
#~ "The structure of this return value "
#~ "provides a lot of flexibility to "
#~ "the user. Since instructions are defined"
#~ " on a per-client basis, different "
#~ "instructions can be sent to each "
#~ "client. This enables custom strategies "
#~ "to evaluate, for example, different "
#~ "models on different clients, or use "
#~ "different hyperparameters on different clients"
#~ " (via the :code:`config` dict)."
#~ msgstr ""

#~ msgid "The :code:`aggregate_evaluate` method"
#~ msgstr ""

#~ msgid ""
#~ ":code:`aggregate_evaluate` is responsible for "
#~ "aggregating the results returned by the"
#~ " clients that were selected and asked"
#~ " to evaluate in :code:`configure_evaluate`."
#~ msgstr ""

#~ msgid ""
#~ "Of course, failures can happen, so "
#~ "there is no guarantee that the "
#~ "server will get results from all "
#~ "the clients it sent instructions to "
#~ "(via :code:`configure_evaluate`). "
#~ ":code:`aggregate_evaluate` therefore receives a "
#~ "list of :code:`results`, but also a "
#~ "list of :code:`failures`."
#~ msgstr ""

#~ msgid ""
#~ ":code:`aggregate_evaluate` returns an optional "
#~ ":code:`float` (loss) and a dictionary of"
#~ " aggregated metrics. The :code:`float` "
#~ "return value is optional because "
#~ ":code:`aggregate_evaluate` might decide that "
#~ "the results provided are not sufficient"
#~ " for aggregation (e.g., too many "
#~ "failures)."
#~ msgstr ""

#~ msgid "The :code:`evaluate` method"
#~ msgstr ""

#~ msgid ""
#~ ":code:`evaluate` is responsible for evaluating"
#~ " model parameters on the server-side."
#~ " Having :code:`evaluate` in addition to "
#~ ":code:`configure_evaluate`/:code:`aggregate_evaluate` enables"
#~ " strategies to perform both servers-"
#~ "side and client-side (federated) "
#~ "evaluation."
#~ msgstr ""

#~ msgid ""
#~ "The return value is again optional "
#~ "because the strategy might not need "
#~ "to implement server-side evaluation or"
#~ " because the user-defined :code:`evaluate`"
#~ " method might not complete successfully "
#~ "(e.g., it might fail to load the"
#~ " server-side evaluation data)."
#~ msgstr ""

#~ msgid ""
#~ "Stable releases are available on `PyPI"
#~ " <https://pypi.org/project/flwr/>`_::"
#~ msgstr ""

#~ msgid ""
#~ "For simulations that use the Virtual "
#~ "Client Engine, ``flwr`` should be "
#~ "installed with the ``simulation`` extra::"
#~ msgstr ""

#~ msgid ""
#~ "If you have not added ``conda-"
#~ "forge`` to your channels, you will "
#~ "first need to run the following::"
#~ msgstr ""

#~ msgid ""
#~ "Once the ``conda-forge`` channel has "
#~ "been enabled, ``flwr`` can be installed"
#~ " with ``conda``::"
#~ msgstr ""

#~ msgid "or with ``mamba``::"
#~ msgstr ""

#~ msgid ""
#~ "New (possibly unstable) versions of "
#~ "Flower are sometimes available as "
#~ "pre-release versions (alpha, beta, release"
#~ " candidate) before the stable release "
#~ "happens::"
#~ msgstr ""

#~ msgid ""
#~ "For simulations that use the Virtual "
#~ "Client Engine, ``flwr`` pre-releases "
#~ "should be installed with the "
#~ "``simulation`` extra::"
#~ msgstr ""

#~ msgid ""
#~ "The latest (potentially unstable) changes "
#~ "in Flower are available as nightly "
#~ "releases::"
#~ msgstr ""

#~ msgid ""
#~ "For simulations that use the Virtual "
#~ "Client Engine, ``flwr-nightly`` should "
#~ "be installed with the ``simulation`` "
#~ "extra::"
#~ msgstr ""

#~ msgid "You can look at everything at `<http://127.0.0.1:8265>`_ ."
#~ msgstr ""

#~ msgid ""
#~ "After you finish the visualization, stop"
#~ " Prometheus and Grafana. This is "
#~ "important as they will otherwise block,"
#~ " for example port :code:`3000` on "
#~ "your machine as long as they are"
#~ " running."
#~ msgstr ""

#~ msgid ""
#~ "In the example above, only one "
#~ "client will be run, so your "
#~ "clients won't run concurrently. Setting "
#~ ":code:`client_num_gpus = 0.5` would allow "
#~ "running two clients and therefore enable"
#~ " them to run concurrently. Be careful"
#~ " not to require more resources than"
#~ " available. If you specified "
#~ ":code:`client_num_gpus = 2`, the simulation"
#~ " wouldn't start (even if you had "
#~ "2 GPUs but decided to set 1 "
#~ "in :code:`ray_init_args`)."
#~ msgstr ""

#~ msgid ""
#~ "Q: I see \"This site can't be "
#~ "reached\" when going to "
#~ "`<http://127.0.0.1:8265>`_."
#~ msgstr ""

#~ msgid ""
#~ "Ray Dashboard: `<https://docs.ray.io/en/latest/ray-"
#~ "observability/getting-started.html>`_"
#~ msgstr ""

#~ msgid "Ray Metrics: `<https://docs.ray.io/en/latest/cluster/metrics.html>`_"
#~ msgstr ""

#~ msgid ""
#~ "The :code:`VirtualClientEngine` schedules, launches"
#~ " and manages `virtual` clients. These "
#~ "clients are identical to `non-virtual`"
#~ " clients (i.e. the ones you launch"
#~ " via the command `flwr.client.start_client "
#~ "<ref-api-flwr.html#start-client>`_) in the"
#~ " sense that they can be configure "
#~ "by creating a class inheriting, for "
#~ "example, from `flwr.client.NumPyClient <ref-"
#~ "api-flwr.html#flwr.client.NumPyClient>`_ and therefore"
#~ " behave in an identical way. In "
#~ "addition to that, clients managed by "
#~ "the :code:`VirtualClientEngine` are:"
#~ msgstr ""

#~ msgid ""
#~ "self-managed: this means that you "
#~ "as a user do not need to "
#~ "launch clients manually, instead this "
#~ "gets delegated to :code:`VirtualClientEngine`'s "
#~ "internals."
#~ msgstr ""

#~ msgid ""
#~ "The :code:`VirtualClientEngine` implements `virtual`"
#~ " clients using `Ray <https://www.ray.io/>`_, "
#~ "an open-source framework for scalable"
#~ " Python workloads. In particular, Flower's"
#~ " :code:`VirtualClientEngine` makes use of "
#~ "`Actors <https://docs.ray.io/en/latest/ray-"
#~ "core/actors.html>`_ to spawn `virtual` clients"
#~ " and run their workload."
#~ msgstr ""

#~ msgid ""
#~ "By default the VCE has access to"
#~ " all system resources (i.e. all CPUs,"
#~ " all GPUs, etc) since that is "
#~ "also the default behavior when starting"
#~ " Ray. However, in some settings you"
#~ " might want to limit how many "
#~ "of your system resources are used "
#~ "for simulation. You can do this "
#~ "via the :code:`ray_init_args` input argument"
#~ " to :code:`start_simulation` which the VCE"
#~ " internally passes to Ray's "
#~ ":code:`ray.init` command. For a complete "
#~ "list of settings you can configure "
#~ "check the `ray.init <https://docs.ray.io/en/latest"
#~ "/ray-core/api/doc/ray.init.html#ray-init>`_ "
#~ "documentation. Do not set "
#~ ":code:`ray_init_args` if you want the "
#~ "VCE to use all your system's CPUs"
#~ " and GPUs."
#~ msgstr ""

#~ msgid ""
#~ "By default the :code:`VirtualClientEngine` "
#~ "assigns a single CPU core (and "
#~ "nothing else) to each virtual client."
#~ " This means that if your system "
#~ "has 10 cores, that many virtual "
#~ "clients can be concurrently running."
#~ msgstr ""

#~ msgid ":code:`num_cpus` indicates the number of CPU cores a client would get."
#~ msgstr ""

#~ msgid ""
#~ ":code:`num_gpus` indicates the **ratio** of"
#~ " GPU memory a client gets assigned."
#~ msgstr ""

#~ msgid ""
#~ "While the :code:`client_resources` can be "
#~ "used to control the degree of "
#~ "concurrency in your FL simulation, this"
#~ " does not stop you from running "
#~ "dozens, hundreds or even thousands of"
#~ " clients in the same round and "
#~ "having orders of magnitude more "
#~ "`dormant` (i.e. not participating in a"
#~ " round) clients. Let's say you want"
#~ " to have 100 clients per round "
#~ "but your system can only accommodate "
#~ "8 clients concurrently. The "
#~ ":code:`VirtualClientEngine` will schedule 100 "
#~ "jobs to run (each simulating a "
#~ "client sampled by the strategy) and "
#~ "then will execute them in a "
#~ "resource-aware manner in batches of "
#~ "8."
#~ msgstr ""

#~ msgid ""
#~ "Flower's :code:`VirtualClientEngine` allows you "
#~ "to run FL simulations across multiple"
#~ " compute nodes. Before starting your "
#~ "multi-node simulation ensure that you:"
#~ msgstr ""

#~ msgid ""
#~ "Pass :code:`ray_init_args={\"address\"=\"auto\"}` to "
#~ "`start_simulation <ref-api-"
#~ "flwr.html#flwr.simulation.start_simulation>`_ so the "
#~ ":code:`VirtualClientEngine` attaches to a "
#~ "running Ray instance."
#~ msgstr ""

#~ msgid ""
#~ "Start Ray on you head node: on "
#~ "the terminal type :code:`ray start "
#~ "--head`. This command will print a "
#~ "few lines, one of which indicates "
#~ "how to attach other nodes to the"
#~ " head node."
#~ msgstr ""

#~ msgid ""
#~ "Attach other nodes to the head "
#~ "node: copy the command shown after "
#~ "starting the head and execute it "
#~ "on terminal of a new node: for "
#~ "example :code:`ray start "
#~ "--address='192.168.1.132:6379'`"
#~ msgstr ""

#~ msgid ""
#~ "Once your simulation is finished, if "
#~ "you'd like to dismantle your cluster "
#~ "you simply need to run the command"
#~ " :code:`ray stop` in each node's "
#~ "terminal (including the head node)."
#~ msgstr ""

#~ msgid ""
#~ "User :code:`ray status` to check all "
#~ "nodes connected to your head node "
#~ "as well as the total resources "
#~ "available to the :code:`VirtualClientEngine`."
#~ msgstr ""

#~ msgid ""
#~ "When attaching a new node to the"
#~ " head, all its resources (i.e. all"
#~ " CPUs, all GPUs) will be visible "
#~ "by the head node. This means that"
#~ " the :code:`VirtualClientEngine` can schedule "
#~ "as many `virtual` clients as that "
#~ "node can possible run. In some "
#~ "settings you might want to exclude "
#~ "certain resources from the simulation. "
#~ "You can do this by appending "
#~ "`--num-cpus=<NUM_CPUS_FROM_NODE>` and/or `--num-"
#~ "gpus=<NUM_GPUS_FROM_NODE>` in any :code:`ray "
#~ "start` command (including when starting "
#~ "the head)"
#~ msgstr ""

#~ msgid ""
#~ "The VCE assigns a share of GPU "
#~ "memory to a client that specifies "
#~ "the key :code:`num_gpus` in "
#~ ":code:`client_resources`. This being said, Ray"
#~ " (used internally by the VCE) is "
#~ "by default:"
#~ msgstr ""

#~ msgid ""
#~ "not aware of the total VRAM "
#~ "available on the GPUs. This means "
#~ "that if you set :code:`num_gpus=0.5` and"
#~ " you have two GPUs in your "
#~ "system with different (e.g. 32GB and "
#~ "8GB) VRAM amounts, they both would "
#~ "run 2 clients concurrently."
#~ msgstr ""

#~ msgid ""
#~ "If you want to run several "
#~ "independent Flower simulations on the "
#~ "same machine you need to mask-out"
#~ " your GPUs with "
#~ ":code:`CUDA_VISIBLE_DEVICES=\"<GPU_IDs>\"` when launching"
#~ " your experiment."
#~ msgstr ""

#~ msgid ""
#~ "In addition, the GPU resource limits "
#~ "passed to :code:`client_resources` are not "
#~ "`enforced` (i.e. they can be exceeded)"
#~ " which can result in the situation"
#~ " of client using more VRAM than "
#~ "the ratio specified when starting the"
#~ " simulation."
#~ msgstr ""

#~ msgid ""
#~ "This would need to be done in "
#~ "the main process (which is where "
#~ "the server would run) and in each"
#~ " Actor created by the VCE. By "
#~ "means of :code:`actor_kwargs` we can "
#~ "pass the reserved key `\"on_actor_init_fn\"`"
#~ " in order to specify a function "
#~ "to be executed upon actor "
#~ "initialization. In this case, to enable"
#~ " GPU growth for TF workloads. It "
#~ "would look as follows:"
#~ msgstr ""

#~ msgid ""
#~ "Model updates can be persisted on "
#~ "the server-side by customizing "
#~ ":code:`Strategy` methods. Implementing custom "
#~ "strategies is always an option, but "
#~ "for many cases it may be more "
#~ "convenient to simply customize an "
#~ "existing strategy. The following code "
#~ "example defines a new "
#~ ":code:`SaveModelStrategy` which customized the "
#~ "existing built-in :code:`FedAvg` strategy. "
#~ "In particular, it customizes "
#~ ":code:`aggregate_fit` by calling "
#~ ":code:`aggregate_fit` in the base class "
#~ "(:code:`FedAvg`). It then continues to "
#~ "save returned (aggregated) weights before "
#~ "it returns those aggregated weights to"
#~ " the caller (i.e., the server):"
#~ msgstr ""

#~ msgid ""
#~ "For central DP with server-side "
#~ "clipping, there are two :code:`Strategy` "
#~ "classes that act as wrappers around "
#~ "the actual :code:`Strategy` instance (for "
#~ "example, :code:`FedAvg`). The two wrapper "
#~ "classes are "
#~ ":code:`DifferentialPrivacyServerSideFixedClipping` and "
#~ ":code:`DifferentialPrivacyServerSideAdaptiveClipping` for "
#~ "fixed and adaptive clipping."
#~ msgstr ""

#~ msgid ""
#~ "The code sample below enables the "
#~ ":code:`FedAvg` strategy to use server-"
#~ "side fixed clipping using the "
#~ ":code:`DifferentialPrivacyServerSideFixedClipping` wrapper "
#~ "class. The same approach can be "
#~ "used with "
#~ ":code:`DifferentialPrivacyServerSideAdaptiveClipping` by "
#~ "adjusting the corresponding input parameters."
#~ msgstr ""

#~ msgid ""
#~ "For central DP with client-side "
#~ "clipping, the server sends the clipping"
#~ " value to selected clients on each"
#~ " round. Clients can use existing "
#~ "Flower :code:`Mods` to perform the "
#~ "clipping. Two mods are available for "
#~ "fixed and adaptive client-side clipping:"
#~ " :code:`fixedclipping_mod` and "
#~ ":code:`adaptiveclipping_mod` with corresponding "
#~ "server-side wrappers "
#~ ":code:`DifferentialPrivacyClientSideFixedClipping` and "
#~ ":code:`DifferentialPrivacyClientSideAdaptiveClipping`."
#~ msgstr ""

#~ msgid ""
#~ "The code sample below enables the "
#~ ":code:`FedAvg` strategy to use differential"
#~ " privacy with client-side fixed "
#~ "clipping using both the "
#~ ":code:`DifferentialPrivacyClientSideFixedClipping` wrapper "
#~ "class and, on the client, "
#~ ":code:`fixedclipping_mod`:"
#~ msgstr ""

#~ msgid ""
#~ "In addition to the server-side "
#~ "strategy wrapper, the :code:`ClientApp` needs"
#~ " to configure the matching "
#~ ":code:`fixedclipping_mod` to perform the "
#~ "client-side clipping:"
#~ msgstr ""

#~ msgid "Below is a code example that shows how to use :code:`LocalDpMod`:"
#~ msgstr ""

#~ msgid ""
#~ "Flower allows full customization of the"
#~ " learning process through the "
#~ ":code:`Strategy` abstraction. A number of "
#~ "built-in strategies are provided in "
#~ "the core framework."
#~ msgstr ""

#~ msgid "Use an existing strategy, for example, :code:`FedAvg`"
#~ msgstr ""

#~ msgid ""
#~ "This creates a strategy with all "
#~ "parameters left at their default values"
#~ " and passes it to the "
#~ ":code:`start_server` function. It is usually"
#~ " recommended to adjust a few "
#~ "parameters during instantiation:"
#~ msgstr ""

#~ msgid ""
#~ "The server can pass new configuration"
#~ " values to the client each round "
#~ "by providing a function to "
#~ ":code:`on_fit_config_fn`. The provided function "
#~ "will be called by the strategy and"
#~ " must return a dictionary of "
#~ "configuration key values pairs that will"
#~ " be sent to the client. It must"
#~ " return a dictionary of arbitrary "
#~ "configuration values  :code:`client.fit` and "
#~ ":code:`client.evaluate` functions during each "
#~ "round of federated learning."
#~ msgstr ""

#~ msgid ""
#~ "The :code:`on_fit_config_fn` can be used "
#~ "to pass arbitrary configuration values "
#~ "from server to client, and potentially"
#~ " change these values each round, for"
#~ " example, to adjust the learning "
#~ "rate. The client will receive the "
#~ "dictionary returned by the "
#~ ":code:`on_fit_config_fn` in its own "
#~ ":code:`client.fit()` function."
#~ msgstr ""

#~ msgid ""
#~ "Similar to :code:`on_fit_config_fn`, there is"
#~ " also :code:`on_evaluate_config_fn` to customize"
#~ " the configuration sent to "
#~ ":code:`client.evaluate()`"
#~ msgstr ""

#~ msgid ""
#~ "Server-side evaluation can be enabled"
#~ " by passing an evaluation function to"
#~ " :code:`evaluate_fn`."
#~ msgstr ""

#~ msgid ""
#~ "Note that since version :code:`1.11.0`, "
#~ ":code:`flower-server-app` no longer "
#~ "supports passing a reference to a "
#~ "`ServerApp` attribute. Instead, you need "
#~ "to pass the path to Flower app "
#~ "via the argument :code:`--app`. This is"
#~ " the path to a directory containing"
#~ " a `pyproject.toml`. You can create a"
#~ " valid Flower app by executing "
#~ ":code:`flwr new` and following the "
#~ "prompt."
#~ msgstr ""

#~ msgid ""
#~ "The following examples are available as"
#~ " standalone projects. Quickstart TensorFlow/Keras"
#~ " ---------------------------"
#~ msgstr ""

#~ msgid ""
#~ "Let's create a new application project"
#~ " in Xcode and add :code:`flwr` as "
#~ "a dependency in your project. For "
#~ "our application, we will store the "
#~ "logic of our app in "
#~ ":code:`FLiOSModel.swift` and the UI elements"
#~ " in :code:`ContentView.swift`. We will "
#~ "focus more on :code:`FLiOSModel.swift` in "
#~ "this quickstart. Please refer to the "
#~ "`full code example "
#~ "<https://github.com/adap/flower/tree/main/examples/ios>`_ to "
#~ "learn more about the app."
#~ msgstr ""

#~ msgid "Import Flower and CoreML related packages in :code:`FLiOSModel.swift`:"
#~ msgstr ""

#~ msgid ""
#~ "Then add the mlmodel to the "
#~ "project simply by drag-and-drop, "
#~ "the mlmodel will be bundled inside "
#~ "the application during deployment to "
#~ "your iOS device. We need to pass"
#~ " the url to access mlmodel and "
#~ "run CoreML machine learning processes, "
#~ "it can be retrieved by calling the"
#~ " function :code:`Bundle.main.url`. For the "
#~ "MNIST dataset, we need to preprocess "
#~ "it into :code:`MLBatchProvider` object. The"
#~ " preprocessing is done inside "
#~ ":code:`DataLoader.swift`."
#~ msgstr ""

#~ msgid ""
#~ "Since CoreML does not allow the "
#~ "model parameters to be seen before "
#~ "training, and accessing the model "
#~ "parameters during or after the training"
#~ " can only be done by specifying "
#~ "the layer name, we need to know"
#~ " this information beforehand, through "
#~ "looking at the model specification, "
#~ "which are written as proto files. "
#~ "The implementation can be seen in "
#~ ":code:`MLModelInspect`."
#~ msgstr ""

#~ msgid ""
#~ "Then start the Flower gRPC client "
#~ "and start communicating to the server"
#~ " by passing our Flower client to "
#~ "the function :code:`startFlwrGRPC`."
#~ msgstr ""

#~ msgid ""
#~ "That's it for the client. We only"
#~ " have to implement :code:`Client` or "
#~ "call the provided :code:`MLFlwrClient` and "
#~ "call :code:`startFlwrGRPC()`. The attribute "
#~ ":code:`hostname` and :code:`port` tells the"
#~ " client which server to connect to."
#~ " This can be done by entering "
#~ "the hostname and port in the "
#~ "application before clicking the start "
#~ "button to start the federated learning"
#~ " process."
#~ msgstr ""

#~ msgid ""
#~ "For simple workloads we can start "
#~ "a Flower server and leave all the"
#~ " configuration possibilities at their "
#~ "default values. In a file named "
#~ ":code:`server.py`, import Flower and start "
#~ "the server:"
#~ msgstr ""

#~ msgid ""
#~ "Congratulations! You've successfully built and"
#~ " run your first federated learning "
#~ "system in your ios device. The "
#~ "full `source code "
#~ "<https://github.com/adap/flower/blob/main/examples/ios>`_ for"
#~ " this example can be found in "
#~ ":code:`examples/ios`."
#~ msgstr ""

#~ msgid ""
#~ "Before we start building our JAX "
#~ "example, we need install the packages"
#~ " :code:`jax`, :code:`jaxlib`, :code:`scikit-"
#~ "learn`, and :code:`flwr`:"
#~ msgstr ""

#~ msgid ""
#~ "We begin with a brief description "
#~ "of the centralized training code based"
#~ " on a :code:`Linear Regression` model. "
#~ "If you want a more in-depth "
#~ "explanation of what's going on then "
#~ "have a look at the official `JAX"
#~ " documentation <https://jax.readthedocs.io/>`_."
#~ msgstr ""

#~ msgid ""
#~ "Let's create a new file called "
#~ ":code:`jax_training.py` with all the "
#~ "components required for a traditional "
#~ "(centralized) linear regression training. "
#~ "First, the JAX packages :code:`jax` and"
#~ " :code:`jaxlib` need to be imported. "
#~ "In addition, we need to import "
#~ ":code:`sklearn` since we use "
#~ ":code:`make_regression` for the dataset and"
#~ " :code:`train_test_split` to split the "
#~ "dataset into a training and test "
#~ "set. You can see that we do "
#~ "not yet import the :code:`flwr` package"
#~ " for federated learning. This will be"
#~ " done later."
#~ msgstr ""

#~ msgid ""
#~ "The :code:`load_data()` function loads the "
#~ "mentioned training and test sets."
#~ msgstr ""

#~ msgid ""
#~ "The model architecture (a very simple"
#~ " :code:`Linear Regression` model) is "
#~ "defined in :code:`load_model()`."
#~ msgstr ""

#~ msgid ""
#~ "We now need to define the training"
#~ " (function :code:`train()`), which loops "
#~ "over the training set and measures "
#~ "the loss (function :code:`loss_fn()`) for "
#~ "each batch of training examples. The "
#~ "loss function is separate since JAX "
#~ "takes derivatives with a :code:`grad()` "
#~ "function (defined in the :code:`main()` "
#~ "function and called in :code:`train()`)."
#~ msgstr ""

#~ msgid ""
#~ "The evaluation of the model is "
#~ "defined in the function :code:`evaluation()`."
#~ " The function takes all test examples"
#~ " and measures the loss of the "
#~ "linear regression model."
#~ msgstr ""

#~ msgid ""
#~ "Having defined the data loading, model"
#~ " architecture, training, and evaluation we"
#~ " can put everything together and "
#~ "train our model using JAX. As "
#~ "already mentioned, the :code:`jax.grad()` "
#~ "function is defined in :code:`main()` "
#~ "and passed to :code:`train()`."
#~ msgstr ""

#~ msgid ""
#~ "The concept of federating an existing"
#~ " workload is always the same and "
#~ "easy to understand. We have to "
#~ "start a *server* and then use the"
#~ " code in :code:`jax_training.py` for the"
#~ " *clients* that are connected to the"
#~ " *server*. The *server* sends model "
#~ "parameters to the clients. The *clients*"
#~ " run the training and update the "
#~ "parameters. The updated parameters are "
#~ "sent back to the *server*, which "
#~ "averages all received parameter updates. "
#~ "This describes one round of the "
#~ "federated learning process, and we "
#~ "repeat this for multiple rounds."
#~ msgstr ""

#~ msgid ""
#~ "Finally, we will define our *client* "
#~ "logic in :code:`client.py` and build "
#~ "upon the previously defined JAX training"
#~ " in :code:`jax_training.py`. Our *client* "
#~ "needs to import :code:`flwr`, but also"
#~ " :code:`jax` and :code:`jaxlib` to update"
#~ " the parameters on our JAX model:"
#~ msgstr ""

#~ msgid ""
#~ "Implementing a Flower *client* basically "
#~ "means implementing a subclass of either"
#~ " :code:`flwr.client.Client` or "
#~ ":code:`flwr.client.NumPyClient`. Our implementation "
#~ "will be based on "
#~ ":code:`flwr.client.NumPyClient` and we'll call "
#~ "it :code:`FlowerClient`. :code:`NumPyClient` is "
#~ "slightly easier to implement than "
#~ ":code:`Client` if you use a framework"
#~ " with good NumPy interoperability (like "
#~ "JAX) because it avoids some of the"
#~ " boilerplate that would otherwise be "
#~ "necessary. :code:`FlowerClient` needs to "
#~ "implement four methods, two methods for"
#~ " getting/setting model parameters, one "
#~ "method for training the model, and "
#~ "one method for testing the model:"
#~ msgstr ""

#~ msgid ":code:`set_parameters (optional)`"
#~ msgstr ""

#~ msgid "transform parameters to NumPy :code:`ndarray`'s"
#~ msgstr ""

#~ msgid ""
#~ "The challenging part is to transform "
#~ "the JAX model parameters from "
#~ ":code:`DeviceArray` to :code:`NumPy ndarray` "
#~ "to make them compatible with "
#~ "`NumPyClient`."
#~ msgstr ""

#~ msgid ""
#~ "The two :code:`NumPyClient` methods "
#~ ":code:`fit` and :code:`evaluate` make use "
#~ "of the functions :code:`train()` and "
#~ ":code:`evaluate()` previously defined in "
#~ ":code:`jax_training.py`. So what we really "
#~ "do here is we tell Flower through"
#~ " our :code:`NumPyClient` subclass which of"
#~ " our already defined functions to "
#~ "call for training and evaluation. We "
#~ "included type annotations to give you"
#~ " a better understanding of the data"
#~ " types that get passed around."
#~ msgstr ""

#~ msgid ""
#~ "In this tutorial, we will learn "
#~ "how to train a :code:`Logistic "
#~ "Regression` model on MNIST using Flower"
#~ " and scikit-learn."
#~ msgstr ""

#~ msgid ""
#~ "Now that we have all our "
#~ "dependencies installed, let's run a "
#~ "simple distributed training with two "
#~ "clients and one server. However, before"
#~ " setting up the client and server,"
#~ " we will define all functionalities "
#~ "that we need for our federated "
#~ "learning setup within :code:`utils.py`. The"
#~ " :code:`utils.py` contains different functions"
#~ " defining all the machine learning "
#~ "basics:"
#~ msgstr ""

#~ msgid ":code:`get_model_parameters()`"
#~ msgstr ""

#~ msgid "Returns the parameters of a :code:`sklearn` LogisticRegression model"
#~ msgstr ""

#~ msgid ":code:`set_model_params()`"
#~ msgstr ""

#~ msgid "Sets the parameters of a :code:`sklearn` LogisticRegression model"
#~ msgstr ""

#~ msgid ":code:`set_initial_params()`"
#~ msgstr ""

#~ msgid ""
#~ "Please check out :code:`utils.py` `here "
#~ "<https://github.com/adap/flower/blob/main/examples/sklearn-"
#~ "logreg-mnist/utils.py>`_ for more details. "
#~ "The pre-defined functions are used "
#~ "in the :code:`client.py` and imported. "
#~ "The :code:`client.py` also requires to "
#~ "import several packages such as Flower"
#~ " and scikit-learn:"
#~ msgstr ""

#~ msgid ""
#~ "Prior to local training, we need "
#~ "to load the MNIST dataset, a "
#~ "popular image classification dataset of "
#~ "handwritten digits for machine learning, "
#~ "and partition the dataset for FL. "
#~ "This can be conveniently achieved using"
#~ " `Flower Datasets <https://flower.ai/docs/datasets>`_."
#~ " The :code:`FederatedDataset.load_partition()` method"
#~ " loads the partitioned training set "
#~ "for each partition ID defined in "
#~ "the :code:`--partition-id` argument."
#~ msgstr ""

#~ msgid ""
#~ "Next, the logistic regression model is"
#~ " defined and initialized with "
#~ ":code:`utils.set_initial_params()`."
#~ msgstr ""

#~ msgid ""
#~ "The Flower server interacts with clients"
#~ " through an interface called "
#~ ":code:`Client`. When the server selects "
#~ "a particular client for training, it "
#~ "sends training instructions over the "
#~ "network. The client receives those "
#~ "instructions and calls one of the "
#~ ":code:`Client` methods to run your code"
#~ " (i.e., to fit the logistic "
#~ "regression we defined earlier)."
#~ msgstr ""

#~ msgid ""
#~ "Flower provides a convenience class "
#~ "called :code:`NumPyClient` which makes it "
#~ "easier to implement the :code:`Client` "
#~ "interface when your workload uses "
#~ "scikit-learn. Implementing :code:`NumPyClient` "
#~ "usually means defining the following "
#~ "methods (:code:`set_parameters` is optional "
#~ "though):"
#~ msgstr ""

#~ msgid ":code:`set_parameters` (optional)"
#~ msgstr ""

#~ msgid "is directly imported with :code:`utils.set_model_params()`"
#~ msgstr ""

#~ msgid ""
#~ "We can now create an instance of"
#~ " our class :code:`MnistClient` and add "
#~ "one line to actually run this "
#~ "client:"
#~ msgstr ""

#~ msgid ""
#~ "That's it for the client. We only"
#~ " have to implement :code:`Client` or "
#~ ":code:`NumPyClient` and call "
#~ ":code:`fl.client.start_client()`. If you implement"
#~ " a client of type :code:`NumPyClient` "
#~ "you'll need to first call its "
#~ ":code:`to_client()` method. The string "
#~ ":code:`\"0.0.0.0:8080\"` tells the client "
#~ "which server to connect to. In our"
#~ " case we can run the server and"
#~ " the client on the same machine, "
#~ "therefore we use :code:`\"0.0.0.0:8080\"`. If"
#~ " we run a truly federated workload"
#~ " with the server and clients running"
#~ " on different machines, all that "
#~ "needs to change is the "
#~ ":code:`server_address` we pass to the "
#~ "client."
#~ msgstr ""

#~ msgid ":code:`server.py`, import Flower and start the server:"
#~ msgstr ""

#~ msgid ""
#~ "The number of federated learning rounds"
#~ " is set in :code:`fit_round()` and "
#~ "the evaluation is defined in "
#~ ":code:`get_evaluate_fn()`. The evaluation function"
#~ " is called after each federated "
#~ "learning round and gives you information"
#~ " about loss and accuracy. Note that"
#~ " we also make use of Flower "
#~ "Datasets here to load the test "
#~ "split of the MNIST dataset for "
#~ "server-side evaluation."
#~ msgstr ""

#~ msgid ""
#~ "The :code:`main` contains the server-"
#~ "side parameter initialization "
#~ ":code:`utils.set_initial_params()` as well as "
#~ "the aggregation strategy "
#~ ":code:`fl.server.strategy:FedAvg()`. The strategy is"
#~ " the default one, federated averaging "
#~ "(or FedAvg), with two clients and "
#~ "evaluation after each federated learning "
#~ "round. The server can be started "
#~ "with the command "
#~ ":code:`fl.server.start_server(server_address=\"0.0.0.0:8080\", "
#~ "strategy=strategy, "
#~ "config=fl.server.ServerConfig(num_rounds=3))`."
#~ msgstr ""

#~ msgid ""
#~ "Congratulations! You've successfully built and"
#~ " run your first federated learning "
#~ "system. The full `source code "
#~ "<https://github.com/adap/flower/tree/main/examples/sklearn-"
#~ "logreg-mnist>`_ for this example can "
#~ "be found in :code:`examples/sklearn-logreg-"
#~ "mnist`."
#~ msgstr ""

#~ msgid ""
#~ "In this tutorial we will learn how"
#~ " to train a federated XGBoost model"
#~ " on HIGGS dataset using Flower and"
#~ " :code:`xgboost` package. We use a "
#~ "simple example (`full code xgboost-"
#~ "quickstart <https://github.com/adap/flower/tree/main/examples"
#~ "/xgboost-quickstart>`_) with two *clients* "
#~ "and one *server* to demonstrate how "
#~ "federated XGBoost works, and then we "
#~ "dive into a more complex example "
#~ "(`full code xgboost-comprehensive "
#~ "<https://github.com/adap/flower/tree/main/examples/xgboost-"
#~ "comprehensive>`_) to run various experiments."
#~ msgstr ""

#~ msgid ""
#~ "Since we want to use :code:`xgboost` "
#~ "package to build up XGBoost trees, "
#~ "let's go ahead and install "
#~ ":code:`xgboost`:"
#~ msgstr ""

#~ msgid ""
#~ "In a file called :code:`client.py`, "
#~ "import xgboost, Flower, Flower Datasets "
#~ "and other related functions:"
#~ msgstr ""

#~ msgid ""
#~ "In this example, we split the "
#~ "dataset into 30 partitions with uniform"
#~ " distribution (:code:`IidPartitioner(num_partitions=30)`)."
#~ " Then, we load the partition for "
#~ "the given client based on "
#~ ":code:`partition_id`:"
#~ msgstr ""

#~ msgid ""
#~ "After that, we do train/test splitting"
#~ " on the given partition (client's "
#~ "local data), and transform data format"
#~ " for :code:`xgboost` package."
#~ msgstr ""

#~ msgid ""
#~ "The functions of :code:`train_test_split` and"
#~ " :code:`transform_dataset_to_dmatrix` are defined "
#~ "as below:"
#~ msgstr ""

#~ msgid ""
#~ "The :code:`num_local_round` represents the "
#~ "number of iterations for local tree "
#~ "boost. We use CPU for the training"
#~ " in default. One can shift it "
#~ "to GPU by setting :code:`tree_method` to"
#~ " :code:`gpu_hist`. We use AUC as "
#~ "evaluation metric."
#~ msgstr ""

#~ msgid ""
#~ "After loading the dataset we define "
#~ "the Flower client. We follow the "
#~ "general rule to define :code:`XgbClient` "
#~ "class inherited from :code:`fl.client.Client`."
#~ msgstr ""

#~ msgid ""
#~ "All required parameters defined above "
#~ "are passed to :code:`XgbClient`'s constructor."
#~ msgstr ""

#~ msgid ""
#~ "Then, we override :code:`get_parameters`, "
#~ ":code:`fit` and :code:`evaluate` methods "
#~ "insides :code:`XgbClient` class as follows."
#~ msgstr ""

#~ msgid ""
#~ "Unlike neural network training, XGBoost "
#~ "trees are not started from a "
#~ "specified random weights. In this case,"
#~ " we do not use :code:`get_parameters` "
#~ "and :code:`set_parameters` to initialise model"
#~ " parameters for XGBoost. As a result,"
#~ " let's return an empty tensor in "
#~ ":code:`get_parameters` when it is called "
#~ "by the server at the first round."
#~ msgstr ""

#~ msgid ""
#~ "In :code:`fit`, at the first round, "
#~ "we call :code:`xgb.train()` to build up"
#~ " the first set of trees. From "
#~ "the second round, we load the "
#~ "global model sent from server to "
#~ "new build Booster object, and then "
#~ "update model weights on local training"
#~ " data with function :code:`local_boost` as"
#~ " follows:"
#~ msgstr ""

#~ msgid ""
#~ "Given :code:`num_local_round`, we update trees"
#~ " by calling :code:`bst_input.update` method. "
#~ "After training, the last "
#~ ":code:`N=num_local_round` trees will be "
#~ "extracted to send to the server."
#~ msgstr ""

#~ msgid ""
#~ "In :code:`evaluate`, after loading the "
#~ "global model, we call :code:`bst.eval_set` "
#~ "function to conduct evaluation on valid"
#~ " set. The AUC value will be "
#~ "returned."
#~ msgstr ""

#~ msgid ""
#~ "Now, we can create an instance of"
#~ " our class :code:`XgbClient` and add "
#~ "one line to actually run this "
#~ "client:"
#~ msgstr ""

#~ msgid ""
#~ "That's it for the client. We only"
#~ " have to implement :code:`Client` and "
#~ "call :code:`fl.client.start_client()`. The string"
#~ " :code:`\"[::]:8080\"` tells the client "
#~ "which server to connect to. In our"
#~ " case we can run the server and"
#~ " the client on the same machine, "
#~ "therefore we use :code:`\"[::]:8080\"`. If "
#~ "we run a truly federated workload "
#~ "with the server and clients running "
#~ "on different machines, all that needs"
#~ " to change is the :code:`server_address`"
#~ " we point the client at."
#~ msgstr ""

#~ msgid ""
#~ "In a file named :code:`server.py`, "
#~ "import Flower and FedXgbBagging from "
#~ ":code:`flwr.server.strategy`."
#~ msgstr ""

#~ msgid ""
#~ "We use two clients for this "
#~ "example. An :code:`evaluate_metrics_aggregation` "
#~ "function is defined to collect and "
#~ "wighted average the AUC values from "
#~ "clients. The :code:`config_func` function is"
#~ " to return the current FL round "
#~ "number to client's :code:`fit()` and "
#~ ":code:`evaluate()` methods."
#~ msgstr ""

#~ msgid ""
#~ "In file :code:`flwr.server.strategy.fedxgb_bagging.py`,"
#~ " we define :code:`FedXgbBagging` inherited "
#~ "from :code:`flwr.server.strategy.FedAvg`. Then, we"
#~ " override the :code:`aggregate_fit`, "
#~ ":code:`aggregate_evaluate` and :code:`evaluate` "
#~ "methods as follows:"
#~ msgstr ""

#~ msgid ""
#~ "In :code:`aggregate_fit`, we sequentially "
#~ "aggregate the clients' XGBoost trees by"
#~ " calling :code:`aggregate()` function:"
#~ msgstr ""

#~ msgid ""
#~ "In this function, we first fetch "
#~ "the number of trees and the number"
#~ " of parallel trees for the current"
#~ " and previous model by calling "
#~ ":code:`_get_tree_nums`. Then, the fetched "
#~ "information will be aggregated. After "
#~ "that, the trees (containing model "
#~ "weights) are aggregated to generate a"
#~ " new tree model."
#~ msgstr ""

#~ msgid ""
#~ "Congratulations! You've successfully built and"
#~ " run your first federated XGBoost "
#~ "system. The AUC values can be "
#~ "checked in :code:`metrics_distributed`. One "
#~ "can see that the average AUC "
#~ "increases over FL rounds."
#~ msgstr ""

#~ msgid ""
#~ "The full `source code "
#~ "<https://github.com/adap/flower/blob/main/examples/xgboost-"
#~ "quickstart/>`_ for this example can be"
#~ " found in :code:`examples/xgboost-quickstart`."
#~ msgstr ""

#~ msgid ""
#~ "To do this, we first customise a"
#~ " :code:`ClientManager` in :code:`server_utils.py`:"
#~ msgstr ""

#~ msgid ""
#~ "The customised :code:`ClientManager` samples "
#~ "all available clients in each FL "
#~ "round based on the order of "
#~ "connection to the server. Then, we "
#~ "define a new strategy :code:`FedXgbCyclic` "
#~ "in :code:`flwr.server.strategy.fedxgb_cyclic.py`, in "
#~ "order to sequentially select only one"
#~ " client in given round and pass "
#~ "the received model to next client."
#~ msgstr ""

#~ msgid ""
#~ "Unlike the original :code:`FedAvg`, we "
#~ "don't perform aggregation here. Instead, "
#~ "we just make a copy of the "
#~ "received client model as global model"
#~ " by overriding :code:`aggregate_fit`."
#~ msgstr ""

#~ msgid ""
#~ "Also, the customised :code:`configure_fit` and"
#~ " :code:`configure_evaluate` methods ensure the"
#~ " clients to be sequentially selected "
#~ "given FL round:"
#~ msgstr ""

#~ msgid ""
#~ "In :code:`dataset.py`, we have a "
#~ "function :code:`instantiate_partitioner` to "
#~ "instantiate the data partitioner based "
#~ "on the given :code:`num_partitions` and "
#~ ":code:`partitioner_type`. Currently, we provide "
#~ "four supported partitioner type to "
#~ "simulate the uniformity/non-uniformity in "
#~ "data quantity (uniform, linear, square, "
#~ "exponential)."
#~ msgstr ""

#~ msgid ""
#~ "To facilitate centralised evaluation, we "
#~ "define a function in :code:`server_utils.py`:"
#~ msgstr ""

#~ msgid ""
#~ "This function returns a evaluation "
#~ "function which instantiates a :code:`Booster`"
#~ " object and loads the global model"
#~ " weights to it. The evaluation is "
#~ "conducted by calling :code:`eval_set()` "
#~ "method, and the tested AUC value "
#~ "is reported."
#~ msgstr ""

#~ msgid ""
#~ "As for distributed evaluation on the "
#~ "clients, it's same as the quick-"
#~ "start example by overriding the "
#~ ":code:`evaluate()` method insides the "
#~ ":code:`XgbClient` class in :code:`client_utils.py`."
#~ msgstr ""

#~ msgid ""
#~ "We also provide an example code "
#~ "(:code:`sim.py`) to use the simulation "
#~ "capabilities of Flower to simulate "
#~ "federated XGBoost training on either a"
#~ " single machine or a cluster of "
#~ "machines."
#~ msgstr ""

#~ msgid ""
#~ "After importing all required packages, "
#~ "we define a :code:`main()` function to"
#~ " perform the simulation process:"
#~ msgstr ""

#~ msgid ""
#~ "We first load the dataset and "
#~ "perform data partitioning, and the "
#~ "pre-processed data is stored in a "
#~ ":code:`list`. After the simulation begins, "
#~ "the clients won't need to pre-"
#~ "process their partitions again."
#~ msgstr ""

#~ msgid ""
#~ "After that, we start the simulation "
#~ "by calling :code:`fl.simulation.start_simulation`:"
#~ msgstr ""

#~ msgid ""
#~ "One of key parameters for "
#~ ":code:`start_simulation` is :code:`client_fn` which"
#~ " returns a function to construct a"
#~ " client. We define it as follows:"
#~ msgstr ""

#~ msgid ""
#~ "In :code:`utils.py`, we define the "
#~ "arguments parsers for clients, server "
#~ "and simulation, allowing users to "
#~ "specify different experimental settings. Let's"
#~ " first see the sever side:"
#~ msgstr ""

#~ msgid ""
#~ "This allows user to specify training "
#~ "strategies / the number of total "
#~ "clients / FL rounds / participating "
#~ "clients / clients for evaluation, and"
#~ " evaluation fashion. Note that with "
#~ ":code:`--centralised-eval`, the sever will "
#~ "do centralised evaluation and all "
#~ "functionalities for client evaluation will "
#~ "be disabled."
#~ msgstr ""

#~ msgid ""
#~ "This defines various options for client"
#~ " data partitioning. Besides, clients also"
#~ " have an option to conduct evaluation"
#~ " on centralised test set by setting"
#~ " :code:`--centralised-eval`, as well as "
#~ "an option to perform scaled learning "
#~ "rate based on the number of "
#~ "clients by setting :code:`--scaled-lr`."
#~ msgstr ""

#~ msgid ""
#~ "The full `code "
#~ "<https://github.com/adap/flower/blob/main/examples/xgboost-"
#~ "comprehensive/>`_ for this comprehensive "
#~ "example can be found in :code:`examples"
#~ "/xgboost-comprehensive`."
#~ msgstr ""

#~ msgid "|b8714c45b74b4d8fb008e2ebb3bc1d44|"
#~ msgstr ""

#~ msgid "|75f1561efcfd422ea67d28d1513120dc|"
#~ msgstr ""

#~ msgid "|6a1f51b235304558a9bdaaabfc93b8d2|"
#~ msgstr ""

#~ msgid "|35e70dab1fb544af9aa3a9c09c4f9797|"
#~ msgstr ""

#~ msgid "|d7efb5705dd3467f991ed23746824a07|"
#~ msgstr ""

#~ msgid "|94e7b021c7b540bfbedf7f082a41ff87|"
#~ msgstr ""

#~ msgid "|a80714782dde439ab73936518f91fc3c|"
#~ msgstr ""

#~ msgid "|c62080ca6197473da57d191c8225a9d9|"
#~ msgstr ""

#~ msgid "|21a8f1e6a5b14a7bbb8559979d0e8a2b|"
#~ msgstr ""

#~ msgid "|c310f2a22f7b4917bf42775aae7a1c09|"
#~ msgstr ""

#~ msgid "|a0c5b43401194535a8460bcf02e65f9a|"
#~ msgstr ""

#~ msgid "|aabfdbd5564e41a790f8ea93cc21a444|"
#~ msgstr ""

#~ msgid "|c9cc8f160fa647b09e742fe4dc8edb54|"
#~ msgstr ""

#~ msgid "|7e83aad011cd4907b2f02f907c6922e9|"
#~ msgstr ""

#~ msgid "|4627c2bb6cc443ae9e079f81f33c9dd9|"
#~ msgstr ""

#~ msgid "|131af8322dc5466b827afd24be98f8c0|"
#~ msgstr ""

#~ msgid "|f92920b87f3a40179bf7ddd0b6144c53|"
#~ msgstr ""

#~ msgid "|d62da263071d45a496f543e41fce3a19|"
#~ msgstr ""

#~ msgid "|ad851971645b4e1fbf8d15bcc0b2ee11|"
#~ msgstr ""

#~ msgid "|929e9a6de6b34edb8488e644e2bb5221|"
#~ msgstr ""

#~ msgid "|404cf9c9e8d64784a55646c0f9479cbc|"
#~ msgstr ""

#~ msgid "|b021ff9d25814458b1e631f8985a648b|"
#~ msgstr ""

#~ msgid "|e6ca84e1df244f238288a768352678e5|"
#~ msgstr ""

#~ msgid "|39c2422082554a21963baffb33a0d057|"
#~ msgstr ""

#~ msgid "|07ecf5fcd6814e88906accec6fa0fbfb|"
#~ msgstr ""

#~ msgid "|57e78c0ca8a94ba5a64a04b1f2280e55|"
#~ msgstr ""

#~ msgid "|9819b40e59ee40a4921e1244e8c99bac|"
#~ msgstr ""

#~ msgid "|797bf279c4894b5ead31dc9b0534ed62|"
#~ msgstr ""

#~ msgid ""
#~ "If you don't have ``pyenv`` installed,"
#~ " the following script that will "
#~ "install it, set it up, and create"
#~ " the virtual environment (with ``Python "
#~ "3.9.20`` by default):"
#~ msgstr ""

#~ msgid ""
#~ "If you already have ``pyenv`` installed"
#~ " (along with the ``pyenv-virtualenv`` "
#~ "plugin), you can use the following "
#~ "convenience script (with ``Python 3.9.20`` "
#~ "by default):"
#~ msgstr ""

#~ msgid "|3a7aceef05f0421794726ac54aaf12fd|"
#~ msgstr ""

#~ msgid "|d741075f8e624331b42c0746f7d258a0|"
#~ msgstr ""

#~ msgid "|8fc92d668bcb42b8bda55143847f2329|"
#~ msgstr ""

#~ msgid "|1c705d833a024f22adcaeb8ae3d13b0b|"
#~ msgstr ""

#~ msgid "|77a037b546a84262b608e04bc82a2c96|"
#~ msgstr ""

#~ msgid "|f568e24c9fb0435690ac628210a4be96|"
#~ msgstr ""

#~ msgid "|a7bf029981514e2593aa3a2b48c9d76a|"
#~ msgstr ""

#~ msgid "|3f645ad807f84be8b1f8f3267173939c|"
#~ msgstr ""

#~ msgid "|a06a9dbd603f45819afd8e8cfc3c4b8f|"
#~ msgstr ""

#~ msgid "|edcf9a04d96e42608fd01a333375febe|"
#~ msgstr ""

#~ msgid "|3dae22fe797043968e2b7aa7073c78bd|"
#~ msgstr ""

#~ msgid "|ba178f75267d4ad8aa7363f20709195f|"
#~ msgstr ""

#~ msgid "|c380c750bfd2444abce039a1c6fa8e60|"
#~ msgstr ""

#~ msgid "|e7cec00a114b48359935c6510595132e|"
#~ msgstr ""

#~ msgid ""
#~ "Include SecAgg, SecAgg+, and LightSecAgg "
#~ "protocol. The LightSecAgg protocol has "
#~ "not been implemented yet, so its "
#~ "diagram and abstraction may not be "
#~ "accurate in practice. The SecAgg "
#~ "protocol can be considered as a "
#~ "special case of the SecAgg+ protocol."
#~ msgstr ""

#~ msgid "The ``SecAgg+`` abstraction"
#~ msgstr ""

#~ msgid ""
#~ "In this implementation, each client will"
#~ " be assigned with a unique index "
#~ "(int) for secure aggregation, and thus"
#~ " many python dictionaries used have "
#~ "keys of int type rather than "
#~ "ClientProxy type."
#~ msgstr ""

#~ msgid ""
#~ "The Flower server will execute and "
#~ "process received results in the "
#~ "following order:"
#~ msgstr ""

#~ msgid "The ``LightSecAgg`` abstraction"
#~ msgstr ""

#~ msgid "Types"
#~ msgstr ""

#~ msgid ""
#~ "Docker Compose is `installed "
#~ "<https://docs.docker.com/compose/install/>`_."
#~ msgstr ""

#~ msgid "Build and start the services using the following command:"
#~ msgstr ""

#~ msgid "Run the example:"
#~ msgstr "Exemplo"

#~ msgid "Follow the logs of the SuperExec service:"
#~ msgstr ""

#~ msgid "Only runs on AMD64."
#~ msgstr ""

#~ msgid ""
#~ "Use the method that works best for"
#~ " you to copy the ``server`` "
#~ "directory, the certificates, and your "
#~ "Flower project to the remote machine."
#~ msgstr ""

#~ msgid ""
#~ "The Path of the ``PROJECT_DIR`` should"
#~ " be relative to the location of "
#~ "the ``server`` Docker Compose files."
#~ msgstr ""

#~ msgid ""
#~ "The Path of the ``PROJECT_DIR`` should"
#~ " be relative to the location of "
#~ "the ``client`` Docker Compose files."
#~ msgstr ""

#~ msgid ""
#~ "The Path of the ``root-certificates``"
#~ " should be relative to the location"
#~ " of the ``pyproject.toml`` file."
#~ msgstr ""

#~ msgid "To run the project, execute:"
#~ msgstr ""

#~ msgid "Run the ``quickstart-docker`` project by executing the command:"
#~ msgstr ""

#~ msgid "Follow the SuperExec logs to track the execution of the run:"
#~ msgstr ""

#~ msgid "Execute the command to run the quickstart example:"
#~ msgstr ""

#~ msgid "Monitor the SuperExec logs and wait for the summary to appear:"
#~ msgstr ""

#~ msgid "Example: FedBN in PyTorch - From Centralized To Federated"
#~ msgstr ""

#~ msgid ""
#~ "This tutorial will show you how to"
#~ " use Flower to build a federated "
#~ "version of an existing machine learning"
#~ " workload with `FedBN <https://github.com/med-"
#~ "air/FedBN>`_, a federated training strategy"
#~ " designed for non-iid data. We "
#~ "are using PyTorch to train a "
#~ "Convolutional Neural Network(with Batch "
#~ "Normalization layers) on the CIFAR-10 "
#~ "dataset. When applying FedBN, only few"
#~ " changes needed compared to :doc:`Example:"
#~ " PyTorch - From Centralized To "
#~ "Federated <example-pytorch-from-"
#~ "centralized-to-federated>`."
#~ msgstr ""

#~ msgid "Centralized Training"
#~ msgstr ""

#~ msgid ""
#~ "All files are revised based on "
#~ ":doc:`Example: PyTorch - From Centralized "
#~ "To Federated <example-pytorch-from-"
#~ "centralized-to-federated>`. The only thing"
#~ " to do is modifying the file "
#~ "called ``cifar.py``, revised part is "
#~ "shown below:"
#~ msgstr ""

#~ msgid ""
#~ "The model architecture defined in class"
#~ " Net() is added with Batch "
#~ "Normalization layers accordingly."
#~ msgstr ""

#~ msgid "You can now run your machine learning workload:"
#~ msgstr ""

#~ msgid ""
#~ "So far this should all look fairly"
#~ " familiar if you've used PyTorch "
#~ "before. Let's take the next step "
#~ "and use what we've built to create"
#~ " a federated learning system within "
#~ "FedBN, the system consists of one "
#~ "server and two clients."
#~ msgstr ""

#~ msgid "Federated Training"
#~ msgstr ""

#~ msgid ""
#~ "If you have read :doc:`Example: PyTorch"
#~ " - From Centralized To Federated "
#~ "<example-pytorch-from-centralized-to-"
#~ "federated>`, the following parts are "
#~ "easy to follow, only ``get_parameters`` "
#~ "and ``set_parameters`` function in "
#~ "``client.py`` needed to revise. If not,"
#~ " please read the :doc:`Example: PyTorch "
#~ "- From Centralized To Federated "
#~ "<example-pytorch-from-centralized-to-"
#~ "federated>`. first."
#~ msgstr ""

#~ msgid ""
#~ "Our example consists of one *server* "
#~ "and two *clients*. In FedBN, "
#~ "``server.py`` keeps unchanged, we can "
#~ "start the server directly."
#~ msgstr ""

#~ msgid ""
#~ "Finally, we will revise our *client* "
#~ "logic by changing ``get_parameters`` and "
#~ "``set_parameters`` in ``client.py``, we will"
#~ " exclude batch normalization parameters "
#~ "from model parameter list when sending"
#~ " to or receiving from the server."
#~ msgstr ""

#~ msgid "Now, you can now open two additional terminal windows and run"
#~ msgstr ""

#~ msgid ""
#~ "in each window (make sure that the"
#~ " server is still running before you"
#~ " do so) and see your (previously "
#~ "centralized) PyTorch project run federated "
#~ "learning with FedBN strategy across two"
#~ " clients. Congratulations!"
#~ msgstr ""

#~ msgid ""
#~ "The full source code for this "
#~ "example can be found `here "
#~ "<https://github.com/adap/flower/blob/main/examples/pytorch-"
#~ "from-centralized-to-federated>`_. Our "
#~ "example is of course somewhat over-"
#~ "simplified because both clients load the"
#~ " exact same dataset, which isn't "
#~ "realistic. You're now prepared to "
#~ "explore this topic further. How about"
#~ " using different subsets of CIFAR-10 "
#~ "on each client? How about adding "
#~ "more clients?"
#~ msgstr ""

#~ msgid "Example: PyTorch - From Centralized To Federated"
#~ msgstr ""

#~ msgid ""
#~ "This tutorial will show you how to"
#~ " use Flower to build a federated "
#~ "version of an existing machine learning"
#~ " workload. We are using PyTorch to"
#~ " train a Convolutional Neural Network "
#~ "on the CIFAR-10 dataset. First, we "
#~ "introduce this machine learning task "
#~ "with a centralized training approach "
#~ "based on the `Deep Learning with "
#~ "PyTorch "
#~ "<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_"
#~ " tutorial. Then, we build upon the"
#~ " centralized training code to run the"
#~ " training in a federated fashion."
#~ msgstr ""

#~ msgid ""
#~ "We begin with a brief description "
#~ "of the centralized CNN training code."
#~ " If you want a more in-depth"
#~ " explanation of what's going on then"
#~ " have a look at the official "
#~ "`PyTorch tutorial "
#~ "<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_."
#~ msgstr ""

#~ msgid ""
#~ "Let's create a new file called "
#~ "``cifar.py`` with all the components "
#~ "required for a traditional (centralized) "
#~ "training on CIFAR-10. First, all "
#~ "required packages (such as ``torch`` and"
#~ " ``torchvision``) need to be imported. "
#~ "You can see that we do not "
#~ "import any package for federated "
#~ "learning. You can keep all these "
#~ "imports as they are even when we"
#~ " add the federated learning components "
#~ "at a later point."
#~ msgstr ""

#~ msgid ""
#~ "As already mentioned we will use "
#~ "the CIFAR-10 dataset for this machine"
#~ " learning workload. The model architecture"
#~ " (a very simple Convolutional Neural "
#~ "Network) is defined in ``class Net()``."
#~ msgstr ""

#~ msgid ""
#~ "The ``load_data()`` function loads the "
#~ "CIFAR-10 training and test sets. The "
#~ "``transform`` normalized the data after "
#~ "loading."
#~ msgstr ""

#~ msgid ""
#~ "We now need to define the training"
#~ " (function ``train()``) which loops over"
#~ " the training set, measures the loss,"
#~ " backpropagates it, and then takes "
#~ "one optimizer step for each batch "
#~ "of training examples."
#~ msgstr ""

#~ msgid ""
#~ "The evaluation of the model is "
#~ "defined in the function ``test()``. The"
#~ " function loops over all test samples"
#~ " and measures the loss of the "
#~ "model based on the test dataset."
#~ msgstr ""

#~ msgid ""
#~ "Having defined the data loading, model"
#~ " architecture, training, and evaluation we"
#~ " can put everything together and "
#~ "train our CNN on CIFAR-10."
#~ msgstr ""

#~ msgid ""
#~ "So far, this should all look "
#~ "fairly familiar if you've used PyTorch"
#~ " before. Let's take the next step "
#~ "and use what we've built to create"
#~ " a simple federated learning system "
#~ "consisting of one server and two "
#~ "clients."
#~ msgstr ""

#~ msgid ""
#~ "The simple machine learning project "
#~ "discussed in the previous section trains"
#~ " the model on a single dataset "
#~ "(CIFAR-10), we call this centralized "
#~ "learning. This concept of centralized "
#~ "learning, as shown in the previous "
#~ "section, is probably known to most "
#~ "of you, and many of you have "
#~ "used it previously. Normally, if you'd"
#~ " want to run machine learning "
#~ "workloads in a federated fashion, then"
#~ " you'd have to change most of "
#~ "your code and set everything up "
#~ "from scratch. This can be a "
#~ "considerable effort."
#~ msgstr ""

#~ msgid ""
#~ "However, with Flower you can evolve "
#~ "your pre-existing code into a "
#~ "federated learning setup without the "
#~ "need for a major rewrite."
#~ msgstr ""

#~ msgid ""
#~ "The concept is easy to understand. "
#~ "We have to start a *server* and"
#~ " then use the code in ``cifar.py``"
#~ " for the *clients* that are connected"
#~ " to the *server*. The *server* sends"
#~ " model parameters to the clients. The"
#~ " *clients* run the training and "
#~ "update the parameters. The updated "
#~ "parameters are sent back to the "
#~ "*server* which averages all received "
#~ "parameter updates. This describes one "
#~ "round of the federated learning process"
#~ " and we repeat this for multiple "
#~ "rounds."
#~ msgstr ""

#~ msgid ""
#~ "Our example consists of one *server* "
#~ "and two *clients*. Let's set up "
#~ "``server.py`` first. The *server* needs "
#~ "to import the Flower package ``flwr``."
#~ " Next, we use the ``start_server`` "
#~ "function to start a server and "
#~ "tell it to perform three rounds of"
#~ " federated learning."
#~ msgstr ""

#~ msgid "We can already start the *server*:"
#~ msgstr ""

#~ msgid ""
#~ "Finally, we will define our *client* "
#~ "logic in ``client.py`` and build upon"
#~ " the previously defined centralized "
#~ "training in ``cifar.py``. Our *client* "
#~ "needs to import ``flwr``, but also "
#~ "``torch`` to update the parameters on"
#~ " our PyTorch model:"
#~ msgstr ""

#~ msgid ""
#~ "Implementing a Flower *client* basically "
#~ "means implementing a subclass of either"
#~ " ``flwr.client.Client`` or ``flwr.client.NumPyClient``."
#~ " Our implementation will be based on"
#~ " ``flwr.client.NumPyClient`` and we'll call "
#~ "it ``CifarClient``. ``NumPyClient`` is "
#~ "slightly easier to implement than "
#~ "``Client`` if you use a framework "
#~ "with good NumPy interoperability (like "
#~ "PyTorch or TensorFlow/Keras) because it "
#~ "avoids some of the boilerplate that "
#~ "would otherwise be necessary. ``CifarClient``"
#~ " needs to implement four methods, two"
#~ " methods for getting/setting model "
#~ "parameters, one method for training the"
#~ " model, and one method for testing"
#~ " the model:"
#~ msgstr ""

#~ msgid "``set_parameters``"
#~ msgstr "``SETUPTOOLS_VERSION``"

#~ msgid ""
#~ "set the model parameters on the "
#~ "local model that are received from "
#~ "the server"
#~ msgstr ""

#~ msgid ""
#~ "loop over the list of model "
#~ "parameters received as NumPy ``ndarray``'s "
#~ "(think list of neural network layers)"
#~ msgstr ""

#~ msgid "``get_parameters``"
#~ msgstr ""

#~ msgid ""
#~ "get the model parameters and return "
#~ "them as a list of NumPy "
#~ "``ndarray``'s (which is what "
#~ "``flwr.client.NumPyClient`` expects)"
#~ msgstr ""

#~ msgid "``fit``"
#~ msgstr ""

#~ msgid ""
#~ "update the parameters of the local "
#~ "model with the parameters received from"
#~ " the server"
#~ msgstr ""

#~ msgid "train the model on the local training set"
#~ msgstr ""

#~ msgid "get the updated local model weights and return them to the server"
#~ msgstr ""

#~ msgid "``evaluate``"
#~ msgstr ""

#~ msgid "evaluate the updated model on the local test set"
#~ msgstr ""

#~ msgid "return the local loss and accuracy to the server"
#~ msgstr ""

#~ msgid ""
#~ "The two ``NumPyClient`` methods ``fit`` "
#~ "and ``evaluate`` make use of the "
#~ "functions ``train()`` and ``test()`` "
#~ "previously defined in ``cifar.py``. So "
#~ "what we really do here is we "
#~ "tell Flower through our ``NumPyClient`` "
#~ "subclass which of our already defined"
#~ " functions to call for training and"
#~ " evaluation. We included type annotations"
#~ " to give you a better understanding"
#~ " of the data types that get "
#~ "passed around."
#~ msgstr ""

#~ msgid ""
#~ "All that's left to do it to "
#~ "define a function that loads both "
#~ "model and data, creates a "
#~ "``CifarClient``, and starts this client. "
#~ "You load your data and model by"
#~ " using ``cifar.py``. Start ``CifarClient`` "
#~ "with the function ``fl.client.start_client()`` "
#~ "by pointing it at the same IP "
#~ "address we used in ``server.py``:"
#~ msgstr ""

#~ msgid "And that's it. You can now open two additional terminal windows and run"
#~ msgstr ""

#~ msgid ""
#~ "in each window (make sure that the"
#~ " server is running before you do "
#~ "so) and see your (previously "
#~ "centralized) PyTorch project run federated "
#~ "learning across two clients. Congratulations!"
#~ msgstr ""

#~ msgid ""
#~ "The full source code for this "
#~ "example: `PyTorch: From Centralized To "
#~ "Federated (Code) "
#~ "<https://github.com/adap/flower/blob/main/examples/pytorch-"
#~ "from-centralized-to-federated>`_. Our "
#~ "example is, of course, somewhat over-"
#~ "simplified because both clients load the"
#~ " exact same dataset, which isn't "
#~ "realistic. You're now prepared to "
#~ "explore this topic further. How about"
#~ " using different subsets of CIFAR-10 "
#~ "on each client? How about adding "
#~ "more clients?"
#~ msgstr ""

#~ msgid ""
#~ "For a full code example that uses"
#~ " both centralized and federated evaluation,"
#~ " see the *Advanced TensorFlow Example* "
#~ "(the same approach can be applied "
#~ "to workloads implemented in any other"
#~ " framework): "
#~ "https://github.com/adap/flower/tree/main/examples/advanced-"
#~ "tensorflow"
#~ msgstr ""

#~ msgid ""
#~ "To help you start and manage all"
#~ " of the concurrently executing training "
#~ "runs, Flower offers one additional "
#~ "long-running server-side service called "
#~ "**SuperExec**. When you type ``flwr "
#~ "run`` to start a new training run,"
#~ " the ``flwr`` CLI bundles your local"
#~ " project (mainly your ``ServerApp`` and "
#~ "``ClientApp``) and sends it to the "
#~ "**SuperExec**. The **SuperExec** will then "
#~ "take care of starting and managing "
#~ "your ``ServerApp``, which in turn "
#~ "selects SuperNodes to execute your "
#~ "``ClientApp``."
#~ msgstr ""

#~ msgid ""
#~ "This architecture allows many users to"
#~ " (concurrently) run their projects on "
#~ "the same federation, simply by typing"
#~ " ``flwr run`` on their local "
#~ "developer machine."
#~ msgstr ""

#~ msgid "Flower Deployment Engine with SuperExec"
#~ msgstr ""

#~ msgid "The SuperExec service for managing concurrent training runs in Flower."
#~ msgstr ""

#~ msgid "FED Template"
#~ msgstr ""

#~ msgid "Table of Contents"
#~ msgstr ""

#~ msgid "[Table of Contents](#table-of-contents)"
#~ msgstr ""

#~ msgid "[Summary](#summary)"
#~ msgstr ""

#~ msgid "[Motivation](#motivation)"
#~ msgstr ""

#~ msgid "[Goals](#goals)"
#~ msgstr ""

#~ msgid "[Non-Goals](#non-goals)"
#~ msgstr ""

#~ msgid "[Proposal](#proposal)"
#~ msgstr ""

#~ msgid "[Drawbacks](#drawbacks)"
#~ msgstr ""

#~ msgid "[Alternatives Considered](#alternatives-considered)"
#~ msgstr ""

#~ msgid "[Appendix](#appendix)"
#~ msgstr ""

#~ msgid "Summary"
#~ msgstr ""

#~ msgid "\\[TODO - sentence 1: summary of the problem\\]"
#~ msgstr ""

#~ msgid "\\[TODO - sentence 2: summary of the solution\\]"
#~ msgstr ""

#~ msgid "Motivation"
#~ msgstr ""

#~ msgid "\\[TODO\\]"
#~ msgstr ""

#~ msgid "Goals"
#~ msgstr ""

#~ msgid "Non-Goals"
#~ msgstr ""

#~ msgid "Proposal"
#~ msgstr ""

#~ msgid "Drawbacks"
#~ msgstr ""

#~ msgid "Alternatives Considered"
#~ msgstr ""

#~ msgid "\\[Alternative 1\\]"
#~ msgstr ""

#~ msgid "\\[Alternative 2\\]"
#~ msgstr ""

#~ msgid "Flower Enhancement Doc"
#~ msgstr ""

#~ msgid "[Enhancement Doc Template](#enhancement-doc-template)"
#~ msgstr ""

#~ msgid "[Metadata](#metadata)"
#~ msgstr ""

#~ msgid "[Workflow](#workflow)"
#~ msgstr ""

#~ msgid "[GitHub Issues](#github-issues)"
#~ msgstr ""

#~ msgid "[Google Docs](#google-docs)"
#~ msgstr ""

#~ msgid "A Flower Enhancement is a standardized development process to"
#~ msgstr ""

#~ msgid "provide a common structure for proposing larger changes"
#~ msgstr ""

#~ msgid "ensure that the motivation for a change is clear"
#~ msgstr ""

#~ msgid "persist project information in a version control system"
#~ msgstr ""

#~ msgid "document the motivation for impactful user-facing changes"
#~ msgstr ""

#~ msgid "reserve GitHub issues for tracking work in flight"
#~ msgstr ""

#~ msgid ""
#~ "ensure community participants can successfully"
#~ " drive changes to completion across "
#~ "one or more releases while stakeholders"
#~ " are adequately represented throughout the"
#~ " process"
#~ msgstr ""

#~ msgid "Hence, an Enhancement Doc combines aspects of"
#~ msgstr ""

#~ msgid "a feature, and effort-tracking document"
#~ msgstr ""

#~ msgid "a product requirements document"
#~ msgstr ""

#~ msgid "a design document"
#~ msgstr ""

#~ msgid ""
#~ "into one file, which is created "
#~ "incrementally in collaboration with the "
#~ "community."
#~ msgstr ""

#~ msgid ""
#~ "For far-fetching changes or features "
#~ "proposed to Flower, an abstraction "
#~ "beyond a single GitHub issue or "
#~ "pull request is required to understand"
#~ " and communicate upcoming changes to "
#~ "the project."
#~ msgstr ""

#~ msgid ""
#~ "The purpose of this process is to"
#~ " reduce the amount of \"tribal "
#~ "knowledge\" in our community. By moving"
#~ " decisions from Slack threads, video "
#~ "calls, and hallway conversations into a"
#~ " well-tracked artifact, this process "
#~ "aims to enhance communication and "
#~ "discoverability."
#~ msgstr ""

#~ msgid ""
#~ "Roughly any larger, user-facing "
#~ "enhancement should follow the Enhancement "
#~ "process. If an enhancement would be "
#~ "described in either written or verbal"
#~ " communication to anyone besides the "
#~ "author or developer, then consider "
#~ "creating an Enhancement Doc."
#~ msgstr ""

#~ msgid ""
#~ "Similarly, any technical effort (refactoring,"
#~ " major architectural change) that will "
#~ "impact a large section of the "
#~ "development community should also be "
#~ "communicated widely. The Enhancement process"
#~ " is suited for this even if it"
#~ " will have zero impact on the "
#~ "typical user or operator."
#~ msgstr ""

#~ msgid ""
#~ "For small changes and additions, going"
#~ " through the Enhancement process would "
#~ "be time-consuming and unnecessary. This"
#~ " includes, for example, adding new "
#~ "Federated Learning algorithms, as these "
#~ "only add features without changing how"
#~ " Flower works or is used."
#~ msgstr ""

#~ msgid ""
#~ "Enhancements are different from feature "
#~ "requests, as they are already providing"
#~ " a laid-out path for implementation"
#~ " and are championed by members of "
#~ "the community."
#~ msgstr ""

#~ msgid ""
#~ "An Enhancement is captured in a "
#~ "Markdown file that follows a defined "
#~ "template and a workflow to review "
#~ "and store enhancement docs for reference"
#~ " — the Enhancement Doc."
#~ msgstr ""

#~ msgid "Enhancement Doc Template"
#~ msgstr ""

#~ msgid ""
#~ "Each enhancement doc is provided as "
#~ "a Markdown file having the following "
#~ "structure"
#~ msgstr ""

#~ msgid "Metadata (as [described below](#metadata) in form of a YAML preamble)"
#~ msgstr ""

#~ msgid "Title (same as in metadata)"
#~ msgstr ""

#~ msgid "Table of Contents (if needed)"
#~ msgstr ""

#~ msgid "Notes/Constraints/Caveats (optional)"
#~ msgstr ""

#~ msgid "Design Details (optional)"
#~ msgstr ""

#~ msgid "Graduation Criteria"
#~ msgstr ""

#~ msgid "Upgrade/Downgrade Strategy (if applicable)"
#~ msgstr ""

#~ msgid "As a reference, this document follows the above structure."
#~ msgstr ""

#~ msgid ""
#~ "**fed-number** (Required) The `fed-"
#~ "number` of the last Flower Enhancement"
#~ " Doc + 1. With this number, it"
#~ " becomes easy to reference other "
#~ "proposals."
#~ msgstr ""

#~ msgid "**title** (Required) The title of the proposal in plain language."
#~ msgstr ""

#~ msgid ""
#~ "**status** (Required) The current status "
#~ "of the proposal. See [workflow](#workflow) "
#~ "for the possible states."
#~ msgstr ""

#~ msgid ""
#~ "**authors** (Required) A list of authors"
#~ " of the proposal. This is simply "
#~ "the GitHub ID."
#~ msgstr ""

#~ msgid ""
#~ "**creation-date** (Required) The date "
#~ "that the proposal was first submitted"
#~ " in a PR."
#~ msgstr ""

#~ msgid ""
#~ "**last-updated** (Optional) The date "
#~ "that the proposal was last changed "
#~ "significantly."
#~ msgstr ""

#~ msgid ""
#~ "**see-also** (Optional) A list of "
#~ "other proposals that are relevant to "
#~ "this one."
#~ msgstr ""

#~ msgid "**replaces** (Optional) A list of proposals that this one replaces."
#~ msgstr ""

#~ msgid ""
#~ "**superseded-by** (Optional) A list of"
#~ " proposals that this one supersedes."
#~ msgstr ""

#~ msgid "Workflow"
#~ msgstr ""

#~ msgid ""
#~ "The idea forming the enhancement should"
#~ " already have been discussed or "
#~ "pitched in the community. As such, "
#~ "it needs a champion, usually the "
#~ "author, who shepherds the enhancement. "
#~ "This person also has to find "
#~ "committers to Flower willing to review"
#~ " the proposal."
#~ msgstr ""

#~ msgid ""
#~ "New enhancements are checked in with "
#~ "a file name in the form of "
#~ "`NNNN-YYYYMMDD-enhancement-title.md`, with "
#~ "`NNNN` being the Flower Enhancement Doc"
#~ " number, to `enhancements`. All "
#~ "enhancements start in `provisional` state "
#~ "as part of a pull request. "
#~ "Discussions are done as part of "
#~ "the pull request review."
#~ msgstr ""

#~ msgid ""
#~ "Once an enhancement has been reviewed"
#~ " and approved, its status is changed"
#~ " to `implementable`. The actual "
#~ "implementation is then done in separate"
#~ " pull requests. These pull requests "
#~ "should mention the respective enhancement "
#~ "as part of their description. After "
#~ "the implementation is done, the proposal"
#~ " status is changed to `implemented`."
#~ msgstr ""

#~ msgid ""
#~ "Under certain conditions, other states "
#~ "are possible. An Enhancement has the "
#~ "following states:"
#~ msgstr ""

#~ msgid ""
#~ "`provisional`: The enhancement has been "
#~ "proposed and is actively being defined."
#~ " This is the starting state while "
#~ "the proposal is being fleshed out "
#~ "and actively defined and discussed."
#~ msgstr ""

#~ msgid "`implementable`: The enhancement has been reviewed and approved."
#~ msgstr ""

#~ msgid ""
#~ "`implemented`: The enhancement has been "
#~ "implemented and is no longer actively"
#~ " changed."
#~ msgstr ""

#~ msgid ""
#~ "`deferred`: The enhancement is proposed "
#~ "but not actively being worked on."
#~ msgstr ""

#~ msgid ""
#~ "`rejected`: The authors and reviewers "
#~ "have decided that this enhancement is"
#~ " not moving forward."
#~ msgstr ""

#~ msgid "`withdrawn`: The authors have withdrawn the enhancement."
#~ msgstr ""

#~ msgid "`replaced`: The enhancement has been replaced by a new enhancement."
#~ msgstr ""

#~ msgid ""
#~ "Adding an additional process to the "
#~ "ones already provided by GitHub (Issues"
#~ " and Pull Requests) adds more "
#~ "complexity and can be a barrier "
#~ "for potential first-time contributors."
#~ msgstr ""

#~ msgid ""
#~ "Expanding the proposal template beyond "
#~ "the single-sentence description currently "
#~ "required in the features issue template"
#~ " may be a heavy burden for "
#~ "non-native English speakers."
#~ msgstr ""

#~ msgid "GitHub Issues"
#~ msgstr ""

#~ msgid ""
#~ "Using GitHub Issues for these kinds "
#~ "of enhancements is doable. One could "
#~ "use, for example, tags, to differentiate"
#~ " and filter them from other issues."
#~ " The main issue is in discussing "
#~ "and reviewing an enhancement: GitHub "
#~ "issues only have a single thread "
#~ "for comments. Enhancements usually have "
#~ "multiple threads of discussion at the"
#~ " same time for various parts of "
#~ "the doc. Managing these multiple "
#~ "discussions can be confusing when using"
#~ " GitHub Issues."
#~ msgstr ""

#~ msgid "Google Docs"
#~ msgstr ""

#~ msgid ""
#~ "Google Docs allow for multiple threads"
#~ " of discussions. But as Google Docs"
#~ " are hosted outside the project, "
#~ "their discoverability by the community "
#~ "needs to be taken care of. A "
#~ "list of links to all proposals has"
#~ " to be managed and made available "
#~ "for the community. Compared to shipping"
#~ " proposals as part of Flower's "
#~ "repository, the potential for missing "
#~ "links is much higher."
#~ msgstr ""

#~ msgid "FED - Flower Enhancement Doc"
#~ msgstr ""

#~ msgid "Configure clients"
#~ msgstr ""

#~ msgid ""
#~ "Along with model parameters, Flower can"
#~ " send configuration values to clients. "
#~ "Configuration values can be used for "
#~ "various purposes. They are, for example,"
#~ " a popular way to control client-"
#~ "side hyperparameters from the server."
#~ msgstr ""

#~ msgid ""
#~ "Configuration values are represented as "
#~ "a dictionary with ``str`` keys and "
#~ "values of type ``bool``, ``bytes``, "
#~ "``double`` (64-bit precision float), ``int``,"
#~ " or ``str`` (or equivalent types in"
#~ " different languages). Here is an "
#~ "example of a configuration dictionary in"
#~ " Python:"
#~ msgstr ""

#~ msgid ""
#~ "Flower serializes these configuration "
#~ "dictionaries (or *config dict* for "
#~ "short) to their ProtoBuf representation, "
#~ "transports them to the client using "
#~ "gRPC, and then deserializes them back"
#~ " to Python dictionaries."
#~ msgstr ""

#~ msgid ""
#~ "Currently, there is no support for "
#~ "directly sending collection types (e.g., "
#~ "``Set``, ``List``, ``Map``) as values in"
#~ " configuration dictionaries. There are "
#~ "several workarounds to send collections "
#~ "as values by converting them to "
#~ "one of the supported value types "
#~ "(and converting them back on the "
#~ "client-side)."
#~ msgstr ""

#~ msgid ""
#~ "One can, for example, convert a "
#~ "list of floating-point numbers to "
#~ "a JSON string, then send the JSON"
#~ " string using the configuration dictionary,"
#~ " and then convert the JSON string "
#~ "back to a list of floating-point"
#~ " numbers on the client."
#~ msgstr ""

#~ msgid "Configuration through built-in strategies"
#~ msgstr ""

#~ msgid ""
#~ "The easiest way to send configuration"
#~ " values to clients is to use a"
#~ " built-in strategy like ``FedAvg``. "
#~ "Built-in strategies support so-called "
#~ "configuration functions. A configuration "
#~ "function is a function that the "
#~ "built-in strategy calls to get the"
#~ " configuration dictionary for the current"
#~ " round. It then forwards the "
#~ "configuration dictionary to all the "
#~ "clients selected during that round."
#~ msgstr ""

#~ msgid ""
#~ "Let's start with a simple example. "
#~ "Imagine we want to send (a) the"
#~ " batch size that the client should"
#~ " use, (b) the current global round"
#~ " of federated learning, and (c) the"
#~ " number of epochs to train on "
#~ "the client-side. Our configuration "
#~ "function could look like this:"
#~ msgstr ""

#~ msgid ""
#~ "To make the built-in strategies "
#~ "use this function, we can pass it"
#~ " to ``FedAvg`` during initialization using"
#~ " the parameter ``on_fit_config_fn``:"
#~ msgstr ""

#~ msgid ""
#~ "One the client side, we receive "
#~ "the configuration dictionary in ``fit``:"
#~ msgstr ""

#~ msgid ""
#~ "There is also an `on_evaluate_config_fn` "
#~ "to configure evaluation, which works the"
#~ " same way. They are separate "
#~ "functions because one might want to "
#~ "send different configuration values to "
#~ "`evaluate` (for example, to use a "
#~ "different batch size)."
#~ msgstr ""

#~ msgid ""
#~ "The built-in strategies call this "
#~ "function every round (that is, every "
#~ "time `Strategy.configure_fit` or "
#~ "`Strategy.configure_evaluate` runs). Calling "
#~ "`on_evaluate_config_fn` every round allows us"
#~ " to vary/change the config dict over"
#~ " consecutive rounds. If we wanted to"
#~ " implement a hyperparameter schedule, for"
#~ " example, to increase the number of"
#~ " local epochs during later rounds, we"
#~ " could do the following:"
#~ msgstr ""

#~ msgid "The ``FedAvg`` strategy will call this function *every round*."
#~ msgstr ""

#~ msgid "Configuring individual clients"
#~ msgstr ""

#~ msgid ""
#~ "In some cases, it is necessary to"
#~ " send different configuration values to "
#~ "different clients."
#~ msgstr ""

#~ msgid ""
#~ "This can be achieved by customizing "
#~ "an existing strategy or by "
#~ ":doc:`implementing a custom strategy from "
#~ "scratch <how-to-implement-strategies>`. "
#~ "Here's a nonsensical example that "
#~ "customizes ``FedAvg`` by adding a custom"
#~ " ``\"hello\": \"world\"`` configuration key/value"
#~ " pair to the config dict of a"
#~ " *single client* (only the first "
#~ "client in the list, the other "
#~ "clients in this round to not "
#~ "receive this \"special\" config value):"
#~ msgstr ""

#~ msgid "Configure logging"
#~ msgstr ""

#~ msgid ""
#~ "The Flower logger keeps track of "
#~ "all core events that take place in"
#~ " federated learning workloads. It presents"
#~ " information by default following a "
#~ "standard message format:"
#~ msgstr ""

#~ msgid ""
#~ "containing relevant information including: log"
#~ " message level (e.g. ``INFO``, ``DEBUG``),"
#~ " a timestamp, the line where the "
#~ "logging took place from, as well "
#~ "as the log message itself. In this"
#~ " way, the logger would typically "
#~ "display information on your terminal as"
#~ " follows:"
#~ msgstr ""

#~ msgid "Saving log to file"
#~ msgstr ""

#~ msgid ""
#~ "By default, the Flower log is "
#~ "outputted to the terminal where you "
#~ "launch your Federated Learning workload "
#~ "from. This applies for both gRPC-"
#~ "based federation (i.e. when you do "
#~ "``fl.server.start_server``) and when using the"
#~ " ``VirtualClientEngine`` (i.e. when you do"
#~ " ``fl.simulation.start_simulation``). In some "
#~ "situations you might want to save "
#~ "this log to disk. You can do "
#~ "so by calling the "
#~ "`fl.common.logger.configure() "
#~ "<https://github.com/adap/flower/blob/main/src/py/flwr/common/logger.py>`_"
#~ " function. For example:"
#~ msgstr ""

#~ msgid ""
#~ "With the above, Flower will record "
#~ "the log you see on your terminal"
#~ " to ``log.txt``. This file will be"
#~ " created in the same directory as "
#~ "were you are running the code "
#~ "from. If we inspect we see the "
#~ "log above is also recorded but "
#~ "prefixing with ``identifier`` each line:"
#~ msgstr ""

#~ msgid "Log your own messages"
#~ msgstr ""

#~ msgid ""
#~ "You might expand the information shown"
#~ " by default with the Flower logger"
#~ " by adding more messages relevant to"
#~ " your application. You can achieve "
#~ "this easily as follows."
#~ msgstr ""

#~ msgid ""
#~ "In this way your logger will show,"
#~ " in addition to the default messages,"
#~ " the ones introduced by the clients"
#~ " as specified above."
#~ msgstr ""

#~ msgid "Log to a remote service"
#~ msgstr ""

#~ msgid ""
#~ "The ``fl.common.logger.configure`` function, also"
#~ " allows specifying a host to which"
#~ " logs can be pushed (via ``POST``)"
#~ " through a native Python "
#~ "``logging.handler.HTTPHandler``. This is a "
#~ "particularly useful feature in ``gRPC``-based"
#~ " Federated Learning workloads where "
#~ "otherwise gathering logs from all "
#~ "entities (i.e. the server and the "
#~ "clients) might be cumbersome. Note that"
#~ " in Flower simulation, the server "
#~ "automatically displays all logs. You can"
#~ " still specify a ``HTTPHandler`` should "
#~ "you wish to backup or analyze the"
#~ " logs somewhere else."
#~ msgstr ""

#~ msgid "Monitor simulation"
#~ msgstr ""

#~ msgid ""
#~ "Flower allows you to monitor system "
#~ "resources while running your simulation. "
#~ "Moreover, the Flower simulation engine "
#~ "is powerful and enables you to "
#~ "decide how to allocate resources per "
#~ "client manner and constrain the total"
#~ " usage. Insights from resource consumption"
#~ " can help you make smarter decisions"
#~ " and speed up the execution time."
#~ msgstr ""

#~ msgid ""
#~ "The specific instructions assume you are"
#~ " using macOS and have the `Homebrew"
#~ " <https://brew.sh/>`_ package manager installed."
#~ msgstr ""

#~ msgid "Downloads"
#~ msgstr ""

#~ msgid ""
#~ "`Prometheus <https://prometheus.io/>`_ is used "
#~ "for data collection, while `Grafana "
#~ "<https://grafana.com/>`_ will enable you to"
#~ " visualize the collected data. They "
#~ "are both well integrated with `Ray "
#~ "<https://www.ray.io/>`_ which Flower uses "
#~ "under the hood."
#~ msgstr ""

#~ msgid ""
#~ "Overwrite the configuration files (depending"
#~ " on your device, it might be "
#~ "installed on a different path)."
#~ msgstr ""

#~ msgid "If you are on an M1 Mac, it should be:"
#~ msgstr ""

#~ msgid "On the previous generation Intel Mac devices, it should be:"
#~ msgstr ""

#~ msgid ""
#~ "Open the respective configuration files "
#~ "and change them. Depending on your "
#~ "device, use one of the two "
#~ "following commands:"
#~ msgstr ""

#~ msgid ""
#~ "and then delete all the text in"
#~ " the file and paste a new "
#~ "Prometheus config you see below. You "
#~ "may adjust the time intervals to "
#~ "your requirements:"
#~ msgstr ""

#~ msgid ""
#~ "Now after you have edited the "
#~ "Prometheus configuration, do the same "
#~ "with the Grafana configuration files. "
#~ "Open those using one of the "
#~ "following commands as before:"
#~ msgstr ""

#~ msgid ""
#~ "Your terminal editor should open and "
#~ "allow you to apply the following "
#~ "configuration as before."
#~ msgstr ""

#~ msgid ""
#~ "Congratulations, you just downloaded all "
#~ "the necessary software needed for "
#~ "metrics tracking. Now, let’s start it."
#~ msgstr ""

#~ msgid "Tracking metrics"
#~ msgstr ""

#~ msgid ""
#~ "Before running your Flower simulation, "
#~ "you have to start the monitoring "
#~ "tools you have just installed and "
#~ "configured."
#~ msgstr ""

#~ msgid ""
#~ "Please include the following argument in"
#~ " your Python code when starting a "
#~ "simulation."
#~ msgstr ""

#~ msgid "Now, you are ready to start your workload."
#~ msgstr ""

#~ msgid ""
#~ "Shortly after the simulation starts, you"
#~ " should see the following logs in "
#~ "your terminal:"
#~ msgstr ""

#~ msgid "You can look at everything at http://127.0.0.1:8265 ."
#~ msgstr ""

#~ msgid ""
#~ "It's a Ray Dashboard. You can "
#~ "navigate to Metrics (on the left "
#~ "panel, the lowest option)."
#~ msgstr ""

#~ msgid ""
#~ "Or alternatively, you can just see "
#~ "them in Grafana by clicking on the"
#~ " right-up corner, “View in Grafana”."
#~ " Please note that the Ray dashboard"
#~ " is only accessible during the "
#~ "simulation. After the simulation ends, "
#~ "you can only use Grafana to "
#~ "explore the metrics. You can start "
#~ "Grafana by going to "
#~ "``http://localhost:3000/``."
#~ msgstr ""

#~ msgid ""
#~ "After you finish the visualization, stop"
#~ " Prometheus and Grafana. This is "
#~ "important as they will otherwise block,"
#~ " for example port ``3000`` on your"
#~ " machine as long as they are "
#~ "running."
#~ msgstr ""

#~ msgid "Resource allocation"
#~ msgstr ""

#~ msgid ""
#~ "You must understand how the Ray "
#~ "library works to efficiently allocate "
#~ "system resources to simulation clients "
#~ "on your own."
#~ msgstr ""

#~ msgid ""
#~ "Initially, the simulation (which Ray "
#~ "handles under the hood) starts by "
#~ "default with all the available resources"
#~ " on the system, which it shares "
#~ "among the clients. It doesn't mean "
#~ "it divides it equally among all of"
#~ " them, nor that the model training"
#~ " happens at all of them "
#~ "simultaneously. You will learn more "
#~ "about that in the later part of"
#~ " this blog. You can check the "
#~ "system resources by running the "
#~ "following:"
#~ msgstr ""

#~ msgid "In Google Colab, the result you see might be similar to this:"
#~ msgstr ""

#~ msgid ""
#~ "However, you can overwrite the defaults."
#~ " When starting a simulation, do the"
#~ " following (you don't need to "
#~ "overwrite all of them):"
#~ msgstr ""

#~ msgid "Let’s also specify the resource for a single client."
#~ msgstr ""

#~ msgid ""
#~ "Now comes the crucial part. Ray "
#~ "will start a new client only when"
#~ " it has all the required resources"
#~ " (such that they run in parallel) "
#~ "when the resources allow."
#~ msgstr ""

#~ msgid ""
#~ "In the example above, only one "
#~ "client will be run, so your "
#~ "clients won't run concurrently. Setting "
#~ "``client_num_gpus = 0.5`` would allow "
#~ "running two clients and therefore enable"
#~ " them to run concurrently. Be careful"
#~ " not to require more resources than"
#~ " available. If you specified "
#~ "``client_num_gpus = 2``, the simulation "
#~ "wouldn't start (even if you had 2"
#~ " GPUs but decided to set 1 in"
#~ " ``ray_init_args``)."
#~ msgstr ""

#~ msgid "Q: I don't see any metrics logged."
#~ msgstr ""

#~ msgid ""
#~ "A: The timeframe might not be "
#~ "properly set. The setting is in "
#~ "the top right corner (\"Last 30 "
#~ "minutes\" by default). Please change the"
#~ " timeframe to reflect the period when"
#~ " the simulation was running."
#~ msgstr ""

#~ msgid ""
#~ "Q: I see “Grafana server not "
#~ "detected. Please make sure the Grafana"
#~ " server is running and refresh this"
#~ " page” after going to the Metrics "
#~ "tab in Ray Dashboard."
#~ msgstr ""

#~ msgid ""
#~ "A: You probably don't have Grafana "
#~ "running. Please check the running "
#~ "services"
#~ msgstr ""

#~ msgid ""
#~ "Q: I see \"This site can't be "
#~ "reached\" when going to http://127.0.0.1:8265."
#~ msgstr ""

#~ msgid ""
#~ "A: Either the simulation has already "
#~ "finished, or you still need to "
#~ "start Prometheus."
#~ msgstr ""

#~ msgid "Resources"
#~ msgstr ""

#~ msgid ""
#~ "Ray Dashboard: https://docs.ray.io/en/latest/ray-"
#~ "observability/getting-started.html"
#~ msgstr ""

#~ msgid "Ray Metrics: https://docs.ray.io/en/latest/cluster/metrics.html"
#~ msgstr ""

#~ msgid ""
#~ "Simulating Federated Learning workloads is "
#~ "useful for a multitude of use-"
#~ "cases: you might want to run your"
#~ " workload on a large cohort of "
#~ "clients but without having to source,"
#~ " configure and mange a large number"
#~ " of physical devices; you might want"
#~ " to run your FL workloads as "
#~ "fast as possible on the compute "
#~ "systems you have access to without "
#~ "having to go through a complex "
#~ "setup process; you might want to "
#~ "validate your algorithm on different "
#~ "scenarios at varying levels of data "
#~ "and system heterogeneity, client availability,"
#~ " privacy budgets, etc. These are "
#~ "among some of the use-cases where"
#~ " simulating FL workloads makes sense. "
#~ "Flower can accommodate these scenarios "
#~ "by means of its `VirtualClientEngine "
#~ "<contributor-explanation-architecture.html#virtual-"
#~ "client-engine>`_ or VCE."
#~ msgstr ""

#~ msgid ""
#~ "The ``VirtualClientEngine`` schedules, launches "
#~ "and manages `virtual` clients. These "
#~ "clients are identical to `non-virtual`"
#~ " clients (i.e. the ones you launch"
#~ " via the command `flwr.client.start_client "
#~ "<ref-api-flwr.html#start-client>`_) in the"
#~ " sense that they can be configure "
#~ "by creating a class inheriting, for "
#~ "example, from `flwr.client.NumPyClient <ref-"
#~ "api-flwr.html#flwr.client.NumPyClient>`_ and therefore"
#~ " behave in an identical way. In "
#~ "addition to that, clients managed by "
#~ "the ``VirtualClientEngine`` are:"
#~ msgstr ""

#~ msgid ""
#~ "resource-aware: this means that each "
#~ "client gets assigned a portion of "
#~ "the compute and memory on your "
#~ "system. You as a user can control"
#~ " this at the beginning of the "
#~ "simulation and allows you to control "
#~ "the degree of parallelism of your "
#~ "Flower FL simulation. The fewer the "
#~ "resources per client, the more clients"
#~ " can run concurrently on the same "
#~ "hardware."
#~ msgstr ""

#~ msgid ""
#~ "self-managed: this means that you "
#~ "as a user do not need to "
#~ "launch clients manually, instead this "
#~ "gets delegated to ``VirtualClientEngine``'s "
#~ "internals."
#~ msgstr ""

#~ msgid ""
#~ "ephemeral: this means that a client "
#~ "is only materialized when it is "
#~ "required in the FL process (e.g. "
#~ "to do `fit() <ref-api-"
#~ "flwr.html#flwr.client.Client.fit>`_). The object is"
#~ " destroyed afterwards, releasing the "
#~ "resources it was assigned and allowing"
#~ " in this way other clients to "
#~ "participate."
#~ msgstr ""

#~ msgid ""
#~ "The ``VirtualClientEngine`` implements `virtual` "
#~ "clients using `Ray <https://www.ray.io/>`_, an"
#~ " open-source framework for scalable "
#~ "Python workloads. In particular, Flower's "
#~ "``VirtualClientEngine`` makes use of `Actors"
#~ " <https://docs.ray.io/en/latest/ray-core/actors.html>`_ "
#~ "to spawn `virtual` clients and run "
#~ "their workload."
#~ msgstr ""

#~ msgid ""
#~ "Running Flower simulations still require "
#~ "you to define your client class, a"
#~ " strategy, and utility functions to "
#~ "download and load (and potentially "
#~ "partition) your dataset. With that out"
#~ " of the way, launching your "
#~ "simulation is done with `start_simulation "
#~ "<ref-api-flwr.html#flwr.simulation.start_simulation>`_ "
#~ "and a minimal example looks as "
#~ "follows:"
#~ msgstr ""

#~ msgid "VirtualClientEngine resources"
#~ msgstr ""

#~ msgid ""
#~ "By default the VCE has access to"
#~ " all system resources (i.e. all CPUs,"
#~ " all GPUs, etc) since that is "
#~ "also the default behavior when starting"
#~ " Ray. However, in some settings you"
#~ " might want to limit how many "
#~ "of your system resources are used "
#~ "for simulation. You can do this "
#~ "via the ``ray_init_args`` input argument "
#~ "to ``start_simulation`` which the VCE "
#~ "internally passes to Ray's ``ray.init`` "
#~ "command. For a complete list of "
#~ "settings you can configure check the "
#~ "`ray.init <https://docs.ray.io/en/latest/ray-"
#~ "core/api/doc/ray.init.html#ray-init>`_ documentation. "
#~ "Do not set ``ray_init_args`` if you "
#~ "want the VCE to use all your "
#~ "system's CPUs and GPUs."
#~ msgstr ""

#~ msgid "Assigning client resources"
#~ msgstr ""

#~ msgid ""
#~ "By default the ``VirtualClientEngine`` assigns"
#~ " a single CPU core (and nothing "
#~ "else) to each virtual client. This "
#~ "means that if your system has 10"
#~ " cores, that many virtual clients can"
#~ " be concurrently running."
#~ msgstr ""

#~ msgid ""
#~ "More often than not, you would "
#~ "probably like to adjust the resources"
#~ " your clients get assigned based on"
#~ " the complexity (i.e. compute and "
#~ "memory footprint) of your FL workload."
#~ " You can do so when starting "
#~ "your simulation by setting the argument"
#~ " `client_resources` to `start_simulation <ref-"
#~ "api-flwr.html#flwr.simulation.start_simulation>`_. Two "
#~ "keys are internally used by Ray to"
#~ " schedule and spawn workloads (in our"
#~ " case Flower clients):"
#~ msgstr ""

#~ msgid "``num_cpus`` indicates the number of CPU cores a client would get."
#~ msgstr ""

#~ msgid ""
#~ "``num_gpus`` indicates the **ratio** of "
#~ "GPU memory a client gets assigned."
#~ msgstr ""

#~ msgid "Let's see a few examples:"
#~ msgstr ""

#~ msgid ""
#~ "While the ``client_resources`` can be "
#~ "used to control the degree of "
#~ "concurrency in your FL simulation, this"
#~ " does not stop you from running "
#~ "dozens, hundreds or even thousands of"
#~ " clients in the same round and "
#~ "having orders of magnitude more "
#~ "`dormant` (i.e. not participating in a"
#~ " round) clients. Let's say you want"
#~ " to have 100 clients per round "
#~ "but your system can only accommodate "
#~ "8 clients concurrently. The "
#~ "``VirtualClientEngine`` will schedule 100 jobs"
#~ " to run (each simulating a client "
#~ "sampled by the strategy) and then "
#~ "will execute them in a resource-"
#~ "aware manner in batches of 8."
#~ msgstr ""

#~ msgid ""
#~ "To understand all the intricate details"
#~ " on how resources are used to "
#~ "schedule FL clients and how to "
#~ "define custom resources, please take a"
#~ " look at the `Ray documentation "
#~ "<https://docs.ray.io/en/latest/ray-"
#~ "core/scheduling/resources.html>`_."
#~ msgstr ""

#~ msgid ""
#~ "A few ready-to-run complete "
#~ "examples for Flower simulation in "
#~ "Tensorflow/Keras and PyTorch are provided "
#~ "in the `Flower repository "
#~ "<https://github.com/adap/flower>`_. You can run "
#~ "them on Google Colab too:"
#~ msgstr ""

#~ msgid ""
#~ "`Tensorflow/Keras Simulation "
#~ "<https://github.com/adap/flower/tree/main/examples/simulation-"
#~ "tensorflow>`_: 100 clients collaboratively "
#~ "train a MLP model on MNIST."
#~ msgstr ""

#~ msgid ""
#~ "`PyTorch Simulation "
#~ "<https://github.com/adap/flower/tree/main/examples/simulation-"
#~ "pytorch>`_: 100 clients collaboratively train"
#~ " a CNN model on MNIST."
#~ msgstr ""

#~ msgid ""
#~ "Flower's ``VirtualClientEngine`` allows you to"
#~ " run FL simulations across multiple "
#~ "compute nodes. Before starting your "
#~ "multi-node simulation ensure that you:"
#~ msgstr ""

#~ msgid "Have the same Python environment in all nodes."
#~ msgstr ""

#~ msgid "Have a copy of your code (e.g. your entire repo) in all nodes."
#~ msgstr ""

#~ msgid ""
#~ "Have a copy of your dataset in "
#~ "all nodes (more about this in "
#~ ":ref:`simulation considerations <considerations-"
#~ "for-simulations>`)"
#~ msgstr ""

#~ msgid ""
#~ "Pass ``ray_init_args={\"address\"=\"auto\"}`` to "
#~ "`start_simulation <ref-api-"
#~ "flwr.html#flwr.simulation.start_simulation>`_ so the "
#~ "``VirtualClientEngine`` attaches to a running"
#~ " Ray instance."
#~ msgstr ""

#~ msgid ""
#~ "Start Ray on you head node: on "
#~ "the terminal type ``ray start --head``."
#~ " This command will print a few "
#~ "lines, one of which indicates how "
#~ "to attach other nodes to the head"
#~ " node."
#~ msgstr ""

#~ msgid ""
#~ "Attach other nodes to the head "
#~ "node: copy the command shown after "
#~ "starting the head and execute it "
#~ "on terminal of a new node: for "
#~ "example ``ray start --address='192.168.1.132:6379'``"
#~ msgstr ""

#~ msgid ""
#~ "With all the above done, you can"
#~ " run your code from the head "
#~ "node as you would if the "
#~ "simulation was running on a single "
#~ "node."
#~ msgstr ""

#~ msgid ""
#~ "Once your simulation is finished, if "
#~ "you'd like to dismantle your cluster "
#~ "you simply need to run the command"
#~ " ``ray stop`` in each node's terminal"
#~ " (including the head node)."
#~ msgstr ""

#~ msgid "Multi-node simulation good-to-know"
#~ msgstr ""

#~ msgid ""
#~ "Here we list a few interesting "
#~ "functionality when running multi-node FL"
#~ " simulations:"
#~ msgstr ""

#~ msgid ""
#~ "User ``ray status`` to check all "
#~ "nodes connected to your head node "
#~ "as well as the total resources "
#~ "available to the ``VirtualClientEngine``."
#~ msgstr ""

#~ msgid ""
#~ "When attaching a new node to the"
#~ " head, all its resources (i.e. all"
#~ " CPUs, all GPUs) will be visible "
#~ "by the head node. This means that"
#~ " the ``VirtualClientEngine`` can schedule "
#~ "as many `virtual` clients as that "
#~ "node can possible run. In some "
#~ "settings you might want to exclude "
#~ "certain resources from the simulation. "
#~ "You can do this by appending "
#~ "`--num-cpus=<NUM_CPUS_FROM_NODE>` and/or `--num-"
#~ "gpus=<NUM_GPUS_FROM_NODE>` in any ``ray "
#~ "start`` command (including when starting "
#~ "the head)"
#~ msgstr ""

#~ msgid "Considerations for simulations"
#~ msgstr ""

#~ msgid ""
#~ "We are actively working on these "
#~ "fronts so to make it trivial to"
#~ " run any FL workload with Flower "
#~ "simulation."
#~ msgstr ""

#~ msgid ""
#~ "The current VCE allows you to run"
#~ " Federated Learning workloads in simulation"
#~ " mode whether you are prototyping "
#~ "simple scenarios on your personal laptop"
#~ " or you want to train a complex"
#~ " FL pipeline across multiple high-"
#~ "performance GPU nodes. While we add "
#~ "more capabilities to the VCE, the "
#~ "points below highlight some of the "
#~ "considerations to keep in mind when "
#~ "designing your FL pipeline with Flower."
#~ " We also highlight a couple of "
#~ "current limitations in our implementation."
#~ msgstr ""

#~ msgid "GPU resources"
#~ msgstr ""

#~ msgid ""
#~ "The VCE assigns a share of GPU "
#~ "memory to a client that specifies "
#~ "the key ``num_gpus`` in ``client_resources``."
#~ " This being said, Ray (used "
#~ "internally by the VCE) is by "
#~ "default:"
#~ msgstr ""

#~ msgid ""
#~ "not aware of the total VRAM "
#~ "available on the GPUs. This means "
#~ "that if you set ``num_gpus=0.5`` and "
#~ "you have two GPUs in your system"
#~ " with different (e.g. 32GB and 8GB)"
#~ " VRAM amounts, they both would run"
#~ " 2 clients concurrently."
#~ msgstr ""

#~ msgid ""
#~ "not aware of other unrelated (i.e. "
#~ "not created by the VCE) workloads "
#~ "are running on the GPU. Two "
#~ "takeaways from this are:"
#~ msgstr ""

#~ msgid ""
#~ "Your Flower server might need a "
#~ "GPU to evaluate the `global model` "
#~ "after aggregation (by instance when "
#~ "making use of the `evaluate method "
#~ "<how-to-implement-strategies.html#the-"
#~ "evaluate-method>`_)"
#~ msgstr ""

#~ msgid ""
#~ "If you want to run several "
#~ "independent Flower simulations on the "
#~ "same machine you need to mask-out"
#~ " your GPUs with "
#~ "``CUDA_VISIBLE_DEVICES=\"<GPU_IDs>\"`` when launching "
#~ "your experiment."
#~ msgstr ""

#~ msgid ""
#~ "In addition, the GPU resource limits "
#~ "passed to ``client_resources`` are not "
#~ "`enforced` (i.e. they can be exceeded)"
#~ " which can result in the situation"
#~ " of client using more VRAM than "
#~ "the ratio specified when starting the"
#~ " simulation."
#~ msgstr ""

#~ msgid "TensorFlow with GPUs"
#~ msgstr ""

#~ msgid ""
#~ "When `using a GPU with TensorFlow "
#~ "<https://www.tensorflow.org/guide/gpu>`_ nearly your "
#~ "entire GPU memory of all your GPUs"
#~ " visible to the process will be "
#~ "mapped. This is done by TensorFlow "
#~ "for optimization purposes. However, in "
#~ "settings such as FL simulations where"
#~ " we want to split the GPU into"
#~ " multiple `virtual` clients, this is "
#~ "not a desirable mechanism. Luckily we"
#~ " can disable this default behavior by"
#~ " `enabling memory growth "
#~ "<https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth>`_."
#~ msgstr ""

#~ msgid ""
#~ "This would need to be done in "
#~ "the main process (which is where "
#~ "the server would run) and in each"
#~ " Actor created by the VCE. By "
#~ "means of ``actor_kwargs`` we can pass"
#~ " the reserved key `\"on_actor_init_fn\"` in"
#~ " order to specify a function to "
#~ "be executed upon actor initialization. "
#~ "In this case, to enable GPU growth"
#~ " for TF workloads. It would look "
#~ "as follows:"
#~ msgstr ""

#~ msgid ""
#~ "This is precisely the mechanism used "
#~ "in `Tensorflow/Keras Simulation "
#~ "<https://github.com/adap/flower/tree/main/examples/simulation-"
#~ "tensorflow>`_ example."
#~ msgstr ""

#~ msgid "Multi-node setups"
#~ msgstr ""

#~ msgid ""
#~ "The VCE does not currently offer a"
#~ " way to control on which node a"
#~ " particular `virtual` client is executed."
#~ " In other words, if more than a"
#~ " single node have the resources "
#~ "needed by a client to run, then"
#~ " any of those nodes could get "
#~ "the client workload scheduled onto. "
#~ "Later in the FL process (i.e. in"
#~ " a different round) the same client"
#~ " could be executed by a different "
#~ "node. Depending on how your clients "
#~ "access their datasets, this might "
#~ "require either having a copy of "
#~ "all dataset partitions on all nodes "
#~ "or a dataset serving mechanism (e.g. "
#~ "using nfs, a database) to circumvent "
#~ "data duplication."
#~ msgstr ""

#~ msgid ""
#~ "By definition virtual clients are "
#~ "`stateless` due to their ephemeral "
#~ "nature. A client state can be "
#~ "implemented as part of the Flower "
#~ "client class but users need to "
#~ "ensure this saved to persistent storage"
#~ " (e.g. a database, disk) and that "
#~ "can be retrieve later by the same"
#~ " client regardless on which node it"
#~ " is running from. This is related "
#~ "to the point above also since, in"
#~ " some way, the client's dataset could"
#~ " be seen as a type of `state`."
#~ msgstr ""

#~ msgid "Save and load model checkpoints"
#~ msgstr ""

#~ msgid "Model checkpointing"
#~ msgstr ""

#~ msgid "Save and load PyTorch checkpoints"
#~ msgstr ""

#~ msgid ""
#~ "For ensuring data instance-level privacy"
#~ " during local model training on the"
#~ " client side, consider leveraging privacy"
#~ " engines such as Opacus and "
#~ "TensorFlow Privacy. For examples of "
#~ "using Flower with these engines, please"
#~ " refer to the Flower examples "
#~ "directory (`Opacus "
#~ "<https://github.com/adap/flower/tree/main/examples/opacus>`_, "
#~ "`Tensorflow Privacy "
#~ "<https://github.com/adap/flower/tree/main/examples/dp-sgd-"
#~ "mnist>`_)."
#~ msgstr ""

#~ msgid ""
#~ "Flower comes with a number of "
#~ "popular federated learning strategies "
#~ "built-in. A built-in strategy can "
#~ "be instantiated as follows:"
#~ msgstr ""

#~ msgid ""
#~ "This creates a strategy with all "
#~ "parameters left at their default values"
#~ " and passes it to the "
#~ "``start_server`` function. It is usually "
#~ "recommended to adjust a few parameters"
#~ " during instantiation:"
#~ msgstr ""

#~ msgid ""
#~ "Existing strategies provide several ways "
#~ "to customize their behaviour. Callback "
#~ "functions allow strategies to call "
#~ "user-provided code during execution."
#~ msgstr ""

#~ msgid ""
#~ "The server can pass new configuration"
#~ " values to the client each round "
#~ "by providing a function to "
#~ "``on_fit_config_fn``. The provided function "
#~ "will be called by the strategy and"
#~ " must return a dictionary of "
#~ "configuration key values pairs that will"
#~ " be sent to the client. It must"
#~ " return a dictionary of arbitrary "
#~ "configuration values ``client.fit`` and "
#~ "``client.evaluate`` functions during each "
#~ "round of federated learning."
#~ msgstr ""

#~ msgid ""
#~ "The ``on_fit_config_fn`` can be used to"
#~ " pass arbitrary configuration values from"
#~ " server to client, and potentially "
#~ "change these values each round, for "
#~ "example, to adjust the learning rate."
#~ " The client will receive the "
#~ "dictionary returned by the "
#~ "``on_fit_config_fn`` in its own "
#~ "``client.fit()`` function."
#~ msgstr ""

#~ msgid "Legacy example guides"
#~ msgstr ""

#~ msgid ""
#~ "Welcome to Flower's documentation. `Flower "
#~ "<https://flower.ai>`_ is a friendly federated"
#~ " AI framework."
#~ msgstr ""

#~ msgid "flwr CLI"
#~ msgstr ""

#~ msgid "flwr is the Flower command line interface."
#~ msgstr ""

#~ msgid "Options"
#~ msgstr ""

#~ msgid "Install completion for the current shell."
#~ msgstr ""

#~ msgid ""
#~ "Show completion for the current shell,"
#~ " to copy it or customize the "
#~ "installation."
#~ msgstr ""

#~ msgid "Build a Flower App into a Flower App Bundle (FAB)."
#~ msgstr ""

#~ msgid ""
#~ "You can run ``flwr build`` without "
#~ "any arguments to bundle the app "
#~ "located in the current directory. "
#~ "Alternatively, you can you can specify"
#~ " a path using the ``--app`` option"
#~ " to bundle an app located at "
#~ "the provided path. For example:"
#~ msgstr ""

#~ msgid "``flwr build --app ./apps/flower-hello-world``."
#~ msgstr ""

#~ msgid "Path of the Flower App to bundle into a FAB"
#~ msgstr ""

#~ msgid "Install a Flower App Bundle."
#~ msgstr ""

#~ msgid "It can be ran with a single FAB file argument:"
#~ msgstr ""

#~ msgid "``flwr install ./target_project.fab``"
#~ msgstr ""

#~ msgid "The target install directory can be specified with ``--flwr-dir``:"
#~ msgstr ""

#~ msgid "``flwr install ./target_project.fab --flwr-dir ./docs/flwr``"
#~ msgstr ""

#~ msgid ""
#~ "This will install ``target_project`` to "
#~ "``./docs/flwr/``. By default, ``flwr-dir`` "
#~ "is equal to:"
#~ msgstr ""

#~ msgid "``$FLWR_HOME/`` if ``$FLWR_HOME`` is defined"
#~ msgstr ""

#~ msgid "``$XDG_DATA_HOME/.flwr/`` if ``$XDG_DATA_HOME`` is defined"
#~ msgstr ""

#~ msgid "``$HOME/.flwr/`` in all other cases"
#~ msgstr ""

#~ msgid "The desired install path."
#~ msgstr ""

#~ msgid "Optional argument"
#~ msgstr "Argumento de compilação"

#~ msgid "The source FAB file to install."
#~ msgstr ""

#~ msgid "Get logs from a Flower project run."
#~ msgstr ""

#~ msgid "Flag to stream or print logs from the Flower run"
#~ msgstr ""

#~ msgid "default"
#~ msgstr ""

#~ msgid "``True``"
#~ msgstr ""

#~ msgid "Required argument"
#~ msgstr "Argumento de compilação"

#~ msgid "The Flower run ID to query"
#~ msgstr ""

#~ msgid "Path of the Flower project to run"
#~ msgstr ""

#~ msgid "Name of the federation to run the app on"
#~ msgstr ""

#~ msgid "Create new Flower App."
#~ msgstr ""

#~ msgid "The ML framework to use"
#~ msgstr ""

#~ msgid "options"
#~ msgstr ""

#~ msgid ""
#~ "PyTorch | TensorFlow | sklearn | "
#~ "HuggingFace | JAX | MLX | NumPy"
#~ " | FlowerTune | Flower Baseline"
#~ msgstr ""

#~ msgid "The Flower username of the author"
#~ msgstr ""

#~ msgid "The name of the Flower App"
#~ msgstr "O nome do repositório da imagem base."

#~ msgid "Run Flower App."
#~ msgstr ""

#~ msgid "Override configuration key-value pairs, should be of the format:"
#~ msgstr ""

#~ msgid ""
#~ "`--run-config 'key1=\"value1\" key2=\"value2\"' "
#~ "--run-config 'key3=\"value3\"'`"
#~ msgstr ""

#~ msgid ""
#~ "Note that `key1`, `key2`, and `key3` "
#~ "in this example need to exist "
#~ "inside the `pyproject.toml` in order to"
#~ " be properly overriden."
#~ msgstr ""

#~ msgid ""
#~ "Use `--stream` with `flwr run` to "
#~ "display logs; logs are not streamed "
#~ "by default."
#~ msgstr ""

#~ msgid "``False``"
#~ msgstr "``FLWR_VERSION``"

#~ msgid "Path of the Flower App to run."
#~ msgstr "O nome do repositório da imagem base."

#~ msgid "Name of the federation to run the app on."
#~ msgstr ""

#~ msgid "flower-simulation"
#~ msgstr ""

#~ msgid "flower-superlink"
#~ msgstr ""

#~ msgid "flower-supernode"
#~ msgstr ""

#~ msgid "flower-server-app"
#~ msgstr ""

#~ msgid ""
#~ "Note that since version ``1.11.0``, "
#~ "``flower-server-app`` no longer supports"
#~ " passing a reference to a `ServerApp`"
#~ " attribute. Instead, you need to pass"
#~ " the path to Flower app via the"
#~ " argument ``--app``. This is the path"
#~ " to a directory containing a "
#~ "`pyproject.toml`. You can create a valid"
#~ " Flower app by executing ``flwr new``"
#~ " and following the prompt."
#~ msgstr ""

#~ msgid "flower-superexec"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`Context <flwr.common.Context>`\\ \\(node\\_id\\,"
#~ " node\\_config\\, state\\, run\\_config\\)"
#~ msgstr ""

#~ msgid ""
#~ "Holds records added by the entity "
#~ "in a given run and that will "
#~ "stay local. This means that the "
#~ "data it holds will never leave the"
#~ " system it's running from. This can"
#~ " be used as an intermediate storage"
#~ " or scratchpad when executing mods. "
#~ "It can also be used as a "
#~ "memory to access at different points "
#~ "during the lifecycle of this entity "
#~ "(e.g. across multiple rounds)"
#~ msgstr ""

#~ msgid ""
#~ "A config (key/value mapping) held by "
#~ "the entity in a given run and "
#~ "that will stay local. It can be"
#~ " used at any point during the "
#~ "lifecycle of this entity (e.g. across"
#~ " multiple rounds)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`RUN_SUPEREXEC_ENTER "
#~ "<flwr.common.EventType.RUN_SUPEREXEC_ENTER>`\\"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`RUN_SUPEREXEC_LEAVE "
#~ "<flwr.common.EventType.RUN_SUPEREXEC_LEAVE>`\\"
#~ msgstr ""

#~ msgid "Abstract base Driver class for the Driver API."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`start_simulation <flwr.simulation.start_simulation>`\\"
#~ " \\(\\*args\\, \\*\\*kwargs\\)"
#~ msgstr ""

#~ msgid "Log error stating that module `ray` could not be imported."
#~ msgstr ""

#~ msgid ""
#~ "This tutorial will show you how to"
#~ " use Flower to build a federated "
#~ "version of an existing JAX workload. "
#~ "We are using JAX to train a "
#~ "linear regression model on a scikit-"
#~ "learn dataset. We will structure the "
#~ "example similar to our `PyTorch - "
#~ "From Centralized To Federated "
#~ "<https://github.com/adap/flower/blob/main/examples/pytorch-"
#~ "from-centralized-to-federated>`_ walkthrough. "
#~ "First, we build a centralized training"
#~ " approach based on the `Linear "
#~ "Regression with JAX "
#~ "<https://coax.readthedocs.io/en/latest/examples/linear_regression/jax.html>`_"
#~ " tutorial`. Then, we build upon the"
#~ " centralized training code to run the"
#~ " training in a federated fashion."
#~ msgstr ""

#~ msgid ""
#~ "Before we start building our JAX "
#~ "example, we need install the packages"
#~ " ``jax``, ``jaxlib``, ``scikit-learn``, and"
#~ " ``flwr``:"
#~ msgstr ""

#~ msgid "Linear Regression with JAX"
#~ msgstr ""

#~ msgid ""
#~ "We begin with a brief description "
#~ "of the centralized training code based"
#~ " on a ``Linear Regression`` model. If"
#~ " you want a more in-depth "
#~ "explanation of what's going on then "
#~ "have a look at the official `JAX"
#~ " documentation <https://jax.readthedocs.io/>`_."
#~ msgstr ""

#~ msgid ""
#~ "Let's create a new file called "
#~ "``jax_training.py`` with all the components"
#~ " required for a traditional (centralized)"
#~ " linear regression training. First, the "
#~ "JAX packages ``jax`` and ``jaxlib`` need"
#~ " to be imported. In addition, we "
#~ "need to import ``sklearn`` since we "
#~ "use ``make_regression`` for the dataset "
#~ "and ``train_test_split`` to split the "
#~ "dataset into a training and test "
#~ "set. You can see that we do "
#~ "not yet import the ``flwr`` package "
#~ "for federated learning. This will be "
#~ "done later."
#~ msgstr ""

#~ msgid ""
#~ "The ``load_data()`` function loads the "
#~ "mentioned training and test sets."
#~ msgstr ""

#~ msgid ""
#~ "The model architecture (a very simple"
#~ " ``Linear Regression`` model) is defined"
#~ " in ``load_model()``."
#~ msgstr ""

#~ msgid ""
#~ "We now need to define the training"
#~ " (function ``train()``), which loops over"
#~ " the training set and measures the"
#~ " loss (function ``loss_fn()``) for each "
#~ "batch of training examples. The loss "
#~ "function is separate since JAX takes "
#~ "derivatives with a ``grad()`` function "
#~ "(defined in the ``main()`` function and"
#~ " called in ``train()``)."
#~ msgstr ""

#~ msgid ""
#~ "The evaluation of the model is "
#~ "defined in the function ``evaluation()``. "
#~ "The function takes all test examples "
#~ "and measures the loss of the "
#~ "linear regression model."
#~ msgstr ""

#~ msgid ""
#~ "Having defined the data loading, model"
#~ " architecture, training, and evaluation we"
#~ " can put everything together and "
#~ "train our model using JAX. As "
#~ "already mentioned, the ``jax.grad()`` function"
#~ " is defined in ``main()`` and passed"
#~ " to ``train()``."
#~ msgstr ""

#~ msgid "You can now run your (centralized) JAX linear regression workload:"
#~ msgstr ""

#~ msgid ""
#~ "So far this should all look fairly"
#~ " familiar if you've used JAX before."
#~ " Let's take the next step and "
#~ "use what we've built to create a"
#~ " simple federated learning system "
#~ "consisting of one server and two "
#~ "clients."
#~ msgstr ""

#~ msgid "JAX meets Flower"
#~ msgstr ""

#~ msgid ""
#~ "The concept of federating an existing"
#~ " workload is always the same and "
#~ "easy to understand. We have to "
#~ "start a *server* and then use the"
#~ " code in ``jax_training.py`` for the "
#~ "*clients* that are connected to the "
#~ "*server*. The *server* sends model "
#~ "parameters to the clients. The *clients*"
#~ " run the training and update the "
#~ "parameters. The updated parameters are "
#~ "sent back to the *server*, which "
#~ "averages all received parameter updates. "
#~ "This describes one round of the "
#~ "federated learning process, and we "
#~ "repeat this for multiple rounds."
#~ msgstr ""

#~ msgid ""
#~ "Finally, we will define our *client* "
#~ "logic in ``client.py`` and build upon"
#~ " the previously defined JAX training "
#~ "in ``jax_training.py``. Our *client* needs "
#~ "to import ``flwr``, but also ``jax`` "
#~ "and ``jaxlib`` to update the parameters"
#~ " on our JAX model:"
#~ msgstr ""

#~ msgid ""
#~ "Implementing a Flower *client* basically "
#~ "means implementing a subclass of either"
#~ " ``flwr.client.Client`` or ``flwr.client.NumPyClient``."
#~ " Our implementation will be based on"
#~ " ``flwr.client.NumPyClient`` and we'll call "
#~ "it ``FlowerClient``. ``NumPyClient`` is "
#~ "slightly easier to implement than "
#~ "``Client`` if you use a framework "
#~ "with good NumPy interoperability (like "
#~ "JAX) because it avoids some of the"
#~ " boilerplate that would otherwise be "
#~ "necessary. ``FlowerClient`` needs to implement"
#~ " four methods, two methods for "
#~ "getting/setting model parameters, one method"
#~ " for training the model, and one "
#~ "method for testing the model:"
#~ msgstr ""

#~ msgid "``set_parameters (optional)``"
#~ msgstr ""

#~ msgid "transform parameters to NumPy ``ndarray``'s"
#~ msgstr ""

#~ msgid "get the updated local model parameters and return them to the server"
#~ msgstr ""

#~ msgid "return the local loss to the server"
#~ msgstr ""

#~ msgid ""
#~ "The challenging part is to transform "
#~ "the JAX model parameters from "
#~ "``DeviceArray`` to ``NumPy ndarray`` to "
#~ "make them compatible with `NumPyClient`."
#~ msgstr ""

#~ msgid ""
#~ "The two ``NumPyClient`` methods ``fit`` "
#~ "and ``evaluate`` make use of the "
#~ "functions ``train()`` and ``evaluate()`` "
#~ "previously defined in ``jax_training.py``. So"
#~ " what we really do here is we"
#~ " tell Flower through our ``NumPyClient``"
#~ " subclass which of our already "
#~ "defined functions to call for training"
#~ " and evaluation. We included type "
#~ "annotations to give you a better "
#~ "understanding of the data types that "
#~ "get passed around."
#~ msgstr ""

#~ msgid "Having defined the federation process, we can run it."
#~ msgstr ""

#~ msgid ""
#~ "in each window (make sure that the"
#~ " server is still running before you"
#~ " do so) and see your JAX "
#~ "project run federated learning across "
#~ "two clients. Congratulations!"
#~ msgstr ""

#~ msgid ""
#~ "The source code of this example "
#~ "was improved over time and can be"
#~ " found here: `Quickstart JAX "
#~ "<https://github.com/adap/flower/blob/main/examples/quickstart-"
#~ "jax>`_. Our example is somewhat over-"
#~ "simplified because both clients load the"
#~ " same dataset."
#~ msgstr ""

#~ msgid ""
#~ "You're now prepared to explore this "
#~ "topic further. How about using a "
#~ "more sophisticated model or using a "
#~ "different dataset? How about adding more"
#~ " clients?"
#~ msgstr ""

#~ msgid ""
#~ "In this tutorial, we will learn "
#~ "how to train a ``Logistic Regression``"
#~ " model on MNIST using Flower and "
#~ "scikit-learn."
#~ msgstr ""

#~ msgid ""
#~ "It is recommended to create a "
#~ "virtual environment and run everything "
#~ "within this :doc:`virtualenv <contributor-"
#~ "how-to-set-up-a-virtual-env>`."
#~ msgstr ""

#~ msgid ""
#~ "Our example consists of one *server* "
#~ "and two *clients* all having the "
#~ "same model."
#~ msgstr ""

#~ msgid ""
#~ "*Clients* are responsible for generating "
#~ "individual model parameter updates for "
#~ "the model based on their local "
#~ "datasets. These updates are then sent"
#~ " to the *server* which will aggregate"
#~ " them to produce an updated global"
#~ " model. Finally, the *server* sends "
#~ "this improved version of the model "
#~ "back to each *client*. A complete "
#~ "cycle of parameters updates is called"
#~ " a *round*."
#~ msgstr ""

#~ msgid ""
#~ "Now that we have a rough idea "
#~ "of what is going on, let's get "
#~ "started. We first need to install "
#~ "Flower. You can do this by "
#~ "running:"
#~ msgstr ""

#~ msgid "Since we want to use scikit-learn, let's go ahead and install it:"
#~ msgstr ""

#~ msgid "Or simply install all dependencies using Poetry:"
#~ msgstr ""

#~ msgid ""
#~ "Now that we have all our "
#~ "dependencies installed, let's run a "
#~ "simple distributed training with two "
#~ "clients and one server. However, before"
#~ " setting up the client and server,"
#~ " we will define all functionalities "
#~ "that we need for our federated "
#~ "learning setup within ``utils.py``. The "
#~ "``utils.py`` contains different functions "
#~ "defining all the machine learning "
#~ "basics:"
#~ msgstr ""

#~ msgid "``get_model_parameters()``"
#~ msgstr ""

#~ msgid "Returns the parameters of a ``sklearn`` LogisticRegression model"
#~ msgstr ""

#~ msgid "``set_model_params()``"
#~ msgstr ""

#~ msgid "Sets the parameters of a ``sklearn`` LogisticRegression model"
#~ msgstr ""

#~ msgid "``set_initial_params()``"
#~ msgstr ""

#~ msgid "Initializes the model parameters that the Flower server will ask for"
#~ msgstr ""

#~ msgid ""
#~ "Please check out ``utils.py`` `here "
#~ "<https://github.com/adap/flower/blob/main/examples/sklearn-"
#~ "logreg-mnist/utils.py>`_ for more details. "
#~ "The pre-defined functions are used "
#~ "in the ``client.py`` and imported. The"
#~ " ``client.py`` also requires to import "
#~ "several packages such as Flower and "
#~ "scikit-learn:"
#~ msgstr ""

#~ msgid ""
#~ "Prior to local training, we need "
#~ "to load the MNIST dataset, a "
#~ "popular image classification dataset of "
#~ "handwritten digits for machine learning, "
#~ "and partition the dataset for FL. "
#~ "This can be conveniently achieved using"
#~ " `Flower Datasets <https://flower.ai/docs/datasets>`_."
#~ " The ``FederatedDataset.load_partition()`` method "
#~ "loads the partitioned training set for"
#~ " each partition ID defined in the "
#~ "``--partition-id`` argument."
#~ msgstr ""

#~ msgid ""
#~ "Next, the logistic regression model is"
#~ " defined and initialized with "
#~ "``utils.set_initial_params()``."
#~ msgstr ""

#~ msgid ""
#~ "The Flower server interacts with clients"
#~ " through an interface called ``Client``."
#~ " When the server selects a particular"
#~ " client for training, it sends "
#~ "training instructions over the network. "
#~ "The client receives those instructions "
#~ "and calls one of the ``Client`` "
#~ "methods to run your code (i.e., to"
#~ " fit the logistic regression we "
#~ "defined earlier)."
#~ msgstr ""

#~ msgid ""
#~ "Flower provides a convenience class "
#~ "called ``NumPyClient`` which makes it "
#~ "easier to implement the ``Client`` "
#~ "interface when your workload uses "
#~ "scikit-learn. Implementing ``NumPyClient`` "
#~ "usually means defining the following "
#~ "methods (``set_parameters`` is optional "
#~ "though):"
#~ msgstr ""

#~ msgid "return the model weight as a list of NumPy ndarrays"
#~ msgstr ""

#~ msgid "``set_parameters`` (optional)"
#~ msgstr ""

#~ msgid ""
#~ "update the local model weights with "
#~ "the parameters received from the server"
#~ msgstr ""

#~ msgid "is directly imported with ``utils.set_model_params()``"
#~ msgstr ""

#~ msgid "set the local model weights"
#~ msgstr ""

#~ msgid "train the local model"
#~ msgstr ""

#~ msgid "return the updated local model weights"
#~ msgstr ""

#~ msgid "test the local model"
#~ msgstr ""

#~ msgid "The methods can be implemented in the following way:"
#~ msgstr ""

#~ msgid ""
#~ "We can now create an instance of"
#~ " our class ``MnistClient`` and add "
#~ "one line to actually run this "
#~ "client:"
#~ msgstr ""

#~ msgid ""
#~ "That's it for the client. We only"
#~ " have to implement ``Client`` or "
#~ "``NumPyClient`` and call "
#~ "``fl.client.start_client()``. If you implement "
#~ "a client of type ``NumPyClient`` you'll"
#~ " need to first call its "
#~ "``to_client()`` method. The string "
#~ "``\"0.0.0.0:8080\"`` tells the client which"
#~ " server to connect to. In our "
#~ "case we can run the server and "
#~ "the client on the same machine, "
#~ "therefore we use ``\"0.0.0.0:8080\"``. If "
#~ "we run a truly federated workload "
#~ "with the server and clients running "
#~ "on different machines, all that needs"
#~ " to change is the ``server_address`` "
#~ "we pass to the client."
#~ msgstr ""

#~ msgid ""
#~ "The following Flower server is a "
#~ "little bit more advanced and returns "
#~ "an evaluation function for the "
#~ "server-side evaluation. First, we import"
#~ " again all required libraries such as"
#~ " Flower and scikit-learn."
#~ msgstr ""

#~ msgid "``server.py``, import Flower and start the server:"
#~ msgstr ""

#~ msgid ""
#~ "The number of federated learning rounds"
#~ " is set in ``fit_round()`` and the"
#~ " evaluation is defined in "
#~ "``get_evaluate_fn()``. The evaluation function "
#~ "is called after each federated learning"
#~ " round and gives you information "
#~ "about loss and accuracy. Note that "
#~ "we also make use of Flower "
#~ "Datasets here to load the test "
#~ "split of the MNIST dataset for "
#~ "server-side evaluation."
#~ msgstr ""

#~ msgid ""
#~ "The ``main`` contains the server-side"
#~ " parameter initialization "
#~ "``utils.set_initial_params()`` as well as the"
#~ " aggregation strategy ``fl.server.strategy:FedAvg()``."
#~ " The strategy is the default one, "
#~ "federated averaging (or FedAvg), with "
#~ "two clients and evaluation after each"
#~ " federated learning round. The server "
#~ "can be started with the command "
#~ "``fl.server.start_server(server_address=\"0.0.0.0:8080\", "
#~ "strategy=strategy, "
#~ "config=fl.server.ServerConfig(num_rounds=3))``."
#~ msgstr ""

#~ msgid ""
#~ "With both client and server ready, "
#~ "we can now run everything and see"
#~ " federated learning in action. Federated"
#~ " learning systems usually have a "
#~ "server and multiple clients. We, "
#~ "therefore, have to start the server "
#~ "first:"
#~ msgstr ""

#~ msgid ""
#~ "Once the server is running we can"
#~ " start the clients in different "
#~ "terminals. Open a new terminal and "
#~ "start the first client:"
#~ msgstr ""

#~ msgid "Open another terminal and start the second client:"
#~ msgstr ""

#~ msgid ""
#~ "Each client will have its own "
#~ "dataset. You should now see how "
#~ "the training does in the very "
#~ "first terminal (the one that started "
#~ "the server):"
#~ msgstr ""

#~ msgid ""
#~ "Congratulations! You've successfully built and"
#~ " run your first federated learning "
#~ "system. The full `source code "
#~ "<https://github.com/adap/flower/tree/main/examples/sklearn-"
#~ "logreg-mnist>`_ for this example can "
#~ "be found in ``examples/sklearn-logreg-"
#~ "mnist``."
#~ msgstr ""

#~ msgid "Federated XGBoost"
#~ msgstr ""

#~ msgid "Why federated XGBoost?"
#~ msgstr ""

#~ msgid ""
#~ "Indeed, as the demand for data "
#~ "privacy and decentralized learning grows, "
#~ "there's an increasing requirement to "
#~ "implement federated XGBoost systems for "
#~ "specialised applications, like survival "
#~ "analysis and financial fraud detection."
#~ msgstr ""

#~ msgid ""
#~ "Federated learning ensures that raw data"
#~ " remains on the local device, making"
#~ " it an attractive approach for "
#~ "sensitive domains where data security "
#~ "and privacy are paramount. Given the "
#~ "robustness and efficiency of XGBoost, "
#~ "combining it with federated learning "
#~ "offers a promising solution for these"
#~ " specific challenges."
#~ msgstr ""

#~ msgid ""
#~ "In this tutorial we will learn how"
#~ " to train a federated XGBoost model"
#~ " on HIGGS dataset using Flower and"
#~ " ``xgboost`` package. We use a simple"
#~ " example (`full code xgboost-quickstart "
#~ "<https://github.com/adap/flower/tree/main/examples/xgboost-"
#~ "quickstart>`_) with two *clients* and "
#~ "one *server* to demonstrate how "
#~ "federated XGBoost works, and then we "
#~ "dive into a more complex example "
#~ "(`full code xgboost-comprehensive "
#~ "<https://github.com/adap/flower/tree/main/examples/xgboost-"
#~ "comprehensive>`_) to run various experiments."
#~ msgstr ""

#~ msgid ""
#~ "First of all, it is recommended to"
#~ " create a virtual environment and run"
#~ " everything within a :doc:`virtualenv "
#~ "<contributor-how-to-set-up-a-virtual-env>`."
#~ msgstr ""

#~ msgid ""
#~ "*Clients* are responsible for generating "
#~ "individual weight-updates for the model"
#~ " based on their local datasets. Now"
#~ " that we have all our dependencies"
#~ " installed, let's run a simple "
#~ "distributed training with two clients "
#~ "and one server."
#~ msgstr ""

#~ msgid ""
#~ "In a file called ``client.py``, import"
#~ " xgboost, Flower, Flower Datasets and "
#~ "other related functions:"
#~ msgstr ""

#~ msgid "Dataset partition and hyper-parameter selection"
#~ msgstr ""

#~ msgid ""
#~ "Prior to local training, we require "
#~ "loading the HIGGS dataset from Flower"
#~ " Datasets and conduct data partitioning "
#~ "for FL:"
#~ msgstr ""

#~ msgid ""
#~ "In this example, we split the "
#~ "dataset into 30 partitions with uniform"
#~ " distribution (``IidPartitioner(num_partitions=30)``). "
#~ "Then, we load the partition for "
#~ "the given client based on "
#~ "``partition_id``:"
#~ msgstr ""

#~ msgid ""
#~ "After that, we do train/test splitting"
#~ " on the given partition (client's "
#~ "local data), and transform data format"
#~ " for ``xgboost`` package."
#~ msgstr ""

#~ msgid "Finally, we define the hyper-parameters used for XGBoost training."
#~ msgstr ""

#~ msgid ""
#~ "The ``num_local_round`` represents the number"
#~ " of iterations for local tree boost."
#~ " We use CPU for the training in"
#~ " default. One can shift it to "
#~ "GPU by setting ``tree_method`` to "
#~ "``gpu_hist``. We use AUC as evaluation"
#~ " metric."
#~ msgstr ""

#~ msgid "Flower client definition for XGBoost"
#~ msgstr ""

#~ msgid ""
#~ "After loading the dataset we define "
#~ "the Flower client. We follow the "
#~ "general rule to define ``XgbClient`` "
#~ "class inherited from ``fl.client.Client``."
#~ msgstr ""

#~ msgid ""
#~ "All required parameters defined above "
#~ "are passed to ``XgbClient``'s constructor."
#~ msgstr ""

#~ msgid ""
#~ "Then, we override ``get_parameters``, ``fit``"
#~ " and ``evaluate`` methods insides "
#~ "``XgbClient`` class as follows."
#~ msgstr ""

#~ msgid ""
#~ "Unlike neural network training, XGBoost "
#~ "trees are not started from a "
#~ "specified random weights. In this case,"
#~ " we do not use ``get_parameters`` and"
#~ " ``set_parameters`` to initialise model "
#~ "parameters for XGBoost. As a result, "
#~ "let's return an empty tensor in "
#~ "``get_parameters`` when it is called by"
#~ " the server at the first round."
#~ msgstr ""

#~ msgid ""
#~ "In ``fit``, at the first round, we"
#~ " call ``xgb.train()`` to build up the"
#~ " first set of trees. From the "
#~ "second round, we load the global "
#~ "model sent from server to new "
#~ "build Booster object, and then update"
#~ " model weights on local training data"
#~ " with function ``local_boost`` as follows:"
#~ msgstr ""

#~ msgid ""
#~ "Now, we can create an instance of"
#~ " our class ``XgbClient`` and add one"
#~ " line to actually run this client:"
#~ msgstr ""

#~ msgid ""
#~ "That's it for the client. We only"
#~ " have to implement ``Client`` and "
#~ "call ``fl.client.start_client()``. The string "
#~ "``\"[::]:8080\"`` tells the client which "
#~ "server to connect to. In our case"
#~ " we can run the server and the"
#~ " client on the same machine, "
#~ "therefore we use ``\"[::]:8080\"``. If "
#~ "we run a truly federated workload "
#~ "with the server and clients running "
#~ "on different machines, all that needs"
#~ " to change is the ``server_address`` "
#~ "we point the client at."
#~ msgstr ""

#~ msgid ""
#~ "These updates are then sent to the"
#~ " *server* which will aggregate them "
#~ "to produce a better model. Finally, "
#~ "the *server* sends this improved version"
#~ " of the model back to each "
#~ "*client* to finish a complete FL "
#~ "round."
#~ msgstr ""

#~ msgid ""
#~ "In a file named ``server.py``, import"
#~ " Flower and FedXgbBagging from "
#~ "``flwr.server.strategy``."
#~ msgstr ""

#~ msgid "We first define a strategy for XGBoost bagging aggregation."
#~ msgstr ""

#~ msgid ""
#~ "We use two clients for this "
#~ "example. An ``evaluate_metrics_aggregation`` "
#~ "function is defined to collect and "
#~ "wighted average the AUC values from "
#~ "clients. The ``config_func`` function is "
#~ "to return the current FL round "
#~ "number to client's ``fit()`` and "
#~ "``evaluate()`` methods."
#~ msgstr ""

#~ msgid "Then, we start the server:"
#~ msgstr ""

#~ msgid "Tree-based bagging aggregation"
#~ msgstr ""

#~ msgid ""
#~ "After traversal of all clients' models,"
#~ " a new global model is generated, "
#~ "followed by the serialisation, and "
#~ "sending back to each client."
#~ msgstr ""

#~ msgid ""
#~ "Congratulations! You've successfully built and"
#~ " run your first federated XGBoost "
#~ "system. The AUC values can be "
#~ "checked in ``metrics_distributed``. One can"
#~ " see that the average AUC increases"
#~ " over FL rounds."
#~ msgstr ""

#~ msgid ""
#~ "The full `source code "
#~ "<https://github.com/adap/flower/blob/main/examples/xgboost-"
#~ "quickstart/>`_ for this example can be"
#~ " found in ``examples/xgboost-quickstart``."
#~ msgstr ""

#~ msgid ""
#~ "Now that you have known how "
#~ "federated XGBoost work with Flower, it's"
#~ " time to run some more comprehensive"
#~ " experiments by customising the "
#~ "experimental settings. In the xgboost-"
#~ "comprehensive example (`full code "
#~ "<https://github.com/adap/flower/tree/main/examples/xgboost-"
#~ "comprehensive>`_), we provide more options "
#~ "to define various experimental setups, "
#~ "including aggregation strategies, data "
#~ "partitioning and centralised/distributed evaluation."
#~ " We also support :doc:`Flower simulation"
#~ " <how-to-run-simulations>` making it"
#~ " easy to simulate large client "
#~ "cohorts in a resource-aware manner. "
#~ "Let's take a look!"
#~ msgstr ""

#~ msgid "Cyclic training"
#~ msgstr ""

#~ msgid ""
#~ "To do this, we first customise a"
#~ " ``ClientManager`` in ``server_utils.py``:"
#~ msgstr ""

#~ msgid ""
#~ "The customised ``ClientManager`` samples all"
#~ " available clients in each FL round"
#~ " based on the order of connection "
#~ "to the server. Then, we define a"
#~ " new strategy ``FedXgbCyclic`` in "
#~ "``flwr.server.strategy.fedxgb_cyclic.py``, in order "
#~ "to sequentially select only one client"
#~ " in given round and pass the "
#~ "received model to next client."
#~ msgstr ""

#~ msgid "Customised data partitioning"
#~ msgstr ""

#~ msgid ""
#~ "In ``dataset.py``, we have a function"
#~ " ``instantiate_partitioner`` to instantiate the"
#~ " data partitioner based on the given"
#~ " ``num_partitions`` and ``partitioner_type``. "
#~ "Currently, we provide four supported "
#~ "partitioner type to simulate the "
#~ "uniformity/non-uniformity in data quantity "
#~ "(uniform, linear, square, exponential)."
#~ msgstr ""

#~ msgid "Customised centralised/distributed evaluation"
#~ msgstr ""

#~ msgid ""
#~ "To facilitate centralised evaluation, we "
#~ "define a function in ``server_utils.py``:"
#~ msgstr ""

#~ msgid ""
#~ "This function returns a evaluation "
#~ "function which instantiates a ``Booster`` "
#~ "object and loads the global model "
#~ "weights to it. The evaluation is "
#~ "conducted by calling ``eval_set()`` method,"
#~ " and the tested AUC value is "
#~ "reported."
#~ msgstr ""

#~ msgid ""
#~ "As for distributed evaluation on the "
#~ "clients, it's same as the quick-"
#~ "start example by overriding the "
#~ "``evaluate()`` method insides the "
#~ "``XgbClient`` class in ``client_utils.py``."
#~ msgstr ""

#~ msgid "Flower simulation"
#~ msgstr ""

#~ msgid ""
#~ "We also provide an example code "
#~ "(``sim.py``) to use the simulation "
#~ "capabilities of Flower to simulate "
#~ "federated XGBoost training on either a"
#~ " single machine or a cluster of "
#~ "machines."
#~ msgstr ""

#~ msgid ""
#~ "After importing all required packages, "
#~ "we define a ``main()`` function to "
#~ "perform the simulation process:"
#~ msgstr ""

#~ msgid ""
#~ "We first load the dataset and "
#~ "perform data partitioning, and the "
#~ "pre-processed data is stored in a "
#~ "``list``. After the simulation begins, "
#~ "the clients won't need to pre-"
#~ "process their partitions again."
#~ msgstr ""

#~ msgid "Then, we define the strategies and other hyper-parameters:"
#~ msgstr ""

#~ msgid ""
#~ "After that, we start the simulation "
#~ "by calling ``fl.simulation.start_simulation``:"
#~ msgstr ""

#~ msgid ""
#~ "One of key parameters for "
#~ "``start_simulation`` is ``client_fn`` which "
#~ "returns a function to construct a "
#~ "client. We define it as follows:"
#~ msgstr ""

#~ msgid "Arguments parser"
#~ msgstr ""

#~ msgid ""
#~ "In ``utils.py``, we define the arguments"
#~ " parsers for clients, server and "
#~ "simulation, allowing users to specify "
#~ "different experimental settings. Let's first"
#~ " see the sever side:"
#~ msgstr ""

#~ msgid ""
#~ "This allows user to specify training "
#~ "strategies / the number of total "
#~ "clients / FL rounds / participating "
#~ "clients / clients for evaluation, and"
#~ " evaluation fashion. Note that with "
#~ "``--centralised-eval``, the sever will do"
#~ " centralised evaluation and all "
#~ "functionalities for client evaluation will "
#~ "be disabled."
#~ msgstr ""

#~ msgid "Then, the argument parser on client side:"
#~ msgstr ""

#~ msgid ""
#~ "This defines various options for client"
#~ " data partitioning. Besides, clients also"
#~ " have an option to conduct evaluation"
#~ " on centralised test set by setting"
#~ " ``--centralised-eval``, as well as "
#~ "an option to perform scaled learning "
#~ "rate based on the number of "
#~ "clients by setting ``--scaled-lr``."
#~ msgstr ""

#~ msgid "We also have an argument parser for simulation:"
#~ msgstr ""

#~ msgid "This integrates all arguments for both client and server sides."
#~ msgstr ""

#~ msgid "Example commands"
#~ msgstr ""

#~ msgid ""
#~ "To run a centralised evaluated "
#~ "experiment with bagging strategy on 5"
#~ " clients with exponential distribution for"
#~ " 50 rounds, we first start the "
#~ "server as below:"
#~ msgstr ""

#~ msgid "Then, on each client terminal, we start the clients:"
#~ msgstr ""

#~ msgid "To run the same experiment with Flower simulation:"
#~ msgstr ""

#~ msgid ""
#~ "The full `code "
#~ "<https://github.com/adap/flower/blob/main/examples/xgboost-"
#~ "comprehensive/>`_ for this comprehensive "
#~ "example can be found in ``examples"
#~ "/xgboost-comprehensive``."
#~ msgstr ""

#~ msgid ""
#~ "🧑‍🏫 This tutorial starts at zero "
#~ "and expects no familiarity with "
#~ "federated learning. Only a basic "
#~ "understanding of data science and Python"
#~ " programming is assumed."
#~ msgstr ""

#~ msgid "Classic machine learning"
#~ msgstr ""

#~ msgid ""
#~ "Before we begin to discuss federated "
#~ "learning, let us quickly recap how "
#~ "most machine learning works today."
#~ msgstr ""

#~ msgid "|ac0a9766e26044d6aea222a829859b20|"
#~ msgstr ""

#~ msgid "|36cd6e248b1443ce8a82b5a025bba368|"
#~ msgstr ""

#~ msgid ""
#~ "Now, in practice, the training data "
#~ "we work with doesn't originate on "
#~ "the machine we train the model on."
#~ " It gets created somewhere else."
#~ msgstr ""

#~ msgid ""
#~ "It originates on a smartphone by "
#~ "the user interacting with an app, "
#~ "a car collecting sensor data, a "
#~ "laptop receiving input via the keyboard,"
#~ " or a smart speaker listening to "
#~ "someone trying to sing a song."
#~ msgstr ""

#~ msgid "|bf4fb057f4774df39e1dcb5c71fd804a|"
#~ msgstr ""

#~ msgid "|71bb9f3c74c04f959b9bc1f02b736c95|"
#~ msgstr ""

#~ msgid ""
#~ "So to use machine learning, or any"
#~ " kind of data analysis, the approach"
#~ " that has been used in the past"
#~ " was to collect all data on a"
#~ " central server. This server can be"
#~ " somewhere in a data center, or "
#~ "somewhere in the cloud."
#~ msgstr ""

#~ msgid "|7605632e1b0f49599ffacf841491fcfb|"
#~ msgstr ""

#~ msgid "|91b1b5a7d3484eb7a2350c1923f18307|"
#~ msgstr ""

#~ msgid ""
#~ "The classic machine learning approach "
#~ "we've just seen can be used in "
#~ "some cases. Great examples include "
#~ "categorizing holiday photos, or analyzing "
#~ "web traffic. Cases, where all the "
#~ "data is naturally available on a "
#~ "centralized server."
#~ msgstr ""

#~ msgid "|5405ed430e4746e28b083b146fb71731|"
#~ msgstr ""

#~ msgid "|a389e87dab394eb48a8949aa2397687b|"
#~ msgstr ""

#~ msgid ""
#~ "There are many reasons why the "
#~ "classic centralized machine learning approach"
#~ " does not work for a large "
#~ "number of highly important real-world"
#~ " use cases. Those reasons include:"
#~ msgstr ""

#~ msgid ""
#~ "**Regulations**: GDPR (Europe), CCPA "
#~ "(California), PIPEDA (Canada), LGPD (Brazil),"
#~ " PDPL (Argentina), KVKK (Turkey), POPI "
#~ "(South Africa), FSS (Russia), CDPR "
#~ "(China), PDPB (India), PIPA (Korea), "
#~ "APPI (Japan), PDP (Indonesia), PDPA "
#~ "(Singapore), APP (Australia), and other "
#~ "regulations protect sensitive data from "
#~ "being moved. In fact, those regulations"
#~ " sometimes even prevent single "
#~ "organizations from combining their own "
#~ "users' data for artificial intelligence "
#~ "training because those users live in "
#~ "different parts of the world, and "
#~ "their data is governed by different "
#~ "data protection regulations."
#~ msgstr ""

#~ msgid ""
#~ "Sensitive healthcare records from multiple "
#~ "hospitals to train cancer detection "
#~ "models"
#~ msgstr ""

#~ msgid ""
#~ "Financial information from different "
#~ "organizations to detect financial fraud"
#~ msgstr ""

#~ msgid "Location data from your electric car to make better range prediction"
#~ msgstr ""

#~ msgid "End-to-end encrypted messages to train better auto-complete models"
#~ msgstr ""

#~ msgid "Federated learning"
#~ msgstr ""

#~ msgid ""
#~ "Federated learning simply reverses this "
#~ "approach. It enables machine learning on"
#~ " distributed data by moving the "
#~ "training to the data, instead of "
#~ "moving the data to the training. "
#~ "Here's the single-sentence explanation:"
#~ msgstr ""

#~ msgid "Central machine learning: move the data to the computation"
#~ msgstr ""

#~ msgid "Federated (machine) learning: move the computation to the data"
#~ msgstr ""

#~ msgid ""
#~ "By doing so, it enables us to "
#~ "use machine learning (and other data "
#~ "science approaches) in areas where it"
#~ " wasn't possible before. We can now"
#~ " train excellent medical AI models by"
#~ " enabling different hospitals to work "
#~ "together. We can solve financial fraud"
#~ " by training AI models on the "
#~ "data of different financial institutions. "
#~ "We can build novel privacy-enhancing "
#~ "applications (such as secure messaging) "
#~ "that have better built-in AI than"
#~ " their non-privacy-enhancing alternatives."
#~ " And those are just a few of"
#~ " the examples that come to mind. "
#~ "As we deploy federated learning, we "
#~ "discover more and more areas that "
#~ "can suddenly be reinvented because they"
#~ " now have access to vast amounts "
#~ "of previously inaccessible data."
#~ msgstr ""

#~ msgid ""
#~ "So how does federated learning work, "
#~ "exactly? Let's start with an intuitive"
#~ " explanation."
#~ msgstr ""

#~ msgid "|89c412136a5146ec8dc32c0973729f12|"
#~ msgstr ""

#~ msgid ""
#~ "Next, we send the parameters of "
#~ "the global model to the connected "
#~ "client nodes (think: edge devices like"
#~ " smartphones or servers belonging to "
#~ "organizations). This is to ensure that"
#~ " each participating node starts their "
#~ "local training using the same model "
#~ "parameters. We often use only a "
#~ "few of the connected nodes instead "
#~ "of all nodes. The reason for this"
#~ " is that selecting more and more "
#~ "client nodes has diminishing returns."
#~ msgstr ""

#~ msgid "|9503d3dc3a144e8aa295f8800cd8a766|"
#~ msgstr ""

#~ msgid "|aadb59e29b9e445d8e239d9a8a7045cb|"
#~ msgstr ""

#~ msgid "|a7579ad7734347508e959d9e14f2f53d|"
#~ msgstr ""

#~ msgid ""
#~ "In order to get one single model,"
#~ " we have to combine all the "
#~ "model updates we received from the "
#~ "client nodes. This process is called "
#~ "*aggregation*, and there are many "
#~ "different ways to do it. The most"
#~ " basic way to do it is called"
#~ " *Federated Averaging* (`McMahan et al.,"
#~ " 2016 <https://arxiv.org/abs/1602.05629>`__), often "
#~ "abbreviated as *FedAvg*. *FedAvg* takes "
#~ "the 100 model updates and, as the"
#~ " name suggests, averages them. To be"
#~ " more precise, it takes the *weighted"
#~ " average* of the model updates, "
#~ "weighted by the number of examples "
#~ "each client used for training. The "
#~ "weighting is important to make sure "
#~ "that each data example has the "
#~ "same \"influence\" on the resulting "
#~ "global model. If one client has 10"
#~ " examples, and another client has 100"
#~ " examples, then - without weighting -"
#~ " each of the 10 examples would "
#~ "influence the global model ten times "
#~ "as much as each of the 100 "
#~ "examples."
#~ msgstr ""

#~ msgid "|73d15dd1d4fc41678b2d54815503fbe8|"
#~ msgstr ""

#~ msgid "Federated analytics"
#~ msgstr ""

#~ msgid "|55472eef61274ba1b739408607e109df|"
#~ msgstr ""

#~ msgid ""
#~ "Run ``python3 src/py/flwr_tool/update_changelog.py "
#~ "<YOUR_GH_TOKEN>`` in order to add every"
#~ " new change to the changelog (feel"
#~ " free to make manual changes to "
#~ "the changelog afterwards until it looks"
#~ " good)."
#~ msgstr ""

#~ msgid ""
#~ "When operating in a production "
#~ "environment, it is strongly recommended "
#~ "to enable Transport Layer Security (TLS)"
#~ " for each Flower Component to ensure"
#~ " secure communication."
#~ msgstr ""

#~ msgid ""
#~ "To enable TLS, you will need a "
#~ "PEM-encoded root certificate, a PEM-"
#~ "encoded private key and a PEM-"
#~ "encoded certificate chain."
#~ msgstr ""

#~ msgid "SuperLink"
#~ msgstr ""

#~ msgid ""
#~ "Assuming all files we need are in"
#~ " the local ``certificates`` directory, we"
#~ " can use the flag ``--volume`` to "
#~ "mount the local directory into the "
#~ "``/app/certificates/`` directory of the "
#~ "container:"
#~ msgstr ""

#~ msgid ""
#~ "``--volume ./certificates/:/app/certificates/:ro``: Mount"
#~ " the ``certificates`` directory in"
#~ msgstr ""

#~ msgid ""
#~ "the current working directory of the "
#~ "host machine as a read-only volume"
#~ " at the"
#~ msgstr ""

#~ msgid "``/app/certificates`` directory inside the container."
#~ msgstr ""

#~ msgid "SuperNode"
#~ msgstr ""

#~ msgid ""
#~ "Assuming that the ``ca.crt`` certificate "
#~ "already exists locally, we can use "
#~ "the flag ``--volume`` to mount the "
#~ "local certificate into the container's "
#~ "``/app/`` directory."
#~ msgstr ""

#~ msgid ""
#~ "``--volume ./ca.crt:/app/ca.crt/:ro``: Mount the "
#~ "``ca.crt`` file from the"
#~ msgstr ""

#~ msgid ""
#~ "current working directory of the host"
#~ " machine as a read-only volume "
#~ "at the ``/app/ca.crt``"
#~ msgstr ""

#~ msgid "SuperExec"
#~ msgstr ""

#~ msgid ""
#~ "Assuming all files we need are in"
#~ " the local ``certificates`` directory where"
#~ " the SuperExec will be executed from,"
#~ " we can use the flag ``--volume`` "
#~ "to mount the local directory into "
#~ "the ``/app/certificates/`` directory of the"
#~ " container:"
#~ msgstr ""

#~ msgid ""
#~ ":substitution-code:`flwr/superexec:|stable_flwr_version|`: "
#~ "The name of the image to be "
#~ "run and the specific"
#~ msgstr ""

#~ msgid "SuperExec."
#~ msgstr ""

#~ msgid ""
#~ "``--ssl-certfile certificates/server.pem``: Specify"
#~ " the location of the SuperExec's"
#~ msgstr ""

#~ msgid ""
#~ "The ``certificates/server.pem`` file is used"
#~ " to identify the SuperExec and to "
#~ "encrypt the"
#~ msgstr ""

#~ msgid ""
#~ "``--ssl-keyfile certificates/server.key``: Specify"
#~ " the location of the SuperExec's"
#~ msgstr ""

#~ msgid ""
#~ "``--executor-config root-"
#~ "certificates=\\\"certificates/superlink_ca.crt\\\"``: Specify"
#~ " the"
#~ msgstr ""

#~ msgid ""
#~ "location of the CA certificate file "
#~ "inside the container that the SuperExec"
#~ " executor"
#~ msgstr ""

#~ msgid "should use to verify the SuperLink's identity."
#~ msgstr ""

#~ msgid "Run ClientApp as a Subprocess"
#~ msgstr ""

#~ msgid ""
#~ "In this mode, the ClientApp is "
#~ "executed as a subprocess within the "
#~ "SuperNode Docker container, rather than "
#~ "running in a separate container. This"
#~ " approach reduces the number of "
#~ "running containers, which can be "
#~ "beneficial for environments with limited "
#~ "resources. However, it also means that"
#~ " the ClientApp is no longer isolated"
#~ " from the SuperNode, which may "
#~ "introduce additional security concerns."
#~ msgstr ""

#~ msgid ""
#~ "Before running the ClientApp as a "
#~ "subprocess, ensure that the FAB "
#~ "dependencies have been installed in the"
#~ " SuperNode images. This can be done"
#~ " by extending the SuperNode image:"
#~ msgstr ""

#~ msgid "Dockerfile.supernode"
#~ msgstr ""

#~ msgid ""
#~ "Next, build the SuperNode Docker image"
#~ " by running the following command in"
#~ " the directory where Dockerfile is "
#~ "located:"
#~ msgstr ""

#~ msgid "Run the ClientApp as a Subprocess"
#~ msgstr ""

#~ msgid ""
#~ "Start the SuperNode with the flag "
#~ "``--isolation subprocess``, which tells the"
#~ " SuperNode to execute the ClientApp "
#~ "as a subprocess:"
#~ msgstr ""

#~ msgid "Run the example and follow the logs of the ServerApp:"
#~ msgstr ""

#~ msgid ""
#~ "That is all it takes! You can "
#~ "monitor the progress of the run "
#~ "through the logs of the SuperExec."
#~ msgstr ""

#~ msgid ""
#~ "You will learn how to run the "
#~ "Flower client and server components on"
#~ " two separate machines, with Flower "
#~ "configured to use TLS encryption and "
#~ "persist SuperLink state across restarts. "
#~ "A server consists of a SuperLink "
#~ "and ``SuperExec``. For more details "
#~ "about the Flower architecture, refer to"
#~ " the :doc:`../explanation-flower-architecture`"
#~ " explainer page."
#~ msgstr ""

#~ msgid ""
#~ "First, set the environment variables "
#~ "``SUPERLINK_IP`` and ``SUPEREXEC_IP`` with the"
#~ " IP address from the remote machine."
#~ " For example, if the IP is "
#~ "``192.168.2.33``, execute:"
#~ msgstr ""

#~ msgid ""
#~ "Log into the remote machine using "
#~ "``ssh`` and run the following command"
#~ " to start the SuperLink and SuperExec"
#~ " services:"
#~ msgstr ""

#~ msgid ""
#~ "Specify the remote SuperExec IP "
#~ "addresses and the path to the root"
#~ " certificate in the ``[tool.flwr.federations"
#~ ".remote-superexec]`` table in the "
#~ "``pyproject.toml`` file. Here, we have "
#~ "named our remote federation ``remote-"
#~ "superexec``:"
#~ msgstr ""

#~ msgid "Run the project and follow the ServerApp logs:"
#~ msgstr ""

#~ msgid ""
#~ "``-p 9091:9091 -p 9092:9092``: Map port"
#~ " ``9091`` and ``9092`` of the "
#~ "container to the same port of"
#~ msgstr ""

#~ msgid "the host machine, allowing other services to access the Driver API on"
#~ msgstr ""

#~ msgid ""
#~ "``http://localhost:9091`` and the Fleet API"
#~ " on ``http://localhost:9092``."
#~ msgstr ""

#~ msgid "Step 3: Start the SuperNode"
#~ msgstr ""

#~ msgid ""
#~ "``flwr/supernode:|stable_flwr_version|``: This is "
#~ "the name of the image to be "
#~ "run and the specific tag"
#~ msgstr ""

#~ msgid ""
#~ "``--supernode-address 0.0.0.0:9094``: Set the"
#~ " address and port number that the "
#~ "SuperNode"
#~ msgstr ""

#~ msgid "is listening on."
#~ msgstr ""

#~ msgid "Step 4: Start the ClientApp"
#~ msgstr ""

#~ msgid ""
#~ "The ClientApp Docker image comes with"
#~ " a pre-installed version of Flower"
#~ " and serves as a base for "
#~ "building your own ClientApp image. In"
#~ " order to install the FAB "
#~ "dependencies, you will need to create"
#~ " a Dockerfile that extends the "
#~ "ClientApp image and installs the "
#~ "required dependencies."
#~ msgstr ""

#~ msgid ""
#~ "Create a ClientApp Dockerfile called "
#~ "``Dockerfile.clientapp`` and paste the "
#~ "following code into it:"
#~ msgstr ""

#~ msgid "Dockerfile.clientapp"
#~ msgstr ""

#~ msgid ""
#~ "to be built from is the "
#~ "``flwr/clientapp image``, version :substitution-"
#~ "code:`|stable_flwr_version|`."
#~ msgstr ""

#~ msgid ""
#~ "``--supernode supernode-1:9094``: Connect to "
#~ "the SuperNode's Fleet API at the "
#~ "address"
#~ msgstr ""

#~ msgid "``supernode-1:9094``."
#~ msgstr ""

#~ msgid "Step 5: Start the SuperExec"
#~ msgstr ""

#~ msgid ""
#~ "The procedure for building and running"
#~ " a SuperExec image is almost "
#~ "identical to the ClientApp image."
#~ msgstr ""

#~ msgid ""
#~ "Similar to the ClientApp image, you "
#~ "will need to create a Dockerfile "
#~ "that extends the SuperExec image and "
#~ "installs the required FAB dependencies."
#~ msgstr ""

#~ msgid ""
#~ "Create a SuperExec Dockerfile called "
#~ "``Dockerfile.superexec`` and paste the "
#~ "following code in:"
#~ msgstr ""

#~ msgid "Dockerfile.superexec"
#~ msgstr ""

#~ msgid ""
#~ ":substitution-code:`FROM "
#~ "flwr/superexec:|stable_flwr_version|`: This line "
#~ "specifies that the Docker image"
#~ msgstr ""

#~ msgid ""
#~ "to be built from is the "
#~ "``flwr/superexec image``, version :substitution-"
#~ "code:`|stable_flwr_version|`."
#~ msgstr ""

#~ msgid ""
#~ "``ENTRYPOINT [\"flower-superexec\"``: Set the"
#~ " command ``flower-superexec`` to be"
#~ msgstr ""

#~ msgid "``\"--executor\", \"flwr.superexec.deployment:executor\"]`` Use the"
#~ msgstr ""

#~ msgid "``flwr.superexec.deployment:executor`` executor to run the ServerApps."
#~ msgstr ""

#~ msgid ""
#~ "Afterward, in the directory that holds"
#~ " the Dockerfile, execute this Docker "
#~ "command to build the SuperExec image:"
#~ msgstr ""

#~ msgid "Start the SuperExec container:"
#~ msgstr ""

#~ msgid ""
#~ "``-p 9093:9093``: Map port ``9093`` of"
#~ " the container to the same port "
#~ "of"
#~ msgstr ""

#~ msgid ""
#~ "the host machine, allowing you to "
#~ "access the SuperExec API on "
#~ "``http://localhost:9093``."
#~ msgstr ""

#~ msgid "``--name superexec``: Assign the name ``superexec`` to the container."
#~ msgstr ""

#~ msgid ""
#~ "``flwr_superexec:0.0.1``: This is the name "
#~ "of the image to be run and "
#~ "the specific tag"
#~ msgstr ""

#~ msgid ""
#~ "``--executor-config superlink=\\\"superlink:9091\\\"``:"
#~ " Configure the SuperExec executor to"
#~ msgstr ""

#~ msgid "connect to the SuperLink running on port ``9091``."
#~ msgstr ""

#~ msgid "Stop the current ClientApp containers:"
#~ msgstr ""

#~ msgid "Launch two new ClientApp containers based on the newly built image:"
#~ msgstr ""

#~ msgid ""
#~ "Setting the ``PROJECT_DIR`` helps Docker "
#~ "Compose locate the ``pyproject.toml`` file,"
#~ " allowing it to install dependencies "
#~ "in the SuperExec and SuperNode images"
#~ " correctly."
#~ msgstr ""

#~ msgid ""
#~ "To ensure the ``flwr`` CLI connects "
#~ "to the SuperExec, you need to "
#~ "specify the SuperExec addresses in the"
#~ " ``pyproject.toml`` file."
#~ msgstr ""

#~ msgid ""
#~ "Run the quickstart example, monitor the"
#~ " ServerApp logs and wait for the "
#~ "summary to appear:"
#~ msgstr ""

#~ msgid "In the SuperExec logs, you should find the ``Get weights`` line:"
#~ msgstr ""

#~ msgid "Step 7: Add another SuperNode"
#~ msgstr ""

#~ msgid ""
#~ "You can add more SuperNodes and "
#~ "ClientApps by duplicating their definitions"
#~ " in the ``compose.yml`` file."
#~ msgstr ""

#~ msgid ""
#~ "Just give each new SuperNode and "
#~ "ClientApp service a unique service name"
#~ " like ``supernode-3``, ``clientapp-3``, etc."
#~ msgstr ""

#~ msgid "In ``compose.yml``, add the following:"
#~ msgstr ""

#~ msgid ""
#~ "If you also want to enable TLS "
#~ "for the new SuperNodes, duplicate the"
#~ " SuperNode definition for each new "
#~ "SuperNode service in the ``with-"
#~ "tls.yml`` file."
#~ msgstr ""

#~ msgid ""
#~ "Make sure that the names of the"
#~ " services match with the one in "
#~ "the ``compose.yml`` file."
#~ msgstr ""

#~ msgid "In ``with-tls.yml``, add the following:"
#~ msgstr ""

#~ msgid "Comment out the lines 2-4 and uncomment the lines 5-9:"
#~ msgstr ""

#~ msgid "Enable SSL connections"
#~ msgstr ""

#~ msgid ""
#~ "This guide describes how to a "
#~ "SSL-enabled secure Flower server "
#~ "(``SuperLink``) can be started and how"
#~ " a Flower client (``SuperNode``) can "
#~ "establish a secure connections to it."
#~ msgstr ""

#~ msgid ""
#~ "The code example comes with a "
#~ "``README.md`` file which explains how to"
#~ " start it. Although it is already "
#~ "SSL-enabled, it might be less "
#~ "descriptive on how it does so. "
#~ "Stick to this guide for a deeper"
#~ " introduction to the topic."
#~ msgstr ""

#~ msgid ""
#~ "Using SSL-enabled connections requires "
#~ "certificates to be passed to the "
#~ "server and client. For the purpose "
#~ "of this guide we are going to "
#~ "generate self-signed certificates. As "
#~ "this can become quite complex we "
#~ "are going to ask you to run "
#~ "the script in ``examples/advanced-"
#~ "tensorflow/certificates/generate.sh`` with the "
#~ "following command sequence:"
#~ msgstr ""

#~ msgid ""
#~ "The approach for generating SSL "
#~ "certificates in the context of this "
#~ "example can serve as an inspiration "
#~ "and starting point, but it should "
#~ "not be used as a reference for "
#~ "production environments. Please refer to "
#~ "other sources regarding the issue of "
#~ "correctly generating certificates for "
#~ "production environments. For non-critical "
#~ "prototyping or research projects, it "
#~ "might be sufficient to use the "
#~ "self-signed certificates generated using "
#~ "the scripts mentioned in this guide."
#~ msgstr ""

#~ msgid ""
#~ "Use the following terminal command to"
#~ " start a sever (SuperLink) that uses"
#~ " the previously generated certificates:"
#~ msgstr ""

#~ msgid "Client (SuperNode)"
#~ msgstr ""

#~ msgid ""
#~ "You should now have learned how to"
#~ " generate self-signed certificates using"
#~ " the given script, start an SSL-"
#~ "enabled server and have a client "
#~ "establish a secure connection to it."
#~ msgstr ""

#~ msgid ""
#~ "This guide is for users who have"
#~ " already worked with Flower 0.x and"
#~ " want to upgrade to Flower 1.0. "
#~ "Newer versions of Flower (1.12+) are "
#~ "based on a new architecture (previously"
#~ " called Flower Next) and not covered"
#~ " in this guide. After upgrading "
#~ "Flower 0.x projects to Flower 1.0, "
#~ "please refer to :doc:`Upgrade to Flower"
#~ " Next <how-to-upgrade-to-flower-"
#~ "next>` to make your project compatible"
#~ " with the lastest version of Flower."
#~ msgstr ""

#~ msgid "Upgrade to Flower Next"
#~ msgstr ""

#~ msgid ""
#~ "Welcome to the migration guide for "
#~ "updating Flower to Flower Next! Whether"
#~ " you're a seasoned user or just "
#~ "getting started, this guide will help"
#~ " you smoothly transition your existing "
#~ "setup to take advantage of the "
#~ "latest features and improvements in "
#~ "Flower Next, starting from version 1.8."
#~ msgstr ""

#~ msgid ""
#~ "This guide shows how to reuse "
#~ "pre-``1.8`` Flower code with minimum "
#~ "code changes by using the *compatibility"
#~ " layer* in Flower Next. In another"
#~ " guide, we will show how to run"
#~ " Flower Next end-to-end with "
#~ "pure Flower Next APIs."
#~ msgstr ""

#~ msgid ""
#~ "Here's how to update an existing "
#~ "installation of Flower to Flower Next"
#~ " with ``pip``:"
#~ msgstr ""

#~ msgid "or if you need Flower Next with simulation:"
#~ msgstr ""

#~ msgid "Using Poetry"
#~ msgstr ""

#~ msgid ""
#~ "Update the ``flwr`` dependency in "
#~ "``pyproject.toml`` and then reinstall (don't"
#~ " forget to delete ``poetry.lock`` via "
#~ "``rm poetry.lock`` before running ``poetry "
#~ "install``)."
#~ msgstr ""

#~ msgid ""
#~ "Ensure you set the following version "
#~ "constraint in your ``pyproject.toml``:"
#~ msgstr ""

#~ msgid ""
#~ "In Flower Next, the *infrastructure* and"
#~ " *application layers* have been decoupled."
#~ " Instead of starting a client in "
#~ "code via ``start_client()``, you create "
#~ "a |clientapp_link|_ and start it via "
#~ "the command line. Instead of starting"
#~ " a server in code via "
#~ "``start_server()``, you create a "
#~ "|serverapp_link|_ and start it via the"
#~ " command line. The long-running "
#~ "components of server and client are "
#~ "called SuperLink and SuperNode. The "
#~ "following non-breaking changes that "
#~ "require manual updates and allow you "
#~ "to run your project both in the"
#~ " traditional way and in the Flower"
#~ " Next way:"
#~ msgstr ""

#~ msgid ""
#~ "Wrap your existing client with "
#~ "|clientapp_link|_ instead of launching it "
#~ "via |startclient_link|_. Here's an example:"
#~ msgstr ""

#~ msgid ""
#~ "Wrap your existing strategy with "
#~ "|serverapp_link|_ instead of starting the "
#~ "server via |startserver_link|_. Here's an "
#~ "example:"
#~ msgstr ""

#~ msgid ""
#~ "Run the ``SuperLink`` using "
#~ "|flowernext_superlink_link|_ before running, in "
#~ "sequence, |flowernext_clientapp_link|_ (2x) and "
#~ "|flowernext_serverapp_link|_. There is no need"
#~ " to execute `client.py` and `server.py` "
#~ "as Python scripts."
#~ msgstr ""

#~ msgid ""
#~ "Here's an example to start the "
#~ "server without HTTPS (only for "
#~ "prototyping):"
#~ msgstr ""

#~ msgid ""
#~ "Here's another example to start with "
#~ "HTTPS. Use the ``--ssl-ca-certfile``,"
#~ " ``--ssl-certfile``, and ``--ssl-keyfile``"
#~ " command line options to pass paths"
#~ " to (CA certificate, server certificate,"
#~ " and server private key)."
#~ msgstr ""

#~ msgid "Simulation in CLI"
#~ msgstr ""

#~ msgid ""
#~ "Wrap your existing client and strategy"
#~ " with |clientapp_link|_ and |serverapp_link|_,"
#~ " respectively. There is no need to"
#~ " use |startsim_link|_ anymore. Here's an"
#~ " example:"
#~ msgstr ""

#~ msgid ""
#~ "Run |flower_simulation_link|_ in CLI and "
#~ "point to the ``server_app`` / "
#~ "``client_app`` object in the code "
#~ "instead of executing the Python script."
#~ " Here's an example (assuming the "
#~ "``server_app`` and ``client_app`` objects are"
#~ " in a ``sim.py`` module):"
#~ msgstr ""

#~ msgid ""
#~ "Set default resources for each "
#~ "|clientapp_link|_ using the ``--backend-"
#~ "config`` command line argument instead "
#~ "of setting the ``client_resources`` argument"
#~ " in |startsim_link|_. Here's an example:"
#~ msgstr ""

#~ msgid "Simulation in a Notebook"
#~ msgstr ""

#~ msgid ""
#~ "Run |runsim_link|_ in your notebook "
#~ "instead of |startsim_link|_. Here's an "
#~ "example:"
#~ msgstr ""

#~ msgid ""
#~ "Some official `Flower code examples "
#~ "<https://flower.ai/docs/examples/>`_ are already "
#~ "updated to Flower Next so they can"
#~ " serve as a reference for using "
#~ "the Flower Next API. If there are"
#~ " further questions, `join the Flower "
#~ "Slack <https://flower.ai/join-slack/>`_ and "
#~ "use the channel ``#questions``. You can"
#~ " also `participate in Flower Discuss "
#~ "<https://discuss.flower.ai/>`_ where you can "
#~ "find us answering questions, or share"
#~ " and learn from others about "
#~ "migrating to Flower Next."
#~ msgstr ""

#~ msgid ""
#~ "As we continuously enhance Flower Next"
#~ " at a rapid pace, we'll be "
#~ "periodically updating this guide. Please "
#~ "feel free to share any feedback "
#~ "with us!"
#~ msgstr ""

#~ msgid ""
#~ "This function is deprecated since "
#~ "1.13.0. Use :code: `flwr run` to "
#~ "start a Flower simulation."
#~ msgstr ""

#~ msgid "|c9344c3dfee24383908fabaac40a8504|"
#~ msgstr ""

#~ msgid "|c10cd8f2177641bd8091c7b76d318ff9|"
#~ msgstr ""

#~ msgid "|3c59c315e67945ea8b839381c5deb6c2|"
#~ msgstr ""

#~ msgid "|eadf87e1e20549789512f7aa9199fcff|"
#~ msgstr ""

#~ msgid "|66ce8f21aeb443fca1fc88f727458417|"
#~ msgstr ""

#~ msgid "|f5768015a1014396b4761bb6cb3677f5|"
#~ msgstr ""

#~ msgid "|a746aa3f56064617a4e00f4c6a0cb140|"
#~ msgstr ""

#~ msgid "|cf8f676dd3534a44995c1b40910fd030|"
#~ msgstr ""

#~ msgid "|d1c0e3a4c9dc4bfd88ee6f1fe626edaf|"
#~ msgstr ""

#~ msgid "|1d8d6298a4014ec3a717135bcc7a94f9|"
#~ msgstr ""

#~ msgid "|e3ea79200ff44d459358b9f4713e582b|"
#~ msgstr ""

#~ msgid "|3e1061718a4a49d485764d30a4bfecdd|"
#~ msgstr ""

#~ msgid "|7750e597d1ea4e319f7e0a40539bf214|"
#~ msgstr ""

#~ msgid "|dd4434075f374e99ac07f509a883778f|"
#~ msgstr ""

#~ msgid "Other changes"
#~ msgstr ""

#~ msgid "|cf5fe148406b44b9a8b842fb01b5a7ea|"
#~ msgstr ""

#~ msgid "|ba25c91426d64cc1ae2d3febc5715b35|"
#~ msgstr ""

#~ msgid "|fca67f83aaab4389aa9ebb4d9c5cd75e|"
#~ msgstr ""

#~ msgid "|6f2e8f95c95443379b0df00ca9824654|"
#~ msgstr ""

#~ msgid "|c0ab3a1a733d4dbc9e1677aa608e8038|"
#~ msgstr ""

#~ msgid "|8f0491bde07341ab9f2e23d50593c0be|"
#~ msgstr ""

#~ msgid "|762fc099899943688361562252c5e600|"
#~ msgstr ""

#~ msgid "|f62d365fd0ae405b975d3ca01e7183fd|"
#~ msgstr ""

#~ msgid "|2c78fc1816b143289f4d909388f92a80|"
#~ msgstr ""

#~ msgid "|4230725aeebe497d8ad84a3efc2a912b|"
#~ msgstr ""

#~ msgid "|64b66a88417240eabe52f5cc55d89d0b|"
#~ msgstr ""

#~ msgid "|726c8eca58bc4f859b06aa24a587b253|"
#~ msgstr ""

#~ msgid "|f9d869e4b33c4093b29cf24ed8dff80a|"
#~ msgstr ""

#~ msgid "|4ab50bc01a9f426a91a2c0cbc3ab7a84|"
#~ msgstr ""

#~ msgid ""
#~ "Until the Flower core library matures"
#~ " it will be easier to get PR's"
#~ " accepted if they only touch non-"
#~ "core areas of the codebase. Good "
#~ "candidates to get started are:"
#~ msgstr ""

#~ msgid "Request for Flower Baselines"
#~ msgstr ""

#~ msgid ""
#~ "If you are not familiar with "
#~ "Flower Baselines, you should probably "
#~ "check-out our `contributing guide for "
#~ "baselines <https://flower.ai/docs/baselines/how-to-"
#~ "contribute-baselines.html>`_."
#~ msgstr ""

#~ msgid ""
#~ "You should then check out the open"
#~ " `issues "
#~ "<https://github.com/adap/flower/issues?q=is%3Aopen+is%3Aissue+label%3A%22new+baseline%22>`_"
#~ " for baseline requests. If you find"
#~ " a baseline that you'd like to "
#~ "work on and that has no assignees,"
#~ " feel free to assign it to "
#~ "yourself and start working on it!"
#~ msgstr ""

#~ msgid ""
#~ "Otherwise, if you don't find a "
#~ "baseline you'd like to work on, be"
#~ " sure to open a new issue with"
#~ " the baseline request template!"
#~ msgstr ""

#~ msgid "Request for examples"
#~ msgstr ""

#~ msgid ""
#~ "We wish we had more time to "
#~ "write usage examples because we believe"
#~ " they help users to get started "
#~ "with building what they want to "
#~ "build. Here are a few ideas where"
#~ " we'd be happy to accept a PR:"
#~ msgstr ""

#~ msgid "Llama 2 fine-tuning, with Hugging Face Transformers and PyTorch"
#~ msgstr ""

#~ msgid "Android ONNX on-device training"
#~ msgstr ""

#~ msgid "|f150b8d6e0074250822c9f6f7a8de3e0|"
#~ msgstr ""

#~ msgid "|72772d10debc4abd8373c0bc82985422|"
#~ msgstr ""

#~ msgid "|5815398552ad41d290a3a2631fe8f6ca|"
#~ msgstr ""

#~ msgid "|e6ac20744bf149378be20ac3dc309356|"
#~ msgstr ""

#~ msgid "|a4011ef443c14725b15a8cf33b0e3443|"
#~ msgstr ""

#~ msgid "|a22faa3617404c06803731525e1c609f|"
#~ msgstr ""

#~ msgid "|84a5c9b5041c43c3beab9786197c3e4e|"
#~ msgstr ""

#~ msgid "|b5c4be0b52d4493ba8c4af14d7c2db97|"
#~ msgstr ""

#~ msgid "|c1c784183d18481186ff65dc261d1335|"
#~ msgstr ""

#~ msgid "|669fcd1f44ab42f5bbd196c3cf1ecbc2|"
#~ msgstr ""

#~ msgid "|edfb08758c9441afb6736045a59e154c|"
#~ msgstr ""

#~ msgid "|82338b8bbad24d5ea9df3801aab37852|"
#~ msgstr ""

#~ msgid "|518d994dd2c844898b441da03b858326|"
#~ msgstr ""

#~ msgid "|7bfcfcb57ae5403f8e18486f45ca48b4|"
#~ msgstr ""

#~ msgid "|80152fa658904be08c849b4a594b76e1|"
#~ msgstr ""

#~ msgid "|35b60a1068f944ce937ac2988661aad5|"
#~ msgstr ""

#~ msgid "|efead7f2c2224b60b7b42705004c15e6|"
#~ msgstr ""

#~ msgid "|5421fee4e7ed450c903cbcd8a9d8a5d4|"
#~ msgstr ""

#~ msgid "|811fcf35e9214bd5b4e613e41f7c0a27|"
#~ msgstr ""

#~ msgid "|e61d38b0948f4c07a7257755f3799b54|"
#~ msgstr ""

#~ msgid "|e82c29351e2e480087c61b939eb7c041|"
#~ msgstr ""

#~ msgid "|21ca40f4fb1a405c89098fd1d24880a4|"
#~ msgstr ""

#~ msgid "|1351a2629c2c46d981b13b19f9fa45f0|"
#~ msgstr ""

#~ msgid "|124c2c188b994c7ab1c862cfdb326923|"
#~ msgstr ""

#~ msgid "|42e1951c36f2406e93c7ae0ec5b299f9|"
#~ msgstr ""

#~ msgid "|ec637b8a84234d068995ee1ccb2dd3b1|"
#~ msgstr ""

#~ msgid "|5bceb9d16b1a4d2db18d8a5b2f0cacb3|"
#~ msgstr ""

#~ msgid "|502b10044e864ca2b15282a393ab7faf|"
#~ msgstr ""

