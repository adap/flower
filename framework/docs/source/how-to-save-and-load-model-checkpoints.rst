:og:description: Save and load model checkpoints in Flower with custom strategies, including PyTorch checkpoints, for efficient federated learning workflows.
.. meta::
    :description: Save and load model checkpoints in Flower with custom strategies, including PyTorch checkpoints, for efficient federated learning workflows.

.. |arrayrecord_link| replace:: ``ArrayRecord``

.. _arrayrecord_link: ref-api/flwr.app.ArrayRecord.html

.. |clientapp_link| replace:: ``ClientApp``

.. _clientapp_link: ref-api/flwr.clientapp.ClientApp.html

.. |serverapp_link| replace:: ``ServerApp``

.. _serverapp_link: ref-api/flwr.serverapp.ServerApp.html

.. |strategy_start_link| replace:: ``start``

.. _strategy_start_link: ref-api/flwr.serverapp.strategy.Strategy.html#flwr.serverapp.strategy.Strategy.start

Save and load model checkpoints
===============================

This how-to guide describes the steps to save (and load) model checkpoints in
``ClientApp`` and ``ServerApp``.

How to save model checkpoints in ``ClientApp``
----------------------------------------------

The model updates are saved in |arrayrecord_link|_ and transmitted between
|serverapp_link|_ and |clientapp_link|_. To save model checkpoints in |clientapp_link|_,
you need to convert the |arrayrecord_link|_ into a format compatible with your ML
framework (e.g., PyTorch, TensorFlow, or NumPy). Include the following code in your
functions registered with the ``ClientApp`` (e.g., in your training function decorated
with ``@app.train()``):

PyTorch

.. code-block:: python

    # Convert ArrayRecord to PyTorch state dict.
    state_dict = arrays.to_torch_state_dict()

    # Save model weights to disk
    torch.save(state_dict, "model.pt")

TensorFlow

.. code-block:: python

    # Convert ArrayRecord to NDarray.
    ndarrays = arrays.to_numpy_ndarrays()

    # Load weights to a keras model
    model.set_weights(ndarrays)

    # Save model weights to disk
    model.save("model.keras")

Numpy

.. code-block:: python

    # Convert ArrayRecord to NDarray.
    ndarrays = arrays.to_numpy_ndarrays()

    # Save model weights to disk
    numpy.savez("model.npz", *ndarrays)

How to Save Model Checkpoints in ServerApp
------------------------------------------

To save model checkpoints in |serverapp_link|_ across different FL rounds, you can
implement this in a customized ``evaluate_fn`` and pass it to the strategy's
|strategy_start_link|_ method. Here's an example showing how to save the global PyTorch
model:

.. code-block:: python

    def get_evaluate_fn(save_every_round, total_round, save_path):
        def evaluate(server_round: int, arrays: ArrayRecord) -> MetricRecord:
            # Save model every `save_every_round` round and for the last round
            if server_round != 0 and (
                server_round == total_round or server_round % save_every_round == 0
            ):
                # Convert ArrayRecord to PyTorch state dict
                state_dict = arrays.to_torch_state_dict()

                # Save model weights to disk
                torch.save(state_dict, f"{save_path}/model_{server_round}.pt")

            return MetricRecord()

        return evaluate

Then, we pass it to the |strategy_start_link|_ method of the defined strategy:

.. code-block:: python

    strategy.start(
        ...,
        evaluate_fn=get_evaluate_fn(save_every_round, total_round, save_path),
    )

Checkout the details in `Advanced PyTorch Example
<https://github.com/adap/flower/tree/main/examples/advanced-pytorch>`_ and `Advanced
TensorFlow Example
<https://github.com/adap/flower/tree/main/examples/advanced-tensorflow>`_.
