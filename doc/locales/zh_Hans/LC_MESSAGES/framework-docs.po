# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022 Flower Labs GmbH
# This file is distributed under the same license as the Flower package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2023.
#
msgid ""
msgstr ""
"Project-Id-Version: Flower main\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2024-11-20 09:07+0100\n"
"PO-Revision-Date: 2024-06-12 10:09+0000\n"
"Last-Translator: Yan Gao <y.gaogy@gmail.com>\n"
"Language: zh_Hans\n"
"Language-Team: Chinese (Simplified) <https://hosted.weblate.org/projects"
"/flower-docs/framework/zh_Hans/>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.16.0\n"

#: ../../source/contributor-explanation-public-and-private-apis.rst:2
msgid "Public and private APIs"
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:4
msgid ""
"In Python, everything is public. To enable developers to understand which"
" components can be relied upon, Flower declares a public API. Components "
"that are part of the public API can be relied upon. Changes to the public"
" API are announced in the release notes and are subject to deprecation "
"policies."
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:9
msgid ""
"Everything that is not part of the public API is part of the private API."
" Even though Python allows accessing them, user code should never use "
"those components. Private APIs can change at any time, even in patch "
"releases."
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:13
msgid ""
"How can you determine whether a component is part of the public API or "
"not? Easy:"
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:15
msgid "`Use the Flower API reference documentation <ref-api/flwr.html>`_"
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:16
msgid "`Use the Flower CLI reference documentation <ref-api-cli.html>`_"
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:18
msgid ""
"Everything listed in the reference documentation is part of the public "
"API. This document explains how Flower maintainers define the public API "
"and how you can determine whether a component is part of the public API "
"or not by reading the Flower source code."
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:23
#, fuzzy
msgid "Flower public API"
msgstr "Flower 客户端。"

#: ../../source/contributor-explanation-public-and-private-apis.rst:25
msgid "Flower has a well-defined public API. Let's look at this in more detail."
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:29
msgid ""
"Every component that is reachable by recursively following "
"``__init__.__all__`` starting from the root package (``flwr``) is part of"
" the public API."
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:32
msgid ""
"If you want to determine whether a component "
"(class/function/generator/...) is part of the public API or not, you need"
" to start at the root of the ``flwr`` package. Let's use ``tree -L 1 -d "
"src/py/flwr`` to look at the Python sub-packages contained ``flwr``:"
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:46
msgid ""
"Contrast this with the definition of ``__all__`` in the root "
"``src/py/flwr/__init__.py``:"
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:59
msgid ""
"You can see that ``flwr`` has six subpackages (``cli``, ``client``, "
"``common``, ``proto``, ``server``, ``simulation``), but only four of them"
" are \"exported\" via ``__all__`` (``client``, ``common``, ``server``, "
"``simulation``)."
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:63
msgid ""
"What does this mean? It means that ``client``, ``common``, ``server`` and"
" ``simulation`` are part of the public API, but ``cli`` and ``proto`` are"
" not. The ``flwr`` subpackages ``cli`` and ``proto`` are private APIs. A "
"private API can change completely from one release to the next (even in "
"patch releases). It can change in a breaking way, it can be renamed (for "
"example, ``flwr.cli`` could be renamed to ``flwr.command``) and it can "
"even be removed completely."
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:70
msgid "Therefore, as a Flower user:"
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:72
msgid "``from flwr import client`` ✅ Ok, you're importing a public API."
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:73
msgid ""
"``from flwr import proto`` ❌ Not recommended, you're importing a private "
"API."
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:75
msgid ""
"What about components that are nested deeper in the hierarchy? Let's look"
" at Flower strategies to see another typical pattern. Flower strategies "
"like ``FedAvg`` are often imported using ``from flwr.server.strategy "
"import FedAvg``. Let's look at "
"``src/py/flwr/server/strategy/__init__.py``:"
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:91
msgid ""
"What's notable here is that all strategies are implemented in dedicated "
"modules (e.g., ``fedavg.py``). In ``__init__.py``, we *import* the "
"components we want to make part of the public API and then *export* them "
"via ``__all__``. Note that we export the component itself (for example, "
"the ``FedAvg`` class), but not the module it is defined in (for example, "
"``fedavg.py``). This allows us to move the definition of ``FedAvg`` into "
"a different module (or even a module in a subpackage) without breaking "
"the public API (as long as we update the import path in ``__init__.py``)."
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:99
msgid "Therefore:"
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:101
msgid ""
"``from flwr.server.strategy import FedAvg`` ✅ Ok, you're importing a "
"class that is part of the public API."
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:103
msgid ""
"``from flwr.server.strategy import fedavg`` ❌ Not recommended, you're "
"importing a private module."
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:106
msgid ""
"This approach is also implemented in the tooling that automatically "
"builds API reference docs."
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:110
msgid "Flower public API of private packages"
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:112
msgid ""
"We also use this to define the public API of private subpackages. Public,"
" in this context, means the API that other ``flwr`` subpackages should "
"use. For example, ``flwr.server.driver`` is a private subpackage (it's "
"not exported via ``src/py/flwr/server/__init__.py``'s ``__all__``)."
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:117
msgid ""
"Still, the private sub-package ``flwr.server.driver`` defines a "
"\"public\" API using ``__all__`` in "
"``src/py/flwr/server/driver/__init__.py``:"
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:132
msgid ""
"The interesting part is that both ``GrpcDriver`` and ``InMemoryDriver`` "
"are never used by Flower framework users, only by other parts of the "
"Flower framework codebase. Those other parts of the codebase import, for "
"example, ``InMemoryDriver`` using ``from flwr.server.driver import "
"InMemoryDriver`` (i.e., the ``InMemoryDriver`` exported via ``__all__``),"
" not ``from flwr.server.driver.in_memory_driver import InMemoryDriver`` "
"(``in_memory_driver.py`` is the module containing the actual "
"``InMemoryDriver`` class definition)."
msgstr ""

#: ../../source/contributor-explanation-public-and-private-apis.rst:140
msgid ""
"This is because ``flwr.server.driver`` defines a public interface for "
"other ``flwr`` subpackages. This allows codeowners of "
"``flwr.server.driver`` to refactor the package without breaking other "
"``flwr``-internal users."
msgstr ""

#: ../../source/contributor-how-to-build-docker-images.rst:2
#, fuzzy
msgid "How to Build Docker Flower Images Locally"
msgstr "如何在本地搭建Docker Flower images"

#: ../../source/contributor-how-to-build-docker-images.rst:4
#, fuzzy
msgid ""
"Flower provides pre-made docker images on `Docker Hub "
"<https://hub.docker.com/u/flwr>`_ that include all necessary dependencies"
" for running the SuperLink, SuperNode or ServerApp. You can also build "
"your own custom docker images from scratch with a different version of "
"Python or Linux distribution (Ubuntu/Alpine) if that is what you need. In"
" this guide, we will explain what images exist and how to build them "
"locally."
msgstr ""
"Flower 在 `Docker Hub <https://hub.docker.com/r/flwr/server/tags>`_ "
"上提供了预制的 docker 镜像，其中包括运行服务器所需的所有依赖项。如果你需要，也可以使用不同版本的 Python 或 Ubuntu "
"从头开始构建自己的定制 docker 镜像。在本指南中，我们将介绍有哪些镜像，以及如何在本地构建它们。"

#: ../../source/contributor-how-to-build-docker-images.rst:10
#, fuzzy
msgid ""
"Before we can start, we need to meet a few prerequisites in our local "
"development environment."
msgstr "在开始之前，我们需要在本地开发环境中满足一些先决条件。"

#: ../../source/contributor-how-to-build-docker-images.rst:13
#, fuzzy
msgid "Clone the ``flower`` repository."
msgstr "**叉花仓库**"

#: ../../source/contributor-how-to-build-docker-images.rst:19
#, fuzzy
msgid "Verify the Docker daemon is running."
msgstr "验证 Docker 守护进程是否正在运行。"

#: ../../source/contributor-how-to-build-docker-images.rst:21
#, fuzzy
msgid ""
"The build instructions that assemble the images are located in the "
"respective Dockerfiles. You can find them in the subdirectories of "
"``src/docker``."
msgstr "组装镜像的构建说明位于各自的 Dockerfile 中。你可以在 ``src/docker`` 的子目录中找到它们。"

#: ../../source/contributor-how-to-build-docker-images.rst:24
#, fuzzy
msgid ""
"Flower Docker images are configured via build arguments. Through build "
"arguments, we can make the creation of images more flexible. For example,"
" in the base image, we can specify the version of Python to install using"
" the ``PYTHON_VERSION`` build argument. Some of the build arguments have "
"default values, others must be specified when building the image. All "
"available build arguments for each image are listed in one of the tables "
"below."
msgstr ""
"基础镜像和服务器镜像都是通过构建参数配置的。通过联编参数，我们可以使联编更加灵活。例如，在基础镜像中，我们可以使用 "
"``PYTHON_VERSION`` 联编参数指定要安装的 Python "
"版本。有些联编参数有默认值，有些则必须在联编映像时指定。每个映像的所有可用联编参数都列在下表中。"

#: ../../source/contributor-how-to-build-docker-images.rst:32
#, fuzzy
msgid "Building the Base Image"
msgstr "加载数据"

#: ../../source/contributor-how-to-build-docker-images.rst:38
#: ../../source/contributor-how-to-build-docker-images.rst:104
#, fuzzy
msgid "Build argument"
msgstr "构建文档"

#: ../../source/contributor-how-to-build-docker-images.rst:39
#: ../../source/contributor-how-to-build-docker-images.rst:105
#, fuzzy
msgid "Description"
msgstr "停用"

#: ../../source/contributor-how-to-build-docker-images.rst:40
#: ../../source/contributor-how-to-build-docker-images.rst:106
#, fuzzy
msgid "Required"
msgstr "所需变更"

#: ../../source/contributor-how-to-build-docker-images.rst:41
#: ../../source/contributor-how-to-build-docker-images.rst:107
#: ../../source/docker/persist-superlink-state.rst:19
#: ../../source/docker/pin-version.rst:12
#: ../../source/docker/set-environment-variables.rst:8
#, fuzzy
msgid "Example"
msgstr "实例"

#: ../../source/contributor-how-to-build-docker-images.rst:42
msgid "``DISTRO``"
msgstr ""

#: ../../source/contributor-how-to-build-docker-images.rst:43
#, fuzzy
msgid "The Linux distribution to use as the base image."
msgstr "基础镜像的存储库名称。"

#: ../../source/contributor-how-to-build-docker-images.rst:44
#: ../../source/contributor-how-to-build-docker-images.rst:48
#: ../../source/contributor-how-to-build-docker-images.rst:52
#: ../../source/contributor-how-to-build-docker-images.rst:68
#: ../../source/contributor-how-to-build-docker-images.rst:75
#: ../../source/contributor-how-to-build-docker-images.rst:110
#, fuzzy
msgid "No"
msgstr "现在"

#: ../../source/contributor-how-to-build-docker-images.rst:45
#, fuzzy
msgid "``ubuntu``"
msgstr "``UBUNTU_VERSION``"

#: ../../source/contributor-how-to-build-docker-images.rst:46
#, fuzzy
msgid "``DISTRO_VERSION``"
msgstr "``PIP_VERSION``"

#: ../../source/contributor-how-to-build-docker-images.rst:47
msgid "Version of the Linux distribution."
msgstr ""

#: ../../source/contributor-how-to-build-docker-images.rst:49
msgid ":substitution-code:`|ubuntu_version|`"
msgstr ""

#: ../../source/contributor-how-to-build-docker-images.rst:50
#, fuzzy
msgid "``PYTHON_VERSION``"
msgstr "Python 版本"

#: ../../source/contributor-how-to-build-docker-images.rst:51
#, fuzzy
msgid "Version of ``python`` to be installed."
msgstr "要安装的 ``python`` 版本。"

#: ../../source/contributor-how-to-build-docker-images.rst:53
msgid "``3.11`` or ``3.11.1``"
msgstr ""

#: ../../source/contributor-how-to-build-docker-images.rst:54
#, fuzzy
msgid "``PIP_VERSION``"
msgstr "``PIP_VERSION``"

#: ../../source/contributor-how-to-build-docker-images.rst:55
#, fuzzy
msgid "Version of ``pip`` to be installed."
msgstr "要安装的 ``pip` 版本。"

#: ../../source/contributor-how-to-build-docker-images.rst:56
#: ../../source/contributor-how-to-build-docker-images.rst:60
#: ../../source/contributor-how-to-build-docker-images.rst:64
#: ../../source/contributor-how-to-build-docker-images.rst:114
#, fuzzy
msgid "Yes"
msgstr "类型"

#: ../../source/contributor-how-to-build-docker-images.rst:57
msgid ":substitution-code:`|pip_version|`"
msgstr ""

#: ../../source/contributor-how-to-build-docker-images.rst:58
#, fuzzy
msgid "``SETUPTOOLS_VERSION``"
msgstr "设置工具版本"

#: ../../source/contributor-how-to-build-docker-images.rst:59
#, fuzzy
msgid "Version of ``setuptools`` to be installed."
msgstr "要安装的 `setuptools`` 版本。"

#: ../../source/contributor-how-to-build-docker-images.rst:61
#, fuzzy
msgid ":substitution-code:`|setuptools_version|`"
msgstr "设置工具版本"

#: ../../source/contributor-how-to-build-docker-images.rst:62
#, fuzzy
msgid "``FLWR_VERSION``"
msgstr "``FLWR_VERSION``"

#: ../../source/contributor-how-to-build-docker-images.rst:63
#, fuzzy
msgid "Version of Flower to be installed."
msgstr "要安装的 Flower 版本。"

#: ../../source/contributor-how-to-build-docker-images.rst:65
msgid ":substitution-code:`|stable_flwr_version|`"
msgstr ""

#: ../../source/contributor-how-to-build-docker-images.rst:66
#, fuzzy
msgid "``FLWR_PACKAGE``"
msgstr "``FLWR_VERSION``"

#: ../../source/contributor-how-to-build-docker-images.rst:67
#, fuzzy
msgid "The Flower package to be installed."
msgstr "要安装的 PyPI 软件包。"

#: ../../source/contributor-how-to-build-docker-images.rst:69
msgid "``flwr`` or ``flwr-nightly``"
msgstr ""

#: ../../source/contributor-how-to-build-docker-images.rst:70
#, fuzzy
msgid "``FLWR_VERSION_REF``"
msgstr "``FLWR_VERSION``"

#: ../../source/contributor-how-to-build-docker-images.rst:71
msgid ""
"A `direct reference "
"<https://packaging.python.org/en/latest/specifications/version-specifiers"
"/#direct-references>`_ without the ``@`` specifier. If both "
"``FLWR_VERSION`` and ``FLWR_VERSION_REF`` are specified, the "
"``FLWR_VERSION_REF`` has precedence."
msgstr ""

#: ../../source/contributor-how-to-build-docker-images.rst:76
#, fuzzy
msgid "`Direct Reference Examples`_"
msgstr "示例请求"

#: ../../source/contributor-how-to-build-docker-images.rst:78
#, fuzzy
msgid ""
"The following example creates a base Ubuntu/Alpine image with Python "
"``3.11.0``, pip :substitution-code:`|pip_version|`, setuptools "
":substitution-code:`|setuptools_version|` and Flower :substitution-"
"code:`|stable_flwr_version|`:"
msgstr "下面的示例使用 Python 3.11.0、pip 23.0.1 和 setuptools 69.0.2 创建了基本映像："

#: ../../source/contributor-how-to-build-docker-images.rst:93
#, fuzzy
msgid ""
"In this example, we specify our image name as ``flwr_base`` and the tag "
"as ``0.1.0``. Remember that the build arguments as well as the name and "
"tag can be adapted to your needs. These values serve as examples only."
msgstr "图像名称为 ``flwr_base``，标记为 ``0.1.0``。请记住，编译参数以及名称和标记都可以根据需要进行调整。这些值仅供参考。"

#: ../../source/contributor-how-to-build-docker-images.rst:98
#, fuzzy
msgid "Building a Flower Binary Image"
msgstr "加载数据"

#: ../../source/contributor-how-to-build-docker-images.rst:108
#, fuzzy
msgid "``BASE_REPOSITORY``"
msgstr "基础存储库"

#: ../../source/contributor-how-to-build-docker-images.rst:109
#, fuzzy
msgid "The repository name of the base image."
msgstr "基础镜像的存储库名称。"

#: ../../source/contributor-how-to-build-docker-images.rst:111
#, fuzzy
msgid "``flwr/base``"
msgstr "``FLWR_VERSION``"

#: ../../source/contributor-how-to-build-docker-images.rst:112
#, fuzzy
msgid "``BASE_IMAGE``"
msgstr "基础存储库"

#: ../../source/contributor-how-to-build-docker-images.rst:113
#, fuzzy
msgid "The Tag of the Flower base image."
msgstr "基础镜像的存储库名称。"

#: ../../source/contributor-how-to-build-docker-images.rst:115
msgid ":substitution-code:`|stable_flwr_version|-py3.11-ubuntu|ubuntu_version|`"
msgstr ""

#: ../../source/contributor-how-to-build-docker-images.rst:117
msgid ""
"For example, to build a SuperLink image with the latest Flower version, "
"Python 3.11 and Ubuntu 22.04, run the following:"
msgstr ""

#: ../../source/contributor-how-to-build-docker-images.rst:128
#, fuzzy
msgid ""
"If you want to use your own base image instead of the official Flower "
"base image, all you need to do is set the ``BASE_REPOSITORY`` build "
"argument to ``flwr_base`` (as we've specified above)."
msgstr ""
"如果您想使用自己的基础图片而不是 Flower 官方的基础图片，只需设置 ``BASE_REPOSITORY`` 和 "
"``BASE_IMAGE_TAG`` "
"联编参数即可。`BASE_REPOSITORY``的值必须与您的图像名称一致，`BASE_IMAGE_TAG``的值必须与您的图像标签一致。"

#: ../../source/contributor-how-to-build-docker-images.rst:140
#, fuzzy
msgid "After creating the image, we can test whether the image is working:"
msgstr "创建图像后，我们可以测试图像是否正常工作："

#: ../../source/contributor-how-to-build-docker-images.rst:147
#, fuzzy
msgid "Direct Reference Examples"
msgstr "示例请求"

#: ../../source/contributor-how-to-contribute-translations.rst:2
msgid "Contribute translations"
msgstr "贡献译文"

#: ../../source/contributor-how-to-contribute-translations.rst:4
#, fuzzy
msgid ""
"Since `Flower 1.5 <https://flower.ai/docs/framework/ref-"
"changelog.html#v1-5-0-2023-08-31>`_ we have introduced translations to "
"our doc pages, but, as you might have noticed, the translations are often"
" imperfect. If you speak languages other than English, you might be able "
"to help us in our effort to make Federated Learning accessible to as many"
" people as possible by contributing to those translations! This might "
"also be a great opportunity for those wanting to become open source "
"contributors with little prerequisites."
msgstr ""
"从 `Flower 1.5 <https://flower.ai/docs/framework/ref-"
"changelog.html#v1-5-0-2023-08-31>`_ "
"开始，我们在文档页面中引入了翻译，但正如你可能已经注意到的，这些翻译往往并不完美。如果您会说英语以外的语言，也许您可以帮助我们翻译这些文档，让更多的人了解"
" Federated Learning！对于那些想成为开源贡献者的人来说，这也是一个很好的机会。"

#: ../../source/contributor-how-to-contribute-translations.rst:13
msgid ""
"Our translation project is publicly available over on `Weblate "
"<https://hosted.weblate.org/projects/flower-docs/framework/>`_, this "
"where most of the work will happen."
msgstr ""
"我们的翻译项目已在 \"Weblate <https://hosted.weblate.org/projects/flower-"
"docs/framework/>`_\"上公开，大部分工作都将在这里进行。"

#: ../../source/contributor-how-to-contribute-translations.rst:18
msgid "Contribute to existing languages"
msgstr "为现有语言作出贡献"

#: ../../source/contributor-how-to-contribute-translations.rst:23
msgid ""
"The first thing you will need to do in order to contribute is to create a"
" free Weblate account on this `page "
"<https://hosted.weblate.org/accounts/register/>`_. More information about"
" profile settings can be found `here "
"<https://docs.weblate.org/en/latest/user/profile.html>`_."
msgstr ""
"您需要做的第一件事就是在本`网页<https://hosted.weblate.org/accounts/register/>`_上创建一个免费的Weblate帐户。有关个人资料设置的更多信息，请参阅`这里"
" <https://docs.weblate.org/en/latest/user/profile.html>`_。"

#: ../../source/contributor-how-to-contribute-translations.rst:28
msgid ""
"Once you are signed in to Weblate, you can navigate to the `Flower "
"Framework project <https://hosted.weblate.org/projects/flower-"
"docs/framework/>`_. Here, you should see the different existing languages"
" that can be found on the website."
msgstr ""
"登录到Weblate后，您可以导航到 \"Flower Framework "
"\"项目<https://hosted.weblate.org/projects/flower-"
"docs/framework/>`_。在这里，您可以看到网站上现有的各种语言。"

#: ../../source/contributor-how-to-contribute-translations.rst:32
msgid ""
"Once you have selected the language you want to contribute to, you should"
" see a similar interface to this:"
msgstr "选择您要贡献的语言后，您应该会看到与此类似的界面："

#: ../../source/contributor-how-to-contribute-translations.rst:37
msgid ""
"The most straight forward option here is to click on the ``Translate`` "
"button on the top right (in the ``Translation status`` section). This "
"will automatically bring you to the translation interface for "
"untranslated strings."
msgstr "最简单的方法是点击右上角（\"翻译状态 \"部分）的 \"翻译 \"按钮。这将自动带您进入未翻译字符串的翻译界面。"

#: ../../source/contributor-how-to-contribute-translations.rst:41
msgid "This is what the interface looks like:"
msgstr "这就是界面的样子："

#: ../../source/contributor-how-to-contribute-translations.rst:45
#, fuzzy
msgid ""
"You input your translation in the text box at the top and then, once you "
"are happy with it, you either press ``Save and continue`` (to save the "
"translation and go to the next untranslated string), ``Save and stay`` "
"(to save the translation and stay on the same page), ``Suggest`` (to add "
"your translation to suggestions for other users to view), or ``Skip`` (to"
" go to the next untranslated string without saving anything)."
msgstr ""
"您可以在顶部的文本框中输入翻译内容，满意后按 "
"\"保存并继续\"（保存翻译内容并转到下一个未翻译的字符串）、\"保存并停留\"（保存翻译内容并停留在同一页面）、\"建议\"（将您的翻译添加到建议中供其他用户查看）或"
" \"跳过\"（转到下一个未翻译的字符串而不保存任何内容）。"

#: ../../source/contributor-how-to-contribute-translations.rst:51
msgid ""
"In order to help with the translations, you can see on the bottom the "
"``Nearby strings``, the ``Comments`` (from other contributors), the "
"``Automatic suggestions`` (from machine translation engines), the "
"translations in ``Other languages``, and the ``History`` of translations "
"for this string."
msgstr ""
"为了帮助翻译，您可以在底部看到 \"邻近字符串\"、\"评论\"（来自其他贡献者）、\"自动建议\"（来自机器翻译引擎）、\"其他语言 "
"\"中的翻译以及该字符串的 \"历史翻译\"。"

#: ../../source/contributor-how-to-contribute-translations.rst:56
msgid ""
"On the right, under the ``String information`` section, you can also "
"click the link under ``Source string location`` in order to view the "
"source of the doc file containing the string."
msgstr "在右侧的 \"字符串信息 \"部分，您还可以单击 \"源字符串位置 \"下的链接，以查看包含字符串的 doc 文件的源文件。"

#: ../../source/contributor-how-to-contribute-translations.rst:60
msgid ""
"For more information about translating using Weblate, you can check out "
"this `in-depth guide "
"<https://docs.weblate.org/en/latest/user/translating.html>`_."
msgstr ""
"有关使用 Weblate 进行翻译的更多信息，您可以查看本 \"深入指南 "
"<https://docs.weblate.org/en/latest/user/translating.html>`_\"。"

#: ../../source/contributor-how-to-contribute-translations.rst:64
msgid "Add new languages"
msgstr "添加新语言"

#: ../../source/contributor-how-to-contribute-translations.rst:66
msgid ""
"If you want to add a new language, you will first have to contact us, "
"either on `Slack <https://flower.ai/join-slack>`_, or by opening an issue"
" on our `GitHub repo <https://github.com/adap/flower>`_."
msgstr ""
"如果您想添加新语言，请先联系我们，可以在 `Slack <https://flower.ai/join-slack>`_ 上联系，也可以在我们的 "
"`GitHub repo <https://github.com/adap/flower>`_ 上提交问题。"

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:2
msgid "Develop in VSCode Dev Containers"
msgstr "使用 VSCode Dev Containers 进行开发"

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:4
msgid ""
"When working on the Flower framework we want to ensure that all "
"contributors use the same developer environment to format code or run "
"tests. For this purpose we are using the VSCode Remote Containers "
"extension. What is it? Read the following quote:"
msgstr ""
"在开发 Flower 框架时，我们希望确保所有贡献者使用相同的开发环境来格式化代码或运行测试。为此，我们使用了 VSCode "
"远程容器扩展。这是什么？请阅读下面这段话："

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:8
#, fuzzy
msgid ""
"The Visual Studio Code Remote - Containers extension lets you use a "
"Docker container as a fully-featured development environment. It allows "
"you to open any folder inside (or mounted into) a container and take "
"advantage of Visual Studio Code's full feature set. A "
"``devcontainer.json`` file in your project tells VS Code how to access "
"(or create) a development container with a well-defined tool and runtime "
"stack. This container can be used to run an application or to separate "
"tools, libraries, or runtimes needed for working with a codebase."
msgstr ""
"Visual Studio Code Remote - "
"Containers扩展可让你将Docker容器用作功能齐全的开发环境。它允许你打开容器内（或挂载到容器内）的任何文件夹，并利用 Visual "
"Studio Code 的全部功能集。项目中的 :code:`devcontainer.json` 文件会告诉 VS Code "
"如何访问（或创建）一个带有定义明确的工具和运行时栈的开发容器。该容器可用于运行应用程序，也可用于分离处理代码库所需的工具、库或运行时。"

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:16
msgid ""
"Workspace files are mounted from the local file system or copied or "
"cloned into the container. Extensions are installed and run inside the "
"container, where they have full access to the tools, platform, and file "
"system. This means that you can seamlessly switch your entire development"
" environment just by connecting to a different container."
msgstr "工作区文件从本地文件系统加载，或复制或克隆到容器中。扩展在容器内安装和运行，在容器内它们可以完全访问工具、平台和文件系统。这意味着，只需连接到不同的容器，就能无缝切换整个开发环境。"

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:22
#, fuzzy
msgid ""
"Source: `Official VSCode documentation "
"<https://code.visualstudio.com/docs/devcontainers/containers>`_"
msgstr "来源：`VSCode 官方文档 <https://code.visualstudio.com/docs/remote/containers>`_"

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:26
msgid "Getting started"
msgstr "开始"

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:28
#, fuzzy
msgid ""
"Configuring and setting up the ``Dockerfile`` as well the configuration "
"for the devcontainer can be a bit more involved. The good thing is you "
"don't have to do it. Usually it should be enough to install `Docker "
"<https://docs.docker.com/engine/install/>`_ on your system and ensure its"
" available on your command line. Additionally, install the `VSCode "
"Containers Extension <vscode:extension/ms-vscode-remote.remote-"
"containers>`_."
msgstr ""
"配置和设置 :code:`Dockerfile` 以及 devcontainer 的配置可能比较复杂。好在你想做就得做。通常只需在系统中安装 "
"Docker 并确保其在命令行中可用即可。此外，请安装 `VSCode Containers Extension "
"<vscode:extension/ms-vscode-remote.remote-containers>`_。"

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:35
msgid ""
"Now you should be good to go. When starting VSCode, it will ask you to "
"run in the container environment and - if you confirm - automatically "
"build the container and use it. To manually instruct VSCode to use the "
"devcontainer, you can, after installing the extension, click the green "
"area in the bottom left corner of your VSCode window and select the "
"option *(Re)Open Folder in Container*."
msgstr ""
"现在你应该可以开始了。启动 VSCode 时，它会要求你在容器环境中运行，如果你确认，它会自动构建容器并使用它。要手动指示 VSCode 使用 "
"devcontainer，可以在安装扩展后，点击 VSCode 窗口左下角的绿色区域，然后选择 \"*（重新）在容器中打开文件夹*\"选项。"

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:41
msgid ""
"In some cases your setup might be more involved. For those cases consult "
"the following sources:"
msgstr "在某些情况下，您的设置可能更复杂。有关这些情况，请参考以下资料："

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:44
#, fuzzy
msgid ""
"`Developing inside a Container "
"<https://code.visualstudio.com/docs/devcontainers/containers#_system-"
"requirements>`_"
msgstr ""
"在容器内开发 <https://code.visualstudio.com/docs/remote/containers#_system-"
"requirements>`_"

#: ../../source/contributor-how-to-develop-in-vscode-dev-containers.rst:46
#, fuzzy
msgid ""
"`Remote development in Containers "
"<https://code.visualstudio.com/docs/devcontainers/tutorial>`_"
msgstr "容器中的远程开发 <https://code.visualstudio.com/docs/remote/containers-tutorial>`_"

#: ../../source/contributor-how-to-install-development-versions.rst:2
msgid "Install development versions"
msgstr "安装开发版本"

#: ../../source/contributor-how-to-install-development-versions.rst:5
msgid "Install development versions of Flower"
msgstr "安装 Flower 的开发版本"

#: ../../source/contributor-how-to-install-development-versions.rst:8
msgid "Using Poetry (recommended)"
msgstr "使用诗歌（推荐）"

#: ../../source/contributor-how-to-install-development-versions.rst:10
msgid ""
"Install a ``flwr`` pre-release from PyPI: update the ``flwr`` dependency "
"in ``pyproject.toml`` and then reinstall (don't forget to delete "
"``poetry.lock`` (``rm poetry.lock``) before running ``poetry install``)."
msgstr ""
"安装来自 PyPI 的 ``flwr`` 预发布版本：更新 ``pyproject.toml`` 中的 ``flwr`` "
"依赖关系，然后重新安装（运行 ``poetry install` 前，别忘了删除 ``poetry.lock` (``rm "
"poetry.lock`))。"

#: ../../source/contributor-how-to-install-development-versions.rst:14
msgid ""
"``flwr = { version = \"1.0.0a0\", allow-prereleases = true }`` (without "
"extras)"
msgstr "``flwr = { version = \"1.0.0a0\", allow-prereleases = true }`` （不含额外内容）"

#: ../../source/contributor-how-to-install-development-versions.rst:15
msgid ""
"``flwr = { version = \"1.0.0a0\", allow-prereleases = true, extras = "
"[\"simulation\"] }`` (with extras)"
msgstr ""
"``flwr = { version = \"1.0.0a0\", allow-prereleases = true, extras = "
"[\"simulation\"] }`` (包含额外内容)"

#: ../../source/contributor-how-to-install-development-versions.rst:18
msgid ""
"Install ``flwr`` from a local copy of the Flower source code via "
"``pyproject.toml``:"
msgstr "通过 ``pyproject.toml`` 从 Flower 源代码的本地副本安装 ``flwr``："

#: ../../source/contributor-how-to-install-development-versions.rst:20
msgid "``flwr = { path = \"../../\", develop = true }`` (without extras)"
msgstr "``flwr = { path = \"../../\", develop = true }`` （不含额外内容）"

#: ../../source/contributor-how-to-install-development-versions.rst:21
msgid ""
"``flwr = { path = \"../../\", develop = true, extras = [\"simulation\"] "
"}`` (with extras)"
msgstr ""
"``flwr = { path = \"../../\", develop = true, extras = [\"simulation\"] "
"}`` (包含额外内容)"

#: ../../source/contributor-how-to-install-development-versions.rst:23
msgid "Install ``flwr`` from a local wheel file via ``pyproject.toml``:"
msgstr "通过 ``pyproject.toml`` 从本地轮子文件安装 ``flwr``："

#: ../../source/contributor-how-to-install-development-versions.rst:25
#, fuzzy
msgid ""
"``flwr = { path = \"../../dist/flwr-1.8.0-py3-none-any.whl\" }`` (without"
" extras)"
msgstr "``flwr = { path = \"../../dist/flwr-1.0.0-py3-none-any.whl\" }``（无额外内容）"

#: ../../source/contributor-how-to-install-development-versions.rst:26
#, fuzzy
msgid ""
"``flwr = { path = \"../../dist/flwr-1.8.0-py3-none-any.whl\", extras = "
"[\"simulation\"] }`` (with extras)"
msgstr ""
"``flwr = { path = \"../../dist/flwr-1.0.0-py3-none-any.whl\", extras = "
"[\"simulation\"] }`` (包含额外内容)"

#: ../../source/contributor-how-to-install-development-versions.rst:29
msgid ""
"Please refer to the Poetry documentation for further details: `Poetry "
"Dependency Specification <https://python-poetry.org/docs/dependency-"
"specification/>`_"
msgstr ""
"有关详细信息，请参阅 Poetry 文档： 诗歌依赖性规范 <https://python-poetry.org/docs/dependency-"
"specification/>`_"

#: ../../source/contributor-how-to-install-development-versions.rst:33
msgid "Using pip (recommended on Colab)"
msgstr "使用 pip（建议在 Colab 上使用）"

#: ../../source/contributor-how-to-install-development-versions.rst:35
msgid "Install a ``flwr`` pre-release from PyPI:"
msgstr "从 PyPI 安装 ``flwr`` 预发行版："

#: ../../source/contributor-how-to-install-development-versions.rst:37
msgid "``pip install -U --pre flwr`` (without extras)"
msgstr "``pip install -U -pre flwr``（不含额外功能）"

#: ../../source/contributor-how-to-install-development-versions.rst:38
msgid "``pip install -U --pre 'flwr[simulation]'`` (with extras)"
msgstr "``pip install -U -pre 'flwr[simulation]'``（包含额外功能）"

#: ../../source/contributor-how-to-install-development-versions.rst:40
msgid ""
"Python packages can be installed from git repositories. Use one of the "
"following commands to install the Flower directly from GitHub."
msgstr "Python 软件包可以从 git 仓库安装。使用以下命令之一直接从 GitHub 安装 Flower。"

#: ../../source/contributor-how-to-install-development-versions.rst:43
msgid "Install ``flwr`` from the default GitHub branch (``main``):"
msgstr "从 GitHub 的默认分支 (``main`) 安装 ``flwr``："

#: ../../source/contributor-how-to-install-development-versions.rst:45
msgid ""
"``pip install flwr@git+https://github.com/adap/flower.git`` (without "
"extras)"
msgstr "``pip install flwr@git+https://github.com/adap/flower.git`` （不含额外功能）"

#: ../../source/contributor-how-to-install-development-versions.rst:46
msgid ""
"``pip install 'flwr[simulation]@git+https://github.com/adap/flower.git'``"
" (with extras)"
msgstr ""
"``pip install "
"'flwr[simulation]@git+https://github.com/adap/flower.git'``（带附加功能）"

#: ../../source/contributor-how-to-install-development-versions.rst:49
msgid "Install ``flwr`` from a specific GitHub branch (``branch-name``):"
msgstr "从特定的 GitHub 分支 (`分支名`) 安装 ``flwr``："

#: ../../source/contributor-how-to-install-development-versions.rst:51
msgid ""
"``pip install flwr@git+https://github.com/adap/flower.git@branch-name`` "
"(without extras)"
msgstr ""
"``pip install flwr@git+https://github.com/adap/flower.git@branch-name`` "
"（不含附加功能）"

#: ../../source/contributor-how-to-install-development-versions.rst:53
msgid ""
"``pip install 'flwr[simulation]@git+https://github.com/adap/flower.git"
"@branch-name'`` (with extras)"
msgstr ""
"``pip install "
"'flwr[simulation]@git+https://github.com/adap/flower.git@分支名'``（带附加功能）"

#: ../../source/contributor-how-to-install-development-versions.rst:57
msgid "Open Jupyter Notebooks on Google Colab"
msgstr "在谷歌 Colab 上打开 Jupyter 笔记本"

#: ../../source/contributor-how-to-install-development-versions.rst:59
#, fuzzy
msgid ""
"Open the notebook ``doc/source/tutorial-series-get-started-with-flower-"
"pytorch.ipynb``:"
msgstr "打开笔记本 ``doc/source/tutorial-get-started-with-flower-pytorch.ipynb``："

#: ../../source/contributor-how-to-install-development-versions.rst:61
#, fuzzy
msgid ""
"https://colab.research.google.com/github/adap/flower/blob/main/doc/source"
"/tutorial-series-get-started-with-flower-pytorch.ipynb"
msgstr ""
"https://colab.research.google.com/github/adap/flower/blob/main/doc/source"
"/tutorial-get-started-with-flower-pytorch.ipynb"

#: ../../source/contributor-how-to-install-development-versions.rst:63
msgid ""
"Open a development version of the same notebook from branch `branch-name`"
" by changing ``main`` to ``branch-name`` (right after ``blob``):"
msgstr ""
"将 ``main`` 改为 ``branch-name``（紧跟在 ``blob``之后），从分支 `branch-name` "
"打开同一笔记本的开发版本："

#: ../../source/contributor-how-to-install-development-versions.rst:66
#, fuzzy
msgid ""
"https://colab.research.google.com/github/adap/flower/blob/branch-"
"name/doc/source/tutorial-series-get-started-with-flower-pytorch.ipynb"
msgstr ""
"https://colab.research.google.com/github/adap/flower/blob/branch-"
"name/doc/source/tutorial-get-started-with-flower-pytorch.ipynb"

#: ../../source/contributor-how-to-install-development-versions.rst:68
msgid "Install a `whl` on Google Colab:"
msgstr "在 Google Colab 上安装 `whl`："

#: ../../source/contributor-how-to-install-development-versions.rst:70
msgid ""
"In the vertical icon grid on the left hand side, select ``Files`` > "
"``Upload to session storage``"
msgstr "在左侧的垂直图标网格中，选择 \"文件\">\"上传到会话存储\""

#: ../../source/contributor-how-to-install-development-versions.rst:72
#, fuzzy
msgid "Upload the whl (e.g., ``flwr-1.8.0-py3-none-any.whl``)"
msgstr "更新 whl (e.g., ``flwr-1.7.0-py3-none-any.whl``)"

#: ../../source/contributor-how-to-install-development-versions.rst:73
#, fuzzy
msgid ""
"Change ``!pip install -q 'flwr[simulation]' torch torchvision "
"matplotlib`` to ``!pip install -q 'flwr-1.8.0-py3-none-"
"any.whl[simulation]' torch torchvision matplotlib``"
msgstr ""
"把``!pip install -q 'flwr[simulation]' torch torchvision "
"matplotlib``变为``!pip install -q 'flwr-1.7.0-py3-none-any.whl[simulation]'"
" torch torchvision matplotlib``"

#: ../../source/contributor-how-to-release-flower.rst:2
msgid "Release Flower"
msgstr "发布 Flower"

#: ../../source/contributor-how-to-release-flower.rst:4
msgid ""
"This document describes the current release process. It may or may not "
"change in the future."
msgstr "本文件描述了当前的发布流程。今后可能会有变化，也可能不会有变化。"

#: ../../source/contributor-how-to-release-flower.rst:8
msgid "During the release"
msgstr "在发布期间"

#: ../../source/contributor-how-to-release-flower.rst:10
msgid ""
"The version number of a release is stated in ``pyproject.toml``. To "
"release a new version of Flower, the following things need to happen (in "
"that order):"
msgstr "版本号在 ``pyproject.toml`` 中说明。要发布 Flower 的新版本，需要完成以下工作（按顺序排列）："

#: ../../source/contributor-how-to-release-flower.rst:13
#, fuzzy
msgid ""
"Run ``python3 src/py/flwr_tool/update_changelog.py <YOUR_GH_TOKEN>`` in "
"order to add every new change to the changelog (feel free to make manual "
"changes to the changelog afterwards until it looks good)."
msgstr ""
"运行 ``python3 src/py/flwr_tool/update_changelog.py <YOUR_GH_TOKEN>`` "
"以将每项新更改添加到更新日志中（之后可对更新日志进行手动更改，直到看起来不错为止）。"

#: ../../source/contributor-how-to-release-flower.rst:16
#, fuzzy
msgid ""
"Once the changelog has been updated with all the changes, run ``./dev"
"/prepare-release-changelog.sh v<NEW_VERSION>``, where ``<NEW_VERSION>`` "
"is the version stated in ``pyproject.toml`` (notice the ``v`` added "
"before it). This will replace the ``Unreleased`` header of the changelog "
"by the version and current date, and it will add a thanking message for "
"the contributors. Open a pull request with those changes."
msgstr ""
"更新更新日志后，运行``./dev/prepare-release-changelog.sh "
"v<NEW_VERSION>``，其中``<NEW_VERSION>``是``pyproject.toml``中的版本（注意前面的``v``）。这将用版本和当前日期替换更新日志中的"
" ``Unreleased`` 标头，并为贡献者添加一条感谢信息。打开一个包含这些更改的拉取请求。"

#: ../../source/contributor-how-to-release-flower.rst:22
#, fuzzy
msgid ""
"Once the pull request is merged, tag the release commit with the version "
"number as soon as the PR is merged: ``git tag v<NEW_VERSION>`` (notice "
"the ``v`` added before the version number), then ``git push --tags``. "
"This will create a draft release on GitHub containing the correct "
"artifacts and the relevant part of the changelog."
msgstr ""
"在 PR 合并后立即用版本号标记发布提交：``git tag v0.12.3``，然后``git push --tags``。这将在 GitHub"
" 上创建一个包含正确工件和更新日志相关部分的发布草案。"

#: ../../source/contributor-how-to-release-flower.rst:26
msgid "Check the draft release on GitHub, and if everything is good, publish it."
msgstr "检查 GitHub 上的发布稿，如果一切正常，就发布它。"

#: ../../source/contributor-how-to-release-flower.rst:29
msgid "After the release"
msgstr "发布后"

#: ../../source/contributor-how-to-release-flower.rst:31
msgid "Create a pull request which contains the following changes:"
msgstr "创建包含以下更改的拉取请求："

#: ../../source/contributor-how-to-release-flower.rst:33
msgid "Increase the minor version in ``pyproject.toml`` by one."
msgstr "将 ``pyproject.toml`` 中的次要版本增加一个。"

#: ../../source/contributor-how-to-release-flower.rst:34
msgid "Update all files which contain the current version number if necessary."
msgstr "如有必要，更新包含当前版本号的所有文件。"

#: ../../source/contributor-how-to-release-flower.rst:35
msgid "Add a new ``Unreleased`` section in ``changelog.md``."
msgstr "在 ``changelog.md`` 中添加新的 ``Unreleased`` 部分。"

#: ../../source/contributor-how-to-release-flower.rst:37
msgid ""
"Merge the pull request on the same day (i.e., before a new nightly "
"release gets published to PyPI)."
msgstr "在同一天合并拉取请求（即在新版本发布到 PyPI 之前）。"

#: ../../source/contributor-how-to-release-flower.rst:41
msgid "Publishing a pre-release"
msgstr "发布预发布版本"

#: ../../source/contributor-how-to-release-flower.rst:44
msgid "Pre-release naming"
msgstr "释放前命名"

#: ../../source/contributor-how-to-release-flower.rst:46
msgid ""
"PyPI supports pre-releases (alpha, beta, release candidate). Pre-releases"
" MUST use one of the following naming patterns:"
msgstr "PyPI 支持预发布版本（alpha、beta、release candidate）。预发布版本必须使用以下命名模式之一："

#: ../../source/contributor-how-to-release-flower.rst:49
msgid "Alpha: ``MAJOR.MINOR.PATCHaN``"
msgstr "阿尔法 ``MAJOR.MINOR.PATCHaN``"

#: ../../source/contributor-how-to-release-flower.rst:50
msgid "Beta: ``MAJOR.MINOR.PATCHbN``"
msgstr "贝塔： ``MAJOR.MINOR.PATCHbN``"

#: ../../source/contributor-how-to-release-flower.rst:51
msgid "Release candidate (RC): ``MAJOR.MINOR.PATCHrcN``"
msgstr "版本代号 (RC)： ``MAJOR.MINOR.PATCHrcN``"

#: ../../source/contributor-how-to-release-flower.rst:53
msgid "Examples include:"
msgstr "例子包括："

#: ../../source/contributor-how-to-release-flower.rst:55
msgid "``1.0.0a0``"
msgstr "``1.0.0a0``"

#: ../../source/contributor-how-to-release-flower.rst:56
msgid "``1.0.0b0``"
msgstr "``1.0.0b0``"

#: ../../source/contributor-how-to-release-flower.rst:57
msgid "``1.0.0rc0``"
msgstr "``1.0.0rc0``"

#: ../../source/contributor-how-to-release-flower.rst:58
msgid "``1.0.0rc1``"
msgstr "``1.0.0rc1``"

#: ../../source/contributor-how-to-release-flower.rst:60
msgid ""
"This is in line with PEP-440 and the recommendations from the Python "
"Packaging Authority (PyPA):"
msgstr "这符合 PEP-440 和 Python 包装管理局 (PyPA) 的建议："

#: ../../source/contributor-how-to-release-flower.rst:63
msgid "`PEP-440 <https://peps.python.org/pep-0440/>`_"
msgstr "`PEP-440 <https://peps.python.org/pep-0440/>`_"

#: ../../source/contributor-how-to-release-flower.rst:64
msgid ""
"`PyPA Choosing a versioning scheme "
"<https://packaging.python.org/en/latest/guides/distributing-packages-"
"using-setuptools/#choosing-a-versioning-scheme>`_"
msgstr ""
"`PyPA 选择版本控制方案 <https://packaging.python.org/en/latest/guides"
"/distributing-packages-using-setuptools/#choosing-a-versioning-scheme>`_"

#: ../../source/contributor-how-to-release-flower.rst:67
msgid ""
"Note that the approach defined by PyPA is not compatible with SemVer "
"2.0.0 spec, for details consult the `Semantic Versioning Specification "
"<https://semver.org/spec/v2.0.0.html#spec-item-11>`_ (specifically item "
"11 on precedence)."
msgstr ""
"请注意，PyPA 所定义的方法与 SemVer 2.0.0 "
"规范不兼容，详情请查阅《语义版本规范》<https://semver.org/spec/v2.0.0.html#spec-"
"item-11>`_（特别是关于优先级的第 11 项）。"

#: ../../source/contributor-how-to-release-flower.rst:73
msgid "Pre-release classification"
msgstr "发布前分类"

#: ../../source/contributor-how-to-release-flower.rst:75
msgid "Should the next pre-release be called alpha, beta, or release candidate?"
msgstr "下一个预发布版应该叫阿尔法版、贝塔版还是候选发布版？"

#: ../../source/contributor-how-to-release-flower.rst:77
msgid ""
"RC: feature complete, no known issues (apart from issues that are "
"classified as \"won't fix\" for the next stable release) - if no issues "
"surface this will become the next stable release"
msgstr "RC：功能完整，无已知问题（除了下一个稳定版中被列为 \"不会修复 \"的问题）--如果没有问题出现，这将成为下一个稳定版"

#: ../../source/contributor-how-to-release-flower.rst:80
msgid "Beta: feature complete, allowed to have known issues"
msgstr "贝塔版：功能完整，允许存在已知问题"

#: ../../source/contributor-how-to-release-flower.rst:81
msgid "Alpha: not feature complete, allowed to have known issues"
msgstr "阿尔法版：功能不完整，允许存在已知问题"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:2
msgid "Set up a virtual env"
msgstr "建立虚拟环境"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:4
msgid ""
"It is recommended to run your Python setup within a virtual environment. "
"This guide shows three different examples how to create a virtual "
"environment with pyenv virtualenv, poetry, or Anaconda. You can follow "
"the instructions or choose your preferred setup."
msgstr ""
"建议在虚拟环境中运行 Python 设置。本指南展示了如何使用 pyenv virtualenv、poes 或 Anaconda "
"创建虚拟环境的三个不同示例。您可以按照说明或选择您喜欢的设置。"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:10
msgid "Python Version"
msgstr "Python 版本"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:12
#: ../../source/how-to-install-flower.rst:7
msgid ""
"Flower requires at least `Python 3.9 <https://docs.python.org/3.9/>`_, "
"but `Python 3.10 <https://docs.python.org/3.10/>`_ or above is "
"recommended."
msgstr ""
"Flower 至少需要 `Python 3.9 <https://docs.python.org/3.9/>`_，但建议使用 `Python "
"3.10 <https://docs.python.org/3.10/>`_或更高版本。"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:17
#, fuzzy
msgid ""
"Due to a known incompatibility with `ray "
"<https://docs.ray.io/en/latest/>`_, we currently recommend utilizing at "
"most `Python 3.11 <https://docs.python.org/3.11/>`_ for running Flower "
"simulations."
msgstr ""
"由于已知与 `ray <https://docs.ray.io/en/latest/>`_ 不兼容，我们目前建议最多使用 `Python 3.11"
" <https://docs.python.org/3.11/>`_ 运行 Flower 仿真。"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:22
#, fuzzy
msgid "Virtualenv with Pyenv/Virtualenv"
msgstr "Virutualenv 和 Pyenv/Virtualenv"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:24
msgid ""
"One of the recommended virtual environment is `pyenv "
"<https://github.com/pyenv/pyenv>`_/`virtualenv <https://github.com/pyenv"
"/pyenv-virtualenv>`_. Please see `Flower examples "
"<https://github.com/adap/flower/tree/main/examples/>`_ for details."
msgstr ""
"其中一个推荐的虚拟环境是 `pyenv <https://github.com/pyenv/pyenv>`_/`virtualenv "
"<https://github.com/pyenv/pyenv-virtualenv>`_。详情请参见 `Flower 示例 "
"<https://github.com/adap/flower/tree/main/examples/>`_。"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:29
msgid ""
"Once Pyenv is set up, you can use it to install `Python Version 3.10 "
"<https://docs.python.org/3.10/>`_ or above:"
msgstr "一旦设置好 Pyenv，就可以用它来安装 `Python 3.10 <https://docs.python.org/3.10/>`_ 或更高版本："

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:36
msgid "Create the virtualenv with:"
msgstr "创建虚拟环境："

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:42
msgid "Activate the virtualenv by running the following command:"
msgstr "运行以下命令激活 virtualenv："

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:49
msgid "Virtualenv with Poetry"
msgstr "有诗意的 Virtualenv"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:51
msgid ""
"The Flower examples are based on `Poetry <https://python-"
"poetry.org/docs/>`_ to manage dependencies. After installing Poetry you "
"simply create a virtual environment with:"
msgstr ""
"Flower 示例基于 `Poetry <https://python-poetry.org/docs/>`_ 来管理依赖关系。安装 Poetry"
" 后，只需创建一个虚拟环境即可："

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:58
msgid ""
"If you open a new terminal you can activate the previously created "
"virtual environment with the following command:"
msgstr "如果打开一个新终端，可以使用以下命令激活之前创建的虚拟环境："

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:66
msgid "Virtualenv with Anaconda"
msgstr "使用 Anaconda 的 Virtualenv"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:68
#, fuzzy
msgid ""
"If you prefer to use Anaconda for your virtual environment then install "
"and setup the `conda <https://docs.conda.io/projects/conda/en/latest"
"/user-guide/install/index.html>`_ package. After setting it up you can "
"create a virtual environment with:"
msgstr ""
"如果你更喜欢在虚拟环境中使用 Anaconda，那么请安装并设置 `conda "
"<https://docs.conda.io/projects/conda/en/latest/user-"
"guide/install/index.html>`_ 软件包。设置完成后，您就可以使用以下工具创建虚拟环境："

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:76
msgid "and activate the virtual environment with:"
msgstr "并激活虚拟环境："

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:83
msgid "And then?"
msgstr "然后呢？"

#: ../../source/contributor-how-to-set-up-a-virtual-env.rst:85
msgid ""
"As soon as you created your virtual environment you clone one of the "
"`Flower examples <https://github.com/adap/flower/tree/main/examples/>`_."
msgstr ""
"创建虚拟环境后，您可以克隆一个 `Flower 示例 "
"<https://github.com/adap/flower/tree/main/examples/>`_。"

#: ../../source/contributor-how-to-write-documentation.rst:2
msgid "Write documentation"
msgstr "编写文件"

#: ../../source/contributor-how-to-write-documentation.rst:5
msgid "Project layout"
msgstr "项目布局"

#: ../../source/contributor-how-to-write-documentation.rst:7
msgid ""
"The Flower documentation lives in the ``doc`` directory. The Sphinx-based"
" documentation system supports both reStructuredText (``.rst`` files) and"
" Markdown (``.md`` files)."
msgstr ""
"Flower 文档位于 ``doc`` 目录中。基于 Sphinx 的文档系统支持 reStructuredText（``.rst`` 文件）和 "
"Markdown（``.md`` 文件）。"

#: ../../source/contributor-how-to-write-documentation.rst:10
#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:196
#, fuzzy
msgid ""
"Note that, in order to build the documentation locally (with ``poetry run"
" make html``, like described below), `Pandoc "
"<https://pandoc.org/installing.html>`_ needs to be installed on the "
"system."
msgstr ""
"请注意，要在本地构建文档（使用 ``poetry run make html``，如下所述），系统上必须安装 ``Pandoc "
"<https://pandoc.org/installing.html>_`。"

#: ../../source/contributor-how-to-write-documentation.rst:15
msgid "Edit an existing page"
msgstr "编辑现有页面"

#: ../../source/contributor-how-to-write-documentation.rst:17
msgid "Edit an existing ``.rst`` (or ``.md``) file under ``doc/source/``"
msgstr "编辑 ``doc/source/`` 下现有的 ``.rst`` (或 ``.md``) 文件"

#: ../../source/contributor-how-to-write-documentation.rst:18
#: ../../source/contributor-how-to-write-documentation.rst:27
msgid "Compile the docs: ``cd doc``, then ``poetry run make html``"
msgstr "编译文档： cd doc``，然后 ``poetry run make html``"

#: ../../source/contributor-how-to-write-documentation.rst:19
#: ../../source/contributor-how-to-write-documentation.rst:28
msgid "Open ``doc/build/html/index.html`` in the browser to check the result"
msgstr "在浏览器中打开 ``doc/build/html/index.html`` 查看结果"

#: ../../source/contributor-how-to-write-documentation.rst:22
msgid "Create a new page"
msgstr "创建新页面"

#: ../../source/contributor-how-to-write-documentation.rst:24
msgid "Add new ``.rst`` file under ``doc/source/``"
msgstr "在 ``doc/source/`` 下添加新的 ``.rst`` 文件"

#: ../../source/contributor-how-to-write-documentation.rst:25
msgid "Add content to the new ``.rst`` file"
msgstr "为新的 ``.rst`` 文件添加内容"

#: ../../source/contributor-how-to-write-documentation.rst:26
msgid "Link to the new rst from ``index.rst``"
msgstr "从 ``index.rst`` 链接到新的 rst"

#: ../../source/contributor-ref-good-first-contributions.rst:2
msgid "Good first contributions"
msgstr "首次代码贡献"

#: ../../source/contributor-ref-good-first-contributions.rst:4
msgid ""
"We welcome contributions to Flower! However, it is not always easy to "
"know where to start. We therefore put together a few recommendations on "
"where to start to increase your chances of getting your PR accepted into "
"the Flower codebase."
msgstr ""
"我们欢迎为Flower做出代码贡献！然而，要知道从哪里开始并非易事。因此，我们提出了一些建议，告诉您从哪里开始，以增加您的 PR 被 Flower"
" 代码库接受的机会。"

#: ../../source/contributor-ref-good-first-contributions.rst:9
msgid "Where to start"
msgstr "从哪里开始"

#: ../../source/contributor-ref-good-first-contributions.rst:11
msgid ""
"Until the Flower core library matures it will be easier to get PR's "
"accepted if they only touch non-core areas of the codebase. Good "
"candidates to get started are:"
msgstr "在 Flower 核心库成熟之前，如果 PR 只涉及代码库中的非核心区域，则会更容易被接受。可以从以下方面入手："

#: ../../source/contributor-ref-good-first-contributions.rst:14
msgid "Documentation: What's missing? What could be expressed more clearly?"
msgstr "文档： 缺少什么？哪些内容可以表达得更清楚？"

#: ../../source/contributor-ref-good-first-contributions.rst:15
msgid "Baselines: See below."
msgstr "Baselines： 见下文。"

#: ../../source/contributor-ref-good-first-contributions.rst:16
msgid "Examples: See below."
msgstr "示例： 见下文。"

#: ../../source/contributor-ref-good-first-contributions.rst:19
msgid "Request for Flower Baselines"
msgstr "Flower Baselines的申请"

#: ../../source/contributor-ref-good-first-contributions.rst:21
#, fuzzy
msgid ""
"If you are not familiar with Flower Baselines, you should probably check-"
"out our `contributing guide for baselines "
"<https://flower.ai/docs/baselines/how-to-contribute-baselines.html>`_."
msgstr ""
"如果您对 Flower Baselines 还不熟悉，也许可以看看我们的 `Baselines贡献指南 "
"<https://flower.ai/docs/baselines/how-to-contribute-baselines.html>`_。"

#: ../../source/contributor-ref-good-first-contributions.rst:25
#, fuzzy
msgid ""
"You should then check out the open `issues "
"<https://github.com/adap/flower/issues?q=is%3Aopen+is%3Aissue+label%3A%22new+baseline%22>`_"
" for baseline requests. If you find a baseline that you'd like to work on"
" and that has no assignees, feel free to assign it to yourself and start "
"working on it!"
msgstr ""
"然后查看开放的 `issues "
"<https://github.com/adap/flower/issues?q=is%3Aopen+is%3Aissue+label%3A%22new+baseline%22>`_"
" baseline请求。如果您发现了自己想做的baseline，而它还没有被分配，请随时把它分配给自己，然后开始工作！"

#: ../../source/contributor-ref-good-first-contributions.rst:30
msgid ""
"Otherwise, if you don't find a baseline you'd like to work on, be sure to"
" open a new issue with the baseline request template!"
msgstr "如果您没有找到想要做的baseline，请务必使用baseline请求模板打开一个新问题（GitHub issue）！"

#: ../../source/contributor-ref-good-first-contributions.rst:34
msgid "Request for examples"
msgstr "示例请求"

#: ../../source/contributor-ref-good-first-contributions.rst:36
msgid ""
"We wish we had more time to write usage examples because we believe they "
"help users to get started with building what they want to build. Here are"
" a few ideas where we'd be happy to accept a PR:"
msgstr "我们希望有更多的时间来撰写使用示例，因为我们相信这些示例可以帮助用户开始构建他们想要的东西。以下是我们乐意接受 PR 的几个想法："

#: ../../source/contributor-ref-good-first-contributions.rst:40
msgid "Llama 2 fine-tuning, with Hugging Face Transformers and PyTorch"
msgstr "微调 Llama 2，使用 Hugging Face Transformers 和 PyTorch"

#: ../../source/contributor-ref-good-first-contributions.rst:41
#: ../../source/tutorial-quickstart-xgboost.rst:7
msgid "XGBoost"
msgstr "XGBoost"

#: ../../source/contributor-ref-good-first-contributions.rst:42
msgid "Android ONNX on-device training"
msgstr "安卓 ONNX 设备上训练"

#: ../../source/contributor-ref-secure-aggregation-protocols.rst:2
msgid "Secure Aggregation Protocols"
msgstr "安全聚合协议"

#: ../../source/contributor-ref-secure-aggregation-protocols.rst:6
msgid ""
"While this term might be used in other places, here it refers to a series"
" of protocols, including ``SecAgg``, ``SecAgg+``, ``LightSecAgg``, "
"``FastSecAgg``, etc. This concept was first proposed by Bonawitz et al. "
"in `Practical Secure Aggregation for Federated Learning on User-Held Data"
" <https://arxiv.org/abs/1611.04482>`_."
msgstr ""

#: ../../source/contributor-ref-secure-aggregation-protocols.rst:11
msgid ""
"Secure Aggregation protocols are used to securely aggregate model updates"
" from multiple clients while keeping the updates private. This is done by"
" encrypting the model updates before sending them to the server. The "
"server can decrypt only the aggregated model update without being able to"
" inspect individual updates."
msgstr ""

#: ../../source/contributor-ref-secure-aggregation-protocols.rst:16
msgid ""
"Flower now provides the ``SecAgg`` and ``SecAgg+`` protocols. While we "
"plan to implement more protocols in the future, one may also implement "
"their own custom secure aggregation protocol via low-level APIs."
msgstr ""

#: ../../source/contributor-ref-secure-aggregation-protocols.rst:21
msgid "The ``SecAgg+`` protocol in Flower"
msgstr ""

#: ../../source/contributor-ref-secure-aggregation-protocols.rst:23
msgid ""
"The ``SecAgg+`` protocol is implemented using the ``SecAggPlusWorkflow`` "
"in the ``ServerApp`` and the ``secaggplus_mod`` in the ``ClientApp``. The"
" ``SecAgg`` protocol is a special case of the ``SecAgg+`` protocol, and "
"one may use ``SecAggWorkflow`` and ``secagg_mod`` for that."
msgstr ""

#: ../../source/contributor-ref-secure-aggregation-protocols.rst:28
msgid ""
"You may find a detailed example in the `Secure Aggregation Example "
"<https://flower.ai/docs/examples/flower-secure-aggregation.html>`_. The "
"documentation for the ``SecAgg+`` protocol configuration is available at "
"`SecAggPlusWorkflow <https://flower.ai/docs/framework/ref-"
"api/flwr.server.workflow.SecAggPlusWorkflow.html>`_."
msgstr ""

#: ../../source/contributor-ref-secure-aggregation-protocols.rst:33
msgid ""
"The logic of the ``SecAgg+`` protocol is illustrated in the following "
"sequence diagram: the dashed lines represent communication over the "
"network, and the solid lines represent communication within the same "
"process. The ``ServerApp`` is connected to ``SuperLink``, and the "
"``ClientApp`` is connected to the ``SuperNode``; thus, the communication "
"between the ``ServerApp`` and the ``ClientApp`` is done via the "
"``SuperLink`` and the ``SuperNode``."
msgstr ""

#: ../../source/contributor-tutorial-contribute-on-github.rst:2
msgid "Contribute on GitHub"
msgstr "在 GitHub 上投稿"

#: ../../source/contributor-tutorial-contribute-on-github.rst:4
msgid ""
"This guide is for people who want to get involved with Flower, but who "
"are not used to contributing to GitHub projects."
msgstr "本指南适用于想参与 Flower，但不习惯为 GitHub 项目贡献的人。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:7
#, fuzzy
msgid ""
"If you're familiar with how contributing on GitHub works, you can "
"directly checkout our :doc:`getting started guide for contributors "
"<contributor-tutorial-get-started-as-a-contributor>`."
msgstr ""
"如果您熟悉如何在 GitHub 上贡献，可以直接查看我们的 \"贡献者入门指南\" <https://flower.ai/docs"
"/getting-started-for-contributors.html>`_ 和 \"优秀的首次贡献示例\" "
"<https://flower.ai/docs/good-first-contributions.html>`_。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:12
msgid "Setting up the repository"
msgstr "建立资源库"

#: ../../source/contributor-tutorial-contribute-on-github.rst:29
msgid "**Create a GitHub account and setup Git**"
msgstr "**创建 GitHub 账户并设置 Git**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:15
#, fuzzy
msgid ""
"Git is a distributed version control tool. This allows for an entire "
"codebase's history to be stored and every developer's machine. It is a "
"software that will need to be installed on your local machine, you can "
"follow this `guide <https://docs.github.com/en/get-started/getting-"
"started-with-git/set-up-git>`_ to set it up."
msgstr ""
"Git 是一种分布式版本控制工具。它可以将整个代码库的历史记录保存在每个开发人员的机器上。您需要在本地计算机上安装该软件，可以按照本指南 "
"<https://docs.github.com/en/get-started/quickstart/set-up-git>`_ 进行设置。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:21
msgid ""
"GitHub, itself, is a code hosting platform for version control and "
"collaboration. It allows for everyone to collaborate and work from "
"anywhere on remote repositories."
msgstr "GitHub 本身是一个用于版本控制和协作的代码托管平台。它允许每个人在任何地方对远程仓库进行协作和工作。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:25
msgid ""
"If you haven't already, you will need to create an account on `GitHub "
"<https://github.com/signup>`_."
msgstr "如果还没有，您需要在 `GitHub <https://github.com/signup>`_ 上创建一个账户。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:28
msgid ""
"The idea behind the generic Git and GitHub workflow boils down to this: "
"you download code from a remote repository on GitHub, make changes "
"locally and keep track of them using Git and then you upload your new "
"history back to GitHub."
msgstr ""
"通用的 Git 和 GitHub 工作流程背后的理念可以归结为：从 GitHub 上的远程仓库下载代码，在本地进行修改并使用 Git "
"进行跟踪，然后将新的历史记录上传回 GitHub。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:42
msgid "**Forking the Flower repository**"
msgstr "**叉花仓库**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:32
#, fuzzy
msgid ""
"A fork is a personal copy of a GitHub repository. To create one for "
"Flower, you must navigate to https://github.com/adap/flower (while "
"connected to your GitHub account) and click the ``Fork`` button situated "
"on the top right of the page."
msgstr ""
"fork 是 GitHub 仓库的个人副本。要为 Flower 创建一个 fork，您必须导航到 "
"https://github.com/adap/flower（同时连接到您的 GitHub 账户），然后点击页面右上方的 ``Fork`` 按钮。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:38
msgid ""
"You can change the name if you want, but this is not necessary as this "
"version of Flower will be yours and will sit inside your own account "
"(i.e., in your own list of repositories). Once created, you should see on"
" the top left corner that you are looking at your own version of Flower."
msgstr ""
"您可以更改名称，但没有必要，因为这个版本的 Flower "
"将是您自己的，并位于您自己的账户中（即，在您自己的版本库列表中）。创建完成后，您会在左上角看到自己的 Flower 版本。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:59
msgid "**Cloning your forked repository**"
msgstr "**克隆你的分叉仓库**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:45
msgid ""
"The next step is to download the forked repository on your machine to be "
"able to make changes to it. On your forked repository page, you should "
"first click on the ``Code`` button on the right, this will give you the "
"ability to copy the HTTPS link of the repository."
msgstr ""
"下一步是在你的机器上下载分叉版本库，以便对其进行修改。在分叉版本库页面上，首先点击右侧的 \"代码 \"按钮，这样就能复制版本库的 HTTPS "
"链接。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:52
msgid ""
"Once you copied the \\<URL\\>, you can open a terminal on your machine, "
"navigate to the place you want to download the repository to and type:"
msgstr "一旦复制了 （<URL\\>），你就可以在你的机器上打开一个终端，导航到你想下载软件源的地方，然后键入："

#: ../../source/contributor-tutorial-contribute-on-github.rst:59
#, fuzzy
msgid ""
"This will create a ``flower/`` (or the name of your fork if you renamed "
"it) folder in the current working directory."
msgstr "这将在当前工作目录下创建一个 `flower/`（如果重命名了，则使用 fork 的名称）文件夹。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:78
msgid "**Add origin**"
msgstr "**添加原产地**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:62
msgid "You can then go into the repository folder:"
msgstr "然后，您就可以进入存储库文件夹："

#: ../../source/contributor-tutorial-contribute-on-github.rst:68
msgid ""
"And here we will need to add an origin to our repository. The origin is "
"the \\<URL\\> of the remote fork repository. To obtain it, we can do as "
"previously mentioned by going to our fork repository on our GitHub "
"account and copying the link."
msgstr ""
"在这里，我们需要为我们的版本库添加一个 origin。origin 是远程 fork 仓库的 "
"\\<URL/>。要获得它，我们可以像前面提到的那样，访问 GitHub 账户上的分叉仓库并复制链接。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:75
msgid ""
"Once the \\<URL\\> is copied, we can type the following command in our "
"terminal:"
msgstr "一旦复制了 \\<URL\\> ，我们就可以在终端中键入以下命令："

#: ../../source/contributor-tutorial-contribute-on-github.rst:102
msgid "**Add upstream**"
msgstr "**增加上游**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:81
#, fuzzy
msgid ""
"Now we will add an upstream address to our repository. Still in the same "
"directory, we must run the following command:"
msgstr "现在，我们要为版本库添加一个上游地址。还是在同一目录下，我们必须运行以下命令："

#: ../../source/contributor-tutorial-contribute-on-github.rst:88
msgid "The following diagram visually explains what we did in the previous steps:"
msgstr "下图直观地解释了我们在前面步骤中的操作："

#: ../../source/contributor-tutorial-contribute-on-github.rst:92
msgid ""
"The upstream is the GitHub remote address of the parent repository (in "
"this case Flower), i.e. the one we eventually want to contribute to and "
"therefore need an up-to-date history of. The origin is just the GitHub "
"remote address of the forked repository we created, i.e. the copy (fork) "
"in our own account."
msgstr ""
"上游是父版本库（这里是 Flower）的 GitHub 远程地址，即我们最终要贡献的版本库，因此需要最新的历史记录。origin "
"只是我们创建的分叉仓库的 GitHub 远程地址，即我们自己账户中的副本（分叉）。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:97
msgid ""
"To make sure our local version of the fork is up-to-date with the latest "
"changes from the Flower repository, we can execute the following command:"
msgstr "为了确保本地版本的分叉程序与 Flower 代码库的最新更改保持一致，我们可以执行以下命令："

#: ../../source/contributor-tutorial-contribute-on-github.rst:105
msgid "Setting up the coding environment"
msgstr "设置编码环境"

#: ../../source/contributor-tutorial-contribute-on-github.rst:107
#, fuzzy
msgid ""
"This can be achieved by following this :doc:`getting started guide for "
"contributors <contributor-tutorial-get-started-as-a-contributor>` (note "
"that you won't need to clone the repository). Once you are able to write "
"code and test it, you can finally start making changes!"
msgstr "您可以按照这份 \"贡献者入门指南\"__（注意，您不需要克隆版本库）来实现这一点。一旦您能够编写代码并进行测试，您就可以开始修改了！"

#: ../../source/contributor-tutorial-contribute-on-github.rst:113
msgid "Making changes"
msgstr "做出改变"

#: ../../source/contributor-tutorial-contribute-on-github.rst:115
msgid ""
"Before making any changes make sure you are up-to-date with your "
"repository:"
msgstr "在进行任何更改之前，请确保您的版本库是最新的："

#: ../../source/contributor-tutorial-contribute-on-github.rst:121
msgid "And with Flower's repository:"
msgstr "还有Flower的存储库："

#: ../../source/contributor-tutorial-contribute-on-github.rst:134
msgid "**Create a new branch**"
msgstr "**创建一个新分支**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:128
msgid ""
"To make the history cleaner and easier to work with, it is good practice "
"to create a new branch for each feature/project that needs to be "
"implemented."
msgstr "为了使历史记录更简洁、更易于操作，为每个需要实现的功能/项目创建一个新分支是个不错的做法。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:131
msgid ""
"To do so, just run the following command inside the repository's "
"directory:"
msgstr "为此，只需在版本库目录下运行以下命令即可："

#: ../../source/contributor-tutorial-contribute-on-github.rst:136
msgid "**Make changes**"
msgstr "**进行修改**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:137
msgid "Write great code and create wonderful changes using your favorite editor!"
msgstr "使用您最喜欢的编辑器编写优秀的代码并创建精彩的更改！"

#: ../../source/contributor-tutorial-contribute-on-github.rst:149
msgid "**Test and format your code**"
msgstr "**测试并格式化您的代码**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:139
msgid ""
"Don't forget to test and format your code! Otherwise your code won't be "
"able to be merged into the Flower repository. This is done so the "
"codebase stays consistent and easy to understand."
msgstr "不要忘记测试和格式化您的代码！否则您的代码将无法并入 Flower 代码库。这样做是为了使代码库保持一致并易于理解。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:143
msgid "To do so, we have written a few scripts that you can execute:"
msgstr "为此，我们编写了一些脚本供您执行："

#: ../../source/contributor-tutorial-contribute-on-github.rst:162
msgid "**Stage changes**"
msgstr "**舞台变化**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:152
msgid ""
"Before creating a commit that will update your history, you must specify "
"to Git which files it needs to take into account."
msgstr "在创建更新历史记录的提交之前，必须向 Git 说明需要考虑哪些文件。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:155
msgid "This can be done with:"
msgstr "这可以通过："

#: ../../source/contributor-tutorial-contribute-on-github.rst:161
#, fuzzy
msgid ""
"To check which files have been modified compared to the last version "
"(last commit) and to see which files are staged for commit, you can use "
"the ``git status`` command."
msgstr "要查看与上一版本（上次提交）相比哪些文件已被修改，以及哪些文件处于提交阶段，可以使用 :code:`git status` 命令。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:173
msgid "**Commit changes**"
msgstr "**提交更改**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:165
#, fuzzy
msgid ""
"Once you have added all the files you wanted to commit using ``git add``,"
" you can finally create your commit using this command:"
msgstr "使用 :code:`git add` 添加完所有要提交的文件后，就可以使用此命令创建提交了："

#: ../../source/contributor-tutorial-contribute-on-github.rst:172
#, fuzzy
msgid ""
"The \\<commit_message\\> is there to explain to others what the commit "
"does. It should be written in an imperative style and be concise. An "
"example would be ``git commit -m \"Add images to README\"``."
msgstr ""
"<commit_message\\> 用于向他人解释提交的作用。它应该以命令式风格书写，并且简明扼要。例如 :code:`git commit "
"-m \"Add images to README\"`。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:185
msgid "**Push the changes to the fork**"
msgstr "**将更改推送到分叉**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:176
msgid ""
"Once we have committed our changes, we have effectively updated our local"
" history, but GitHub has no way of knowing this unless we push our "
"changes to our origin's remote address:"
msgstr "一旦提交了修改，我们就有效地更新了本地历史记录，但除非我们将修改推送到原点的远程地址，否则 GitHub 无法得知："

#: ../../source/contributor-tutorial-contribute-on-github.rst:184
msgid ""
"Once this is done, you will see on the GitHub that your forked repo was "
"updated with the changes you have made."
msgstr "完成此操作后，您将在 GitHub 上看到您的分叉仓库已根据您所做的更改进行了更新。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:188
msgid "Creating and merging a pull request (PR)"
msgstr "创建和合并拉取请求 (PR)"

#: ../../source/contributor-tutorial-contribute-on-github.rst:226
msgid "**Create the PR**"
msgstr "**创建 PR**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:191
msgid ""
"Once you have pushed changes, on the GitHub webpage of your repository "
"you should see the following message:"
msgstr "推送更改后，在仓库的 GitHub 网页上应该会看到以下信息："

#: ../../source/contributor-tutorial-contribute-on-github.rst:196
#, fuzzy
msgid "Otherwise you can always find this option in the ``Branches`` page."
msgstr "否则，您可以在 \"分支 \"页面找到该选项。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:198
#, fuzzy
msgid ""
"Once you click the ``Compare & pull request`` button, you should see "
"something similar to this:"
msgstr "点击 \"比较和拉取请求 \"按钮后，您应该会看到类似下面的内容："

#: ../../source/contributor-tutorial-contribute-on-github.rst:203
msgid "At the top you have an explanation of which branch will be merged where:"
msgstr "在顶部，你可以看到关于哪个分支将被合并的说明："

#: ../../source/contributor-tutorial-contribute-on-github.rst:207
msgid ""
"In this example you can see that the request is to merge the branch "
"``doc-fixes`` from my forked repository to branch ``main`` from the "
"Flower repository."
msgstr "在这个例子中，你可以看到请求将我分叉的版本库中的分支 ``doc-fixes`` 合并到 Flower 版本库中的分支 ``main``。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:210
#, fuzzy
msgid ""
"The title should be changed to adhere to the :ref:`pr_title_format` "
"guidelines, otherwise it won't be possible to merge the PR. So in this "
"case, a correct title might be ``docs(framework:skip) Fix typos``."
msgstr ""
"应该修改标题以符合 :ref:`pr_title_format` 准则，否则将无法合并 PR。因此，在这种情况下，正确的标题可能是 "
"``docs(framework:skip)修复错字``。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:214
msgid ""
"The input box in the middle is there for you to describe what your PR "
"does and to link it to existing issues. We have placed comments (that "
"won't be rendered once the PR is opened) to guide you through the "
"process."
msgstr "中间的输入框供您描述 PR 的作用，并将其与现有问题联系起来。我们在此放置了注释（一旦 PR 打开，注释将不会显示），以指导您完成整个过程。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:218
#, fuzzy
msgid "It is important to follow the instructions described in comments."
msgstr "请务必遵守注释中的说明。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:220
msgid ""
"At the bottom you will find the button to open the PR. This will notify "
"reviewers that a new PR has been opened and that they should look over it"
" to merge or to request changes."
msgstr "在底部，您可以找到打开 PR 的按钮。这将通知审核人员新的 PR 已经打开，他们应该查看该 PR 以进行合并或要求修改。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:224
msgid ""
"If your PR is not yet ready for review, and you don't want to notify "
"anyone, you have the option to create a draft pull request:"
msgstr "如果您的 PR 尚未准备好接受审核，而且您不想通知任何人，您可以选择创建一个草案拉取请求："

#: ../../source/contributor-tutorial-contribute-on-github.rst:230
msgid "**Making new changes**"
msgstr "**作出新的改变**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:229
msgid ""
"Once the PR has been opened (as draft or not), you can still push new "
"commits to it the same way we did before, by making changes to the branch"
" associated with the PR."
msgstr "一旦 PR 被打开（无论是否作为草案），你仍然可以像以前一样，通过修改与 PR 关联的分支来推送新的提交。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:253
msgid "**Review the PR**"
msgstr "**审查 PR**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:233
msgid ""
"Once the PR has been opened or once the draft PR has been marked as "
"ready, a review from code owners will be automatically requested:"
msgstr "一旦 PR 被打开或 PR 草案被标记为就绪，就会自动要求代码所有者进行审核："

#: ../../source/contributor-tutorial-contribute-on-github.rst:238
msgid ""
"Code owners will then look into the code, ask questions, request changes "
"or validate the PR."
msgstr "然后，代码所有者会查看代码、提出问题、要求修改或验证 PR。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:241
msgid "Merging will be blocked if there are ongoing requested changes."
msgstr "如果有正在进行的更改请求，合并将被阻止。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:245
msgid ""
"To resolve them, just push the necessary changes to the branch associated"
" with the PR:"
msgstr "要解决这些问题，只需将必要的更改推送到与 PR 关联的分支即可："

#: ../../source/contributor-tutorial-contribute-on-github.rst:250
msgid "And resolve the conversation:"
msgstr "并解决对话："

#: ../../source/contributor-tutorial-contribute-on-github.rst:254
msgid ""
"Once all the conversations have been resolved, you can re-request a "
"review."
msgstr "一旦所有对话都得到解决，您就可以重新申请审核。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:274
msgid "**Once the PR is merged**"
msgstr "**一旦 PR 被合并**"

#: ../../source/contributor-tutorial-contribute-on-github.rst:256
msgid ""
"If all the automatic tests have passed and reviewers have no more changes"
" to request, they can approve the PR and merge it."
msgstr "如果所有自动测试都已通过，且审核员不再需要修改，他们就可以批准 PR 并将其合并。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:261
msgid ""
"Once it is merged, you can delete the branch on GitHub (a button should "
"appear to do so) and also delete it locally by doing:"
msgstr "合并后，您可以在 GitHub 上删除该分支（会出现一个删除按钮），也可以在本地删除该分支："

#: ../../source/contributor-tutorial-contribute-on-github.rst:269
msgid "Then you should update your forked repository by doing:"
msgstr "然后，你应该更新你的分叉仓库："

#: ../../source/contributor-tutorial-contribute-on-github.rst:277
msgid "Example of first contribution"
msgstr "首次捐款实例"

#: ../../source/contributor-tutorial-contribute-on-github.rst:280
msgid "Problem"
msgstr "问题"

#: ../../source/contributor-tutorial-contribute-on-github.rst:282
#, fuzzy
msgid ""
"For our documentation, we've started to use the `Diàtaxis framework "
"<https://diataxis.fr/>`_."
msgstr "对于我们的文档，我们已经开始使用 \"Diàtaxis 框架 <https://diataxis.fr/>`_\"。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:285
#, fuzzy
msgid ""
"Our \"How to\" guides should have titles that continue the sentence \"How"
" to …\", for example, \"How to upgrade to Flower 1.0\"."
msgstr "我们的 \"如何 \"指南的标题应延续 \"如何...... \"的句式，例如 \"如何升级到 Flower 1.0\"。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:288
msgid ""
"Most of our guides do not follow this new format yet, and changing their "
"title is (unfortunately) more involved than one might think."
msgstr "我们的大多数指南还没有采用这种新格式，而更改其标题（不幸的是）比人们想象的要复杂得多。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:291
#, fuzzy
msgid ""
"This issue is about changing the title of a doc from present continuous "
"to present simple."
msgstr "这个问题是关于将文档标题从现在进行时改为现在进行时。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:294
#, fuzzy
msgid ""
"Let's take the example of \"Saving Progress\" which we changed to \"Save "
"Progress\". Does this pass our check?"
msgstr "以 \"保存进度 \"为例，我们将其改为 \"保存进度\"。这是否通过了我们的检查？"

#: ../../source/contributor-tutorial-contribute-on-github.rst:297
#, fuzzy
msgid "Before: \"How to saving progress\" ❌"
msgstr "之前： \"如何保存进度\" ❌"

#: ../../source/contributor-tutorial-contribute-on-github.rst:299
#, fuzzy
msgid "After: \"How to save progress\" ✅"
msgstr "之后： \"如何保存进度\"✅"

#: ../../source/contributor-tutorial-contribute-on-github.rst:302
msgid "Solution"
msgstr "解决方案"

#: ../../source/contributor-tutorial-contribute-on-github.rst:304
#, fuzzy
msgid ""
"This is a tiny change, but it'll allow us to test your end-to-end setup. "
"After cloning and setting up the Flower repo, here's what you should do:"
msgstr "这只是一个很小的改动，但可以让我们测试你的端到端设置。克隆并设置好 Flower repo 后，你应该这样做："

#: ../../source/contributor-tutorial-contribute-on-github.rst:307
#, fuzzy
msgid "Find the source file in ``doc/source``"
msgstr "在 `doc/source` 中查找源文件"

#: ../../source/contributor-tutorial-contribute-on-github.rst:308
#, fuzzy
msgid ""
"Make the change in the ``.rst`` file (beware, the dashes under the title "
"should be the same length as the title itself)"
msgstr "在 `.rst` 文件中进行修改（注意，标题下的破折号应与标题本身的长度相同）"

#: ../../source/contributor-tutorial-contribute-on-github.rst:310
#, fuzzy
msgid ""
"Build the docs and `check the result <contributor-how-to-write-"
"documentation.html#edit-an-existing-page>`_"
msgstr ""
"构建文档并检查结果： `<https://flower.ai/docs/writing-documentation.html#edit-an-"
"existing-page>`_"

#: ../../source/contributor-tutorial-contribute-on-github.rst:314
msgid "Rename file"
msgstr "重命名文件"

#: ../../source/contributor-tutorial-contribute-on-github.rst:316
msgid ""
"You might have noticed that the file name still reflects the old wording."
" If we just change the file, then we break all existing links to it - it "
"is **very important** to avoid that, breaking links can harm our search "
"engine ranking."
msgstr ""
"您可能已经注意到，文件名仍然反映了旧的措辞。如果我们只是更改文件，那么就会破坏与该文件的所有现有链接--"
"避免这种情况是***重要的，破坏链接会损害我们的搜索引擎排名。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:320
#, fuzzy
msgid "Here's how to change the file name:"
msgstr "下面是更改文件名的方法："

#: ../../source/contributor-tutorial-contribute-on-github.rst:322
#, fuzzy
msgid "Change the file name to ``save-progress.rst``"
msgstr "将文件名改为`save-progress.rst`"

#: ../../source/contributor-tutorial-contribute-on-github.rst:323
#, fuzzy
msgid "Add a redirect rule to ``doc/source/conf.py``"
msgstr "在 `doc/source/conf.py` 中添加重定向规则"

#: ../../source/contributor-tutorial-contribute-on-github.rst:325
#, fuzzy
msgid ""
"This will cause a redirect from ``saving-progress.html`` to ``save-"
"progress.html``, old links will continue to work."
msgstr "这将导致从 `saving-progress.html` 重定向到 `save-progress.html`，旧链接将继续工作。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:329
msgid "Apply changes in the index file"
msgstr "应用索引文件中的更改"

#: ../../source/contributor-tutorial-contribute-on-github.rst:331
#, fuzzy
msgid ""
"For the lateral navigation bar to work properly, it is very important to "
"update the ``index.rst`` file as well. This is where we define the whole "
"arborescence of the navbar."
msgstr "要使横向导航栏正常工作，更新 `index.rst` 文件也非常重要。我们就是在这里定义整个导航栏的结构。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:335
#, fuzzy
msgid "Find and modify the file name in ``index.rst``"
msgstr "查找并修改 `index.rst` 中的文件名"

#: ../../source/contributor-tutorial-contribute-on-github.rst:338
msgid "Open PR"
msgstr "开放式 PR"

#: ../../source/contributor-tutorial-contribute-on-github.rst:340
#, fuzzy
msgid ""
"Commit the changes (commit messages are always imperative: \"Do "
"something\", in this case \"Change …\")"
msgstr "提交更改（提交信息总是命令式的：\"做某事\"，这里是 \"更改......\"）"

#: ../../source/contributor-tutorial-contribute-on-github.rst:342
msgid "Push the changes to your fork"
msgstr "将更改推送到分叉"

#: ../../source/contributor-tutorial-contribute-on-github.rst:343
#, fuzzy
msgid ""
"Open a PR (as shown above) with title ``docs(framework) Update how-to "
"guide title``"
msgstr "打开一个 PR（如上图所示），标题为\"`docs(framework) Update how-to guide title```\"。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:344
msgid "Wait for it to be approved!"
msgstr "等待审批！"

#: ../../source/contributor-tutorial-contribute-on-github.rst:345
msgid "Congrats! 🥳 You're now officially a Flower contributor!"
msgstr "祝贺你 🥳 您现在正式成为 \"Flower \"贡献者！"

#: ../../source/contributor-tutorial-contribute-on-github.rst:348
#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:573
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:1012
#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:811
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:857
#: ../../source/tutorial-series-what-is-federated-learning.ipynb:367
msgid "Next steps"
msgstr "接下来的步骤"

#: ../../source/contributor-tutorial-contribute-on-github.rst:350
msgid ""
"Once you have made your first PR, and want to contribute more, be sure to"
" check out the following :"
msgstr "一旦您完成了第一份 PR，并希望做出更多贡献，请务必查看以下内容："

#: ../../source/contributor-tutorial-contribute-on-github.rst:353
#, fuzzy
msgid ""
":doc:`Good first contributions <contributor-ref-good-first-"
"contributions>`, where you should particularly look into the "
"``baselines`` contributions."
msgstr ""
"`优秀的首次贡献 <https://flower.ai/docs/framework/contributor-ref-good-first-"
"contributions.html>`_，在这里你应该特别看看 :code:`baselines` 的贡献。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:357
msgid "Appendix"
msgstr "附录"

#: ../../source/contributor-tutorial-contribute-on-github.rst:362
#, fuzzy
msgid "PR title format"
msgstr "PR 标题格式"

#: ../../source/contributor-tutorial-contribute-on-github.rst:364
#, fuzzy
msgid "We enforce the following PR title format:"
msgstr "我们执行以下 PR 标题格式："

#: ../../source/contributor-tutorial-contribute-on-github.rst:370
#, fuzzy
msgid ""
"(or ``<type>(<project>:skip) <subject>`` to ignore the PR in the "
"changelog)"
msgstr "(或 ``<type>(<project>:skip) <subject>`` 忽略更新日志中的 PR）。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:372
#, fuzzy
msgid ""
"Where ``<type>`` needs to be in ``{ci, fix, feat, docs, refactor, "
"break}``, ``<project>`` should be in ``{framework, baselines, datasets, "
"examples, or '*' when modifying multiple projects which requires the "
"':skip' flag to be used}``, and ``<subject>`` starts with a capitalised "
"verb in the imperative mood."
msgstr ""
"其中 ``<type>`` 需要使用 ``{ci, fix, feat, docs, refactor, break}``, "
"``<project>`` 应该使用 ``{framework, baselines, datasets, examples, 或者 '*' "
"当修改多个项目时需要使用 ':skip'标记}``, 并且 ``<subject>`` 应该以一个大写的动词开始。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:377
#, fuzzy
msgid "Valid examples:"
msgstr "实例"

#: ../../source/contributor-tutorial-contribute-on-github.rst:379
#, fuzzy
msgid "``feat(framework) Add flwr build CLI command``"
msgstr "`feat(框架) 添加 flwr build CLI 命令```"

#: ../../source/contributor-tutorial-contribute-on-github.rst:380
#, fuzzy
msgid "``refactor(examples:skip) Improve quickstart-pytorch logging``"
msgstr "``refactor(examples:skip) Improve quickstart-pytorch logging``."

#: ../../source/contributor-tutorial-contribute-on-github.rst:381
#, fuzzy
msgid "``ci(*:skip) Enforce PR title format``"
msgstr "`ci(*:skip)执行 PR 标题格式``。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:383
#, fuzzy
msgid "Invalid examples:"
msgstr "模拟示例"

#: ../../source/contributor-tutorial-contribute-on-github.rst:385
#, fuzzy
msgid "``feat(framework): Add flwr build CLI command`` (extra ``:``)"
msgstr "`feat(框架)： 添加 flwr build CLI 命令``（额外的``:``)"

#: ../../source/contributor-tutorial-contribute-on-github.rst:386
#, fuzzy
msgid ""
"``feat(*) Add flwr build CLI command`` (missing ``skip`` flag along with "
"``*``)"
msgstr "`feat(*)添加flwr构建CLI命令``（缺少``skip``标志和``*``）。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:387
#, fuzzy
msgid "``feat(skip) Add flwr build CLI command`` (missing ``<project>``)"
msgstr "`feat(skip)添加flwr构建CLI命令``（缺少``<project>`）。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:388
#, fuzzy
msgid "``feat(framework) add flwr build CLI command`` (non capitalised verb)"
msgstr "`feat(framework)添加 flwr 构建 CLI 命令``（非大写动词）"

#: ../../source/contributor-tutorial-contribute-on-github.rst:389
#, fuzzy
msgid "``feat(framework) Add flwr build CLI command.`` (dot at the end)"
msgstr "feat(框架) 添加 flwr 构建 CLI 命令。"

#: ../../source/contributor-tutorial-contribute-on-github.rst:390
#, fuzzy
msgid "``Add flwr build CLI command.`` (missing ``<type>(<project>)``)"
msgstr ""
"``添加 flwr build CLI 命令.``（缺少``<type>(<project>)``） ``Add flwr build CLI "
"command.`` (missing ``<type>(<project>)``)"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:2
msgid "Get started as a contributor"
msgstr "成为贡献者"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:5
#: ../../source/docker/run-as-subprocess.rst:11
#: ../../source/docker/run-quickstart-examples-docker-compose.rst:16
#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:18
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:13
#: ../../source/docker/tutorial-quickstart-docker.rst:11
msgid "Prerequisites"
msgstr "先决条件"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:7
#, fuzzy
msgid "`Python 3.9 <https://docs.python.org/3.9/>`_ or above"
msgstr "Python 3.9 <https://docs.python.org/3.9/>`_ 或更高版本"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:8
msgid "`Poetry 1.3 <https://python-poetry.org/>`_ or above"
msgstr "`Poetry 1.3 <https://python-poetry.org/>`_ 或更高版本"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:9
msgid "(Optional) `pyenv <https://github.com/pyenv/pyenv>`_"
msgstr "(可选） `pyenv <https://github.com/pyenv/pyenv>`_"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:10
msgid "(Optional) `pyenv-virtualenv <https://github.com/pyenv/pyenv-virtualenv>`_"
msgstr "(可选） `pyenv-virtualenv <https://github.com/pyenv/pyenv-virtualenv>`_"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:12
#, fuzzy
msgid ""
"Flower uses ``pyproject.toml`` to manage dependencies and configure "
"development tools (the ones which support it). Poetry is a build tool "
"which supports `PEP 517 <https://peps.python.org/pep-0517/>`_."
msgstr ""
"Flower 使用 :code:`pyproject.toml` 来管理依赖关系和配置开发工具（支持它的）。Poetry 是一种支持 `PEP "
"517 <https://www.python.org/dev/peps/pep-0517/>`_ 的构建工具。"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:17
msgid "Developer Machine Setup"
msgstr "开发者机器设置"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:20
#, fuzzy
msgid "Preliminaries"
msgstr "前言"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:22
#, fuzzy
msgid "Some system-wide dependencies are needed."
msgstr "需要一些全系统依赖性。"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:25
#, fuzzy
msgid "For macOS"
msgstr "适用于 macOS"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:27
#, fuzzy
msgid ""
"Install `homebrew <https://brew.sh/>`_. Don't forget the post-"
"installation actions to add `brew` to your PATH."
msgstr "安装 `homebrew <https://brew.sh/>`_。别忘了安装后的操作，将 `brew` 添加到你的 PATH。"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:29
#, fuzzy
msgid ""
"Install `xz` (to install different Python versions) and `pandoc` to build"
" the docs:"
msgstr "安装 `xz`（用于安装不同的 Python 版本）和 `pandoc` 以构建文档：："

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:36
#, fuzzy
msgid "For Ubuntu"
msgstr "针对 Ubuntu"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:38
#, fuzzy
msgid ""
"Ensure you system (Ubuntu 22.04+) is up-to-date, and you have all "
"necessary packages:"
msgstr "确保您的系统（Ubuntu 22.04+）为最新版本，并安装了所有必要的软件包：："

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:47
#, fuzzy
msgid "Create Flower Dev Environment"
msgstr "创建/删除虚拟环境"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:49
#, fuzzy
msgid ""
"Clone the `Flower repository <https://github.com/adap/flower>`_ from "
"GitHub:"
msgstr "首先，从 GitHub 克隆 \"Flower 存储库 <https://github.com/adap/flower>`_\"："

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:56
#, fuzzy
msgid ""
"Let's create the Python environment for all-things Flower. If you wish to"
" use ``pyenv``, we provide two convenience scripts that you can use. If "
"you prefer using something else than ``pyenv``, create a new environment,"
" activate and skip to the last point where all packages are installed."
msgstr ""
"让我们为 Flower 创建一个 Python 环境。如果您想使用 :code:`pyenv`，我们提供了两个方便的脚本供您使用。如果你不喜欢使用"
" :code:`pyenv`，请创建一个新环境，激活并跳到最后一点，即安装所有软件包。"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:61
#, fuzzy
msgid ""
"If you don't have ``pyenv`` installed, the following script that will "
"install it, set it up, and create the virtual environment (with "
":substitution-code:`Python |python_full_version|` by default):"
msgstr ""
"如果没有安装 :code:`pyenv`，可以使用以下脚本安装 pyenv、设置并创建虚拟环境（默认使用 :code:`Python "
"3.9.20）：："

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:69
#, fuzzy
msgid ""
"If you already have ``pyenv`` installed (along with the ``pyenv-"
"virtualenv`` plugin), you can use the following convenience script (with "
":substitution-code:`Python |python_full_version|` by default):"
msgstr ""
"如果没有安装 :code:`pyenv`，可以使用以下脚本安装 pyenv、设置并创建虚拟环境（默认使用 :code:`Python "
"3.9.20）：："

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:77
#, fuzzy
msgid ""
"3. Install the Flower package in development mode (think ``pip install "
"-e``) along with all necessary dependencies:"
msgstr "第三，在开发模式下安装 Flower 软件包（想想 :code:`pip install -e`）以及所有必要的依赖项：："

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:85
msgid "Convenience Scripts"
msgstr "便捷脚本"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:87
#, fuzzy
msgid ""
"The Flower repository contains a number of convenience scripts to make "
"recurring development tasks easier and less error-prone. See the ``/dev``"
" subdirectory for a full list. The following scripts are amongst the most"
" important ones:"
msgstr "Flower 软件仓库包含大量便捷脚本，可使重复性开发任务更轻松、更不易出错。完整列表请参见 :code:`/dev` 子目录。以下是最重要的脚本："

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:92
msgid "Create/Delete Virtual Environment"
msgstr "创建/删除虚拟环境"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:101
msgid "Compile ProtoBuf Definitions"
msgstr "编译 ProtoBuf 定义"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:108
msgid "Auto-Format Code"
msgstr "自动格式化代码"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:115
msgid "Run Linters and Tests"
msgstr "运行分类器和测试"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:122
#, fuzzy
msgid "Add a pre-commit hook"
msgstr "添加预先提交钩子"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:124
#, fuzzy
msgid ""
"Developers may integrate a pre-commit hook into their workflow utilizing "
"the `pre-commit <https://pre-commit.com/#install>`_ library. The pre-"
"commit hook is configured to execute two primary operations: "
"``./dev/format.sh`` and ``./dev/test.sh`` scripts."
msgstr ""
"开发人员可利用 `pre-commit <https://pre-commit.com/#install>`_ "
"库将预提交钩子集成到工作流程中。预提交钩子被配置为执行两个主要操作： `./dev/format.sh`` 和 ``./dev/test.sh``"
" 脚本。"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:128
#, fuzzy
msgid "There are multiple ways developers can use this:"
msgstr "开发人员可以通过多种方式使用它："

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:130
#, fuzzy
msgid "Install the pre-commit hook to your local git directory by simply running:"
msgstr "在本地 git 目录中安装预提交钩子，只需运行"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:136
#, fuzzy
msgid ""
"Each ``git commit`` will trigger the execution of formatting and "
"linting/test scripts."
msgstr "每次 \"git 提交 \"都会触发格式化和内核/测试脚本的执行。"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:138
#, fuzzy
msgid ""
"If in a hurry, bypass the hook using ``--no-verify`` with the ``git "
"commit`` command."
msgstr "如果赶时间，可使用 ``--no-verify`` 和 ``git commit` 命令绕过钩子："

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:145
#, fuzzy
msgid ""
"For developers who prefer not to install the hook permanently, it is "
"possible to execute a one-time check prior to committing changes by using"
" the following command:"
msgstr "对于不想永久安装钩子的开发人员，可以使用以下命令在提交更改之前执行一次性检查："

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:152
#, fuzzy
msgid ""
"This executes the formatting and linting checks/tests on all the files "
"without modifying the default behavior of ``git commit``."
msgstr "这将在不修改 ``git commit`` 默认行为的情况下对所有文件执行格式化和词排检查/测试。"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:156
msgid "Run Github Actions (CI) locally"
msgstr "在本地运行 Github 操作 (CI)"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:158
#, fuzzy
msgid ""
"Developers could run the full set of Github Actions workflows under their"
" local environment by using `Act <https://github.com/nektos/act>`_. "
"Please refer to the installation instructions under the linked repository"
" and run the next command under Flower main cloned repository folder:"
msgstr ""
"开发人员可以使用 `Act <https://github.com/nektos/act>_` 在本地环境下运行全套 Github Actions"
" 工作流程。请参考链接仓库下的安装说明，并在 Flower 主克隆仓库文件夹下运行下一条命令：："

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:167
msgid ""
"The Flower default workflow would run by setting up the required Docker "
"machines underneath."
msgstr "Flower 默认工作流程将通过在下面设置所需的 Docker 机器来运行。"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:171
msgid "Build Release"
msgstr "版本发布"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:173
#, fuzzy
msgid ""
"Flower uses Poetry to build releases. The necessary command is wrapped in"
" a simple script:"
msgstr "Flower 使用 Poetry 创建发布版本。必要的命令封装在一个简单的脚本中：："

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:180
#, fuzzy
msgid ""
"The resulting ``.whl`` and ``.tar.gz`` releases will be stored in the "
"``/dist`` subdirectory."
msgstr "生成的 :code:`.whl` 和 :code:`.tar.gz` 版本将存储在 :code:`/dist` 子目录中。"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:184
msgid "Build Documentation"
msgstr "构建文档"

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:186
#, fuzzy
msgid ""
"Flower's documentation uses `Sphinx <https://www.sphinx-doc.org/>`_. "
"There's no convenience script to re-build the documentation yet, but it's"
" pretty easy:"
msgstr ""
"Flower 的文档使用 `Sphinx <https://www.sphinx-"
"doc.org/>`_。目前还没有很方便的脚本来重新构建文档，不过这很容易：："

#: ../../source/contributor-tutorial-get-started-as-a-contributor.rst:194
msgid "This will generate HTML documentation in ``doc/build/html``."
msgstr "这将在 ``doc/build/html`` 中生成 HTML 文档。"

#: ../../source/docker/enable-tls.rst:2
#, fuzzy
msgid "Enable TLS for Secure Connections"
msgstr "启用 SSL 连接"

#: ../../source/docker/enable-tls.rst:4
msgid ""
"When operating in a production environment, it is strongly recommended to"
" enable Transport Layer Security (TLS) for each Flower Component to "
"ensure secure communication."
msgstr ""

#: ../../source/docker/enable-tls.rst:7
#, fuzzy
msgid ""
"To enable TLS, you will need a PEM-encoded root certificate, a PEM-"
"encoded private key and a PEM-encoded certificate chain."
msgstr "要启用 SSL，需要 CA 证书、服务器证书和服务器私钥。"

#: ../../source/docker/enable-tls.rst:12
#, fuzzy
msgid ""
"For testing purposes, you can generate your own self-signed certificates."
" The `Enable SSL connections <https://flower.ai/docs/framework/how-to-"
"enable-ssl-connections.html#certificates>`__ page contains a section that"
" will guide you through the process."
msgstr ""
"出于测试目的，你可以生成自己的自签名证书。启用 SSL 连接 <https://flower.ai/docs/framework/how-to-"
"enable-ssl-connections.html#certificates>`_ 页面中有一个部分将指导你完成这一过程。"

#: ../../source/docker/enable-tls.rst:17
msgid ""
"Because Flower containers, by default, run with a non-root user ``app``, "
"the mounted files and directories must have the proper permissions for "
"the user ID ``49999``."
msgstr ""

#: ../../source/docker/enable-tls.rst:20
msgid ""
"For example, to change the user ID of all files in the ``certificates/`` "
"directory, you can run ``sudo chown -R 49999:49999 certificates/*``."
msgstr ""

#: ../../source/docker/enable-tls.rst:23
msgid ""
"If you later want to delete the directory, you can change the user ID "
"back to the current user ID by running ``sudo chown -R $USER:$(id -gn) "
"certificates``."
msgstr ""

#: ../../source/docker/enable-tls.rst:27
#, fuzzy
msgid "SuperLink"
msgstr "flower-superlink"

#: ../../source/docker/enable-tls.rst:29
msgid ""
"Assuming all files we need are in the local ``certificates`` directory, "
"we can use the flag ``--volume`` to mount the local directory into the "
"``/app/certificates/`` directory of the container:"
msgstr ""

#: ../../source/docker/enable-tls.rst
#, fuzzy
msgid "Understanding the command"
msgstr "训练模型"

#: ../../source/docker/enable-tls.rst:45 ../../source/docker/enable-tls.rst:92
#: ../../source/docker/enable-tls.rst:125
#: ../../source/docker/tutorial-quickstart-docker.rst:65
#: ../../source/docker/tutorial-quickstart-docker.rst:102
#: ../../source/docker/tutorial-quickstart-docker.rst:216
#: ../../source/docker/tutorial-quickstart-docker.rst:304
#, fuzzy
msgid "``docker run``: This tells Docker to run a container from an image."
msgstr "`docker run``： 这是运行新 Docker 容器的命令。"

#: ../../source/docker/enable-tls.rst:46 ../../source/docker/enable-tls.rst:93
#: ../../source/docker/enable-tls.rst:126
#: ../../source/docker/tutorial-quickstart-docker.rst:66
#: ../../source/docker/tutorial-quickstart-docker.rst:103
#: ../../source/docker/tutorial-quickstart-docker.rst:217
#: ../../source/docker/tutorial-quickstart-docker.rst:305
msgid "``--rm``: Remove the container once it is stopped or the command exits."
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"``--volume ./certificates/:/app/certificates/:ro``: Mount the "
"``certificates`` directory in"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"the current working directory of the host machine as a read-only volume "
"at the"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid "``/app/certificates`` directory inside the container."
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"This allows the container to access the TLS certificates that are stored "
"in the certificates"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid "directory."
msgstr ""

#: ../../source/docker/enable-tls.rst
#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
":substitution-code:`flwr/superlink:|stable_flwr_version|`: The name of "
"the image to be run and the specific"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"tag of the image. The tag :substitution-code:`|stable_flwr_version|` "
"represents a specific version of the image."
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"``--ssl-ca-certfile certificates/ca.crt``: Specify the location of the CA"
" certificate file"
msgstr ""

#: ../../source/docker/enable-tls.rst
#, fuzzy
msgid "inside the container."
msgstr "使用 VSCode Dev Containers 进行开发"

#: ../../source/docker/enable-tls.rst
msgid ""
"The ``certificates/ca.crt`` file is a certificate that is used to verify "
"the identity of the"
msgstr ""

#: ../../source/docker/enable-tls.rst
#, fuzzy
msgid "SuperLink."
msgstr "flower-superlink"

#: ../../source/docker/enable-tls.rst
msgid ""
"``--ssl-certfile certificates/server.pem``: Specify the location of the "
"SuperLink's"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid "TLS certificate file inside the container."
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"The ``certificates/server.pem`` file is used to identify the SuperLink "
"and to encrypt the"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid "data that is transmitted over the network."
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"``--ssl-keyfile certificates/server.key``: Specify the location of the "
"SuperLink's"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid "TLS private key file inside the container."
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"The ``certificates/server.key`` file is used to decrypt the data that is "
"transmitted over"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid "the network."
msgstr ""

#: ../../source/docker/enable-tls.rst:72
#, fuzzy
msgid "SuperNode"
msgstr "flower-superlink"

#: ../../source/docker/enable-tls.rst:74
#, fuzzy
msgid ""
"Assuming that the ``ca.crt`` certificate already exists locally, we can "
"use the flag ``--volume`` to mount the local certificate into the "
"container's ``/app/`` directory."
msgstr ""
"假设我们需要的所有文件都在本地的 ``certificates`` 目录中，我们可以使用标记 ``-v`` 将本地目录挂载到容器的 "
"``/app/`` 目录中。这样，服务器就可以访问容器内的文件。最后，我们使用 ``--certificates`` 标志将证书名称传递给服务器。"

#: ../../source/docker/enable-tls.rst:79
msgid ""
"If you're generating self-signed certificates and the ``ca.crt`` "
"certificate doesn't exist on the SuperNode, you can copy it over after "
"the generation step."
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid "``--volume ./ca.crt:/app/ca.crt/:ro``: Mount the ``ca.crt`` file from the"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"current working directory of the host machine as a read-only volume at "
"the ``/app/ca.crt``"
msgstr ""

#: ../../source/docker/enable-tls.rst
#, fuzzy
msgid "directory inside the container."
msgstr "使用 VSCode Dev Containers 进行开发"

#: ../../source/docker/enable-tls.rst
msgid ""
":substitution-code:`flwr/supernode:|stable_flwr_version|`: The name of "
"the image to be run and the specific"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"``--root-certificates ca.crt``: This specifies the location of the CA "
"certificate file"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid "The ``ca.crt`` file is used to verify the identity of the SuperLink."
msgstr ""

#: ../../source/docker/enable-tls.rst:105
msgid "SuperExec"
msgstr ""

#: ../../source/docker/enable-tls.rst:107
msgid ""
"Assuming all files we need are in the local ``certificates`` directory "
"where the SuperExec will be executed from, we can use the flag "
"``--volume`` to mount the local directory into the ``/app/certificates/``"
" directory of the container:"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
":substitution-code:`flwr/superexec:|stable_flwr_version|`: The name of "
"the image to be run and the specific"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid "SuperExec."
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"``--ssl-certfile certificates/server.pem``: Specify the location of the "
"SuperExec's"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"The ``certificates/server.pem`` file is used to identify the SuperExec "
"and to encrypt the"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"``--ssl-keyfile certificates/server.key``: Specify the location of the "
"SuperExec's"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"``--executor-config root-"
"certificates=\\\"certificates/superlink_ca.crt\\\"``: Specify the"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid ""
"location of the CA certificate file inside the container that the "
"SuperExec executor"
msgstr ""

#: ../../source/docker/enable-tls.rst
msgid "should use to verify the SuperLink's identity."
msgstr ""

#: ../../source/docker/index.rst:2
#, fuzzy
msgid "Run Flower using Docker"
msgstr "使用 Docker 运行 Flower"

#: ../../source/docker/index.rst:4
msgid ""
"Start your Flower journey with our pre-made Docker images on Docker Hub, "
"supporting ``amd64`` and ``arm64v8`` architectures."
msgstr ""

#: ../../source/docker/index.rst:7
msgid ""
"Our Quickstart guide walks you through containerizing a Flower project "
"and running it end to end using Docker."
msgstr ""

#: ../../source/docker/index.rst:11
#, fuzzy
msgid "Getting Started"
msgstr "开始"

#: ../../source/docker/index.rst:19
msgid "Running in Production"
msgstr ""

#: ../../source/docker/index.rst:28
#, fuzzy
msgid "Advanced Options"
msgstr "高级安装选项"

#: ../../source/docker/index.rst:40
#, fuzzy
msgid "Run Flower using Docker Compose"
msgstr "使用 Docker 运行 Flower"

#: ../../source/docker/persist-superlink-state.rst:2
msgid "Persist the State of the SuperLink"
msgstr ""

#: ../../source/docker/persist-superlink-state.rst:4
#, fuzzy
msgid ""
"By default, the Flower SuperLink keeps its state in-memory. When using "
"the Docker flag ``--rm``, the state is not persisted between container "
"starts."
msgstr ""
"默认情况下，Flower 服务器会将状态保存在内存中。使用 Docker 标志 ``--rm`` "
"时，状态不会在容器启动之间持久化。下面我们将展示如何将状态保存到主机系统上的文件中。"

#: ../../source/docker/persist-superlink-state.rst:7
msgid ""
"If you want to persist the state of the SuperLink on your host system, "
"all you need to do is specify a directory where you want to save the file"
" on your host system and a name for the database file."
msgstr ""

#: ../../source/docker/persist-superlink-state.rst:11
msgid ""
"By default, the SuperLink container runs with a non-root user called "
"``app`` with the user ID ``49999``. It is recommended to create a new "
"directory and change the user ID of the directory to ``49999`` to ensure "
"the mounted directory has the proper permissions."
msgstr ""

#: ../../source/docker/persist-superlink-state.rst:15
msgid ""
"If you later want to delete the directory, you can change the user ID "
"back to the current user ID by running ``sudo chown -R $USER:$(id -gn) "
"state``."
msgstr ""

#: ../../source/docker/persist-superlink-state.rst:21
#, fuzzy
msgid ""
"In the example below, we create a new directory called ``state``, change "
"the user ID and tell Docker via the flag ``--volume`` to mount the local "
"``state`` directory into the ``/app/state`` directory of the container. "
"Lastly, we use the flag ``--database`` to specify the name of the "
"database file."
msgstr ""
"如果想在主机系统上持久保存服务器的状态，只需在主机系统上指定保存文件的路径和数据库文件的名称即可。在下面的示例中，我们通过标志 ``-v`` 告诉"
" Docker 将用户的主目录（主机上的 ``~/``）挂载到容器的 ``/app/`` 目录中。此外，我们使用标志 ``--database``"
" 来指定数据库文件的名称。"

#: ../../source/docker/persist-superlink-state.rst:36
#, fuzzy
msgid ""
"As soon as the SuperLink starts, the file ``state.db`` is created in the "
"``state`` directory on your host system. If the file already exists, the "
"SuperLink tries to restore the state from the file. To start the "
"SuperLink with an empty database, ensure that there is no database called"
" ``state.db`` in the ``state`` directory (``rm state.db``) before you "
"execute the ``docker run`` command above."
msgstr ""
"服务器一启动，就会在主机系统的用户主目录下创建文件 "
"``state.db``。如果该文件已经存在，服务器会尝试从该文件恢复状态。要以空数据库启动服务器，只需删除 ``state.db`` 文件即可。"

#: ../../source/docker/pin-version.rst:2
#, fuzzy
msgid "Pin a Docker Image to a Specific Version"
msgstr "将 Docker 映像固定到特定版本"

#: ../../source/docker/pin-version.rst:4
#, fuzzy
msgid ""
"It may happen that we update the images behind the tags. Such updates "
"usually include security updates of system dependencies that should not "
"change the functionality of Flower. However, if you want to ensure that "
"you use a fixed version of the Docker image in your deployments, you can "
"`specify the digest "
"<https://docs.docker.com/reference/cli/docker/image/pull/#pull-an-image-"
"by-digest-immutable-identifier>`_ of the image instead of the tag."
msgstr ""
"我们可能会更新标签后面的图像。此类更新通常包括系统依赖项的安全更新，不会改变 Flower "
"的功能。不过，如果您想确保始终使用同一张图片，可以指定图片的哈希值而不是标签。"

#: ../../source/docker/pin-version.rst:14
#, fuzzy
msgid ""
"The following command returns the current image digest referenced by the "
":substitution-code:`superlink:|stable_flwr_version|` tag:"
msgstr "下面的命令将返回由 ``server:1.7.0-py3.11-ubuntu22.04`` 标记引用的当前图像哈希值："

#: ../../source/docker/pin-version.rst:23
msgid "This will output"
msgstr ""

#: ../../source/docker/pin-version.rst:30
#, fuzzy
msgid "Next, we can pin the digest when running a new SuperLink container:"
msgstr "接下来，我们可以在运行新服务器容器时将哈希值固定下来："

#: ../../source/docker/run-as-root-user.rst:2
msgid "Run with Root User Privileges"
msgstr ""

#: ../../source/docker/run-as-root-user.rst:4
msgid ""
"Flower Docker images, by default, run with a non-root user "
"(username/groupname: ``app``, UID/GID: ``49999``). Using root user is "
"**not recommended** unless it is necessary for specific tasks during the "
"build process."
msgstr ""

#: ../../source/docker/run-as-root-user.rst:8
msgid ""
"Always make sure to run the container as a non-root user in production to"
" maintain security best practices."
msgstr ""

#: ../../source/docker/run-as-root-user.rst:12
msgid "Run a Container with Root User Privileges"
msgstr ""

#: ../../source/docker/run-as-root-user.rst:14
msgid ""
"Run the Docker image with the ``-u`` flag and specify ``root`` as the "
"username:"
msgstr ""

#: ../../source/docker/run-as-root-user.rst:21
msgid "This command will run the Docker container with root user privileges."
msgstr ""

#: ../../source/docker/run-as-root-user.rst:24
msgid "Run the Build Process with Root User Privileges"
msgstr ""

#: ../../source/docker/run-as-root-user.rst:26
msgid ""
"If you want to switch to the root user during the build process of the "
"Docker image to install missing system dependencies, you can use the "
"``USER root`` directive within your Dockerfile."
msgstr ""

#: ../../source/docker/run-as-root-user.rst:30
#, fuzzy
msgid "SuperNode Dockerfile"
msgstr "创建超级节点 Dockerfile"

#: ../../source/docker/run-as-subprocess.rst:2
#, fuzzy
msgid "Run ClientApp as a Subprocess"
msgstr "运行分类器和测试"

#: ../../source/docker/run-as-subprocess.rst:4
msgid ""
"In this mode, the ClientApp is executed as a subprocess within the "
"SuperNode Docker container, rather than running in a separate container. "
"This approach reduces the number of running containers, which can be "
"beneficial for environments with limited resources. However, it also "
"means that the ClientApp is no longer isolated from the SuperNode, which "
"may introduce additional security concerns."
msgstr ""

#: ../../source/docker/run-as-subprocess.rst:13
msgid ""
"Before running the ClientApp as a subprocess, ensure that the FAB "
"dependencies have been installed in the SuperNode images. This can be "
"done by extending the SuperNode image:"
msgstr ""

#: ../../source/docker/run-as-subprocess.rst:17
#, fuzzy
msgid "Dockerfile.supernode"
msgstr "Flower 服务器"

#: ../../source/docker/run-as-subprocess.rst:31
#, fuzzy
msgid ""
"Next, build the SuperNode Docker image by running the following command "
"in the directory where Dockerfile is located:"
msgstr "接下来，我们在 Dockerfile 和 ClientApp 代码所在的目录下运行以下命令，构建 SuperNode Docker 映像。"

#: ../../source/docker/run-as-subprocess.rst:39
msgid "Run the ClientApp as a Subprocess"
msgstr ""

#: ../../source/docker/run-as-subprocess.rst:41
msgid ""
"Start the SuperNode with the flag ``--isolation subprocess``, which tells"
" the SuperNode to execute the ClientApp as a subprocess:"
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:2
#, fuzzy
msgid "Run Flower Quickstart Examples with Docker Compose"
msgstr "快速入门 iOS"

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:4
msgid ""
"Flower provides a set of `quickstart examples "
"<https://github.com/adap/flower/tree/main/examples>`_ to help you get "
"started with the framework. These examples are designed to demonstrate "
"the capabilities of Flower and by default run using the Simulation "
"Engine. This guide demonstrates how to run them using Flower's Deployment"
" Engine via Docker Compose."
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:12
msgid ""
"Some quickstart examples may have limitations or requirements that "
"prevent them from running on every environment. For more information, "
"please see Limitations_."
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:18
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:15
#: ../../source/docker/tutorial-quickstart-docker.rst:13
#, fuzzy
msgid "Before you start, make sure that:"
msgstr "开始之前，请确保 Docker 守护进程正在运行："

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:20
#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:22
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:17
#: ../../source/docker/tutorial-quickstart-docker.rst:15
msgid "The ``flwr`` CLI is :doc:`installed <../how-to-install-flower>` locally."
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:21
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:18
#: ../../source/docker/tutorial-quickstart-docker.rst:16
#, fuzzy
msgid "The Docker daemon is running."
msgstr "验证 Docker 守护进程是否正在运行。"

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:22
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:19
msgid ""
"Docker Compose V2 is `installed "
"<https://docs.docker.com/compose/install/>`_."
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:25
#, fuzzy
msgid "Run the Quickstart Example"
msgstr "示例请求"

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:27
msgid ""
"Clone the quickstart example you like to run. For example, ``quickstart-"
"pytorch``:"
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:35
msgid ""
"Download the `compose.yml "
"<https://github.com/adap/flower/blob/main/src/docker/complete/compose.yml>`_"
" file into the example directory:"
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:45
#, fuzzy
msgid ""
"Export the version of Flower that your environment uses. Then, build and "
"start the services using the following command:"
msgstr "运行以下命令激活 virtualenv："

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:54
#, fuzzy
msgid ""
"Append the following lines to the end of the ``pyproject.toml`` file and "
"save it:"
msgstr "将 ``pyproject.toml`` 中的次要版本增加一个。"

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:56
#: ../../source/docker/tutorial-quickstart-docker.rst:323
#, fuzzy
msgid "pyproject.toml"
msgstr "或 ``pyproject.toml```："

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:65
msgid ""
"You can customize the string that follows ``tool.flwr.federations.`` to "
"fit your needs. However, please note that the string cannot contain a dot"
" (``.``)."
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:68
msgid ""
"In this example, ``local-deployment`` has been used. Just remember to "
"replace ``local-deployment`` with your chosen name in both the "
"``tool.flwr.federations.`` string and the corresponding ``flwr run .`` "
"command."
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:72
msgid "Run the example and follow the logs of the ServerApp:"
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:78
msgid ""
"That is all it takes! You can monitor the progress of the run through the"
" logs of the SuperExec."
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:82
msgid "Run a Different Quickstart Example"
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:84
msgid ""
"To run a different quickstart example, such as ``quickstart-tensorflow``,"
" first, shut down the Docker Compose services of the current example:"
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:91
msgid "After that, you can repeat the steps above."
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:94
#: ../../source/docker/run-quickstart-examples-docker-compose.rst:100
#, fuzzy
msgid "Limitations"
msgstr "运行模拟"

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:99
#, fuzzy
msgid "Quickstart Example"
msgstr "快速入门 JAX"

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:101
#, fuzzy
msgid "quickstart-fastai"
msgstr "快速入门 fastai"

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:102
#: ../../source/docker/run-quickstart-examples-docker-compose.rst:104
#: ../../source/docker/run-quickstart-examples-docker-compose.rst:106
#: ../../source/docker/run-quickstart-examples-docker-compose.rst:113
#: ../../source/docker/run-quickstart-examples-docker-compose.rst:115
#: ../../source/docker/run-quickstart-examples-docker-compose.rst:119
#: ../../source/docker/run-quickstart-examples-docker-compose.rst:121
#: ../../source/docker/run-quickstart-examples-docker-compose.rst:125
#: ../../source/ref-changelog.md:103 ../../source/ref-changelog.md:469
#: ../../source/ref-changelog.md:746 ../../source/ref-changelog.md:810
#: ../../source/ref-changelog.md:868 ../../source/ref-changelog.md:937
#: ../../source/ref-changelog.md:999
msgid "None"
msgstr "无"

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:103
#, fuzzy
msgid "quickstart-huggingface"
msgstr "快速入门教程"

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:105
#, fuzzy
msgid "quickstart-jax"
msgstr "快速入门 JAX"

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:107
#, fuzzy
msgid "quickstart-mlcube"
msgstr "快速入门 JAX"

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:108
#: ../../source/docker/run-quickstart-examples-docker-compose.rst:123
#, fuzzy
msgid ""
"The example has not yet been updated to work with the latest ``flwr`` "
"version."
msgstr "涵盖 scikit-learn 和 PyTorch Lightning 的代码示例已更新，以便与最新版本的 Flower 配合使用。"

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:109
#, fuzzy
msgid "quickstart-mlx"
msgstr "快速入门 JAX"

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:110
msgid ""
"`Requires to run on macOS with Apple Silicon <https://ml-"
"explore.github.io/mlx/build/html/install.html#python-installation>`_."
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:112
#, fuzzy
msgid "quickstart-monai"
msgstr "快速入门 JAX"

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:114
#, fuzzy
msgid "quickstart-pandas"
msgstr "快速入门Pandas"

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:116
#, fuzzy
msgid "quickstart-pytorch-lightning"
msgstr "快速入门 PyTorch Lightning"

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:117
msgid ""
"Requires an older pip version that is not supported by the Flower Docker "
"images."
msgstr ""

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:118
#, fuzzy
msgid "quickstart-pytorch"
msgstr "PyTorch快速入门"

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:120
#, fuzzy
msgid "quickstart-sklearn-tabular"
msgstr "scikit-learn快速入门"

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:122
#, fuzzy
msgid "quickstart-tabnet"
msgstr "快速入门 JAX"

#: ../../source/docker/run-quickstart-examples-docker-compose.rst:124
#, fuzzy
msgid "quickstart-tensorflow"
msgstr "快速入门 TensorFlow"

#: ../../source/docker/set-environment-variables.rst:2
#, fuzzy
msgid "Set Environment Variables"
msgstr "设置编码环境"

#: ../../source/docker/set-environment-variables.rst:4
#, fuzzy
msgid ""
"To set a variable inside a Docker container, you can use the ``-e "
"<name>=<value>`` flag. Multiple ``-e`` flags can be used to set multiple "
"environment variables for a container."
msgstr "要在 Docker 容器内设置变量，可以使用 ``-e <name>=<value>`` 标志。"

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:2
#, fuzzy
msgid "Deploy Flower on Multiple Machines with Docker Compose"
msgstr "快速入门 iOS"

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:4
msgid ""
"This guide will help you set up a Flower project on multiple machines "
"using Docker Compose."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:7
msgid ""
"You will learn how to run the Flower client and server components on two "
"separate machines, with Flower configured to use TLS encryption and "
"persist SuperLink state across restarts. A server consists of a SuperLink"
" and ``SuperExec``. For more details about the Flower architecture, refer"
" to the :doc:`../explanation-flower-architecture` explainer page."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:13
msgid ""
"This guide assumes you have completed the :doc:`tutorial-quickstart-"
"docker-compose` tutorial. It is highly recommended that you follow and "
"understand the contents of that tutorial before proceeding with this "
"guide."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:20
msgid "Before you begin, make sure you have the following prerequisites:"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:23
msgid "The Docker daemon is running on your local machine and the remote machine."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:24
msgid ""
"Docker Compose V2 is installed on both your local machine and the remote "
"machine."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:25
msgid "You can connect to the remote machine from your local machine."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:26
msgid "Ports ``9091`` and ``9093`` are accessible on the remote machine."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:30
msgid ""
"The guide uses the |quickstart_sklearn_tabular|_ example as an example "
"project."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:32
msgid ""
"If your project has a different name or location, please remember to "
"adjust the commands/paths accordingly."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:36
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:22
#: ../../source/docker/tutorial-quickstart-docker.rst:19
msgid "Step 1: Set Up"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:38
msgid "Clone the Flower repository and change to the ``distributed`` directory:"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:45
msgid "Get the IP address from the remote machine and save it for later."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:46
msgid ""
"Use the ``certs.yml`` Compose file to generate your own self-signed "
"certificates. If you have certificates, you can continue with Step 2."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:51
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:214
msgid "These certificates should be used only for development purposes."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:53
msgid ""
"For production environments, you may have to use dedicated services to "
"obtain your certificates."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:56
msgid ""
"First, set the environment variables ``SUPERLINK_IP`` and "
"``SUPEREXEC_IP`` with the IP address from the remote machine. For "
"example, if the IP is ``192.168.2.33``, execute:"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:65
msgid "Next, generate the self-signed certificates:"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:72
msgid "Step 2: Copy the Server Compose Files"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:74
msgid ""
"Use the method that works best for you to copy the ``server`` directory, "
"the certificates, and the ``pyproject.toml`` file of your Flower project "
"to the remote machine."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:78
msgid "For example, you can use ``scp`` to copy the directories:"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:88
#, fuzzy
msgid "Step 3: Start the Flower Server Components"
msgstr "然后，我们启动服务器："

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:90
msgid ""
"Log into the remote machine using ``ssh`` and run the following command "
"to start the SuperLink and SuperExec services:"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:104
msgid ""
"The path to the ``PROJECT_DIR`` containing the ``pyproject.toml`` file "
"should be relative to the location of the server ``compose.yml`` file."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:109
msgid ""
"When working with Docker Compose on Linux, you may need to create the "
"``state`` directory first and change its ownership to ensure proper "
"access and permissions. After exporting the ``PROJECT_DIR`` (after line "
"4), run the following commands:"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:118
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:167
msgid ""
"For more information, consult the following page: :doc:`persist-"
"superlink-state`."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:120
msgid "Go back to your terminal on your local machine."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:123
#, fuzzy
msgid "Step 4: Start the Flower Client Components"
msgstr "然后，我们启动服务器："

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:125
msgid ""
"On your local machine, run the following command to start the client "
"components:"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:135
msgid ""
"The path to the ``PROJECT_DIR`` containing the ``pyproject.toml`` file "
"should be relative to the location of the client ``compose.yml`` file."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:139
#, fuzzy
msgid "Step 5: Run Your Flower Project"
msgstr "Flower 服务器。"

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:141
msgid ""
"Specify the remote SuperExec IP addresses and the path to the root "
"certificate in the ``[tool.flwr.federations.remote-superexec]`` table in "
"the ``pyproject.toml`` file. Here, we have named our remote federation "
"``remote-superexec``:"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:145
#, fuzzy
msgid "examples/quickstart-sklearn-tabular/pyproject.toml"
msgstr "scikit-learn快速入门"

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:154
msgid ""
"The path of the ``root-certificates`` should be relative to the location "
"of the ``pyproject.toml`` file."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:157
msgid "Run the project and follow the ServerApp logs:"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:163
msgid ""
"That's it! With these steps, you've set up Flower on two separate "
"machines and are ready to start using it."
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:167
msgid "Step 6: Clean Up"
msgstr ""

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:169
#, fuzzy
msgid "Shut down the Flower client components:"
msgstr "Flower 客户端。"

#: ../../source/docker/tutorial-deploy-on-multiple-machines.rst:176
msgid "Shut down the Flower server components and delete the SuperLink state:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:2
#, fuzzy
msgid "Quickstart with Docker"
msgstr "快速入门 iOS"

#: ../../source/docker/tutorial-quickstart-docker.rst:4
msgid ""
"This quickstart aims to guide you through the process of containerizing a"
" Flower project and running it end to end using Docker on your local "
"machine."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:7
msgid ""
"This tutorial does not use production-ready settings, so you can focus on"
" understanding the basic workflow that uses the minimum configurations."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:32
#: ../../source/docker/tutorial-quickstart-docker.rst:21
msgid "Create a new Flower project (PyTorch):"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:38
msgid "Create a new Docker bridge network called ``flwr-network``:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:44
msgid ""
"User-defined networks, such as ``flwr-network``, enable IP resolution of "
"container names, a feature absent in the default bridge network. This "
"simplifies quickstart example by avoiding the need to determine host IP "
"first."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:49
#, fuzzy
msgid "Step 2: Start the SuperLink"
msgstr "然后，我们启动服务器："

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:62
#: ../../source/docker/tutorial-quickstart-docker.rst:51
#, fuzzy
msgid "Open your terminal and run:"
msgstr "打开另一台终端，启动第二个客户端："

#: ../../source/docker/tutorial-quickstart-docker-compose.rst
#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "Understand the command"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"``-p 9091:9091 -p 9092:9092``: Map port ``9091`` and ``9092`` of the "
"container to the same port of"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "the host machine, allowing other services to access the Driver API on"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "``http://localhost:9091`` and the Fleet API on ``http://localhost:9092``."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:70
#: ../../source/docker/tutorial-quickstart-docker.rst:107
#: ../../source/docker/tutorial-quickstart-docker.rst:218
#: ../../source/docker/tutorial-quickstart-docker.rst:308
msgid ""
"``--network flwr-network``: Make the container join the network named "
"``flwr-network``."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:71
msgid "``--name superlink``: Assign the name ``superlink`` to the container."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:72
#: ../../source/docker/tutorial-quickstart-docker.rst:109
#: ../../source/docker/tutorial-quickstart-docker.rst:219
#: ../../source/docker/tutorial-quickstart-docker.rst:310
msgid ""
"``--detach``: Run the container in the background, freeing up the "
"terminal."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"tag of the image. The tag :substitution-code:`|stable_flwr_version|` "
"represents a :doc:`specific version <pin-version>` of the image."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"``--insecure``: This flag tells the container to operate in an insecure "
"mode, allowing"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "unencrypted communication."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:79
#, fuzzy
msgid "Step 3: Start the SuperNode"
msgstr "然后，我们启动服务器："

#: ../../source/docker/tutorial-quickstart-docker.rst:81
msgid "Start two SuperNode containers."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:83
msgid "Start the first container:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "``-p 9094:9094``: Map port ``9094`` of the container to the same port of"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "the host machine, allowing other services to access the SuperNode API on"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "``http://localhost:9094``."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:108
msgid "``--name supernode-1``: Assign the name ``supernode-1`` to the container."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"``flwr/supernode:|stable_flwr_version|``: This is the name of the image "
"to be run and the specific tag"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "of the image."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"``--superlink superlink:9092``: Connect to the SuperLink's Fleet API at "
"the address"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "``superlink:9092``."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"``--node-config \"partition-id=0 num-partitions=2\"``: Set the partition "
"ID to ``0`` and the"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "number of partitions to ``2`` for the SuperNode configuration."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"``--supernode-address 0.0.0.0:9094``: Set the address and port number "
"that the SuperNode"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "is listening on."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"``--isolation process``: Tells the SuperNode that the ClientApp is "
"created by separate"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "independent process. The SuperNode does not attempt to create it."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:123
#, fuzzy
msgid "Start the second container:"
msgstr "启动服务器"

#: ../../source/docker/tutorial-quickstart-docker.rst:141
msgid "Step 4: Start the ClientApp"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:143
msgid ""
"The ClientApp Docker image comes with a pre-installed version of Flower "
"and serves as a base for building your own ClientApp image. In order to "
"install the FAB dependencies, you will need to create a Dockerfile that "
"extends the ClientApp image and installs the required dependencies."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:148
msgid ""
"Create a ClientApp Dockerfile called ``Dockerfile.clientapp`` and paste "
"the following code into it:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:151
#, fuzzy
msgid "Dockerfile.clientapp"
msgstr "Flower 客户端。"

#: ../../source/docker/tutorial-quickstart-docker.rst
#, fuzzy
msgid "Understand the Dockerfile"
msgstr "创建超级节点 Dockerfile"

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
":substitution-code:`FROM flwr/clientapp:|stable_flwr_version|`: This line"
" specifies that the Docker image"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"to be built from is the ``flwr/clientapp image``, version :substitution-"
"code:`|stable_flwr_version|`."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "``WORKDIR /app``: Set the working directory for the container to ``/app``."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"Any subsequent commands that reference a directory will be relative to "
"this directory."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "``COPY pyproject.toml .``: Copy the ``pyproject.toml`` file"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"from the current working directory into the container's ``/app`` "
"directory."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"``RUN sed -i 's/.*flwr\\[simulation\\].*//' pyproject.toml``: Remove the "
"``flwr`` dependency"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
#, fuzzy
msgid "from the ``pyproject.toml``."
msgstr "或 ``pyproject.toml```："

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"``python -m pip install -U --no-cache-dir .``: Run the ``pip`` install "
"command to"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "install the dependencies defined in the ``pyproject.toml`` file"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"The ``-U`` flag indicates that any existing packages should be upgraded, "
"and"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"``--no-cache-dir`` prevents pip from using the cache to speed up the "
"installation."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"``ENTRYPOINT [\"flwr-clientapp\"]``: Set the command ``flwr-clientapp`` "
"to be"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "the default command run when the container is started."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:185
msgid ""
"Note that `flwr <https://pypi.org/project/flwr/>`__ is already installed "
"in the ``flwr/clientapp`` base image, so only other package dependencies "
"such as ``flwr-datasets``, ``torch``, etc., need to be installed. As a "
"result, the ``flwr`` dependency is removed from the ``pyproject.toml`` "
"after it has been copied into the Docker image (see line 5)."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:191
#, fuzzy
msgid ""
"Next, build the ClientApp Docker image by running the following command "
"in the directory where the Dockerfile is located:"
msgstr "接下来，我们在 Dockerfile 和 ServerApp 代码所在的目录下运行以下命令，构建 ServerApp Docker 镜像。"

#: ../../source/docker/tutorial-quickstart-docker.rst:200
#, fuzzy
msgid ""
"The image name was set as ``flwr_clientapp`` with the tag ``0.0.1``. "
"Remember that these values are merely examples, and you can customize "
"them according to your requirements."
msgstr "我们给图片命名为 ``flwr_serverapp``，标签为 ``0.0.1``。请记住，这里选择的值只是一个示例。您可以根据自己的需要进行更改。"

#: ../../source/docker/tutorial-quickstart-docker.rst:204
#, fuzzy
msgid "Start the first ClientApp container:"
msgstr "使用虚拟客户端引擎"

#: ../../source/docker/tutorial-quickstart-docker.rst
#, fuzzy
msgid ""
"``flwr_clientapp:0.0.1``: This is the name of the image to be run and the"
" specific tag"
msgstr "flwr_serverapp:0.0.1``： 要使用的 Docker 映像的名称和标记。"

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"``--supernode supernode-1:9094``: Connect to the SuperNode's Fleet API at"
" the address"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "``supernode-1:9094``."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:225
msgid "Start the second ClientApp container:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:236
#, fuzzy
msgid "Step 5: Start the SuperExec"
msgstr "然后，我们启动服务器："

#: ../../source/docker/tutorial-quickstart-docker.rst:238
#, fuzzy
msgid ""
"The procedure for building and running a SuperExec image is almost "
"identical to the ClientApp image."
msgstr "构建和运行 ServerApp 映像的程序与 SuperNode 映像几乎完全相同。"

#: ../../source/docker/tutorial-quickstart-docker.rst:241
msgid ""
"Similar to the ClientApp image, you will need to create a Dockerfile that"
" extends the SuperExec image and installs the required FAB dependencies."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:244
msgid ""
"Create a SuperExec Dockerfile called ``Dockerfile.superexec`` and paste "
"the following code in:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:247
msgid "Dockerfile.superexec"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
":substitution-code:`FROM flwr/superexec:|stable_flwr_version|`: This line"
" specifies that the Docker image"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"to be built from is the ``flwr/superexec image``, version :substitution-"
"code:`|stable_flwr_version|`."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"``ENTRYPOINT [\"flower-superexec\"``: Set the command ``flower-"
"superexec`` to be"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "``\"--executor\", \"flwr.superexec.deployment:executor\"]`` Use the"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "``flwr.superexec.deployment:executor`` executor to run the ServerApps."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:282
msgid ""
"Afterward, in the directory that holds the Dockerfile, execute this "
"Docker command to build the SuperExec image:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:289
#, fuzzy
msgid "Start the SuperExec container:"
msgstr "启动服务器"

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "``-p 9093:9093``: Map port ``9093`` of the container to the same port of"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"the host machine, allowing you to access the SuperExec API on "
"``http://localhost:9093``."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:309
msgid "``--name superexec``: Assign the name ``superexec`` to the container."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
#, fuzzy
msgid ""
"``flwr_superexec:0.0.1``: This is the name of the image to be run and the"
" specific tag"
msgstr "flwr_supernode:0.0.1``： 要使用的 Docker 映像的名称和标记。"

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid ""
"``--executor-config superlink=\\\"superlink:9091\\\"``: Configure the "
"SuperExec executor to"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst
msgid "connect to the SuperLink running on port ``9091``."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:319
msgid "Step 6: Run the Quickstart Project"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:321
#, fuzzy
msgid "Add the following lines to the ``pyproject.toml``:"
msgstr "将 ``pyproject.toml`` 中的次要版本增加一个。"

#: ../../source/docker/tutorial-quickstart-docker.rst:330
msgid ""
"Run the ``quickstart-docker`` project and follow the ServerApp logs to "
"track the execution of the run:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:338
#, fuzzy
msgid "Step 7: Update the Application"
msgstr "步骤 3：自定义序列化"

#: ../../source/docker/tutorial-quickstart-docker.rst:340
msgid ""
"Change the application code. For example, change the ``seed`` in "
"``quickstart_docker/task.py`` to ``43`` and save it:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:343
#, fuzzy
msgid "quickstart_docker/task.py"
msgstr "快速入门Pandas"

#: ../../source/docker/tutorial-quickstart-docker.rst:350
#, fuzzy
msgid "Stop the current ClientApp containers:"
msgstr "当前客户端属性。"

#: ../../source/docker/tutorial-quickstart-docker.rst:356
#, fuzzy
msgid "Rebuild the FAB and ClientApp image:"
msgstr "加载数据"

#: ../../source/docker/tutorial-quickstart-docker.rst:362
msgid "Launch two new ClientApp containers based on the newly built image:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:377
msgid "Run the updated project:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:384
msgid "Step 8: Clean Up"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:386
msgid "Remove the containers and the bridge network:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:398
#: ../../source/docker/tutorial-quickstart-docker.rst:398
#, fuzzy
msgid "Where to Go Next"
msgstr "从哪里开始"

#: ../../source/docker/tutorial-quickstart-docker.rst:400
msgid ":doc:`enable-tls`"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:401
msgid ":doc:`persist-superlink-state`"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker.rst:402
msgid ":doc:`tutorial-quickstart-docker-compose`"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:2
#, fuzzy
msgid "Quickstart with Docker Compose"
msgstr "快速入门 iOS"

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:4
msgid ""
"This quickstart shows you how to set up Flower using Docker Compose in a "
"single command, allowing you to focus on developing your application "
"without worrying about the underlying infrastructure."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:8
msgid ""
"You will also learn how to easily enable TLS encryption and persist "
"application state locally, giving you the freedom to choose the "
"configuration that best suits your project's needs."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:24
msgid "Clone the Docker Compose ``complete`` directory:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:38
msgid ""
"Export the path of the newly created project. The path should be relative"
" to the location of the Docker Compose files:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:45
msgid ""
"Setting the ``PROJECT_DIR`` helps Docker Compose locate the "
"``pyproject.toml`` file, allowing it to install dependencies in the "
"SuperExec and SuperNode images correctly."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:49
#, fuzzy
msgid "Step 2: Run Flower in Insecure Mode"
msgstr "Flower 服务器。"

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:51
msgid ""
"To begin, start Flower with the most basic configuration. In this setup, "
"Flower will run without TLS and without persisting the state."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:56
msgid ""
"Without TLS, the data sent between the services remains **unencrypted**. "
"Use it only for development purposes."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:59
msgid ""
"For production-oriented use cases, :ref:`enable TLS<TLS>` for secure data"
" transmission."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:70
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:177
#, fuzzy
msgid "``docker compose``: The Docker command to run the Docker Compose tool."
msgstr "`docker run``： 这是运行新 Docker 容器的命令。"

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:71
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:183
msgid ""
"``--build``: Rebuild the images for each service if they don't already "
"exist."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:72
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:184
msgid ""
"``-d``: Detach the containers from the terminal and run them in the "
"background."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:75
msgid "Step 3: Run the Quickstart Project"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:77
msgid ""
"Now that the Flower services have been started via Docker Compose, it is "
"time to run the quickstart example."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:80
msgid ""
"To ensure the ``flwr`` CLI connects to the SuperExec, you need to specify"
" the SuperExec addresses in the ``pyproject.toml`` file."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:83
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:225
msgid "Add the following lines to the ``quickstart-compose/pyproject.toml``:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:85
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:227
msgid "quickstart-compose/pyproject.toml"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:92
msgid ""
"Run the quickstart example, monitor the ServerApp logs and wait for the "
"summary to appear:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:100
#, fuzzy
msgid "Step 4: Update the Application"
msgstr "步骤 3：自定义序列化"

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:102
msgid "In the next step, change the application code."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:104
msgid ""
"For example, go to the ``task.py`` file in the ``quickstart-"
"compose/quickstart_compose/`` directory and add a ``print`` call in the "
"``get_weights`` function:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:108
msgid "quickstart-compose/quickstart_compose/task.py"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:119
#, fuzzy
msgid "Rebuild and restart the services."
msgstr "我们已经可以启动*服务器*了："

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:123
msgid ""
"If you have modified the dependencies listed in your ``pyproject.toml`` "
"file, it is essential to rebuild images."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:126
msgid "If you haven't made any changes, you can skip this step."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:128
msgid "Run the following command to rebuild and restart the services:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:134
msgid "Run the updated quickstart example:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:140
msgid "In the SuperExec logs, you should find the ``Get weights`` line:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:157
msgid "Step 5: Persisting the SuperLink State"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:159
msgid ""
"In this step, Flower services are configured to persist the state of the "
"SuperLink service, ensuring that it maintains its state even after a "
"restart."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:164
msgid ""
"When working with Docker Compose on Linux, you may need to create the "
"``state`` directory first and change its ownership to ensure proper "
"access and permissions."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:169
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:219
msgid "Run the command:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:178
msgid ""
"``-f compose.yml``: Specify the YAML file that contains the basic Flower "
"service definitions."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst
msgid ""
"``-f with-state.yml``: Specifies the path to an additional Docker Compose"
" file that"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst
msgid "contains the configuration for persisting the SuperLink state."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst
msgid ""
"Docker merges Compose files according to `merging rules "
"<https://docs.docker.com/compose/multiple-compose-files/merge/#merging-"
"rules>`_."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:186
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:240
#: ../../source/docker/tutorial-quickstart-docker-compose.rst:367
msgid "Rerun the ``quickstart-compose`` project:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:192
msgid "Check the content of the ``state`` directory:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:199
msgid ""
"You should see a ``state.db`` file in the ``state`` directory. If you "
"restart the service, the state file will be used to restore the state "
"from the previously saved data. This ensures that the data persists even "
"if the containers are stopped and started again."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:207
msgid "Step 6: Run Flower with TLS"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:209
msgid ""
"To demonstrate how to enable TLS, generate self-signed certificates using"
" the ``certs.yml`` Compose file."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:216
msgid ""
"For production environments, use a service like `Let's Encrypt "
"<https://letsencrypt.org/>`_ to obtain your certificates."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:234
msgid "Restart the services with TLS enabled:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:247
msgid "Step 7: Add another SuperNode"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:249
msgid ""
"You can add more SuperNodes and ClientApps by duplicating their "
"definitions in the ``compose.yml`` file."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:252
msgid ""
"Just give each new SuperNode and ClientApp service a unique service name "
"like ``supernode-3``, ``clientapp-3``, etc."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:255
msgid "In ``compose.yml``, add the following:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:257
msgid "compose.yml"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:308
msgid ""
"If you also want to enable TLS for the new SuperNodes, duplicate the "
"SuperNode definition for each new SuperNode service in the ``with-"
"tls.yml`` file."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:311
msgid ""
"Make sure that the names of the services match with the one in the "
"``compose.yml`` file."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:313
msgid "In ``with-tls.yml``, add the following:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:315
msgid "with-tls.yml"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:337
msgid "Step 8: Persisting the SuperLink State and Enabling TLS"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:339
msgid ""
"To run Flower with persisted SuperLink state and enabled TLS, a slight "
"change in the ``with-state.yml`` file is required:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:342
msgid "Comment out the lines 2-4 and uncomment the lines 5-9:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:344
msgid "with-state.yml"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:361
#, fuzzy
msgid "Restart the services:"
msgstr "启动服务器"

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:374
msgid "Step 9: Merge Multiple Compose Files"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:376
msgid ""
"You can merge multiple Compose files into a single file. For instance, if"
" you wish to combine the basic configuration with the TLS configuration, "
"execute the following command:"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:385
msgid ""
"This will merge the contents of ``compose.yml`` and ``with-tls.yml`` into"
" a new file called ``my_compose.yml``."
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:389
msgid "Step 10: Clean Up"
msgstr ""

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:391
#, fuzzy
msgid "Remove all services and volumes:"
msgstr "从 R 中删除所有项目。"

#: ../../source/docker/tutorial-quickstart-docker-compose.rst:400
#, fuzzy
msgid ":doc:`run-quickstart-examples-docker-compose`"
msgstr "快速入门 iOS"

#: ../../source/docker/use-a-different-version.rst:2
#, fuzzy
msgid "Use a Different Flower Version"
msgstr "使用不同的 Flower 或 Python 版本"

#: ../../source/docker/use-a-different-version.rst:4
#, fuzzy
msgid ""
"If you want to use a different version of Flower, for example Flower "
"nightly, you can do so by changing the tag. All available versions are on"
" `Docker Hub <https://hub.docker.com/u/flwr>`__."
msgstr ""
"如果您想使用不同版本的 Flower 或 Python，可以通过更改标签来实现。我们提供的所有版本都可以在 `Docker Hub "
"<https://hub.docker.com/r/flwr/server/tags>`_ 上找到。"

#: ../../source/docker/use-a-different-version.rst:10
#, fuzzy
msgid ""
"When using Flower nightly, the SuperLink nightly image must be paired "
"with the corresponding SuperNode and ServerApp nightly images released on"
" the same day. To ensure the versions are in sync, using the concrete "
"tag, e.g., ``1.10.0.dev20240610`` instead of ``nightly`` is recommended."
msgstr ""
"超级节点 Docker 映像目前仅适用于 1.9.0-nightly 版本。稳定版将在 Flower "
"1.9.0（稳定版）发布时推出（预计发布时间：5 "
"月）。超级节点夜间镜像必须与同一天发布的相应超级链接和服务器应用程序夜间镜像配对。为确保版本同步，建议使用具体标签，例如``1.9.0.dev20240501``，而不是``nightly``。"

#: ../../source/explanation-differential-privacy.rst:2
#: ../../source/explanation-differential-privacy.rst:14
#: ../../source/tutorial-series-what-is-federated-learning.ipynb:303
msgid "Differential Privacy"
msgstr "差分隐私"

#: ../../source/explanation-differential-privacy.rst:4
#, fuzzy
msgid ""
"The information in datasets like healthcare, financial transactions, user"
" preferences, etc., is valuable and has the potential for scientific "
"breakthroughs and provides important business insights. However, such "
"data is also sensitive and there is a risk of compromising individual "
"privacy."
msgstr "医疗保健、金融交易、用户偏好等数据集中的信息非常宝贵，有可能带来科学突破并提供重要的商业见解。然而，这些数据也是敏感数据，存在泄露个人隐私的风险。"

#: ../../source/explanation-differential-privacy.rst:9
#, fuzzy
msgid ""
"Traditional methods like anonymization alone would not work because of "
"attacks like Re-identification and Data Linkage. That's where "
"differential privacy comes in. It provides the possibility of analyzing "
"data while ensuring the privacy of individuals."
msgstr "单靠匿名等传统方法是行不通的，因为会受到重新识别和数据链接等攻击。这就是差异化隐私的用武之地。它提供了在分析数据的同时确保个人隐私的可能性。"

#: ../../source/explanation-differential-privacy.rst:16
#, fuzzy
msgid ""
"Imagine two datasets that are identical except for a single record (for "
"instance, Alice's data). Differential Privacy (DP) guarantees that any "
"analysis (M), like calculating the average income, will produce nearly "
"identical results for both datasets (O and O' would be similar). This "
"preserves group patterns while obscuring individual details, ensuring the"
" individual's information remains hidden in the crowd."
msgstr ""
"试想一下，两个数据集除了一条记录（例如 Alice "
"的数据）之外完全相同。差分隐私（DP）可以保证任何分析（M），比如计算平均收入，对两个数据集都会产生几乎相同的结果（O 和 O' "
"将是相似的）。这既保留了群体模式，又掩盖了个人细节，确保个人的信息隐藏在人群中。"

#: ../../source/explanation-differential-privacy.rst:-1
#, fuzzy
msgid "DP Intro"
msgstr "DP 介绍"

#: ../../source/explanation-differential-privacy.rst:27
#, fuzzy
msgid ""
"One of the most commonly used mechanisms to achieve DP is adding enough "
"noise to the output of the analysis to mask the contribution of each "
"individual in the data while preserving the overall accuracy of the "
"analysis."
msgstr "实现 DP 的最常用机制之一是在分析输出中加入足够的噪音，以掩盖数据中每个个体的贡献，同时保持分析的整体准确性。"

#: ../../source/explanation-differential-privacy.rst:32
#, fuzzy
msgid "Formal Definition"
msgstr "编译 ProtoBuf 定义"

#: ../../source/explanation-differential-privacy.rst:34
#, fuzzy
msgid ""
"Differential Privacy (DP) provides statistical guarantees against the "
"information an adversary can infer through the output of a randomized "
"algorithm. It provides an unconditional upper bound on the influence of a"
" single individual on the output of the algorithm by adding noise [1]. A "
"randomized mechanism M provides (:math:`\\epsilon`, "
":math:`\\delta`)-differential privacy if for any two neighboring "
"databases, D :sub:`1` and D :sub:`2`, that differ in only a single "
"record, and for all possible outputs S ⊆ Range(A):"
msgstr ""
"差分隐私（Differential "
"Privacy，DP）针对对手通过随机算法的输出所能推断出的信息提供统计保证。它为单个个体通过添加噪声对算法输出的影响提供了一个无条件的上限[1]。如果任意两个相邻的数据库D"
" :sub:`1`和D :sub:`2`只有一条记录不同，并且对于所有可能的输出S ⊆ "
"Range(A)，随机化机制M提供（:math:`epsilon`，:math:`\\delta`）差异隐私："

#: ../../source/explanation-differential-privacy.rst:42
#, fuzzy
msgid ""
"\\small\n"
"P[M(D_{1} \\in A)] \\leq e^{\\epsilon} P[M(D_{2} \\in A)] + \\delta"
msgstr ""
"\\small\n"
"P[M(D_{1} \\in A)] \\leq e^{\\delta} P[M(D_{2} \\in A)] + \\delta"

#: ../../source/explanation-differential-privacy.rst:47
#, fuzzy
msgid ""
"The :math:`\\epsilon` parameter, also known as the privacy budget, is a "
"metric of privacy loss. It also controls the privacy-utility trade-off; "
"lower :math:`\\epsilon` values indicate higher levels of privacy but are "
"likely to reduce utility as well. The :math:`\\delta` parameter accounts "
"for a small probability on which the upper bound :math:`\\epsilon` does "
"not hold. The amount of noise needed to achieve differential privacy is "
"proportional to the sensitivity of the output, which measures the maximum"
" change in the output due to the inclusion or removal of a single record."
msgstr ""
":math:`\\epsilon`参数也称为隐私预算，是衡量隐私损失的指标。较低的 :math:`\\epsilon` "
"值表示较高的隐私级别，但也可能降低效用。:math:`\\delta`参数考虑了:math:`\\epsilon`上限不成立的小概率。实现差异化隐私所需的噪声量与输出的灵敏度成正比，而输出的灵敏度是指由于包含或删除一条记录而导致的输出的最大变化。"

#: ../../source/explanation-differential-privacy.rst:56
#, fuzzy
msgid "Differential Privacy in Machine Learning"
msgstr "差分隐私"

#: ../../source/explanation-differential-privacy.rst:58
#, fuzzy
msgid ""
"DP can be utilized in machine learning to preserve the privacy of the "
"training data. Differentially private machine learning algorithms are "
"designed in a way to prevent the algorithm to learn any specific "
"information about any individual data points and subsequently prevent the"
" model from revealing sensitive information. Depending on the stage at "
"which noise is introduced, various methods exist for applying DP to "
"machine learning algorithms. One approach involves adding noise to the "
"training data (either to the features or labels), while another method "
"entails injecting noise into the gradients of the loss function during "
"model training. Additionally, such noise can be incorporated into the "
"model's output."
msgstr ""
"机器学习中可以利用 DP "
"来保护训练数据的隐私。差分保密机器学习算法的设计方式是防止算法学习到任何单个数据点的任何特定信息，从而防止模型泄露敏感信息。根据引入噪声的阶段，有多种方法可将"
" DP "
"应用于机器学习算法。一种方法是在训练数据（特征或标签）中添加噪声，另一种方法是在模型训练过程中向损失函数的梯度注入噪声。此外，这种噪声还可以被纳入模型的输出中。"

#: ../../source/explanation-differential-privacy.rst:69
#, fuzzy
msgid "Differential Privacy in Federated Learning"
msgstr "扩大联邦学习的规模"

#: ../../source/explanation-differential-privacy.rst:71
#, fuzzy
msgid ""
"Federated learning is a data minimization approach that allows multiple "
"parties to collaboratively train a model without sharing their raw data. "
"However, federated learning also introduces new privacy challenges. The "
"model updates between parties and the central server can leak information"
" about the local data. These leaks can be exploited by attacks such as "
"membership inference and property inference attacks, or model inversion "
"attacks."
msgstr "联合学习是一种数据最小化方法，允许多方在不共享原始数据的情况下合作训练一个模型。然而，联合学习也带来了新的隐私挑战。各方与中央服务器之间的模型更新可能会泄露本地数据信息。这些泄漏信息可能会被攻击利用，如成员推断攻击、属性推断攻击或模型反转攻击。"

#: ../../source/explanation-differential-privacy.rst:78
#, fuzzy
msgid ""
"DP can play a crucial role in federated learning to provide privacy for "
"the clients' data."
msgstr "DP 可以在联合学习中发挥重要作用，为客户数据提供隐私保护。"

#: ../../source/explanation-differential-privacy.rst:81
#, fuzzy
msgid ""
"Depending on the granularity of privacy provision or the location of "
"noise addition, different forms of DP exist in federated learning. In "
"this explainer, we focus on two approaches of DP utilization in federated"
" learning based on where the noise is added: at the server (also known as"
" the center) or at the client (also known as the local)."
msgstr ""
"根据提供隐私的粒度或添加噪声的位置，联合学习中存在不同形式的 DP。在本说明中，我们将根据添加噪声的位置，重点介绍联合学习中利用 DP "
"的两种方法：在服务器（也称为中心）或客户端（也称为本地）。"

#: ../../source/explanation-differential-privacy.rst:86
#, fuzzy
msgid ""
"**Central Differential Privacy**: DP is applied by the server and the "
"goal is to prevent the aggregated model from leaking information about "
"each client's data."
msgstr "**中央差分隐私**： DP 由服务器应用，目标是防止聚合模型泄露每个客户的数据信息。"

#: ../../source/explanation-differential-privacy.rst:88
#, fuzzy
msgid ""
"**Local Differential Privacy**: DP is applied on the client side before "
"sending any information to the server and the goal is to prevent the "
"updates that are sent to the server from leaking any information about "
"the client's data."
msgstr "**本地差分隐私**： 在向服务器发送任何信息之前，在客户端应用 DP，目的是防止向服务器发送的更新泄露任何有关客户端数据的信息。"

#: ../../source/explanation-differential-privacy.rst:-1
#: ../../source/explanation-differential-privacy.rst:93
#: ../../source/how-to-use-differential-privacy.rst:15
#, fuzzy
msgid "Central Differential Privacy"
msgstr "差分隐私"

#: ../../source/explanation-differential-privacy.rst:95
#, fuzzy
msgid ""
"In this approach, which is also known as user-level DP, the central "
"server is responsible for adding noise to the globally aggregated "
"parameters. It should be noted that trust in the server is required."
msgstr "在这种方法（也称为用户级 DP）中，中央服务器负责在全局汇总参数中添加噪声。需要注意的是，这需要对服务器的信任。"

#: ../../source/explanation-differential-privacy.rst:104
#, fuzzy
msgid ""
"While there are various ways to implement central DP in federated "
"learning, we concentrate on the algorithms proposed by [2] and [3]. The "
"overall approach is to clip the model updates sent by the clients and add"
" some amount of noise to the aggregated model. In each iteration, a "
"random set of clients is chosen with a specific probability for training."
" Each client performs local training on its own data. The update of each "
"client is then clipped by some value `S` (sensitivity `S`). This would "
"limit the impact of any individual client which is crucial for privacy "
"and often beneficial for robustness. A common approach to achieve this is"
" by restricting the `L2` norm of the clients' model updates, ensuring "
"that larger updates are scaled down to fit within the norm `S`."
msgstr ""
"虽然在联合学习中实现中央数据处理的方法有很多种，但我们将重点放在[2]和[3]提出的算法上。总体方法是剪辑客户端发送的模型更新，并在聚合模型中添加一定量的噪声。在每次迭代中，以特定概率随机选择一组客户端进行训练。每个客户端对自己的数据进行局部训练。然后，每个客户端的更新会被某个值`S`（灵敏度`S`）剪切。这将限制任何单个客户端的影响，这对隐私至关重要，通常也有利于稳健性。实现这一点的常用方法是限制客户机模型更新的"
" `L2` 准则，确保较大的更新被缩减以适应 `S` 准则。"

#: ../../source/explanation-differential-privacy.rst:-1
#, fuzzy
msgid "clipping"
msgstr "剪贴"

#: ../../source/explanation-differential-privacy.rst:120
#, fuzzy
msgid ""
"Afterwards, the Gaussian mechanism is used to add noise in order to "
"distort the sum of all clients' updates. The amount of noise is scaled to"
" the sensitivity value to obtain a privacy guarantee. The Gaussian "
"mechanism is used with a noise sampled from `N (0, σ²)` where `σ = ( "
"noise_scale * S ) / (number of sampled clients)`."
msgstr ""
"然后，使用高斯机制添加噪声，以扭曲所有客户端的更新总和。噪声量与灵敏度值成正比，以获得隐私保证。高斯机制的噪声采样范围为 `N (0, σ²)` "
"，其中 σ = ( 噪声规模 * S ) / (采样客户数)`。"

#: ../../source/explanation-differential-privacy.rst:126
#, fuzzy
msgid "Clipping"
msgstr "剪贴"

#: ../../source/explanation-differential-privacy.rst:128
#, fuzzy
msgid ""
"There are two forms of clipping commonly used in Central DP: Fixed "
"Clipping and Adaptive Clipping."
msgstr "中央处理器常用的剪切有两种形式：固定剪切和自适应剪切。"

#: ../../source/explanation-differential-privacy.rst:131
#, fuzzy
msgid ""
"**Fixed Clipping** : A predefined fix threshold is set for the magnitude "
"of clients' updates. Any update exceeding this threshold is clipped back "
"to the threshold value."
msgstr "** 固定削波** ： 为客户端更新的大小设置了一个预定义的固定阈值。任何超过该阈值的更新都会被剪切回阈值。"

#: ../../source/explanation-differential-privacy.rst:133
#, fuzzy
msgid ""
"**Adaptive Clipping** : The clipping threshold dynamically adjusts based "
"on the observed update distribution [4]. It means that the clipping value"
" is tuned during the rounds with respect to the quantile of the update "
"norm distribution."
msgstr "** 自适应削波** ： 削波阈值根据观察到的更新分布动态调整[4]。这意味着，在各轮中，会根据更新规范分布的量化值调整削波值。"

#: ../../source/explanation-differential-privacy.rst:137
#, fuzzy
msgid ""
"The choice between fixed and adaptive clipping depends on various factors"
" such as privacy requirements, data distribution, model complexity, and "
"others."
msgstr "在固定剪切和自适应剪切之间做出选择取决于各种因素，如隐私要求、数据分布、模型复杂性等。"

#: ../../source/explanation-differential-privacy.rst:-1
#: ../../source/explanation-differential-privacy.rst:141
#: ../../source/how-to-use-differential-privacy.rst:114
#, fuzzy
msgid "Local Differential Privacy"
msgstr "差分隐私"

#: ../../source/explanation-differential-privacy.rst:143
#, fuzzy
msgid ""
"In this approach, each client is responsible for performing DP. Local DP "
"avoids the need for a fully trusted aggregator, but it should be noted "
"that local DP leads to a decrease in accuracy but better privacy in "
"comparison to central DP."
msgstr ""
"在这种方法中，每个客户端都负责执行 DP。本地 DP 避免了对完全可信的聚合器的需求，但需要注意的是，与中央 DP 相比，本地 DP "
"会降低准确性，但却能更好地保护隐私。"

#: ../../source/explanation-differential-privacy.rst:152
#, fuzzy
msgid "In this explainer, we focus on two forms of achieving Local DP:"
msgstr "在本说明中，我们将重点介绍实现本地 DP 的两种形式："

#: ../../source/explanation-differential-privacy.rst:154
#, fuzzy
msgid ""
"Each client adds noise to the local updates before sending them to the "
"server. To achieve (:math:`\\epsilon`, :math:`\\delta`)-DP, considering "
"the sensitivity of the local model to be ∆, Gaussian noise is applied "
"with a noise scale of σ where:"
msgstr ""
"每个客户端在向服务器发送本地更新之前，都会在本地更新中加入噪声。为了实现（:math:`\\epsilon`, "
":math:`\\delta`）-DP，考虑到本地模型的灵敏度为 ∆，应用了高斯噪声，噪声尺度为 σ，其中："

#: ../../source/explanation-differential-privacy.rst:158
#, fuzzy
msgid ""
"\\small\n"
"\\frac{∆ \\times \\sqrt{2 \\times "
"\\log\\left(\\frac{1.25}{\\delta}\\right)}}{\\epsilon}"
msgstr ""
"\\small\n"
"\\frac{∆ \\times \\sqrt{2 \\times "
"\\log\\left(\\frac{1.25}{\\delta}\\right)}}{\\epsilon}\n"
"\n"

#: ../../source/explanation-differential-privacy.rst:163
#, fuzzy
msgid ""
"Each client adds noise to the gradients of the model during the local "
"training (DP-SGD). More specifically, in this approach, gradients are "
"clipped and an amount of calibrated noise is injected into the gradients."
msgstr "在局部训练过程中，每个客户端都会向模型的梯度添加噪声（DP-SGD）。更具体地说，在这种方法中，梯度会被剪切，并在梯度中注入一定量的校准噪声。"

#: ../../source/explanation-differential-privacy.rst:167
#, fuzzy
msgid ""
"Please note that these two approaches are providing privacy at different "
"levels."
msgstr "请注意，这两种方法提供了不同层次的隐私。"

#: ../../source/explanation-differential-privacy.rst:169
#, fuzzy
msgid "**References:**"
msgstr "参考资料"

#: ../../source/explanation-differential-privacy.rst:171
#, fuzzy
msgid "[1] Dwork et al. The Algorithmic Foundations of Differential Privacy."
msgstr "[1] Dwork 等：《差分隐私的算法基础》。"

#: ../../source/explanation-differential-privacy.rst:173
#, fuzzy
msgid ""
"[2] McMahan et al. Learning Differentially Private Recurrent Language "
"Models."
msgstr ""
"McMahan, H. Brendan等. \"Learning differentially private recurrent "
"language models.\" arXiv preprint arXiv:1710.06963 (2017)."

#: ../../source/explanation-differential-privacy.rst:175
#, fuzzy
msgid ""
"[3] Geyer et al. Differentially Private Federated Learning: A Client "
"Level Perspective."
msgstr "[3] Geyer 等人。差异化化私人联合学习：客户层面的视角。"

#: ../../source/explanation-differential-privacy.rst:177
#, fuzzy
msgid "[4] Galen et al. Differentially Private Learning with Adaptive Clipping."
msgstr ""
"Andrew, Galen等. \"Differentially private learning with adaptive "
"clipping.\" Advances in Neural Information Processing Systems 34 (2021): "
"17455-17466."

#: ../../source/explanation-federated-evaluation.rst:2
msgid "Federated evaluation"
msgstr "联邦学习评估"

#: ../../source/explanation-federated-evaluation.rst:4
msgid ""
"There are two main approaches to evaluating models in federated learning "
"systems: centralized (or server-side) evaluation and federated (or "
"client-side) evaluation."
msgstr "评估联合学习系统中的模型主要有两种方法：集中（或服务器端）评估和联邦（或客户端）评估。"

#: ../../source/explanation-federated-evaluation.rst:8
msgid "Centralized Evaluation"
msgstr "集中评估"

#: ../../source/explanation-federated-evaluation.rst:11
msgid "Built-In Strategies"
msgstr "内置策略"

#: ../../source/explanation-federated-evaluation.rst:13
msgid ""
"All built-in strategies support centralized evaluation by providing an "
"evaluation function during initialization. An evaluation function is any "
"function that can take the current global model parameters as input and "
"return evaluation results:"
msgstr "所有内置策略都通过在初始化过程中提供一个评估函数来支持集中评估。评估函数是任何可以将当前全局模型参数作为输入并返回评估结果的函数："

#: ../../source/explanation-federated-evaluation.rst:70
msgid "Custom Strategies"
msgstr "定制策略"

#: ../../source/explanation-federated-evaluation.rst:72
#, fuzzy
msgid ""
"The ``Strategy`` abstraction provides a method called ``evaluate`` that "
"can directly be used to evaluate the current global model parameters. The"
" current server implementation calls ``evaluate`` after parameter "
"aggregation and before federated evaluation (see next paragraph)."
msgstr ""
":code:`Strategy` 抽象提供了一个名为 :code:`evaluate` "
"的方法，可直接用于评估当前的全局模型参数。服务器会在参数聚合后和联邦评估前调用 :code:`evaluate`（见下段）。"

#: ../../source/explanation-federated-evaluation.rst:78
#: ../../source/tutorial-series-what-is-federated-learning.ipynb:292
msgid "Federated Evaluation"
msgstr "联邦评估"

#: ../../source/explanation-federated-evaluation.rst:81
msgid "Implementing Federated Evaluation"
msgstr "实现联邦评估"

#: ../../source/explanation-federated-evaluation.rst:83
#, fuzzy
msgid ""
"Client-side evaluation happens in the ``Client.evaluate`` method and can "
"be configured from the server side."
msgstr "客户端评估在 :code:`Client.evaluate` 方法中进行，并可从服务器端进行配置。"

#: ../../source/explanation-federated-evaluation.rst:116
msgid "Configuring Federated Evaluation"
msgstr "配置联邦评估"

#: ../../source/explanation-federated-evaluation.rst:118
msgid ""
"Federated evaluation can be configured from the server side. Built-in "
"strategies support the following arguments:"
msgstr "联邦评估可从服务器端进行配置。内置策略支持以下参数："

#: ../../source/explanation-federated-evaluation.rst:121
#, fuzzy
msgid ""
"``fraction_evaluate``: a ``float`` defining the fraction of clients that "
"will be selected for evaluation. If ``fraction_evaluate`` is set to "
"``0.1`` and ``100`` clients are connected to the server, then ``10`` will"
" be randomly selected for evaluation. If ``fraction_evaluate`` is set to "
"``0.0``, federated evaluation will be disabled."
msgstr ""
":code:`fraction_evaluate`： :code:`float`，定义了被选中进行评估的客户端的比例。如果 "
":code:`fraction_evaluate` 设置为 :code:`0.1`，并且 :code:`100` 个客户端连接到服务器，那么 "
":code:`10` 个客户端将被随机选中进行评估。如果 :code:`fraction_evaluate` 设置为 "
":code:`0.0`，联邦评估将被禁用。"

#: ../../source/explanation-federated-evaluation.rst:126
#, fuzzy
msgid ""
"``min_evaluate_clients``: an ``int``: the minimum number of clients to be"
" selected for evaluation. If ``fraction_evaluate`` is set to ``0.1``, "
"``min_evaluate_clients`` is set to 20, and ``100`` clients are connected "
"to the server, then ``20`` clients will be selected for evaluation."
msgstr ""
":code:`min_evaluate_clients`：一个 :code:`int`，需要评估的客户的最小数量。如果 "
":code:`fraction_evaluate` 设置为 :code:`0.1`，:code:`min_evaluate_clients` "
"设置为 20，并且有 :code:`100` 个客户端已连接到服务器，那么 :code:`20` 个客户端将被选中进行评估。"

#: ../../source/explanation-federated-evaluation.rst:130
#, fuzzy
msgid ""
"``min_available_clients``: an ``int`` that defines the minimum number of "
"clients which need to be connected to the server before a round of "
"federated evaluation can start. If fewer than ``min_available_clients`` "
"are connected to the server, the server will wait until more clients are "
"connected before it continues to sample clients for evaluation."
msgstr ""
":code:`min_available_clients`： "
":code:`int`，定义了在一轮联邦评估开始之前，需要连接到服务器的最小客户端数量。如果连接到服务器的客户端数量少于 "
":code:`min_available_clients`，服务器将等待更多客户端连接后，才继续采样客户端进行评估。"

#: ../../source/explanation-federated-evaluation.rst:135
#, fuzzy
msgid ""
"``on_evaluate_config_fn``: a function that returns a configuration "
"dictionary which will be sent to the selected clients. The function will "
"be called during each round and provides a convenient way to customize "
"client-side evaluation from the server side, for example, to configure "
"the number of validation steps performed."
msgstr "code:`on_evaluate_config_fn`：返回配置字典的函数，该字典将发送给选定的客户端。该函数将在每一轮中被调用，并提供了一种方便的方法来从服务器端自定义客户端评估，例如，配置执行的验证步骤数。"

#: ../../source/explanation-federated-evaluation.rst:177
msgid "Evaluating Local Model Updates During Training"
msgstr "评估训练期间的本地模型更新"

#: ../../source/explanation-federated-evaluation.rst:179
#, fuzzy
msgid ""
"Model parameters can also be evaluated during training. ``Client.fit`` "
"can return arbitrary evaluation results as a dictionary:"
msgstr "模型参数也可在训练过程中进行评估。 :code:`Client.fit`可以字典形式返回任意评估结果："

#: ../../source/explanation-federated-evaluation.rst:220
msgid "Full Code Example"
msgstr "完整代码示例"

#: ../../source/explanation-federated-evaluation.rst:222
#, fuzzy
msgid ""
"For a full code example that uses both centralized and federated "
"evaluation, see the `Advanced TensorFlow Example "
"<https://github.com/adap/flower/tree/main/examples/advanced-tensorflow>`_"
" (the same approach can be applied to workloads implemented in any other "
"framework)."
msgstr ""
"有关同时使用集中评估和联邦评估的完整代码示例，请参阅 *Advanced TensorFlow "
"Example*（同样的方法也可应用于任何其他框架中）： "
"https://github.com/adap/flower/tree/main/examples/advanced-tensorflow"

#: ../../source/explanation-flower-architecture.rst:-1
msgid ""
"Explore the federated learning architecture of the Flower framework, "
"featuring multi-run, concurrent execution, and scalable, secure machine "
"learning while preserving data privacy."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:2
msgid "Flower Architecture"
msgstr "Flower的架构"

#: ../../source/explanation-flower-architecture.rst:4
msgid ""
"This page explains the architecture of deployed Flower federated learning"
" system."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:6
msgid ""
"In federated learning (FL), there is typically one server and a number of"
" clients that are connected to the server. This is often called a "
"federation."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:9
msgid ""
"The role of the server is to coordinate the training process. The role of"
" each client is to receive tasks from the server, execute those tasks and"
" return the results back to the server."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:13
msgid "This is sometimes called a hub-and-spoke topology:"
msgstr ""

#: ../../source/explanation-flower-architecture.rst:21
#, fuzzy
msgid "Hub-and-spoke topology in federated learning"
msgstr "什么是联邦学习？"

#: ../../source/explanation-flower-architecture.rst:21
msgid ""
"Hub-and-spoke topology in federated learning (one server, multiple "
"clients)."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:23
msgid ""
"In a real-world deployment, we typically want to run different projects "
"on such a federation. Each project could use different hyperparameters, "
"different model architectures, different aggregation strategies, or even "
"different machine learning frameworks like PyTorch and TensorFlow."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:28
msgid ""
"This is why, in Flower, both the server side and the client side are "
"split into two parts. One part is long-lived and responsible for "
"communicating across the network, the other part is short-lived and "
"executes task-specific code."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:32
msgid "A Flower `server` consists of **SuperLink** and ``ServerApp``:"
msgstr ""

#: ../../source/explanation-flower-architecture.rst:34
msgid ""
"**SuperLink**: a long-running process that forwards task instructions to "
"clients (SuperNodes) and receives task results back."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:36
msgid ""
"``ServerApp``: a short-lived process with project-spcific code that "
"customizes all server-side aspects of federated learning systems (client "
"selection, client configuration, result aggregation). This is what AI "
"researchers and AI engineers write when they build Flower apps."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:41
msgid "A Flower `client` consists of **SuperNode** and ``ClientApp``:"
msgstr ""

#: ../../source/explanation-flower-architecture.rst:43
msgid ""
"**SuperNode**: a long-running process that connects to the SuperLink, "
"asks for tasks, executes tasks (for example, \"train this model on your "
"local data\") and returns task results back to the SuperLink."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:46
msgid ""
"``ClientApp``: a short-lived process with project-specific code that "
"customizes all client-side aspects of federated learning systems (local "
"model training and evaluation, pre- and post-processing). This is what AI"
" researchers and AI engineers write when they build Flower apps."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:51
msgid ""
"Why SuperNode and SuperLink? Well, in federated learning, the clients are"
" the actual stars of the show. They hold the training data and they run "
"the actual training. This is why Flower decided to name them "
"**SuperNode**. The **SuperLink** is then responsible for acting as the "
"`missing link` between all those SuperNodes."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:62
#, fuzzy
msgid "Basic Flower architecture"
msgstr "Flower的架构"

#: ../../source/explanation-flower-architecture.rst:62
#, fuzzy
msgid "The basic Flower architecture for federated learning."
msgstr "本轮联邦学习。"

#: ../../source/explanation-flower-architecture.rst:64
msgid ""
"In a Flower app project, users will typically develop the ``ServerApp`` "
"and the ``ClientApp``. All the network communication between `server` and"
" `clients` is taken care of by the SuperLink and SuperNodes."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:70
msgid ""
"For more details, please refer to the |serverapp_link|_ and "
"|clientapp_link|_ documentation."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:73
msgid ""
"With *multi-run*, multiple ``ServerApp``\\s and ``ClientApp``\\s are now "
"capable of running on the same federation consisting of a single long-"
"running SuperLink and multiple long-running SuperNodes. This is sometimes"
" referred to as `multi-tenancy` or `multi-job`."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:78
msgid ""
"As shown in the figure below, two projects, each consisting of a "
"``ServerApp`` and a ``ClientApp``, could share the same SuperLink and "
"SuperNodes."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:87
#, fuzzy
msgid "Multi-tenancy federated learning architecture"
msgstr "使用联邦学习策略"

#: ../../source/explanation-flower-architecture.rst:87
#, fuzzy
msgid "Multi-tenancy federated learning architecture with Flower"
msgstr "步骤 2：使用 Flower 联邦学习"

#: ../../source/explanation-flower-architecture.rst:89
msgid ""
"To illustrate how multi-run works, consider one federated learning "
"training run where a ``ServerApp`` and a ``ClientApp`` are participating "
"in ``[run 1]``. Note that a SuperNode will only run a ``ClientApp`` if it"
" is selected to participate in the training run."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:94
msgid ""
"In ``[run 1]`` below, all the SuperNodes are selected and therefore run "
"their corresponding ``ClientApp``\\s:"
msgstr ""

#: ../../source/explanation-flower-architecture.rst:103
#, fuzzy
msgid "Multi-tenancy federated learning architecture - Run 1"
msgstr "使用联邦学习策略"

#: ../../source/explanation-flower-architecture.rst:103
msgid ""
"Run 1 in a multi-run federated learning architecture with Flower. All "
"SuperNodes participate in the training round."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:106
msgid ""
"However, in ``[run 2]``, only the first and third SuperNodes are selected"
" to participate in the training:"
msgstr ""

#: ../../source/explanation-flower-architecture.rst:115
#, fuzzy
msgid "Multi-tenancy federated learning architecture - Run 2"
msgstr "使用联邦学习策略"

#: ../../source/explanation-flower-architecture.rst:115
msgid ""
"Run 2 in a multi-run federated learning architecture with Flower. Only "
"the first and third SuperNodes are selected to participate in the "
"training round."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:118
msgid ""
"Therefore, with Flower multi-run, different projects (each consisting of "
"a ``ServerApp`` and ``ClientApp``) can run on different sets of clients."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:123
msgid ""
"This explanation covers the Flower Deployment Engine. An explanation "
"covering the Flower Simulation Engine will follow."
msgstr ""

#: ../../source/explanation-flower-architecture.rst:128
#, fuzzy
msgid ""
"As we continue to enhance Flower at a rapid pace, we'll periodically "
"update this explainer document. Feel free to share any feedback with us."
msgstr "随着 Flower Next 的不断快速改进，我们将定期更新本指南。如有任何反馈，请随时与我们分享！"

#: ../../source/how-to-aggregate-evaluation-results.rst:2
msgid "Aggregate evaluation results"
msgstr "整合评估结果"

#: ../../source/how-to-aggregate-evaluation-results.rst:4
msgid ""
"The Flower server does not prescribe a way to aggregate evaluation "
"results, but it enables the user to fully customize result aggregation."
msgstr "Flower 服务器没有规定整合评估结果的方法，但用户可以完全自定义如何整合。"

#: ../../source/how-to-aggregate-evaluation-results.rst:8
msgid "Aggregate Custom Evaluation Results"
msgstr "自定义整合评估结果"

#: ../../source/how-to-aggregate-evaluation-results.rst:10
#, fuzzy
msgid ""
"The same ``Strategy``-customization approach can be used to aggregate "
"custom evaluation results coming from individual clients. Clients can "
"return custom metrics to the server by returning a dictionary:"
msgstr "同样的 :code:`Strategy` 定制方法也可用于汇总来自单个客户端的自定义评估结果。客户端可以通过返回字典的方式向服务器返回自定义指标："

#: ../../source/how-to-aggregate-evaluation-results.rst:38
msgid ""
"The server can then use a customized strategy to aggregate the metrics "
"provided in these dictionaries:"
msgstr "然后，服务器可以使用定制的策略来汇总这些字典中提供的指标："

#: ../../source/how-to-authenticate-supernodes.rst:2
#, fuzzy
msgid "Authenticate SuperNodes"
msgstr "验证超级节点"

#: ../../source/how-to-authenticate-supernodes.rst:4
#, fuzzy
msgid ""
"Flower has built-in support for authenticated SuperNodes that you can use"
" to verify the identities of each SuperNode connecting to a SuperLink. "
"Flower node authentication works similar to how GitHub SSH authentication"
" works:"
msgstr ""
"Flower 内置了对经过身份验证的超级节点的支持，您可以用它来验证连接到超级链接的每个超级节点的身份。Flower 节点身份验证的工作方式与 "
"GitHub SSH 身份验证的工作方式类似："

#: ../../source/how-to-authenticate-supernodes.rst:8
#, fuzzy
msgid "SuperLink (server) stores a list of known (client) node public keys"
msgstr "超级链接（服务器）存储已知（客户端）节点公钥列表"

#: ../../source/how-to-authenticate-supernodes.rst:9
#, fuzzy
msgid ""
"Using ECDH, both SuperNode and SuperLink independently derive a shared "
"secret"
msgstr "使用 ECDH，超级节点和超级链路可独立生成共享秘密"

#: ../../source/how-to-authenticate-supernodes.rst:10
#, fuzzy
msgid ""
"Shared secret is used to compute the HMAC value of the message sent from "
"SuperNode to SuperLink as a token"
msgstr "共享秘密用于计算作为令牌从超级节点发送到超级链接的信息的 HMAC 值"

#: ../../source/how-to-authenticate-supernodes.rst:12
#, fuzzy
msgid "SuperLink verifies the token"
msgstr "超级链接验证令牌"

#: ../../source/how-to-authenticate-supernodes.rst:14
#, fuzzy
msgid ""
"We recommend you to check out the complete `code example "
"<https://github.com/adap/flower/tree/main/examples/flower-"
"authentication>`_ demonstrating federated learning with Flower in an "
"authenticated setting."
msgstr ""
"请参阅`完整代码示例 "
"<https://github.com/adap/flower/tree/main/examples/android>`_了解更多信息。"

#: ../../source/how-to-authenticate-supernodes.rst:20
#, fuzzy
msgid ""
"This guide covers a preview feature that might change in future versions "
"of Flower."
msgstr "本指南涵盖的预览功能可能会在 Flower 的未来版本中有所改变。"

#: ../../source/how-to-authenticate-supernodes.rst:24
#, fuzzy
msgid ""
"For increased security, node authentication can only be used when "
"encrypted connections (SSL/TLS) are enabled."
msgstr "为提高安全性，只有启用加密连接（SSL/TLS）时才能使用节点验证。"

#: ../../source/how-to-authenticate-supernodes.rst:28
#, fuzzy
msgid "Enable node authentication in ``SuperLink``"
msgstr "在 :code:`SuperLink` 中启用节点验证"

#: ../../source/how-to-authenticate-supernodes.rst:30
#, fuzzy
msgid ""
"To enable node authentication, first you need to configure SSL/TLS "
"connections to secure the SuperLink<>SuperNode communication. You can "
"find the complete guide `here <https://flower.ai/docs/framework/how-to-"
"enable-ssl-connections.html>`_. After configuring secure connections, you"
" can enable client authentication in a long-running Flower ``SuperLink``."
" Use the following terminal command to start a Flower ``SuperNode`` that "
"has both secure connections and node authentication enabled:"
msgstr ""
"要启用节点验证，首先需要配置 SSL/TLS 连接，以确保 SuperLink<>SuperNode 通信的安全。您可以在 "
"<https://flower.ai/docs/framework/how-to-enable-ssl-connections.html>`_ "
"找到完整的指南。配置安全连接后，您就可以在长期运行的 Flower "
":code:`SuperLink`中启用客户端身份验证。使用以下终端命令启动一个同时启用了安全连接和节点验证的 Flower "
":code:`SuperNode`："

#: ../../source/how-to-authenticate-supernodes.rst:47
#, fuzzy
msgid "Let's break down the authentication flags:"
msgstr "让我们来分析一下身份验证标志："

#: ../../source/how-to-authenticate-supernodes.rst:49
#, fuzzy
msgid ""
"The first flag ``--auth-list-public-keys`` expects a path to a CSV file "
"storing all known node public keys. You need to store all known node "
"public keys that are allowed to participate in a federation in one CSV "
"file (``.csv``)."
msgstr ""
"第一个标志 :code:`--auth-list-public-keys`（密码：`--auth-list-public-keys`）需要一个 "
"CSV 文件路径，该文件存储了所有已知节点的公钥。您需要在一个 CSV 文件（:code:`.csv`）中存储所有允许参与联盟的已知节点公钥。"

#: ../../source/how-to-authenticate-supernodes.rst:53
#, fuzzy
msgid ""
"A valid CSV file storing known node public keys should list the keys in "
"OpenSSH format, separated by commas and without any comments. For an "
"example, refer to our code sample, which contains a CSV file with two "
"known node public keys."
msgstr ""
"存储已知节点公开密钥的有效 CSV 文件应以 OpenSSH "
"格式列出密钥，以逗号分隔，不含任何注释。有关示例，请参阅我们的代码示例，其中包含一个包含两个已知节点公钥的 CSV 文件。"

#: ../../source/how-to-authenticate-supernodes.rst:57
#, fuzzy
msgid ""
"The second and third flags ``--auth-superlink-private-key`` and ``--auth-"
"superlink-public-key`` expect paths to the server's private and public "
"keys. For development purposes, you can generate a private and public key"
" pair using ``ssh-keygen -t ecdsa -b 384``."
msgstr ""
"第二和第三个标记 :code:`--auth-superlink-private-key` 和 :code:`--auth-superlink-"
"public-key` 希望指向服务器私钥和公钥的路径。出于开发目的，您可以使用 :code:`ssh-keygen -t ecdsa -b "
"384` 生成一对私钥和公钥。"

#: ../../source/how-to-authenticate-supernodes.rst:64
#, fuzzy
msgid ""
"In Flower 1.9, there is no support for dynamically removing, editing, or "
"adding known node public keys to the SuperLink. To change the set of "
"known nodes, you need to shut the server down, edit the CSV file, and "
"start the server again. Support for dynamically changing the set of known"
" nodes is on the roadmap to be released in Flower 1.10 (ETA: June)."
msgstr ""
"在 Flower 1.9 中，超级链接不支持动态删除、编辑或添加已知节点公钥。要更改已知节点集，您需要关闭服务器，编辑 CSV "
"文件，然后重新启动服务器。动态更改已知节点集的支持已列入 Flower 1.10（预计发布时间：6 月）的路线图。"

#: ../../source/how-to-authenticate-supernodes.rst:71
#, fuzzy
msgid "Enable node authentication in ``SuperNode``"
msgstr "在 :code:`SuperNode` 中启用节点验证"

#: ../../source/how-to-authenticate-supernodes.rst:73
#, fuzzy
msgid ""
"Similar to the long-running Flower server (``SuperLink``), you can easily"
" enable node authentication in the long-running Flower client "
"(``SuperNode``). Use the following terminal command to start an "
"authenticated ``SuperNode``:"
msgstr ""
"与长期运行的 Flower 服务器（:code:`SuperLink`）类似，您也可以在长期运行的 Flower "
"客户端（:code:`SuperNode`）中轻松启用节点身份验证。使用以下终端命令启动已验证的 :code:`SuperNode`："

#: ../../source/how-to-authenticate-supernodes.rst:85
#, fuzzy
msgid ""
"The ``--auth-supernode-private-key`` flag expects a path to the node's "
"private key file and the ``--auth-supernode-public-key`` flag expects a "
"path to the node's public key file. For development purposes, you can "
"generate a private and public key pair using ``ssh-keygen -t ecdsa -b "
"384``."
msgstr ""
":code:`--auth-supernode-private-key`标志需要节点私钥文件的路径，:code:`-auth-supernode-"
"public-key`标志需要节点公钥文件的路径。出于开发目的，可以使用 :code:`ssh-keygen -t ecdsa -b 384` "
"生成一对私钥和公钥。"

#: ../../source/how-to-authenticate-supernodes.rst:91
#, fuzzy
msgid "Security notice"
msgstr "安全通知"

#: ../../source/how-to-authenticate-supernodes.rst:93
#, fuzzy
msgid ""
"The system's security relies on the credentials of the SuperLink and each"
" SuperNode. Therefore, it is imperative to safeguard and safely store the"
" credentials to avoid security risks such as Public Key Infrastructure "
"(PKI) impersonation attacks. The node authentication mechanism also "
"involves human interaction, so please ensure that all of the "
"communication is done in a secure manner, using trusted communication "
"methods."
msgstr ""
"系统的安全性依赖于超级链接和每个超级节点的凭证。因此，必须保护和安全存储凭证，以避免公钥基础设施 (PKI) "
"假冒攻击等安全风险。节点验证机制还涉及人机交互，因此请确保使用可信的通信方法，以安全的方式进行所有通信。"

#: ../../source/how-to-authenticate-supernodes.rst:100
#: ../../source/how-to-enable-ssl-connections.rst:71
#: ../../source/how-to-use-built-in-mods.rst:95
#: ../../source/tutorial-series-what-is-federated-learning.ipynb:287
msgid "Conclusion"
msgstr "总结"

#: ../../source/how-to-authenticate-supernodes.rst:102
#, fuzzy
msgid ""
"You should now have learned how to start a long-running Flower server "
"(``SuperLink``) and client (``SuperNode``) with node authentication "
"enabled. You should also know the significance of the private key and "
"store it safely to minimize security risks."
msgstr ""
"现在，您应该已经学会了如何启动长期运行的 Flower "
"服务器（:code:`SuperLink`）和客户端（:code:`SuperNode`）并启用节点身份验证。您还应该知道私钥的重要性，并将其安全存储，以尽量减少安全风险。"

#: ../../source/how-to-configure-clients.rst:2
#, fuzzy
msgid "Configure Clients"
msgstr "配置客户端"

#: ../../source/how-to-configure-clients.rst:4
msgid ""
"Flower provides the ability to send configuration values to clients, "
"allowing server-side control over client behavior. This feature enables "
"flexible and dynamic adjustment of client-side hyperparameters, improving"
" collaboration and experimentation."
msgstr ""

#: ../../source/how-to-configure-clients.rst:9
msgid "Configuration values"
msgstr "配置值"

#: ../../source/how-to-configure-clients.rst:11
msgid ""
"``FitConfig`` and ``EvaluateConfig`` are dictionaries containing "
"configuration values that the server sends to clients during federated "
"learning rounds. These values must be of type ``Scalar``, which includes "
"``bool``, ``bytes``, ``float``, ``int``, or ``str`` (or equivalent types "
"in different languages). Scalar is the value type directly supported by "
"Flower for these configurations."
msgstr ""

#: ../../source/how-to-configure-clients.rst:17
msgid "For example, a ``FitConfig`` dictionary might look like this:"
msgstr ""

#: ../../source/how-to-configure-clients.rst:28
#, fuzzy
msgid ""
"Flower serializes these configuration dictionaries (or *config dicts* for"
" short) to their ProtoBuf representation, transports them to the client "
"using gRPC, and then deserializes them back to Python dictionaries."
msgstr ""
"Flower 将这些配置字典（简称 *config dict*）序列化为 ProtoBuf 表示形式，使用 gRPC "
"将其传输到客户端，然后再反序列化为 Python 字典。"

#: ../../source/how-to-configure-clients.rst:34
#, fuzzy
msgid ""
"Currently, there is no support for directly sending collection types "
"(e.g., ``Set``, ``List``, ``Map``) as values in configuration "
"dictionaries. To send collections, convert them to a supported type "
"(e.g., JSON string) and decode on the client side."
msgstr ""
"目前，还不支持在配置字典中直接发送作为值的集合类型（例如，`Set``, `List`, "
"`Map``）。有几种变通方法可将集合转换为支持的值类型之一（并在客户端将其转换回），从而将集合作为值发送。"

#: ../../source/how-to-configure-clients.rst:38
#, fuzzy
msgid "Example:"
msgstr "实例"

#: ../../source/how-to-configure-clients.rst:51
#, fuzzy
msgid "Configuration through Built-in Strategies"
msgstr "通过内置策略进行配置"

#: ../../source/how-to-configure-clients.rst:53
msgid ""
"Flower provides configuration options to control client behavior "
"dynamically through ``FitConfig`` and ``EvaluateConfig``. These "
"configurations allow server-side control over client-side parameters such"
" as batch size, number of local epochs, learning rate, and evaluation "
"settings, improving collaboration and experimentation."
msgstr ""

#: ../../source/how-to-configure-clients.rst:59
#, fuzzy
msgid "``FitConfig`` and ``EvaluateConfig``"
msgstr "``eval_fn`` --> ``evaluate_fn``"

#: ../../source/how-to-configure-clients.rst:61
msgid ""
"``FitConfig`` and ``EvaluateConfig`` are dictionaries containing "
"configuration values that the server sends to clients during federated "
"learning rounds. These dictionaries enable the server to adjust client-"
"side hyperparameters and monitor progress effectively."
msgstr ""

#: ../../source/how-to-configure-clients.rst:67
#, fuzzy
msgid "``FitConfig``"
msgstr "配置日志记录"

#: ../../source/how-to-configure-clients.rst:69
msgid ""
"``FitConfig`` specifies the hyperparameters for training rounds, such as "
"the batch size, number of local epochs, and other parameters that "
"influence training."
msgstr ""

#: ../../source/how-to-configure-clients.rst:72
msgid "For example, a ``fit_config`` callback might look like this:"
msgstr ""

#: ../../source/how-to-configure-clients.rst:90
msgid ""
"You can then pass this ``fit_config`` callback to a built-in strategy "
"such as ``FedAvg``:"
msgstr ""

#: ../../source/how-to-configure-clients.rst:101
msgid ""
"On the client side, the configuration is received in the ``fit`` method, "
"where it can be read and used:"
msgstr ""

#: ../../source/how-to-configure-clients.rst:124
#, fuzzy
msgid "``EvaluateConfig``"
msgstr ":code:`evaluate`"

#: ../../source/how-to-configure-clients.rst:126
msgid ""
"``EvaluateConfig`` specifies hyperparameters for the evaluation process, "
"such as the batch size, evaluation frequency, or metrics to compute "
"during evaluation."
msgstr ""

#: ../../source/how-to-configure-clients.rst:129
msgid "For example, an ``evaluate_config`` callback might look like this:"
msgstr ""

#: ../../source/how-to-configure-clients.rst:143
msgid ""
"You can pass this ``evaluate_config`` callback to a built-in strategy "
"like ``FedAvg``:"
msgstr ""

#: ../../source/how-to-configure-clients.rst:151
msgid ""
"On the client side, the configuration is received in the ``evaluate`` "
"method, where it can be used during the evaluation process:"
msgstr ""

#: ../../source/how-to-configure-clients.rst:175
msgid "Example: Sending Training Configurations"
msgstr ""

#: ../../source/how-to-configure-clients.rst:177
#, fuzzy
msgid ""
"Imagine we want to send (a) the batch size, (b) the current global round,"
" and (c) the number of local epochs. Our configuration function could "
"look like this:"
msgstr "让我们从一个简单的例子开始。想象一下，我们想要发送给客户端（a）应该使用的批次大小，（b）当前联邦学习的全局轮次，以及（c）客户端训练的遍历数。我们的配置函数可以是这样的："

#: ../../source/how-to-configure-clients.rst:190
msgid ""
"To use this function with a built-in strategy like ``FedAvg``, pass it to"
" the ``FedAvg`` constructor (typically in your ``server_fn``):"
msgstr ""

#: ../../source/how-to-configure-clients.rst:211
#, fuzzy
msgid "Client-Side Configuration"
msgstr "客户端逻辑"

#: ../../source/how-to-configure-clients.rst:213
msgid ""
"On the client side, configurations are received as input to the ``fit`` "
"and ``evaluate`` methods. For example:"
msgstr ""

#: ../../source/how-to-configure-clients.rst:230
msgid "Dynamic Configurations per Round"
msgstr ""

#: ../../source/how-to-configure-clients.rst:232
msgid ""
"Configuration functions are called at the beginning of every round. This "
"allows for dynamic adjustments based on progress. For example, you can "
"increase the number of local epochs in later rounds:"
msgstr ""

#: ../../source/how-to-configure-clients.rst:247
msgid "Customizing Client Configurations"
msgstr ""

#: ../../source/how-to-configure-clients.rst:249
msgid ""
"In some cases, it may be necessary to send different configurations to "
"individual clients. To achieve this, you can create a custom strategy by "
"extending a built-in one, such as ``FedAvg``:"
msgstr ""

#: ../../source/how-to-configure-clients.rst:254
msgid "Example: Client-Specific Configuration"
msgstr ""

#: ../../source/how-to-configure-clients.rst:273
msgid "Next, use this custom strategy as usual:"
msgstr ""

#: ../../source/how-to-configure-clients.rst:287
msgid "Summary of Enhancements"
msgstr ""

#: ../../source/how-to-configure-clients.rst:289
msgid "**Dynamic Configurations**: Enables per-round adjustments via functions."
msgstr ""

#: ../../source/how-to-configure-clients.rst:290
msgid "**Advanced Customization**: Supports client-specific strategies."
msgstr ""

#: ../../source/how-to-configure-clients.rst:291
msgid ""
"**Client-Side Integration**: Configurations accessible in ``fit`` and "
"``evaluate``."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:2
#, fuzzy
msgid "Design stateful ClientApps"
msgstr "客户端"

#: ../../source/how-to-design-stateful-clients.rst:20
msgid ""
"By design, ClientApp_ objects are stateless. This means that the "
"``ClientApp`` object is recreated each time a new ``Message`` is to be "
"processed. This behaviour is identical with Flower's Simulation Engine "
"and Deployment Engine. For the former, it allows us to simulate the "
"running of a large number of nodes on a single machine or across multiple"
" machines. For the latter, it enables each ``SuperNode`` to be part of "
"multiple runs, each running a different ``ClientApp``."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:27
msgid ""
"When a ``ClientApp`` is executed it receives a Context_. This context is "
"unique for each ``ClientApp``, meaning that subsequent executions of the "
"same ``ClientApp`` from the same node will receive the same ``Context`` "
"object. In the ``Context``, the ``.state`` attribute can be used to store"
" information that you would like the ``ClientApp`` to have access to for "
"the duration of the run. This could be anything from intermediate results"
" such as the history of training losses (e.g. as a list of `float` values"
" with a new entry appended each time the ``ClientApp`` is executed), "
"certain parts of the model that should persist at the client side, or "
"some other arbitrary Python objects. These items would need to be "
"serialized before saving them into the context."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:38
msgid "Saving metrics to the context"
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:40
msgid ""
"This section will demonstrate how to save metrics such as accuracy/loss "
"values to the Context_ so they can be used in subsequent executions of "
"the ``ClientApp``. If your ``ClientApp`` makes use of NumPyClient_ then "
"entire object is also re-created for each call to methods like ``fit()`` "
"or ``evaluate()``."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:45
msgid ""
"Let's begin with a simple setting in which ``ClientApp`` is defined as "
"follows. The ``evaluate()`` method only generates a random number and "
"prints it."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:50
msgid ""
"You can create a PyTorch project with ready-to-use ``ClientApp`` and "
"other components by running ``flwr new``."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:81
msgid ""
"Let's say we want to save that randomly generated integer and append it "
"to a list that persists in the context. To do that, you'll need to do two"
" key things:"
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:84
msgid "Make the ``context.state`` reachable withing your client class"
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:85
msgid ""
"Initialise the appropiate record type (in this example we use "
"ConfigsRecord_) and save/read your entry when required."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:123
msgid ""
"If you run the app, you'll see an output similar to the one below. See "
"how after each round the `n_val` entry in the context gets one additional"
" integer ? Note that the order in which the `ClientApp` logs these "
"messages might differ slightly between rounds."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:146
msgid "Saving model parameters to the context"
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:148
msgid ""
"Using ConfigsRecord_ or MetricsRecord_ to save \"simple\" components is "
"fine (e.g., float, integer, boolean, string, bytes, and lists of these "
"types. Note that MetricsRecord_ only supports float, integer, and lists "
"of these types) Flower has a specific type of record, a "
"ParametersRecord_, for storing model parameters or more generally data "
"arrays."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:153
msgid ""
"Let's see a couple of examples of how to save NumPy arrays first and then"
" how to save parameters of PyTorch and TensorFlow models."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:158
msgid ""
"The examples below omit the definition of a ``ClientApp`` to keep the "
"code blocks concise. To make use of ``ParametersRecord`` objects in your "
"``ClientApp`` you can follow the same principles as outlined earlier."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:163
#, fuzzy
msgid "Saving NumPy arrays to the context"
msgstr "将 NumPy ndarray 序列化为字节。"

#: ../../source/how-to-design-stateful-clients.rst:165
msgid ""
"Elements stored in a `ParametersRecord` are of type Array_, which is a "
"data structure that holds ``bytes`` and metadata that can be used for "
"deserialization. Let's see how to create an ``Array`` from a NumPy array "
"and insert it into a ``ParametersRecord``. Here we will make use of the "
"built-in serialization and deserialization mechanisms in Flower, namely "
"the ``flwr.common.array_from_numpy`` function and the `numpy()` method of"
" an Array_ object."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:174
msgid ""
"Array_ objects carry bytes as their main payload and additional metadata "
"to use for deserialization. You can implement your own "
"serialization/deserialization if the provided ``array_from_numpy`` "
"doesn't fit your usecase."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:178
msgid ""
"Let's see how to use those functions to store a NumPy array into the "
"context."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:206
msgid ""
"To extract the data in a ``ParametersRecord``, you just need to "
"deserialize the array if interest. For example, following the example "
"above:"
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:223
msgid "Saving PyTorch parameters to the context"
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:225
msgid ""
"Following the NumPy example above, to save parameters of a PyTorch model "
"a straightforward way of doing so is to transform the parameters into "
"their NumPy representation and then proceed as shown earlier. Below is a "
"simple self-contained example for how to do this."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:263
msgid ""
"Let say now you want to apply the parameters stored in your context to a "
"new instance of the model (as it happens each time a ``ClientApp`` is "
"executed). You will need to:"
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:266
msgid "Deserialize each element in your specific ``ParametersRecord``"
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:267
msgid "Construct a ``state_dict`` and load it"
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:287
msgid ""
"And that's it! Recall that even though this example shows how to store "
"the entire ``state_dict`` in a ``ParametersRecord``, you can just save "
"part of it. The process would be identical, but you might need to adjust "
"how it is loaded into an existing model using PyTorch APIs."
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:293
msgid "Saving Tensorflow/Keras parameters to the context"
msgstr ""

#: ../../source/how-to-design-stateful-clients.rst:295
msgid ""
"Follow the same steps as done above but replace the ``state_dict`` logic "
"with simply `get_weights() "
"<https://www.tensorflow.org/api_docs/python/tf/keras/Layer#get_weights>`_"
" to convert the model parameters to a list of NumPy arrays that can then "
"be serialized into an ``Array``. Then, after deserialization, use "
"`set_weights() "
"<https://www.tensorflow.org/api_docs/python/tf/keras/Layer#set_weights>`_"
" to apply the new parameters to a model."
msgstr ""

#: ../../source/how-to-enable-ssl-connections.rst:2
msgid "Enable SSL connections"
msgstr "启用 SSL 连接"

#: ../../source/how-to-enable-ssl-connections.rst:4
#, fuzzy
msgid ""
"This guide describes how to a SSL-enabled secure Flower server "
"(``SuperLink``) can be started and how a Flower client (``SuperNode``) "
"can establish a secure connections to it."
msgstr "本指南介绍如何启动启用 SSL 的安全 Flower 服务器，以及 Flower 客户端如何与其建立安全连接。"

#: ../../source/how-to-enable-ssl-connections.rst:8
msgid ""
"A complete code example demonstrating a secure connection can be found "
"`here <https://github.com/adap/flower/tree/main/examples/advanced-"
"tensorflow>`_."
msgstr ""
"有关安全连接的完整代码示例，请参见 <https://github.com/adap/flower/tree/main/examples"
"/advanced-tensorflow>`_ 。"

#: ../../source/how-to-enable-ssl-connections.rst:11
#, fuzzy
msgid ""
"The code example comes with a ``README.md`` file which explains how to "
"start it. Although it is already SSL-enabled, it might be less "
"descriptive on how it does so. Stick to this guide for a deeper "
"introduction to the topic."
msgstr "代码示例附带的 README.md 文件将解释如何启动它。虽然它已经启用了 SSL，但对如何启用可能描述较少。请参考本指南，了解更深入的相关介绍。"

#: ../../source/how-to-enable-ssl-connections.rst:16
msgid "Certificates"
msgstr "证书"

#: ../../source/how-to-enable-ssl-connections.rst:18
#, fuzzy
msgid ""
"Using SSL-enabled connections requires certificates to be passed to the "
"server and client. For the purpose of this guide we are going to generate"
" self-signed certificates. As this can become quite complex we are going "
"to ask you to run the script in ``examples/advanced-"
"tensorflow/certificates/generate.sh`` with the following command "
"sequence:"
msgstr ""
"使用支持 SSL 的连接需要向服务器和客户端传递证书。在本指南中，我们将生成自签名证书。由于这可能会变得相当复杂，我们将要求你运行 "
":code:`examples/advanced-tensorflow/certificates/generate.sh` 中的脚本"

#: ../../source/how-to-enable-ssl-connections.rst:29
#, fuzzy
msgid ""
"This will generate the certificates in ``examples/advanced-"
"tensorflow/.cache/certificates``."
msgstr "这将在 :code:`examples/advanced-tensorflow/.cache/certificates` 中生成证书。"

#: ../../source/how-to-enable-ssl-connections.rst:32
#, fuzzy
msgid ""
"The approach for generating SSL certificates in the context of this "
"example can serve as an inspiration and starting point, but it should not"
" be used as a reference for production environments. Please refer to "
"other sources regarding the issue of correctly generating certificates "
"for production environments. For non-critical prototyping or research "
"projects, it might be sufficient to use the self-signed certificates "
"generated using the scripts mentioned in this guide."
msgstr "本示例中生成 SSL 证书的方法可作为启发和起点，但不应被视为生产环境的完整方法。有关在生产环境中正确生成证书的问题，请参考其他资料。"

#: ../../source/how-to-enable-ssl-connections.rst:40
#, fuzzy
msgid "Server (SuperLink)"
msgstr "flower-superlink"

#: ../../source/how-to-enable-ssl-connections.rst:42
#, fuzzy
msgid ""
"Use the following terminal command to start a sever (SuperLink) that uses"
" the previously generated certificates:"
msgstr "现在我们将演示如何编写一个客户端，使用之前生成的脚本："

#: ../../source/how-to-enable-ssl-connections.rst:52
#, fuzzy
msgid ""
"When providing certificates, the server expects a tuple of three "
"certificates paths: CA certificate, server certificate and server private"
" key."
msgstr "要启用 SSL，需要 CA 证书、服务器证书和服务器私钥。"

#: ../../source/how-to-enable-ssl-connections.rst:56
#, fuzzy
msgid "Client (SuperNode)"
msgstr "客户端状态代码。"

#: ../../source/how-to-enable-ssl-connections.rst:58
#, fuzzy
msgid ""
"Use the following terminal command to start a client (SuperNode) that "
"uses the previously generated certificates:"
msgstr "现在我们将演示如何编写一个客户端，使用之前生成的脚本："

#: ../../source/how-to-enable-ssl-connections.rst:67
#, fuzzy
msgid ""
"When setting ``root_certificates``, the client expects a file path to "
"PEM-encoded root certificates."
msgstr ""
"当设置 :code:`root_certificates` 时，客户端希望 PEM 编码的根证书是字节字符串。我们再次使用 "
":code:`Path` 来简化以字节字符串形式读取证书的过程。"

#: ../../source/how-to-enable-ssl-connections.rst:73
#, fuzzy
msgid ""
"You should now have learned how to generate self-signed certificates "
"using the given script, start an SSL-enabled server and have a client "
"establish a secure connection to it."
msgstr "现在，你应该已经学会了如何使用给定的脚本生成自签名证书、启动启用 SSL 的服务器并让客户端与其建立安全连接。"

#: ../../source/how-to-enable-ssl-connections.rst:78
msgid "Additional resources"
msgstr "补充资源"

#: ../../source/how-to-enable-ssl-connections.rst:80
msgid ""
"These additional sources might be relevant if you would like to dive "
"deeper into the topic of certificates:"
msgstr "如果您想更深入地了解证书主题，这些额外的资料来源可能有帮助："

#: ../../source/how-to-enable-ssl-connections.rst:83
msgid "`Let's Encrypt <https://letsencrypt.org/docs/>`_"
msgstr "`让我们加密 <https://letsencrypt.org/docs/>`_"

#: ../../source/how-to-enable-ssl-connections.rst:84
msgid "`certbot <https://certbot.eff.org/>`_"
msgstr "`certbot <https://certbot.eff.org/>`_"

#: ../../source/how-to-implement-fedbn.rst:2
#, fuzzy
msgid "Implement FedBN"
msgstr "实施策略"

#: ../../source/how-to-implement-fedbn.rst:4
#, fuzzy
msgid ""
"This tutorial will show you how to use Flower to build a federated "
"version of an existing machine learning workload with `FedBN "
"<https://github.com/med-air/FedBN>`_, a federated training method "
"designed for non-IID data. We are using PyTorch to train a Convolutional "
"Neural Network (with Batch Normalization layers) on the CIFAR-10 dataset."
" When applying FedBN, only minor changes are needed compared to "
":doc:`Quickstart PyTorch <tutorial-quickstart-pytorch>`."
msgstr ""
"本教程将向您展示如何使用 Flower 为现有的机器学习框架构建一个联邦学习的版本，并使用 \"FedBN <https://github.com"
"/med-air/FedBN>`_\"（一种针对非 iid 数据设计的联邦训练策略）。我们使用 PyTorch 在 CIFAR-10 "
"数据集上训练一个卷积神经网络（带有Batch Normalization层）。在应用 FedBN 时，只需对 `示例: PyTorch - "
"从集中式到联邦式 <https://flower.ai/docs/examples/pytorch-from-centralized-to-"
"federated.html>`_ 做少量改动。"

#: ../../source/how-to-implement-fedbn.rst:12
#, fuzzy
msgid "Model"
msgstr "模块"

#: ../../source/how-to-implement-fedbn.rst:14
msgid ""
"A full introduction to federated learning with PyTorch and Flower can be "
"found in :doc:`Quickstart PyTorch <tutorial-quickstart-pytorch>`. This "
"how-to guide varies only a few details in ``task.py``. FedBN requires a "
"model architecture (defined in class ``Net()``) that uses Batch "
"Normalization layers:"
msgstr ""

#: ../../source/how-to-implement-fedbn.rst:45
msgid ""
"Try editing the model architecture, then run the project to ensure "
"everything still works:"
msgstr ""

#: ../../source/how-to-implement-fedbn.rst:52
msgid ""
"So far this should all look fairly familiar if you've used Flower with "
"PyTorch before."
msgstr ""

#: ../../source/how-to-implement-fedbn.rst:55
#, fuzzy
msgid "FedBN"
msgstr "DP-FedAvg"

#: ../../source/how-to-implement-fedbn.rst:57
msgid ""
"To adopt FedBN, only the ``get_parameters`` and ``set_parameters`` "
"functions in ``task.py`` need to be revised. FedBN only changes the "
"client-side by excluding batch normalization parameters from being "
"exchanged with the server."
msgstr ""

#: ../../source/how-to-implement-fedbn.rst:61
#, fuzzy
msgid ""
"We revise the *client* logic by changing ``get_parameters`` and "
"``set_parameters`` in ``task.py``. The batch normalization parameters are"
" excluded from model parameter list when sending to or receiving from the"
" server:"
msgstr ""
"最后，我们将修改 *client* 的逻辑，修改 :code:`client.py` 中的 :code:`get_parameters` 和 "
":code:`set_parameters`，在向服务器发送或从服务器接收时，我们将从模型参数列表中排除batch "
"normalization层的参数。"

#: ../../source/how-to-implement-fedbn.rst:90
msgid "To test the new appraoch, run the project again:"
msgstr ""

#: ../../source/how-to-implement-fedbn.rst:96
msgid ""
"Your PyTorch project now runs federated learning with FedBN. "
"Congratulations!"
msgstr ""

#: ../../source/how-to-implement-fedbn.rst:99
msgid "Next Steps"
msgstr "下一步工作"

#: ../../source/how-to-implement-fedbn.rst:101
#, fuzzy
msgid ""
"The example is of course over-simplified since all clients load the exact"
" same dataset. This isn't realistic. You now have the tools to explore "
"this topic further. How about using different subsets of CIFAR-10 on each"
" client? How about adding more clients?"
msgstr ""
"本示例的完整源代码可在 <https://github.com/adap/flower/blob/main/examples/pytorch-"
"from-centralized-to-federated>`_ "
"找到。当然，我们的示例有些过于简单，因为两个客户端都加载了完全相同的数据集，这并不真实。让我们准备好进一步探讨这一主题。如在每个客户端使用不同的 "
"CIFAR-10 子集，或者增加客户端的数量。"

#: ../../source/how-to-implement-strategies.rst:2
msgid "Implement strategies"
msgstr "实施策略"

#: ../../source/how-to-implement-strategies.rst:4
msgid ""
"The strategy abstraction enables implementation of fully custom "
"strategies. A strategy is basically the federated learning algorithm that"
" runs on the server. Strategies decide how to sample clients, how to "
"configure clients for training, how to aggregate updates, and how to "
"evaluate models. Flower provides a few built-in strategies which are "
"based on the same API described below."
msgstr ""
"策略抽象类可以实现完全定制的策略。策略基本上就是在服务器上运行的联邦学习算法。策略决定如何对客户端进行采样、如何配置客户端进行训练、如何聚合参数更新以及如何评估模型。Flower"
" 提供了一些内置策略，这些策略基于下文所述的相同 API。"

#: ../../source/how-to-implement-strategies.rst:11
#, fuzzy
msgid "The ``Strategy`` abstraction"
msgstr ":code:`策略 ` 抽象类"

#: ../../source/how-to-implement-strategies.rst:13
#, fuzzy
msgid ""
"All strategy implementation are derived from the abstract base class "
"``flwr.server.strategy.Strategy``, both built-in implementations and "
"third party implementations. This means that custom strategy "
"implementations have the exact same capabilities at their disposal as "
"built-in ones."
msgstr ""
"所有策略实现均源自抽象基类 "
":code:`flwr.server.strategy.Strategy`，包括内置实现和第三方实现。这意味着自定义策略实现与内置实现具有完全相同的功能。"

#: ../../source/how-to-implement-strategies.rst:18
msgid ""
"The strategy abstraction defines a few abstract methods that need to be "
"implemented:"
msgstr "策略抽象定义了一些需要实现的抽象方法："

#: ../../source/how-to-implement-strategies.rst:67
#, fuzzy
msgid ""
"Creating a new strategy means implementing a new ``class`` (derived from "
"the abstract base class ``Strategy``) that implements for the previously "
"shown abstract methods:"
msgstr "创建一个新策略意味着要实现一个新的 :code:`class`（从抽象基类 :code:`Strategy` 派生），该类要实现前面显示的抽象方法："

#: ../../source/how-to-implement-strategies.rst:97
msgid "The Flower server calls these methods in the following order:"
msgstr "Flower 服务器按以下顺序调用这些方法："

#: ../../source/how-to-implement-strategies.rst:174
msgid "The following sections describe each of those methods in more detail."
msgstr "下文将详细介绍每种方法。"

#: ../../source/how-to-implement-strategies.rst:177
#, fuzzy
msgid "The ``initialize_parameters`` method"
msgstr ":code:`初始化参数` 方法"

#: ../../source/how-to-implement-strategies.rst:179
#, fuzzy
msgid ""
"``initialize_parameters`` is called only once, at the very beginning of "
"an execution. It is responsible for providing the initial global model "
"parameters in a serialized form (i.e., as a ``Parameters`` object)."
msgstr ""
":code:`initialize_parameters` 只调用一次，即在执行开始时。它负责以序列化形式（即 "
":code:`Parameters` 对象）提供初始全局模型参数。"

#: ../../source/how-to-implement-strategies.rst:183
#, fuzzy
msgid ""
"Built-in strategies return user-provided initial parameters. The "
"following example shows how initial parameters can be passed to "
"``FedAvg``:"
msgstr "内置策略会返回用户提供的初始参数。下面的示例展示了如何将初始参数传递给 :code:`FedAvg`："

#: ../../source/how-to-implement-strategies.rst:209
#, fuzzy
msgid ""
"The Flower server will call ``initialize_parameters``, which either "
"returns the parameters that were passed to ``initial_parameters``, or "
"``None``. If no parameters are returned from ``initialize_parameters`` "
"(i.e., ``None``), the server will randomly select one client and ask it "
"to provide its parameters. This is a convenience feature and not "
"recommended in practice, but it can be useful for prototyping. In "
"practice, it is recommended to always use server-side parameter "
"initialization."
msgstr ""
"Flower 服务器将调用 :code:`initialize_parameters`，返回传给 "
":code:`initial_parameters` 的参数或 :code:`None`。如果 "
":code:`initialize_parameters` 没有返回任何参数（即 "
":code:`None`），服务器将随机选择一个客户端并要求其提供参数。这只是一个便捷的功能，在实际应用中并不推荐使用，但在原型开发中可能很有用。在实践中，建议始终使用服务器端参数初始化。"

#: ../../source/how-to-implement-strategies.rst:218
msgid ""
"Server-side parameter initialization is a powerful mechanism. It can be "
"used, for example, to resume training from a previously saved checkpoint."
" It is also the fundamental capability needed to implement hybrid "
"approaches, for example, to fine-tune a pre-trained model using federated"
" learning."
msgstr "服务器端参数初始化是一种强大的机制。例如，它可以用来从先前保存的检查点恢复训练。它也是实现混合方法所需的基本能力，例如，使用联邦学习对预先训练好的模型进行微调。"

#: ../../source/how-to-implement-strategies.rst:224
#, fuzzy
msgid "The ``configure_fit`` method"
msgstr ":code:`configure_fit`方法"

#: ../../source/how-to-implement-strategies.rst:226
#, fuzzy
msgid ""
"``configure_fit`` is responsible for configuring the upcoming round of "
"training. What does *configure* mean in this context? Configuring a round"
" means selecting clients and deciding what instructions to send to these "
"clients. The signature of ``configure_fit`` makes this clear:"
msgstr ""
":code:`configure_fit` "
"负责配置即将开始的一轮训练。*配置*在这里是什么意思？配置一轮训练意味着选择客户并决定向这些客户发送什么指令。:code:`configure_fit`"
" 说明了这一点："

#: ../../source/how-to-implement-strategies.rst:239
#, fuzzy
msgid ""
"The return value is a list of tuples, each representing the instructions "
"that will be sent to a particular client. Strategy implementations "
"usually perform the following steps in ``configure_fit``:"
msgstr "返回值是一个元组列表，每个元组代表将发送到特定客户端的指令。策略实现通常在 :code:`configure_fit` 中执行以下步骤："

#: ../../source/how-to-implement-strategies.rst:243
#: ../../source/how-to-implement-strategies.rst:307
#, fuzzy
msgid ""
"Use the ``client_manager`` to randomly sample all (or a subset of) "
"available clients (each represented as a ``ClientProxy`` object)"
msgstr ""
"使用 :code:`client_manager` 随机抽样所有（或部分）可用客户端（每个客户端都表示为 :code:`ClientProxy` "
"对象）"

#: ../../source/how-to-implement-strategies.rst:245
#, fuzzy
msgid ""
"Pair each ``ClientProxy`` with the same ``FitIns`` holding the current "
"global model ``parameters`` and ``config`` dict"
msgstr ""
"将每个 :code:`ClientProxy` 与持有当前全局模型 :code:`parameters` 和 :code:`config` "
"dict 的 :code:`FitIns` 配对"

#: ../../source/how-to-implement-strategies.rst:248
#, fuzzy
msgid ""
"More sophisticated implementations can use ``configure_fit`` to implement"
" custom client selection logic. A client will only participate in a round"
" if the corresponding ``ClientProxy`` is included in the list returned "
"from ``configure_fit``."
msgstr ""
"更复杂的实现可以使用 :code:`configure_fit` 来实现自定义的客户端选择逻辑。只有当相应的 "
":code:`ClientProxy` 包含在 :code:`configure_fit` 返回的列表中时，客户端才会参与进来。"

#: ../../source/how-to-implement-strategies.rst:254
#, fuzzy
msgid ""
"The structure of this return value provides a lot of flexibility to the "
"user. Since instructions are defined on a per-client basis, different "
"instructions can be sent to each client. This enables custom strategies "
"to train, for example, different models on different clients, or use "
"different hyperparameters on different clients (via the ``config`` dict)."
msgstr ""
"该返回值的结构为用户提供了很大的灵活性。由于指令是按客户端定义的，因此可以向每个客户端发送不同的指令。这使得自定义策略成为可能，例如在不同的客户端上训练不同的模型，或在不同的客户端上使用不同的超参数（通过"
" :code:`config` dict）。"

#: ../../source/how-to-implement-strategies.rst:261
#, fuzzy
msgid "The ``aggregate_fit`` method"
msgstr ":code:`aggregate_fit` 方法"

#: ../../source/how-to-implement-strategies.rst:263
#, fuzzy
msgid ""
"``aggregate_fit`` is responsible for aggregating the results returned by "
"the clients that were selected and asked to train in ``configure_fit``."
msgstr ":code:`aggregate_fit` 负责汇总在 :code:`configure_fit` 中选择并要求训练的客户端所返回的结果。"

#: ../../source/how-to-implement-strategies.rst:277
#, fuzzy
msgid ""
"Of course, failures can happen, so there is no guarantee that the server "
"will get results from all the clients it sent instructions to (via "
"``configure_fit``). ``aggregate_fit`` therefore receives a list of "
"``results``, but also a list of ``failures``."
msgstr ""
"当然，失败是有可能发生的，因此无法保证服务器会从它发送指令（通过 :code:`configure_fit`）的所有客户端获得结果。因此 "
":code:`aggregate_fit` 会收到 :code:`results` 的列表，但也会收到 :code:`failures` 的列表。"

#: ../../source/how-to-implement-strategies.rst:282
#, fuzzy
msgid ""
"``aggregate_fit`` returns an optional ``Parameters`` object and a "
"dictionary of aggregated metrics. The ``Parameters`` return value is "
"optional because ``aggregate_fit`` might decide that the results provided"
" are not sufficient for aggregation (e.g., too many failures)."
msgstr ""
":code:`aggregate_fit` 返回一个可选的 :code:`Parameters` "
"对象和一个聚合度量的字典。:code:`Parameters` 返回值是可选的，因为 :code:`aggregate_fit` "
"可能会认为所提供的结果不足以进行聚合（例如，失败次数过多）。"

#: ../../source/how-to-implement-strategies.rst:288
#, fuzzy
msgid "The ``configure_evaluate`` method"
msgstr ":code:`configure_evaluate`方法"

#: ../../source/how-to-implement-strategies.rst:290
#, fuzzy
msgid ""
"``configure_evaluate`` is responsible for configuring the upcoming round "
"of evaluation. What does *configure* mean in this context? Configuring a "
"round means selecting clients and deciding what instructions to send to "
"these clients. The signature of ``configure_evaluate`` makes this clear:"
msgstr ""
":code:`configure_evaluate` "
"负责配置下一轮评估。*配置*在这里是什么意思？配置一轮评估意味着选择客户端并决定向这些客户端发送什么指令。:code:`configure_evaluate`"
" 说明了这一点："

#: ../../source/how-to-implement-strategies.rst:303
#, fuzzy
msgid ""
"The return value is a list of tuples, each representing the instructions "
"that will be sent to a particular client. Strategy implementations "
"usually perform the following steps in ``configure_evaluate``:"
msgstr "返回值是一个元组列表，每个元组代表将发送到特定客户端的指令。策略实现通常在 :code:`configure_evaluate` 中执行以下步骤："

#: ../../source/how-to-implement-strategies.rst:309
#, fuzzy
msgid ""
"Pair each ``ClientProxy`` with the same ``EvaluateIns`` holding the "
"current global model ``parameters`` and ``config`` dict"
msgstr ""
"将每个 :code:`ClientProxy` 与持有当前全局模型 :code:`parameters` 和 :code:`config` "
"dict 的 :code:`EvaluateIns` 配对"

#: ../../source/how-to-implement-strategies.rst:312
#, fuzzy
msgid ""
"More sophisticated implementations can use ``configure_evaluate`` to "
"implement custom client selection logic. A client will only participate "
"in a round if the corresponding ``ClientProxy`` is included in the list "
"returned from ``configure_evaluate``."
msgstr ""
"更复杂的实现可以使用 :code:`configure_evaluate` 来实现自定义的客户端选择逻辑。只有当相应的 "
":code:`ClientProxy` 包含在 :code:`configure_evaluate` 返回的列表中时，客户端才会参与进来。"

#: ../../source/how-to-implement-strategies.rst:318
#, fuzzy
msgid ""
"The structure of this return value provides a lot of flexibility to the "
"user. Since instructions are defined on a per-client basis, different "
"instructions can be sent to each client. This enables custom strategies "
"to evaluate, for example, different models on different clients, or use "
"different hyperparameters on different clients (via the ``config`` dict)."
msgstr ""
"该返回值的结构为用户提供了很大的灵活性。由于指令是按客户端定义的，因此可以向每个客户端发送不同的指令。这使得自定义策略可以在不同客户端上评估不同的模型，或在不同客户端上使用不同的超参数（通过"
" :code:`config` dict）。"

#: ../../source/how-to-implement-strategies.rst:325
#, fuzzy
msgid "The ``aggregate_evaluate`` method"
msgstr ":code:`aggregate_evaluate` 方法"

#: ../../source/how-to-implement-strategies.rst:327
#, fuzzy
msgid ""
"``aggregate_evaluate`` is responsible for aggregating the results "
"returned by the clients that were selected and asked to evaluate in "
"``configure_evaluate``."
msgstr ""
":code:`aggregate_evaluate` 负责汇总在 :code:`configure_evaluate` "
"中选择并要求评估的客户端返回的结果。"

#: ../../source/how-to-implement-strategies.rst:341
#, fuzzy
msgid ""
"Of course, failures can happen, so there is no guarantee that the server "
"will get results from all the clients it sent instructions to (via "
"``configure_evaluate``). ``aggregate_evaluate`` therefore receives a list"
" of ``results``, but also a list of ``failures``."
msgstr ""
"当然，失败是有可能发生的，因此无法保证服务器会从它发送指令（通过 "
":code:`configure_evaluate`）的所有客户端获得结果。因此， :code:`aggregate_evaluate` 会接收 "
":code:`results` 的列表，但也会接收 :code:`failures` 的列表。"

#: ../../source/how-to-implement-strategies.rst:346
#, fuzzy
msgid ""
"``aggregate_evaluate`` returns an optional ``float`` (loss) and a "
"dictionary of aggregated metrics. The ``float`` return value is optional "
"because ``aggregate_evaluate`` might decide that the results provided are"
" not sufficient for aggregation (e.g., too many failures)."
msgstr ""
":code:`aggregate_evaluate` 返回一个可选的 "
":code:`float`（损失值）和一个聚合指标字典。:code:`float` 返回值是可选的，因为 "
":code:`aggregate_evaluate` 可能会认为所提供的结果不足以进行聚合（例如，失败次数过多）。"

#: ../../source/how-to-implement-strategies.rst:352
#, fuzzy
msgid "The ``evaluate`` method"
msgstr ":code:`evaluate`方法"

#: ../../source/how-to-implement-strategies.rst:354
#, fuzzy
msgid ""
"``evaluate`` is responsible for evaluating model parameters on the "
"server-side. Having ``evaluate`` in addition to "
"``configure_evaluate``/``aggregate_evaluate`` enables strategies to "
"perform both servers-side and client-side (federated) evaluation."
msgstr ""
":code:`evaluate` 负责在服务器端评估模型参数。除了 "
":code:`configure_evaluate`/:code:`aggregate_evaluate` 之外，:code:`evaluate`"
" 可以使策略同时执行服务器端和客户端（联邦）评估。"

#: ../../source/how-to-implement-strategies.rst:364
#, fuzzy
msgid ""
"The return value is again optional because the strategy might not need to"
" implement server-side evaluation or because the user-defined "
"``evaluate`` method might not complete successfully (e.g., it might fail "
"to load the server-side evaluation data)."
msgstr ""
"返回值也是可选的，因为策略可能不需要执行服务器端评估，或者因为用户定义的 :code:`evaluate` "
"方法可能无法成功完成（例如，它可能无法加载服务器端评估数据）。"

#: ../../source/how-to-install-flower.rst:2
msgid "Install Flower"
msgstr "安装Flower"

#: ../../source/how-to-install-flower.rst:5
msgid "Python version"
msgstr "Python 版本"

#: ../../source/how-to-install-flower.rst:11
msgid "Install stable release"
msgstr "安装稳定版"

#: ../../source/how-to-install-flower.rst:14
#: ../../source/how-to-upgrade-to-flower-next.rst:66
#, fuzzy
msgid "Using pip"
msgstr "使用 pip"

#: ../../source/how-to-install-flower.rst:16
#, fuzzy
msgid "Stable releases are available on `PyPI <https://pypi.org/project/flwr/>`_:"
msgstr "稳定版本可在 `PyPI <https://pypi.org/project/flwr/>`_:："

#: ../../source/how-to-install-flower.rst:22
#, fuzzy
msgid ""
"For simulations that use the Virtual Client Engine, ``flwr`` should be "
"installed with the ``simulation`` extra:"
msgstr "对于使用虚拟客户端引擎的模拟，`flwr`` 应与`simulation`` 一起安装："

#: ../../source/how-to-install-flower.rst:30
#, fuzzy
msgid "Using conda (or mamba)"
msgstr "使用 conda（或 mamba）"

#: ../../source/how-to-install-flower.rst:32
#, fuzzy
msgid "Flower can also be installed from the ``conda-forge`` channel."
msgstr "Flower 也可以从 ``conda-forge`` 频道安装。"

#: ../../source/how-to-install-flower.rst:34
#, fuzzy
msgid ""
"If you have not added ``conda-forge`` to your channels, you will first "
"need to run the following:"
msgstr "如果您尚未在频道中添加 ``conda-forge``，则首先需要运行以下程序：："

#: ../../source/how-to-install-flower.rst:42
#, fuzzy
msgid ""
"Once the ``conda-forge`` channel has been enabled, ``flwr`` can be "
"installed with ``conda``:"
msgstr "一旦启用了 ``conda-forge`` 频道，就可以使用 ``conda``: 安装 ``flwr``："

#: ../../source/how-to-install-flower.rst:49
#, fuzzy
msgid "or with ``mamba``:"
msgstr "或用 ``mamba`` ：："

#: ../../source/how-to-install-flower.rst:56
msgid "Verify installation"
msgstr "验证安装"

#: ../../source/how-to-install-flower.rst:58
#, fuzzy
msgid ""
"The following command can be used to verify if Flower was successfully "
"installed. If everything worked, it should print the version of Flower to"
" the command line:"
msgstr "可以使用以下命令来验证 Flower 是否安装成功。如果一切正常，它将在命令行中打印 Flower 的版本：："

#: ../../source/how-to-install-flower.rst:68
msgid "Advanced installation options"
msgstr "高级安装选项"

#: ../../source/how-to-install-flower.rst:71
#, fuzzy
msgid "Install via Docker"
msgstr "安装Flower"

#: ../../source/how-to-install-flower.rst:73
#, fuzzy
msgid ":doc:`Run Flower using Docker <docker/index>`"
msgstr ""
"`TensorFlow快速入门 (教程) <https://flower.ai/docs/framework/tutorial-"
"quickstart-tensorflow.html>`_"

#: ../../source/how-to-install-flower.rst:76
msgid "Install pre-release"
msgstr "安装预发布版本"

#: ../../source/how-to-install-flower.rst:78
#, fuzzy
msgid ""
"New (possibly unstable) versions of Flower are sometimes available as "
"pre-release versions (alpha, beta, release candidate) before the stable "
"release happens:"
msgstr "在稳定版发布之前，Flower 的新版本（可能是不稳定版）有时会作为预发布版本（alpha、beta、候选发布版本）提供：："

#: ../../source/how-to-install-flower.rst:85
#, fuzzy
msgid ""
"For simulations that use the Virtual Client Engine, ``flwr`` pre-releases"
" should be installed with the ``simulation`` extra:"
msgstr "对于使用虚拟客户端引擎的模拟，`flwr``预发行版应与`simulation``一起安装："

#: ../../source/how-to-install-flower.rst:93
msgid "Install nightly release"
msgstr "安装隔夜版本"

#: ../../source/how-to-install-flower.rst:95
#, fuzzy
msgid ""
"The latest (potentially unstable) changes in Flower are available as "
"nightly releases:"
msgstr "Flower 中最新（可能不稳定）的更改以隔夜发布的形式提供：："

#: ../../source/how-to-install-flower.rst:101
#, fuzzy
msgid ""
"For simulations that use the Virtual Client Engine, ``flwr-nightly`` "
"should be installed with the ``simulation`` extra:"
msgstr "对于使用虚拟客户端引擎的模拟，`flwr-nightly`应与`simulation`一起安装："

#: ../../source/how-to-run-simulations.rst:22
msgid "Run simulations"
msgstr "运行模拟"

#: ../../source/how-to-run-simulations.rst:24
#, fuzzy
msgid ""
"Simulating Federated Learning workloads is useful for a multitude of use "
"cases: you might want to run your workload on a large cohort of clients "
"without having to source, configure, and manage a large number of "
"physical devices; you might want to run your FL workloads as fast as "
"possible on the compute systems you have access to without going through "
"a complex setup process; you might want to validate your algorithm in "
"different scenarios at varying levels of data and system heterogeneity, "
"client availability, privacy budgets, etc. These are among some of the "
"use cases where simulating FL workloads makes sense."
msgstr ""
"模拟联邦学习工作负载可用于多种案例：您可能希望在大量客户端上运行您的工作负载，但无需采购、配置和管理大量物理设备；您可能希望在您可以访问的计算系统上尽可能快地运行您的"
" FL 工作负载，而无需经过复杂的设置过程；您可能希望在不同数据和系统异构性、客户端可用性、隐私预算等不同水平的场景中验证您的算法。这些都是模拟 "
"FL 工作负载的一些案例。Flower 可以通过其 \"虚拟客户端引擎\"（VirtualClientEngine）<contributor-"
"explanation-architecture.html#virtual-client-engine>_或 VCE 来匹配这些情况。"

#: ../../source/how-to-run-simulations.rst:33
msgid ""
"Flower's ``Simulation Engine`` schedules, launches, and manages "
"|clientapp_link|_ instances. It does so through a ``Backend``, which "
"contains several workers (i.e., Python processes) that can execute a "
"``ClientApp`` by passing it a |context_link|_ and a |message_link|_. "
"These ``ClientApp`` objects are identical to those used by Flower's "
"`Deployment Engine <contributor-explanation-architecture.html>`_, making "
"alternating between *simulation* and *deployment* an effortless process. "
"The execution of ``ClientApp`` objects through Flower's ``Simulation "
"Engine`` is:"
msgstr ""

#: ../../source/how-to-run-simulations.rst:41
#, fuzzy
msgid ""
"**Resource-aware**: Each backend worker executing ``ClientApp``\\s gets "
"assigned a portion of the compute and memory on your system. You can "
"define these at the beginning of the simulation, allowing you to control "
"the degree of parallelism of your simulation. For a fixed total pool of "
"resources, the fewer the resources per backend worker, the more "
"``ClientApps`` can run concurrently on the same hardware."
msgstr ""
"资源感知：这意味着每个客户端都会分配到系统中的一部分计算和内存。作为用户，您可以在模拟开始时对其进行控制，从而控制 Flower FL "
"模拟的并行程度。每个客户端的资源越少，在同一硬件上并发运行的客户端就越多。"

#: ../../source/how-to-run-simulations.rst:46
msgid ""
"**Batchable**: When there are more ``ClientApps`` to execute than backend"
" workers, ``ClientApps`` are queued and executed as soon as resources are"
" freed. This means that ``ClientApps`` are typically executed in batches "
"of N, where N is the number of backend workers."
msgstr ""

#: ../../source/how-to-run-simulations.rst:50
#, fuzzy
msgid ""
"**Self-managed**: This means that you, as a user, do not need to launch "
"``ClientApps`` manually; instead, the ``Simulation Engine``'s internals "
"orchestrates the execution of all ``ClientApp``\\s."
msgstr "自管理：这意味着用户无需手动启动客户端，而是由 :code:`VirtualClientEngine` 负责。"

#: ../../source/how-to-run-simulations.rst:53
#, fuzzy
msgid ""
"**Ephemeral**: This means that a ``ClientApp`` is only materialized when "
"it is required by the application (e.g., to do `fit() <ref-api-"
"flwr.html#flwr.client.Client.fit>`_). The object is destroyed afterward, "
"releasing the resources it was assigned and allowing other clients to "
"participate."
msgstr ""
"即时性：这意味着客户端只有在 FL 进程中需要它时才会被实体化（例如执行 `fit() <ref-api-"
"flwr.html#flwr.client.Client.fit>`_ "
"）。之后该对象将被销毁，释放分配给它的资源，并允许其他客户端以这种方式参与。"

#: ../../source/how-to-run-simulations.rst:60
msgid ""
"You can preserve the state (e.g., internal variables, parts of an ML "
"model, intermediate results) of a ``ClientApp`` by saving it to its "
"``Context``. Check the `Designing Stateful Clients <how-to-design-"
"stateful-clients.rst>`_ guide for a complete walkthrough."
msgstr ""

#: ../../source/how-to-run-simulations.rst:65
#, fuzzy
msgid ""
"The ``Simulation Engine`` delegates to a ``Backend`` the role of spawning"
" and managing ``ClientApps``. The default backend is the ``RayBackend``, "
"which uses `Ray <https://www.ray.io/>`_, an open-source framework for "
"scalable Python workloads. In particular, each worker is an `Actor "
"<https://docs.ray.io/en/latest/ray-core/actors.html>`_ capable of "
"spawning a ``ClientApp`` given its ``Context`` and a ``Message`` to "
"process."
msgstr ""
":code:`VirtualClientEngine`使用`Ray "
"<https://www.ray.io/>`_来实现`虚拟`客户端，这是一个用于可扩展 Python 工作负载的开源框架。特别地，Flower 的"
" :code:`VirtualClientEngine` 使用 `Actors <https://docs.ray.io/en/latest"
"/ray-core/actors.html>`_ 来生成 `virtual` 客户端并运行它们的工作负载。"

#: ../../source/how-to-run-simulations.rst:73
msgid "Launch your Flower simulation"
msgstr "启动 Flower 模拟"

#: ../../source/how-to-run-simulations.rst:75
msgid ""
"Running a simulation is straightforward; in fact, it is the default mode "
"of operation for |flwr_run_link|_. Therefore, running Flower simulations "
"primarily requires you to first define a ``ClientApp`` and a "
"``ServerApp``. A convenient way to generate a minimal but fully "
"functional Flower app is by means of the |flwr_new_link|_ command. There "
"are multiple templates to choose from. The example below uses the "
"``PyTorch`` template."
msgstr ""

#: ../../source/how-to-run-simulations.rst:83
msgid ""
"If you haven't already, install Flower via ``pip install -U flwr`` in a "
"Python environment."
msgstr ""

#: ../../source/how-to-run-simulations.rst:91
msgid ""
"Then, follow the instructions shown after completing the |flwr_new_link|_"
" command. When you execute |flwr_run_link|_, you'll be using the "
"``Simulation Engine``."
msgstr ""

#: ../../source/how-to-run-simulations.rst:94
msgid ""
"If we take a look at the ``pyproject.toml`` that was generated from the "
"|flwr_new_link|_ command (and loaded upon |flwr_run_link|_ execution), we"
" see that a *default* federation is defined. It sets the number of "
"supernodes to 10."
msgstr ""

#: ../../source/how-to-run-simulations.rst:106
msgid ""
"You can modify the size of your simulations by adjusting ``options.num-"
"supernodes``."
msgstr ""

#: ../../source/how-to-run-simulations.rst:109
msgid "Simulation examples"
msgstr "模拟示例"

#: ../../source/how-to-run-simulations.rst:111
msgid ""
"In addition to the quickstart tutorials in the documentation (e.g., "
"`quickstart PyTorch Tutorial <tutorial-quickstart-pytorch.html>`_, "
"`quickstart JAX Tutorial <tutorial-quickstart-jax.html>`_), most examples"
" in the Flower repository are simulation-ready."
msgstr ""

#: ../../source/how-to-run-simulations.rst:116
#, fuzzy
msgid ""
"`Quickstart TensorFlow/Keras "
"<https://github.com/adap/flower/tree/main/examples/quickstart-"
"tensorflow>`_."
msgstr ""
"`TensorFlow快速入门 (代码) <https://github.com/adap/flower/tree/main/examples"
"/quickstart-tensorflow>`_"

#: ../../source/how-to-run-simulations.rst:118
#, fuzzy
msgid ""
"`Quickstart PyTorch <https://github.com/adap/flower/tree/main/examples"
"/quickstart-pytorch>`_"
msgstr ""
"`PyTorch快速入门 (代码) <https://github.com/adap/flower/tree/main/examples"
"/quickstart-pytorch>`_"

#: ../../source/how-to-run-simulations.rst:120
#, fuzzy
msgid ""
"`Advanced PyTorch <https://github.com/adap/flower/tree/main/examples"
"/advanced-pytorch>`_"
msgstr ""
"`PyTorch快速入门 (代码) <https://github.com/adap/flower/tree/main/examples"
"/quickstart-pytorch>`_"

#: ../../source/how-to-run-simulations.rst:122
#, fuzzy
msgid ""
"`Quickstart MLX <https://github.com/adap/flower/tree/main/examples"
"/quickstart-mlx>`_"
msgstr ""
"`PyTorch快速入门 (代码) <https://github.com/adap/flower/tree/main/examples"
"/quickstart-pytorch>`_"

#: ../../source/how-to-run-simulations.rst:123
#, fuzzy
msgid ""
"`ViT fine-tuning <https://github.com/adap/flower/tree/main/examples"
"/flowertune-vit>`_"
msgstr ""
"`PyTorch快速入门 (代码) <https://github.com/adap/flower/tree/main/examples"
"/quickstart-pytorch>`_"

#: ../../source/how-to-run-simulations.rst:125
#, fuzzy
msgid ""
"The complete list of examples can be found in `the Flower GitHub "
"<https://github.com/adap/flower/tree/main/examples>`_."
msgstr ""
"有关安全连接的完整代码示例，请参见 <https://github.com/adap/flower/tree/main/examples"
"/advanced-tensorflow>`_ 。"

#: ../../source/how-to-run-simulations.rst:131
#, fuzzy
msgid "Defining ``ClientApp`` resources"
msgstr "分配客户端资源"

#: ../../source/how-to-run-simulations.rst:133
msgid ""
"By default, the ``Simulation Engine`` assigns two CPU cores to each "
"backend worker. This means that if your system has 10 CPU cores, five "
"backend workers can be running in parallel, each executing a different "
"``ClientApp`` instance."
msgstr ""

#: ../../source/how-to-run-simulations.rst:137
#, fuzzy
msgid ""
"More often than not, you would probably like to adjust the resources your"
" ``ClientApp`` gets assigned based on the complexity (i.e., compute and "
"memory footprint) of your workload. You can do so by adjusting the "
"backend resources for your federation."
msgstr ""
"通常情况下，您可能希望根据 FL 工作负载的复杂性（即计算和内存占用）来调整分配给客户端的资源。您可以在启动模拟时将参数 "
"`client_resources` 设置为 `start_simulation <ref-api-"
"flwr.html#flwr.simulation.start_simulation>`_ 。Ray "
"内部使用两个键来调度和生成工作负载（在我们的例子中是 Flower 客户端）："

#: ../../source/how-to-run-simulations.rst:143
#, python-format
msgid ""
"Note that the resources the backend assigns to each worker (and hence to "
"each ``ClientApp`` being executed) are assigned in a *soft* manner. This "
"means that the resources are primarily taken into account in order to "
"control the degree of parallelism at which ``ClientApp`` instances should"
" be executed. Resource assignment is **not strict**, meaning that if you "
"specified your ``ClientApp`` is assumed to make use of 25% of the "
"available VRAM but it ends up using 50%, it might cause other "
"``ClientApp`` instances to crash throwing an out-of-memory (OOM) error."
msgstr ""

#: ../../source/how-to-run-simulations.rst:151
msgid ""
"Customizing resources can be done directly in the ``pyproject.toml`` of "
"your app."
msgstr ""

#: ../../source/how-to-run-simulations.rst:160
msgid ""
"With the above backend settings, your simulation will run as many "
"``ClientApps`` in parallel as CPUs you have in your system. GPU resources"
" for your ``ClientApp`` can be assigned by specifying the **ratio** of "
"VRAM each should make use of."
msgstr ""

#: ../../source/how-to-run-simulations.rst:173
msgid ""
"If you are using TensorFlow, you need to `enable memory growth "
"<https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth>`_ so "
"multiple ``ClientApp`` instances can share a GPU. This needs to be done "
"before launching the simulation. To do so, set the environment variable "
"``TF_FORCE_GPU_ALLOW_GROWTH=\"1\"``."
msgstr ""

#: ../../source/how-to-run-simulations.rst:179
msgid ""
"Let's see how the above configuration results in a different number of "
"``ClientApps`` running in parallel depending on the resources available "
"in your system. If your system has:"
msgstr ""

#: ../../source/how-to-run-simulations.rst:183
#, python-format
msgid ""
"10x CPUs and 1x GPU: at most 4 ``ClientApps`` will run in parallel since "
"each requires 25% of the available VRAM."
msgstr ""

#: ../../source/how-to-run-simulations.rst:185
msgid ""
"10x CPUs and 2x GPUs: at most 8 ``ClientApps`` will run in parallel "
"(VRAM-limited)."
msgstr ""

#: ../../source/how-to-run-simulations.rst:186
msgid ""
"6x CPUs and 4x GPUs: at most 6 ``ClientApps`` will run in parallel (CPU-"
"limited)."
msgstr ""

#: ../../source/how-to-run-simulations.rst:187
msgid ""
"10x CPUs but 0x GPUs: you won't be able to run the simulation since not "
"even the resources for a single ``ClientApp`` can be met."
msgstr ""

#: ../../source/how-to-run-simulations.rst:190
msgid ""
"A generalization of this is given by the following equation. It gives the"
" maximum number of ``ClientApps`` that can be executed in parallel on "
"available CPU cores (SYS_CPUS) and VRAM (SYS_GPUS)."
msgstr ""

#: ../../source/how-to-run-simulations.rst:194
msgid ""
"N = \\min\\left(\\left\\lfloor \\frac{\\text{SYS_CPUS}}{\\text{num_cpus}}"
" \\right\\rfloor, \\left\\lfloor "
"\\frac{\\text{SYS_GPUS}}{\\text{num_gpus}} \\right\\rfloor\\right)"
msgstr ""

#: ../../source/how-to-run-simulations.rst:198
msgid ""
"Both ``num_cpus`` (an integer higher than 1) and ``num_gpus`` (a non-"
"negative real number) should be set on a per ``ClientApp`` basis. If, for"
" example, you want only a single ``ClientApp`` to run on each GPU, then "
"set ``num_gpus=1.0``. If, for example, a ``ClientApp`` requires access to"
" two whole GPUs, you'd set ``num_gpus=2``."
msgstr ""

#: ../../source/how-to-run-simulations.rst:203
#, fuzzy
msgid ""
"While the ``options.backend.client-resources`` can be used to control the"
" degree of concurrency in your simulations, this does not stop you from "
"running hundreds or even thousands of clients in the same round and "
"having orders of magnitude more *dormant* (i.e., not participating in a "
"round) clients. Let's say you want to have 100 clients per round but your"
" system can only accommodate 8 clients concurrently. The ``Simulation "
"Engine`` will schedule 100 ``ClientApps`` to run and then will execute "
"them in a resource-aware manner in batches of 8."
msgstr ""
"虽然 :code:`client_resources` 可用来控制 FL "
"模拟的并发程度，但这并不能阻止您在同一轮模拟中运行几十、几百甚至上千个客户端，并拥有数量级更多的 "
"\"休眠\"（即不参与一轮模拟）客户端。比方说，您希望每轮有 100 个客户端，但您的系统只能同时容纳 8 "
"个客户端。:code:`VirtualClientEngine` 将安排运行 100 "
"个工作（每个工作模拟策略采样的一个客户端），然后以资源感知的方式分批执行。"

#: ../../source/how-to-run-simulations.rst:212
#, fuzzy
msgid "Simulation Engine resources"
msgstr "虚拟客户端引擎资源"

#: ../../source/how-to-run-simulations.rst:214
msgid ""
"By default, the ``Simulation Engine`` has **access to all system "
"resources** (i.e., all CPUs, all GPUs). However, in some settings, you "
"might want to limit how many of your system resources are used for "
"simulation. You can do this in the ``pyproject.toml`` of your app by "
"setting the ``options.backend.init_args`` variable."
msgstr ""

#: ../../source/how-to-run-simulations.rst:228
msgid ""
"With the above setup, the Backend will be initialized with a single CPU "
"and GPU. Therefore, even if more CPUs and GPUs are available in your "
"system, they will not be used for the simulation. The example above "
"results in a single ``ClientApp`` running at any given point."
msgstr ""

#: ../../source/how-to-run-simulations.rst:233
msgid ""
"For a complete list of settings you can configure, check the `ray.init "
"<https://docs.ray.io/en/latest/ray-core/api/doc/ray.init.html#ray-init>`_"
" documentation."
msgstr ""

#: ../../source/how-to-run-simulations.rst:236
msgid "For the highest performance, do not set ``options.backend.init_args``."
msgstr ""

#: ../../source/how-to-run-simulations.rst:239
#, fuzzy
msgid "Simulation in Colab/Jupyter"
msgstr "运行模拟"

#: ../../source/how-to-run-simulations.rst:241
msgid ""
"The preferred way of running simulations should always be "
"|flwr_run_link|_. However, the core functionality of the ``Simulation "
"Engine`` can be used from within a Google Colab or Jupyter environment by"
" means of `run_simulation <ref-api-"
"flwr.html#flwr.simulation.run_simulation>`_."
msgstr ""

#: ../../source/how-to-run-simulations.rst:262
msgid ""
"With ``run_simulation``, you can also control the amount of resources for"
" your ``ClientApp`` instances. Do so by setting ``backend_config``. If "
"unset, the default resources are assigned (i.e., 2xCPUs per ``ClientApp``"
" and no GPU)."
msgstr ""

#: ../../source/how-to-run-simulations.rst:273
msgid ""
"Refer to the `30 minutes Federated AI Tutorial "
"<https://colab.research.google.com/github/adap/flower/blob/main/examples"
"/flower-in-30-minutes/tutorial.ipynb>`_ for a complete example on how to "
"run Flower Simulations in Colab."
msgstr ""

#: ../../source/how-to-run-simulations.rst:280
msgid "Multi-node Flower simulations"
msgstr "多节点 Flower 模拟"

#: ../../source/how-to-run-simulations.rst:282
#, fuzzy
msgid ""
"Flower's ``Simulation Engine`` allows you to run FL simulations across "
"multiple compute nodes so that you're not restricted to running "
"simulations on a _single_ machine. Before starting your multi-node "
"simulation, ensure that you:"
msgstr "Flower 的 :code:`VirtualClientEngine` 允许您在多个计算节点上运行 FL 模拟。在开始多节点模拟之前，请确保："

#: ../../source/how-to-run-simulations.rst:286
#, fuzzy
msgid "Have the same Python environment on all nodes."
msgstr "所有节点都有相同的 Python 环境。"

#: ../../source/how-to-run-simulations.rst:287
#, fuzzy
msgid "Have a copy of your code on all nodes."
msgstr "在所有节点上都有一份代码副本（例如整个软件包）。"

#: ../../source/how-to-run-simulations.rst:288
msgid ""
"Have a copy of your dataset on all nodes. If you are using partitions "
"from `Flower Datasets <https://flower.ai/docs/datasets>`_, ensure the "
"partitioning strategy its parameterization are the same. The expectation "
"is that the i-th dataset partition is identical in all nodes."
msgstr ""

#: ../../source/how-to-run-simulations.rst:292
#, fuzzy
msgid ""
"Start Ray on your head node: on the terminal, type ``ray start --head``. "
"This command will print a few lines, one of which indicates how to attach"
" other nodes to the head node."
msgstr ""
"在头部节点上启动 Ray：在终端上输入 :code:`raystart--"
"head`。该命令将打印几行输出，其中一行说明如何将其他节点连接到头部节点。"

#: ../../source/how-to-run-simulations.rst:295
#, fuzzy
msgid ""
"Attach other nodes to the head node: copy the command shown after "
"starting the head and execute it on the terminal of a new node (before "
"executing |flwr_run_link|_). For example: ``ray start "
"--address='192.168.1.132:6379'``. Note that to be able to attach nodes to"
" the head node they should be discoverable by each other."
msgstr ""
"将其他节点附加到头部节点：复制启动头部后显示的命令，并在新节点的终端上执行：例如 :code:`ray start "
"--address='192.168.1.132:6379'`"

#: ../../source/how-to-run-simulations.rst:300
#, fuzzy
msgid ""
"With all the above done, you can run your code from the head node as you "
"would if the simulation were running on a single node. In other words:"
msgstr "完成上述所有操作后，您就可以在头部节点上运行代码了，就像在单个节点上运行模拟一样。"

#: ../../source/how-to-run-simulations.rst:308
#, fuzzy
msgid ""
"Once your simulation is finished, if you'd like to dismantle your "
"cluster, you simply need to run the command ``ray stop`` in each node's "
"terminal (including the head node)."
msgstr "模拟结束后，如果要拆除集群，只需在每个节点（包括头部节点）的终端运行 :code:`ray stop` 命令即可。"

#: ../../source/how-to-run-simulations.rst:313
#, fuzzy
msgid ""
"When attaching a new node to the head, all its resources (i.e., all CPUs,"
" all GPUs) will be visible by the head node. This means that the "
"``Simulation Engine`` can schedule as many ``ClientApp`` instances as "
"that node can possibly run. In some settings, you might want to exclude "
"certain resources from the simulation. You can do this by appending "
"``--num-cpus=<NUM_CPUS_FROM_NODE>`` and/or ``--num-"
"gpus=<NUM_GPUS_FROM_NODE>`` in any ``ray start`` command (including when "
"starting the head)."
msgstr ""
"将新节点附加到头部节点时，头部节点将可见其所有资源（即所有 CPU 和 GPU）。这意味着 :code:`VirtualClientEngine`"
" 可以调度尽可能多的 \"虚拟 \"客户端来运行该节点。在某些设置中，您可能希望将某些资源排除在模拟之外。为此，您可以在任何 :code:`ray"
" start` 命令（包括启动头部时）中添加 `--num-cpus=<NUM_CPUS_FROM_NODE>`和/或 `--num-"
"gpus=<NUM_GPUS_FROM_NODE>`"

#: ../../source/how-to-run-simulations.rst:322
#, fuzzy
msgid "FAQ for Simulations"
msgstr "运行模拟"

#: ../../source/how-to-run-simulations.rst
msgid "Can I make my ``ClientApp`` instances stateful?"
msgstr ""

#: ../../source/how-to-run-simulations.rst:326
msgid ""
"Yes. Use the ``state`` attribute of the |context_link|_ object that is "
"passed to the ``ClientApp`` to save variables, parameters, or results to "
"it. Read the `Designing Stateful Clients <how-to-design-stateful-"
"clients.rst>`_ guide for a complete walkthrough."
msgstr ""

#: ../../source/how-to-run-simulations.rst
msgid "Can I run multiple simulations on the same machine?"
msgstr ""

#: ../../source/how-to-run-simulations.rst:330
msgid ""
"Yes, but bear in mind that each simulation isn't aware of the resource "
"usage of the other. If your simulations make use of GPUs, consider "
"setting the ``CUDA_VISIBLE_DEVICES`` environment variable to make each "
"simulation use a different set of the available GPUs. Export such an "
"environment variable before starting |flwr_run_link|_."
msgstr ""

#: ../../source/how-to-run-simulations.rst
msgid ""
"Do the CPU/GPU resources set for each ``ClientApp`` restrict how much "
"compute/memory these make use of?"
msgstr ""

#: ../../source/how-to-run-simulations.rst:334
msgid ""
"No. These resources are exclusively used by the simulation backend to "
"control how many workers can be created on startup. Let's say N backend "
"workers are launched, then at most N ``ClientApp`` instances will be "
"running in parallel. It is your responsibility to ensure ``ClientApp`` "
"instances have enough resources to execute their workload (e.g., fine-"
"tune a transformer model)."
msgstr ""

#: ../../source/how-to-run-simulations.rst
msgid "My ``ClientApp`` is triggering OOM on my GPU. What should I do?"
msgstr ""

#: ../../source/how-to-run-simulations.rst:338
msgid ""
"It is likely that your `num_gpus` setting, which controls the number of "
"``ClientApp`` instances that can share a GPU, is too low (meaning too "
"many ``ClientApps`` share the same GPU). Try the following:"
msgstr ""

#: ../../source/how-to-run-simulations.rst:340
msgid ""
"Set your ``num_gpus=1``. This will make a single ``ClientApp`` run on a "
"GPU."
msgstr ""

#: ../../source/how-to-run-simulations.rst:341
msgid "Inspect how much VRAM is being used (use ``nvidia-smi`` for this)."
msgstr ""

#: ../../source/how-to-run-simulations.rst:342
msgid ""
"Based on the VRAM you see your single ``ClientApp`` using, calculate how "
"many more would fit within the remaining VRAM. One divided by the total "
"number of ``ClientApps`` is the ``num_gpus`` value you should set."
msgstr ""

#: ../../source/how-to-run-simulations.rst:344
msgid "Refer to :ref:`clientappresources` for more details."
msgstr ""

#: ../../source/how-to-run-simulations.rst:346
msgid ""
"If your ``ClientApp`` is using TensorFlow, make sure you are exporting "
"``TF_FORCE_GPU_ALLOW_GROWTH=\"1\"`` before starting your simulation. For "
"more details, check."
msgstr ""

#: ../../source/how-to-run-simulations.rst
msgid ""
"How do I know what's the right ``num_cpus`` and ``num_gpus`` for my "
"``ClientApp``?"
msgstr ""

#: ../../source/how-to-run-simulations.rst:350
msgid ""
"A good practice is to start by running the simulation for a few rounds "
"with higher ``num_cpus`` and ``num_gpus`` than what is really needed "
"(e.g., ``num_cpus=8`` and, if you have a GPU, ``num_gpus=1``). Then "
"monitor your CPU and GPU utilization. For this, you can make use of tools"
" such as ``htop`` and ``nvidia-smi``. If you see overall resource "
"utilization remains low, try lowering ``num_cpus`` and ``num_gpus`` "
"(recall this will make more ``ClientApp`` instances run in parallel) "
"until you see a satisfactory system resource utilization."
msgstr ""

#: ../../source/how-to-run-simulations.rst:352
msgid ""
"Note that if the workload on your ``ClientApp`` instances is not "
"homogeneous (i.e., some come with a larger compute or memory footprint), "
"you'd probably want to focus on those when coming up with a good value "
"for ``num_gpus`` and ``num_cpus``."
msgstr ""

#: ../../source/how-to-run-simulations.rst
msgid "Can I assign different resources to each ``ClientApp`` instance?"
msgstr ""

#: ../../source/how-to-run-simulations.rst:356
msgid ""
"No. All ``ClientApp`` objects are assumed to make use of the same "
"``num_cpus`` and ``num_gpus``. When setting these values (refer to "
":ref:`clientappresources` for more details), ensure the ``ClientApp`` "
"with the largest memory footprint (either RAM or VRAM) can run in your "
"system with others like it in parallel."
msgstr ""

#: ../../source/how-to-run-simulations.rst
msgid ""
"Can I run single simulation accross multiple compute nodes (e.g. GPU "
"servers)?"
msgstr ""

#: ../../source/how-to-run-simulations.rst:360
msgid ""
"Yes. If you are using the ``RayBackend`` (the *default* backend) you can "
"first interconnect your nodes through Ray's cli and then launch the "
"simulation. Refer to :ref:`multinodesimulations` for a step-by-step "
"guide."
msgstr ""

#: ../../source/how-to-run-simulations.rst
msgid ""
"My ``ServerApp`` also needs to make use of the GPU (e.g., to do "
"evaluation of the *global model* after aggregation). Is this GPU usage "
"taken into account by the ``Simulation Engine``?"
msgstr ""

#: ../../source/how-to-run-simulations.rst:364
msgid ""
"No. The ``Simulation Engine`` only manages ``ClientApps`` and therefore "
"is only aware of the system resources they require. If your ``ServerApp``"
" makes use of substantial compute or memory resources, factor that into "
"account when setting ``num_cpus`` and ``num_gpus``."
msgstr ""

#: ../../source/how-to-run-simulations.rst
msgid ""
"Can I indicate on what resource a specific instance of a ``ClientApp`` "
"should run? Can I do resource placement?"
msgstr ""

#: ../../source/how-to-run-simulations.rst:368
msgid ""
"Currently, the placement of ``ClientApp`` instances is managed by the "
"``RayBackend`` (the only backend available as of ``flwr==1.13.0``) and "
"cannot be customized. Implementing a *custom* backend would be a way of "
"achieving resource placement."
msgstr ""

#: ../../source/how-to-save-and-load-model-checkpoints.rst:2
#, fuzzy
msgid "Save and Load Model Checkpoints"
msgstr "保存和加载模型检查点"

#: ../../source/how-to-save-and-load-model-checkpoints.rst:4
msgid ""
"Flower does not automatically save model updates on the server-side. This"
" how-to guide describes the steps to save (and load) model checkpoints in"
" Flower."
msgstr "Flower 不会在服务器端自动保存模型更新。本指南将介绍在 Flower 中保存（和加载）模型检查点的步骤。"

#: ../../source/how-to-save-and-load-model-checkpoints.rst:8
#, fuzzy
msgid "Model Checkpointing"
msgstr "模型检查点"

#: ../../source/how-to-save-and-load-model-checkpoints.rst:10
#, fuzzy
msgid ""
"Model updates can be persisted on the server-side by customizing "
"``Strategy`` methods. Implementing custom strategies is always an option,"
" but for many cases it may be more convenient to simply customize an "
"existing strategy. The following code example defines a new "
"``SaveModelStrategy`` which customized the existing built-in ``FedAvg`` "
"strategy. In particular, it customizes ``aggregate_fit`` by calling "
"``aggregate_fit`` in the base class (``FedAvg``). It then continues to "
"save returned (aggregated) weights before it returns those aggregated "
"weights to the caller (i.e., the server):"
msgstr ""
"模型更新可通过自定义 :code:`Strategy` "
"方法在服务器端持久化。实现自定义策略始终是一种选择，但在许多情况下，简单地自定义现有策略可能更方便。下面的代码示例定义了一个新的 "
":code:`SaveModelStrategy`，它自定义了现有的内置 :code:`FedAvg` "
"策略。特别是，它通过调用基类（:code:`FedAvg`）中的 :code:`aggregate_fit` 来定制 "
":code:`aggregate_fit`。然后继续保存返回的（聚合）参数，然后再将这些聚合参数返回给调用者（即服务器）："

#: ../../source/how-to-save-and-load-model-checkpoints.rst:58
#, fuzzy
msgid "Save and Load PyTorch Checkpoints"
msgstr "保存和加载 PyTorch 检查点"

#: ../../source/how-to-save-and-load-model-checkpoints.rst:60
msgid ""
"Similar to the previous example but with a few extra steps, we'll show "
"how to store a PyTorch checkpoint we'll use the ``torch.save`` function. "
"Firstly, ``aggregate_fit`` returns a ``Parameters`` object that has to be"
" transformed into a list of NumPy ``ndarray``'s, then those are "
"transformed into the PyTorch ``state_dict`` following the ``OrderedDict``"
" class structure."
msgstr ""
"与前面的例子类似，但多了几个步骤，我们将展示如何存储一个 PyTorch 检查点，我们将使用 ``torch.save`` "
"函数。首先，``aggregate_fit`` 返回一个 ``Parameters`` 对象，它必须被转换成一个 NumPy "
"``ndarray`` 的列表，然后这些对象按照 ``OrderedDict`` 类结构被转换成 PyTorch `state_dict` 对象。"

#: ../../source/how-to-save-and-load-model-checkpoints.rst:103
msgid ""
"To load your progress, you simply append the following lines to your "
"code. Note that this will iterate over all saved checkpoints and load the"
" latest one:"
msgstr "要加载进度，只需在代码中添加以下几行。请注意，这将遍历所有已保存的检查点，并加载最新的检查点："

#: ../../source/how-to-save-and-load-model-checkpoints.rst:116
#, fuzzy
msgid ""
"Return/use this object of type ``Parameters`` wherever necessary, such as"
" in the ``initial_parameters`` when defining a ``Strategy``."
msgstr ""
"在必要时返回/使用此 ``Parameters`` 类型的对象，例如在定义 ``Strategy` 时的 "
"``initial_parameters` 中。"

#: ../../source/how-to-save-and-load-model-checkpoints.rst:119
msgid ""
"Alternatively, we can save and load the model updates during evaluation "
"phase by overriding ``evaluate()`` or ``aggregate_evaluate()`` method of "
"the strategy (``FedAvg``). Checkout the details in `Advanced PyTorch "
"Example <https://github.com/adap/flower/tree/main/examples/advanced-"
"pytorch>`_ and `Advanced TensorFlow Example "
"<https://github.com/adap/flower/tree/main/examples/advanced-"
"tensorflow>`_."
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:2
msgid "Upgrade to Flower 1.0"
msgstr "升级至 Flower 1.0"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:6
msgid ""
"This guide is for users who have already worked with Flower 0.x and want "
"to upgrade to Flower 1.0. Newer versions of Flower (1.12+) are based on a"
" new architecture (previously called Flower Next) and not covered in this"
" guide. After upgrading Flower 0.x projects to Flower 1.0, please refer "
"to :doc:`Upgrade to Flower Next <how-to-upgrade-to-flower-next>` to make "
"your project compatible with the lastest version of Flower."
msgstr ""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:13
msgid ""
"Flower 1.0 is here. Along with new features, Flower 1.0 provides a stable"
" foundation for future growth. Compared to Flower 0.19 (and other 0.x "
"series releases), there are a few breaking changes that make it necessary"
" to change the code of existing 0.x-series projects."
msgstr ""
"Flower 1.0 正式发布。除了新功能，Flower 1.0 还为未来的发展奠定了稳定的基础。与 Flower 0.19（以及其他 0.x "
"系列版本）相比，有一些破坏性改动需要修改现有 0.x 系列项目的代码。"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:19
#: ../../source/how-to-upgrade-to-flower-next.rst:63
msgid "Install update"
msgstr "安装更新"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:21
msgid ""
"Here's how to update an existing installation to Flower 1.0 using either "
"pip or Poetry:"
msgstr "下面介绍如何使用 pip 或 Poetry 将现有安装更新到 Flower 1.0："

#: ../../source/how-to-upgrade-to-flower-1.0.rst:23
msgid "pip: add ``-U`` when installing."
msgstr "pip: 安装时添加 ``-U``."

#: ../../source/how-to-upgrade-to-flower-1.0.rst:25
msgid ""
"``python -m pip install -U flwr`` (when using ``start_server`` and "
"``start_client``)"
msgstr "`python -m pip install -U flwr``（当使用`start_server`和`start_client`时）"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:26
msgid ""
"``python -m pip install -U 'flwr[simulation]'`` (when using "
"``start_simulation``)"
msgstr "``python -m pip install -U 'flwr[simulation]'``（当使用`start_simulation``时）"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:28
msgid ""
"Poetry: update the ``flwr`` dependency in ``pyproject.toml`` and then "
"reinstall (don't forget to delete ``poetry.lock`` via ``rm poetry.lock`` "
"before running ``poetry install``)."
msgstr ""
"Poetry：更新 ``pyproject.toml`` 中的 ``flwr`` 依赖包，然后重新安装（运行 ``poetry install``"
" 前，别忘了通过 ``rm poetry.lock` 删除 ``poetry.lock`）。"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:32
msgid "``flwr = \"^1.0.0\"`` (when using ``start_server`` and ``start_client``)"
msgstr "``flwr = \"^1.0.0\"`` （当使用 ``start_server` 和 ``start_client` 时）"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:33
msgid ""
"``flwr = { version = \"^1.0.0\", extras = [\"simulation\"] }`` (when "
"using ``start_simulation``)"
msgstr ""
"``flwr = { version = \"^1.0.0\", extras = [\"simulation\"] "
"}``（当使用``start_simulation``时）"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:37
#: ../../source/how-to-upgrade-to-flower-next.rst:121
msgid "Required changes"
msgstr "所需变更"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:39
msgid "The following breaking changes require manual updates."
msgstr "以下更改需要手动更新。"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:42
msgid "General"
msgstr "一般情况"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:44
msgid ""
"Pass all arguments as keyword arguments (not as positional arguments). "
"Here's an example:"
msgstr "将所有参数作为关键字参数传递（而不是位置参数）。下面是一个例子："

#: ../../source/how-to-upgrade-to-flower-1.0.rst:47
msgid ""
"Flower 0.19 (positional arguments): ``start_client(\"127.0.0.1:8080\", "
"FlowerClient())``"
msgstr "Flower 0.19 (位置参数)： ``start_client(\"127.0.0.1:8080\", FlowerClient())``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:48
msgid ""
"Flower 1.0 (keyword arguments): "
"``start_client(server_address=\"127.0.0.1:8080\", "
"client=FlowerClient())``"
msgstr ""
"Flower 1.0（关键字参数）： ``start_client(server_address=\"127.0.0.1:8080\", "
"client=FlowerClient())``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:52
#: ../../source/ref-api/flwr.client.Client.rst:2
msgid "Client"
msgstr "客户端"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:54
msgid ""
"Subclasses of ``NumPyClient``: change ``def get_parameters(self):``` to "
"``def get_parameters(self, config):``"
msgstr ""
"NumPyClient的子类：将``def get_parameters(self):```改为``def "
"get_parameters(self,config):``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:56
msgid ""
"Subclasses of ``Client``: change ``def get_parameters(self):``` to ``def "
"get_parameters(self, ins: GetParametersIns):``"
msgstr ""
"客户端 \"的子类：将 \"get_parameters(self): \"改为 \"get_parameters(self, ins: "
"GetParametersIns):\""

#: ../../source/how-to-upgrade-to-flower-1.0.rst:60
msgid "Strategies / ``start_server`` / ``start_simulation``"
msgstr "策略 / ``start_server`` / ``start_simulation``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:62
msgid ""
"Pass ``ServerConfig`` (instead of a dictionary) to ``start_server`` and "
"``start_simulation``. Here's an example:"
msgstr ""
"向 ``start_server`` 和 ``start_simulation` 传递 ``ServerConfig``（而不是 "
"dictionary）。下面是一个例子："

#: ../../source/how-to-upgrade-to-flower-1.0.rst:65
msgid ""
"Flower 0.19: ``start_server(..., config={\"num_rounds\": 3, "
"\"round_timeout\": 600.0}, ...)``"
msgstr ""
"Flower 0.19: ``start_server(..., config={\"num_rounds\": 3, "
"\"round_timeout\": 600.0}, ...)``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:67
msgid ""
"Flower 1.0: ``start_server(..., "
"config=flwr.server.ServerConfig(num_rounds=3, round_timeout=600.0), "
"...)``"
msgstr ""
"Flower 1.0: ``start_server(..., "
"config=flwr.server.ServerConfig(num_rounds=3, round_timeout=600.0), "
"...)``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:70
msgid ""
"Replace ``num_rounds=1`` in ``start_simulation`` with the new "
"``config=ServerConfig(...)`` (see previous item)"
msgstr "将`start_simulation``中的`num_rounds=1``替换为新的`config=ServerConfig(...)`（参见前一项）"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:72
msgid ""
"Remove ``force_final_distributed_eval`` parameter from calls to "
"``start_server``. Distributed evaluation on all clients can be enabled by"
" configuring the strategy to sample all clients for evaluation after the "
"last round of training."
msgstr ""
"删除调用 ``start_server`` 时的 ``force_final_distributed_eval` "
"参数。可以通过配置策略，在最后一轮训练后对所有客户端进行抽样评估，从而启用对所有客户端的分布式评估。"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:75
msgid "Rename parameter/ndarray conversion functions:"
msgstr "重命名参数/数组转换函数："

#: ../../source/how-to-upgrade-to-flower-1.0.rst:77
msgid "``parameters_to_weights`` --> ``parameters_to_ndarrays``"
msgstr "``parameters_to_weights`` --> ``parameters_to_ndarrays``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:78
msgid "``weights_to_parameters`` --> ``ndarrays_to_parameters``"
msgstr "``weights_to_parameters`` --> ``ndarrays_to_parameters``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:80
msgid ""
"Strategy initialization: if the strategy relies on the default values for"
" ``fraction_fit`` and ``fraction_evaluate``, set ``fraction_fit`` and "
"``fraction_evaluate`` manually to ``0.1``. Projects that do not manually "
"create a strategy (by calling ``start_server`` or ``start_simulation`` "
"without passing a strategy instance) should now manually initialize "
"FedAvg with ``fraction_fit`` and ``fraction_evaluate`` set to ``0.1``."
msgstr ""
"策略初始化：如果策略依赖于 ``fraction_fit`` 和 ``fraction_evaluate`` 的默认值，请手动将 "
"``fraction_fit`` 和 ``fraction_evaluate`` 设置为 ``0.1``。未手动创建策略的项目（调用 "
"``start_server` 或 ``start_simulation` 时未传递策略实例）现在应手动初始化 FedAvg，并将 "
"`fraction_fit` 和 `fraction_evaluate` 设为 `0.1``。"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:86
msgid "Rename built-in strategy parameters (e.g., ``FedAvg``):"
msgstr "重命名内置策略参数（例如，`FedAvg``）："

#: ../../source/how-to-upgrade-to-flower-1.0.rst:88
msgid "``fraction_eval`` --> ``fraction_evaluate``"
msgstr "``fraction_eval`` --> ``fraction_evaluate``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:89
msgid "``min_eval_clients`` --> ``min_evaluate_clients``"
msgstr "``min_eval_clients`` --> ``min_evaluate_clients``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:90
msgid "``eval_fn`` --> ``evaluate_fn``"
msgstr "``eval_fn`` --> ``evaluate_fn``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:92
msgid ""
"Rename ``rnd`` to ``server_round``. This impacts multiple methods and "
"functions, for example, ``configure_fit``, ``aggregate_fit``, "
"``configure_evaluate``, ``aggregate_evaluate``, and ``evaluate_fn``."
msgstr ""
"将 `rnd` 更名为 `server_round`。这会影响多个方法和函数，例如 "
"``configure_fit``、``aggregate_fit``、``configure_evaluate``、`aggregate_evaluate``"
" 和 ``evaluate_fn``。"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:95
msgid "Add ``server_round`` and ``config`` to ``evaluate_fn``:"
msgstr "在 ``evaluate_fn` 中添加 ``server_round` 和 ``config`："

#: ../../source/how-to-upgrade-to-flower-1.0.rst:97
msgid ""
"Flower 0.19: ``def evaluate(parameters: NDArrays) -> "
"Optional[Tuple[float, Dict[str, Scalar]]]:``"
msgstr ""
"Flower 0.19: ``def evaluate(parameters: NDArrays) -> "
"Optional[Tuple[float, Dict[str, Scalar]]]:``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:99
msgid ""
"Flower 1.0: ``def evaluate(server_round: int, parameters: NDArrays, "
"config: Dict[str, Scalar]) -> Optional[Tuple[float, Dict[str, "
"Scalar]]]:``"
msgstr ""
"Flower 1.0: ``def evaluate(server_round: int, parameters: NDArrays, "
"config: Dict[str, Scalar]) -> Optional[Tuple[float, Dict[str, "
"Scalar]]]:``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:103
msgid "Custom strategies"
msgstr "定制策略"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:105
msgid ""
"The type of parameter ``failures`` has changed from "
"``List[BaseException]`` to ``List[Union[Tuple[ClientProxy, FitRes], "
"BaseException]]`` (in ``aggregate_fit``) and "
"``List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]]`` (in "
"``aggregate_evaluate``)"
msgstr ""
"参数``failures``的类型已从``List[BaseException]``变为``List[Union[Tuple[ClientProxy,"
" FitRes], "
"BaseException]]``（在``agregate_fit``中）和``List[Union[Tuple[ClientProxy, "
"EvaluateRes], BaseException]]``（在``agregate_evaluate``中）"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:109
msgid ""
"The ``Strategy`` method ``evaluate`` now receives the current round of "
"federated learning/evaluation as the first parameter:"
msgstr "``Strategy``方法 的``evaluate``现在会接收当前一轮联邦学习/评估作为第一个参数："

#: ../../source/how-to-upgrade-to-flower-1.0.rst:112
msgid ""
"Flower 0.19: ``def evaluate(self, parameters: Parameters) -> "
"Optional[Tuple[float, Dict[str, Scalar]]]:``"
msgstr ""
"Flower 0.19: ``def evaluate(self, parameters: Parameters) -> "
"Optional[Tuple[float, Dict[str, Scalar]]]:```"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:114
msgid ""
"Flower 1.0: ``def evaluate(self, server_round: int, parameters: "
"Parameters) -> Optional[Tuple[float, Dict[str, Scalar]]]:``"
msgstr ""
"Flower 1.0: ``def evaluate(self, server_round: int, parameters: "
"Parameters) -> Optional[Tuple[float, Dict[str, Scalar]]]:``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:118
msgid "Optional improvements"
msgstr "可选的改进措施"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:120
msgid ""
"Along with the necessary changes above, there are a number of potential "
"improvements that just became possible:"
msgstr "除了上述必要的改动之外，还有一些潜在的改进措施："

#: ../../source/how-to-upgrade-to-flower-1.0.rst:123
msgid ""
"Remove \"placeholder\" methods from subclasses of ``Client`` or "
"``NumPyClient``. If you, for example, use server-side evaluation, then "
"empty placeholder implementations of ``evaluate`` are no longer "
"necessary."
msgstr ""
"删除 ``Client`` 或 ``NumPyClient`` 子类中的 \"占位符 "
"\"方法。例如，如果你使用服务器端评估，那么就不再需要``evaluate``的 \"空占位符 \"实现。"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:126
msgid ""
"Configure the round timeout via ``start_simulation``: "
"``start_simulation(..., config=flwr.server.ServerConfig(num_rounds=3, "
"round_timeout=600.0), ...)``"
msgstr ""
"通过 ``start_simulation`` 配置循环超时： ``start_simulation(..., "
"config=flwr.server.ServerConfig(num_rounds=3, round_timeout=600.0), "
"...)``"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:130
#: ../../source/how-to-upgrade-to-flower-next.rst:349
msgid "Further help"
msgstr "更多帮助"

#: ../../source/how-to-upgrade-to-flower-1.0.rst:132
msgid ""
"Most official `Flower code examples "
"<https://github.com/adap/flower/tree/main/examples>`_ are already updated"
" to Flower 1.0, they can serve as a reference for using the Flower 1.0 "
"API. If there are further questions, `join the Flower Slack "
"<https://flower.ai/join-slack/>`_ and use the channel ``#questions``."
msgstr ""
"大多数官方的 `Flower 代码示例 <https://github.com/adap/flower/tree/main/examples>`_"
" 已经更新到 Flower 1.0，它们可以作为使用 Flower 1.0 API 的参考。如果还有其他问题，请加入 Flower Slack "
"<https://flower.ai/join-slack/>`_ 并使用 \"#questions``\"。"

#: ../../source/how-to-upgrade-to-flower-next.rst:2
#, fuzzy
msgid "Upgrade to Flower Next"
msgstr "升级至 Flower 1.0"

#: ../../source/how-to-upgrade-to-flower-next.rst:4
#, fuzzy
msgid ""
"Welcome to the migration guide for updating Flower to Flower Next! "
"Whether you're a seasoned user or just getting started, this guide will "
"help you smoothly transition your existing setup to take advantage of the"
" latest features and improvements in Flower Next, starting from version "
"1.8."
msgstr ""
"欢迎阅读从 Flower 升级到 Flower Next 的迁移指南！无论您是经验丰富的用户还是刚刚开始使用 "
"Flower，本指南都将帮助您顺利过渡现有设置，以利用 Flower Next 从 1.8 版开始的最新功能和改进。"

#: ../../source/how-to-upgrade-to-flower-next.rst:11
#, fuzzy
msgid ""
"This guide shows how to reuse pre-``1.8`` Flower code with minimum code "
"changes by using the *compatibility layer* in Flower Next. In another "
"guide, we will show how to run Flower Next end-to-end with pure Flower "
"Next APIs."
msgstr ""
"本指南展示了如何通过使用 Flower Next 中的*可兼容层*，以最小的代码改动重用```1.8```前的 Flower "
"代码。在另一个指南中，我们将介绍如何使用纯 Flower Next API 端到端运行 Flower Next。"

#: ../../source/how-to-upgrade-to-flower-next.rst:15
#, fuzzy
msgid "Let's dive in!"
msgstr "让我们深入了解一下！"

#: ../../source/how-to-upgrade-to-flower-next.rst:68
#, fuzzy
msgid ""
"Here's how to update an existing installation of Flower to Flower Next "
"with ``pip``:"
msgstr "下面介绍如何使用 pip 或 Poetry 将现有安装更新到 Flower 1.0："

#: ../../source/how-to-upgrade-to-flower-next.rst:74
#, fuzzy
msgid "or if you need Flower Next with simulation:"
msgstr "启动 Flower 模拟"

#: ../../source/how-to-upgrade-to-flower-next.rst:80
#, fuzzy
msgid ""
"Ensure you set the following version constraint in your "
"``requirements.txt``"
msgstr "确保在 ``requirements.txt`` 中设置了以下版本限制"

#: ../../source/how-to-upgrade-to-flower-next.rst:90
#, fuzzy
msgid "or ``pyproject.toml``:"
msgstr "或 ``pyproject.toml```："

#: ../../source/how-to-upgrade-to-flower-next.rst:101
#, fuzzy
msgid "Using Poetry"
msgstr "使用 pip"

#: ../../source/how-to-upgrade-to-flower-next.rst:103
#, fuzzy
msgid ""
"Update the ``flwr`` dependency in ``pyproject.toml`` and then reinstall "
"(don't forget to delete ``poetry.lock`` via ``rm poetry.lock`` before "
"running ``poetry install``)."
msgstr ""
"Poetry：更新 ``pyproject.toml`` 中的 ``flwr`` 依赖包，然后重新安装（运行 ``poetry install``"
" 前，别忘了通过 ``rm poetry.lock` 删除 ``poetry.lock`）。"

#: ../../source/how-to-upgrade-to-flower-next.rst:106
#, fuzzy
msgid ""
"Ensure you set the following version constraint in your "
"``pyproject.toml``:"
msgstr "将 ``pyproject.toml`` 中的次要版本增加一个。"

#: ../../source/how-to-upgrade-to-flower-next.rst:123
#, fuzzy
msgid ""
"In Flower Next, the *infrastructure* and *application layers* have been "
"decoupled. Instead of starting a client in code via ``start_client()``, "
"you create a |clientapp_link|_ and start it via the command line. Instead"
" of starting a server in code via ``start_server()``, you create a "
"|serverapp_link|_ and start it via the command line. The long-running "
"components of server and client are called SuperLink and SuperNode. The "
"following non-breaking changes that require manual updates and allow you "
"to run your project both in the traditional way and in the Flower Next "
"way:"
msgstr ""
"在 Flower Next "
"中，*基础架构层*和*应用层*已经解耦。你不再需要在代码中通过``start_client()``启动客户端，而是创建一个|clientapp_link|_，然后通过命令行启动它。无需通过``start_server()``在代码中启动服务器，而是创建一个"
" |serverapp_link|_ "
"并通过命令行启动它。服务器和客户端的长期运行组件被称为超级链接（SuperLink）和超级节点（SuperNode）。以下是无需手动更新的非破坏性更改，可让您以传统方式和"
" Flower Next 方式运行项目："

#: ../../source/how-to-upgrade-to-flower-next.rst:132
#, fuzzy
msgid "|clientapp_link|_"
msgstr "客户端"

#: ../../source/how-to-upgrade-to-flower-next.rst:134
#, fuzzy
msgid ""
"Wrap your existing client with |clientapp_link|_ instead of launching it "
"via |startclient_link|_. Here's an example:"
msgstr "用 |clientapp_link|_ 封装现有客户端，而不是通过 |startclient_link|_ 启动。下面是一个例子："

#: ../../source/how-to-upgrade-to-flower-next.rst:157
#, fuzzy
msgid "|serverapp_link|_"
msgstr "服务器"

#: ../../source/how-to-upgrade-to-flower-next.rst:159
#, fuzzy
msgid ""
"Wrap your existing strategy with |serverapp_link|_ instead of starting "
"the server via |startserver_link|_. Here's an example:"
msgstr "用 |serverapp_link|_ 包住现有策略，而不是通过 |startserver_link|_ 启动服务器。下面是一个例子："

#: ../../source/how-to-upgrade-to-flower-next.rst:180
#, fuzzy
msgid "Deployment"
msgstr "调配"

#: ../../source/how-to-upgrade-to-flower-next.rst:182
#, fuzzy
msgid ""
"Run the ``SuperLink`` using |flowernext_superlink_link|_ before running, "
"in sequence, |flowernext_clientapp_link|_ (2x) and "
"|flowernext_serverapp_link|_. There is no need to execute `client.py` and"
" `server.py` as Python scripts."
msgstr ""
"在依次运行 |flowernext_clientapp_link|_ (2x) 和 |flowernext_serverapp_link|_ "
"之前，使用 |flowernext_superlink_link|_ 运行 ``SuperLink`` 。无需将 |client.py` 和 "
"`server.py` 作为 Python 脚本执行。"

#: ../../source/how-to-upgrade-to-flower-next.rst:185
#, fuzzy
msgid ""
"Here's an example to start the server without HTTPS (only for "
"prototyping):"
msgstr "下面是一个在不使用 HTTPS 的情况下启动服务器的示例（仅用于原型开发）："

#: ../../source/how-to-upgrade-to-flower-next.rst:201
#, fuzzy
msgid ""
"Here's another example to start with HTTPS. Use the ``--ssl-ca-"
"certfile``, ``--ssl-certfile``, and ``--ssl-keyfile`` command line "
"options to pass paths to (CA certificate, server certificate, and server "
"private key)."
msgstr "下面是另一个使用 HTTPS 的示例。使用 ``--certificates`` 命令行参数传递路径（CA 证书、服务器证书和服务器私钥）。"

#: ../../source/how-to-upgrade-to-flower-next.rst:229
#, fuzzy
msgid "Simulation in CLI"
msgstr "运行模拟"

#: ../../source/how-to-upgrade-to-flower-next.rst:231
#, fuzzy
msgid ""
"Wrap your existing client and strategy with |clientapp_link|_ and "
"|serverapp_link|_, respectively. There is no need to use |startsim_link|_"
" anymore. Here's an example:"
msgstr ""
"分别用 |clientapp_link|_ 和 |serverapp_link|_ 封装现有的客户端和策略。无需再使用 "
"|startsim_link|_。下面是一个示例："

#: ../../source/how-to-upgrade-to-flower-next.rst:264
#, fuzzy
msgid ""
"Run |flower_simulation_link|_ in CLI and point to the ``server_app`` / "
"``client_app`` object in the code instead of executing the Python script."
" Here's an example (assuming the ``server_app`` and ``client_app`` "
"objects are in a ``sim.py`` module):"
msgstr ""
"在 CLI 中运行 |flower_simulation_link|_ 并指向代码中的 ``server_app`` "
"/``client_app`` 对象，而不是执行 Python 脚本。下面是一个示例（假定 `server_app`` 和 "
"`client_app`` 对象位于 `sim.py`` 模块中）："

#: ../../source/how-to-upgrade-to-flower-next.rst:281
#, fuzzy
msgid ""
"Set default resources for each |clientapp_link|_ using the ``--backend-"
"config`` command line argument instead of setting the "
"``client_resources`` argument in |startsim_link|_. Here's an example:"
msgstr ""
"使用 ``--backend-config`` 命令行参数为每个 |clientapp_link|_ 设置默认资源，而不是在 "
"|startsim_link|_ 中设置 ``client_resources`` 参数。下面是一个例子："

#: ../../source/how-to-upgrade-to-flower-next.rst:305
#, fuzzy
msgid "Simulation in a Notebook"
msgstr "笔记本中的模拟"

#: ../../source/how-to-upgrade-to-flower-next.rst:307
#, fuzzy
msgid ""
"Run |runsim_link|_ in your notebook instead of |startsim_link|_. Here's "
"an example:"
msgstr "在笔记本中运行 |runsim_link|_，而不是 |startsim_link|_。下面是一个例子："

#: ../../source/how-to-upgrade-to-flower-next.rst:351
#, fuzzy
msgid ""
"Some official `Flower code examples <https://flower.ai/docs/examples/>`_ "
"are already updated to Flower Next so they can serve as a reference for "
"using the Flower Next API. If there are further questions, `join the "
"Flower Slack <https://flower.ai/join-slack/>`_ and use the channel "
"``#questions``. You can also `participate in Flower Discuss "
"<https://discuss.flower.ai/>`_ where you can find us answering questions,"
" or share and learn from others about migrating to Flower Next."
msgstr ""
"大多数官方的 `Flower 代码示例 <https://github.com/adap/flower/tree/main/examples>`_"
" 已经更新到 Flower 1.0，它们可以作为使用 Flower 1.0 API 的参考。如果还有其他问题，请加入 Flower Slack "
"<https://flower.ai/join-slack/>`_ 并使用 \"#questions``\"。"

#: ../../source/how-to-upgrade-to-flower-next.rst:358
#, fuzzy
msgid "Important"
msgstr "重要变更："

#: ../../source/how-to-upgrade-to-flower-next.rst:360
#, fuzzy
msgid ""
"As we continuously enhance Flower Next at a rapid pace, we'll be "
"periodically updating this guide. Please feel free to share any feedback "
"with us!"
msgstr "随着 Flower Next 的不断快速改进，我们将定期更新本指南。如有任何反馈，请随时与我们分享！"

#: ../../source/how-to-upgrade-to-flower-next.rst:366
#, fuzzy
msgid "Happy migrating! 🚀"
msgstr "移民愉快！🚀"

#: ../../source/how-to-use-built-in-mods.rst:2
#, fuzzy
msgid "Use Built-in Mods"
msgstr "使用内置调制器"

#: ../../source/how-to-use-built-in-mods.rst:4
#, fuzzy
msgid ""
"**Note: This tutorial covers experimental features. The functionality and"
" interfaces may change in future versions.**"
msgstr "**注：本教程涵盖实验性功能。功能和界面可能会在未来版本中发生变化。"

#: ../../source/how-to-use-built-in-mods.rst:7
#, fuzzy
msgid ""
"In this tutorial, we will learn how to utilize built-in mods to augment "
"the behavior of a ``ClientApp``. Mods (sometimes also called Modifiers) "
"allow us to perform operations before and after a task is processed in "
"the ``ClientApp``."
msgstr ""
"在本教程中，我们将学习如何利用内置模块来增强 ``ClientApp`` 的行为。修改器（有时也称为修改器）允许我们在 ``ClientApp``"
" 处理任务之前和之后执行操作。"

#: ../../source/how-to-use-built-in-mods.rst:12
#, fuzzy
msgid "What are Mods?"
msgstr "什么是 Mods？"

#: ../../source/how-to-use-built-in-mods.rst:14
#, fuzzy
msgid ""
"A Mod is a callable that wraps around a ``ClientApp``. It can manipulate "
"or inspect the incoming ``Message`` and the resulting outgoing "
"``Message``. The signature for a ``Mod`` is as follows:"
msgstr ""
"Mod 是包裹在 ``ClientApp`` 周围的可调用程序。它可以操作或检查传入的 ``Message`` 和由此产生的传出的 "
"``Message`` 。一个 ``Mod`` 的签名如下："

#: ../../source/how-to-use-built-in-mods.rst:23
#, fuzzy
msgid "A typical mod function might look something like this:"
msgstr "一个典型的修改函数可能是这样的："

#: ../../source/how-to-use-built-in-mods.rst:36
#, fuzzy
msgid "Using Mods"
msgstr "使用修改器"

#: ../../source/how-to-use-built-in-mods.rst:38
#, fuzzy
msgid "To use mods in your ``ClientApp``, you can follow these steps:"
msgstr "要在您的 ``ClientApp`` 中使用 mod，可以按照以下步骤操作："

#: ../../source/how-to-use-built-in-mods.rst:41
#, fuzzy
msgid "1. Import the required mods"
msgstr "1. 导入所需修改"

#: ../../source/how-to-use-built-in-mods.rst:43
#, fuzzy
msgid "First, import the built-in mod you intend to use:"
msgstr "首先，导入您打算使用的内置模式："

#: ../../source/how-to-use-built-in-mods.rst:51
#, fuzzy
msgid "2. Define your client function"
msgstr "2. 定义客户功能"

#: ../../source/how-to-use-built-in-mods.rst:53
#, fuzzy
msgid ""
"Define your client function (``client_fn``) that will be wrapped by the "
"mod(s):"
msgstr "定义将被 mod 封装的客户端函数（``client_fn``）："

#: ../../source/how-to-use-built-in-mods.rst:62
#, fuzzy
msgid "3. Create the ``ClientApp`` with mods"
msgstr "3. 用模块创建 ``ClientApp``"

#: ../../source/how-to-use-built-in-mods.rst:64
#, fuzzy
msgid ""
"Create your ``ClientApp`` and pass the mods as a list to the ``mods`` "
"argument. The order in which you provide the mods matters:"
msgstr "创建您的 ``ClientApp`` 并将 mods 作为列表传递给 ``mods`` 参数。提供 mod 的顺序很重要："

#: ../../source/how-to-use-built-in-mods.rst:78
#, fuzzy
msgid "Order of execution"
msgstr "停用"

#: ../../source/how-to-use-built-in-mods.rst:80
#, fuzzy
msgid ""
"When the ``ClientApp`` runs, the mods are executed in the order they are "
"provided in the list:"
msgstr "当运行 ``ClientApp`` 时，会按照列表中提供的顺序执行模块："

#: ../../source/how-to-use-built-in-mods.rst:83
#, fuzzy
msgid "``example_mod_1`` (outermost mod)"
msgstr "``example_mod_1`` （最外层模块）"

#: ../../source/how-to-use-built-in-mods.rst:84
#, fuzzy
msgid "``example_mod_2`` (next mod)"
msgstr "示例模式 2（下一个模式）"

#: ../../source/how-to-use-built-in-mods.rst:85
#, fuzzy
msgid ""
"Message handler (core function that handles the incoming ``Message`` and "
"returns the outgoing ``Message``)"
msgstr "消息处理程序（处理传入的 \"消息 \"并返回传出的 \"消息 \"的核心函数）"

#: ../../source/how-to-use-built-in-mods.rst:87
#, fuzzy
msgid "``example_mod_2`` (on the way back)"
msgstr "``example_mod_2`` （返回途中）"

#: ../../source/how-to-use-built-in-mods.rst:88
#, fuzzy
msgid "``example_mod_1`` (outermost mod on the way back)"
msgstr "``example_mod_1`` （返回途中最外层的模式）"

#: ../../source/how-to-use-built-in-mods.rst:90
#, fuzzy
msgid ""
"Each mod has a chance to inspect and modify the incoming ``Message`` "
"before passing it to the next mod, and likewise with the outgoing "
"``Message`` before returning it up the stack."
msgstr "每个模块都有机会检查和修改传入的 \"信息\"，然后再将其传递给下一个模块，同样，也有机会检查和修改传出的 \"信息\"，然后再将其返回堆栈。"

#: ../../source/how-to-use-built-in-mods.rst:97
#, fuzzy
msgid ""
"By following this guide, you have learned how to effectively use mods to "
"enhance your ``ClientApp``'s functionality. Remember that the order of "
"mods is crucial and affects how the input and output are processed."
msgstr ""
"通过本指南，您已学会如何有效地使用 mod 来增强您的 ``ClientApp`` 的功能。请记住，mod "
"的顺序至关重要，它会影响输入和输出的处理方式。"

#: ../../source/how-to-use-built-in-mods.rst:101
#, fuzzy
msgid "Enjoy building a more robust and flexible ``ClientApp`` with mods!"
msgstr "使用 mods 构建更强大、更灵活的 \"客户端应用程序\"！"

#: ../../source/how-to-use-differential-privacy.rst:2
#, fuzzy
msgid "Use Differential Privacy"
msgstr "差分隐私"

#: ../../source/how-to-use-differential-privacy.rst:4
#, fuzzy
msgid ""
"This guide explains how you can utilize differential privacy in the "
"Flower framework. If you are not yet familiar with differential privacy, "
"you can refer to :doc:`explanation-differential-privacy`."
msgstr ""
"本指南解释了如何在 Flower 框架中使用差分隐私。如果您还不熟悉差分隐私，可以参考 :doc:`explanation-"
"differential-privacy` 。"

#: ../../source/how-to-use-differential-privacy.rst:10
#, fuzzy
msgid ""
"Differential Privacy in Flower is in a preview phase. If you plan to use "
"these features in a production environment with sensitive data, feel free"
" contact us to discuss your requirements and to receive guidance on how "
"to best use these features."
msgstr ""
"Flower "
"中的差异隐私处于预览阶段。如果您计划在生产环境中使用这些敏感数据功能，请随时联系我们，讨论您的需求，并获得如何最好地使用这些功能的指导。"

#: ../../source/how-to-use-differential-privacy.rst:17
#, fuzzy
msgid ""
"This approach consists of two separate phases: clipping of the updates "
"and adding noise to the aggregated model. For the clipping phase, Flower "
"framework has made it possible to decide whether to perform clipping on "
"the server side or the client side."
msgstr "这种方法包括两个独立的阶段：对更新进行剪切和在聚合模型中添加噪声。在剪切阶段，Flower 框架可以决定是在服务器端还是在客户端执行剪切。"

#: ../../source/how-to-use-differential-privacy.rst:21
#, fuzzy
msgid ""
"**Server-side Clipping**: This approach has the advantage of the server "
"enforcing uniform clipping across all clients' updates and reducing the "
"communication overhead for clipping values. However, it also has the "
"disadvantage of increasing the computational load on the server due to "
"the need to perform the clipping operation for all clients."
msgstr ""
"** 服务器端剪切**： "
"这种方法的优点是服务器可对所有客户端的更新执行统一的剪切，并减少剪切值的通信开销。不过，这种方法也有缺点，那就是需要为所有客户端执行剪切操作，从而增加了服务器的计算负荷。"

#: ../../source/how-to-use-differential-privacy.rst:26
#, fuzzy
msgid ""
"**Client-side Clipping**: This approach has the advantage of reducing the"
" computational overhead on the server. However, it also has the "
"disadvantage of lacking centralized control, as the server has less "
"control over the clipping process."
msgstr "**客户端剪切**： 这种方法的优点是可以减少服务器的计算开销。不过，它也有缺乏集中控制的缺点，因为服务器对剪切过程的控制较少。"

#: ../../source/how-to-use-differential-privacy.rst:31
#, fuzzy
msgid "Server-side Clipping"
msgstr "服务器端逻辑"

#: ../../source/how-to-use-differential-privacy.rst:33
#, fuzzy
msgid ""
"For central DP with server-side clipping, there are two ``Strategy`` "
"classes that act as wrappers around the actual ``Strategy`` instance (for"
" example, ``FedAvg``). The two wrapper classes are "
"``DifferentialPrivacyServerSideFixedClipping`` and "
"``DifferentialPrivacyServerSideAdaptiveClipping`` for fixed and adaptive "
"clipping."
msgstr ""
"对于具有服务器端剪裁功能的中央 DP，有两个 :code:`Strategy` 类作为实际 :code:`Strategy` 实例（例如 "
":code:`FedAvg`）的包装器。这两个封装类分别是 "
":code:`DifferentialPrivacyServerSideFixedClipping` 和 "
":code:`DifferentialPrivacyServerSideAdaptiveClipping` ，用于固定剪辑和自适应剪辑。"

#: ../../source/how-to-use-differential-privacy.rst:-1
#, fuzzy
msgid "server side clipping"
msgstr "服务器端逻辑"

#: ../../source/how-to-use-differential-privacy.rst:43
#, fuzzy
msgid ""
"The code sample below enables the ``FedAvg`` strategy to use server-side "
"fixed clipping using the ``DifferentialPrivacyServerSideFixedClipping`` "
"wrapper class. The same approach can be used with "
"``DifferentialPrivacyServerSideAdaptiveClipping`` by adjusting the "
"corresponding input parameters."
msgstr ""
"下面的代码示例使用 :code:`DifferentialPrivacyServerSideFixedClipping` 封装类使 "
":code:`FedAvg` 策略使用服务器端固定剪辑。通过调整相应的输入参数，同样的方法也可用于 "
":code:`DifferentialPrivacyServerSideAdaptiveClipping`。"

#: ../../source/how-to-use-differential-privacy.rst:64
#, fuzzy
msgid "Client-side Clipping"
msgstr "客户端逻辑"

#: ../../source/how-to-use-differential-privacy.rst:66
#, fuzzy
msgid ""
"For central DP with client-side clipping, the server sends the clipping "
"value to selected clients on each round. Clients can use existing Flower "
"``Mods`` to perform the clipping. Two mods are available for fixed and "
"adaptive client-side clipping: ``fixedclipping_mod`` and "
"``adaptiveclipping_mod`` with corresponding server-side wrappers "
"``DifferentialPrivacyClientSideFixedClipping`` and "
"``DifferentialPrivacyClientSideAdaptiveClipping``."
msgstr ""
"对于带有客户端剪裁功能的中央 DP，服务器会在每一轮向选定的客户端发送剪裁值。客户端可以使用现有的 Flower "
":code:`Mods`来执行剪裁。有两种模式可用于固定和自适应客户端剪辑：:code:`fixedclipping_mod` 和 "
":code:`adaptiveclipping_mod`，以及相应的服务器端封装 "
":code:`DifferentialPrivacyClientSideFixedClipping` 和 "
":code:`DifferentialPrivacyClientSideAdaptiveClipping`。"

#: ../../source/how-to-use-differential-privacy.rst:-1
#, fuzzy
msgid "client side clipping"
msgstr "客户端逻辑"

#: ../../source/how-to-use-differential-privacy.rst:78
#, fuzzy
msgid ""
"The code sample below enables the ``FedAvg`` strategy to use differential"
" privacy with client-side fixed clipping using both the "
"``DifferentialPrivacyClientSideFixedClipping`` wrapper class and, on the "
"client, ``fixedclipping_mod``:"
msgstr ""
"下面的代码示例使用 :code:`DifferentialPrivacyClientSideFixedClipping` 封装类和客户端的 "
":code:`fixedclipping_mod` 使 :code:`FedAvg` 策略在客户端固定剪辑的情况下使用差分隐私："

#: ../../source/how-to-use-differential-privacy.rst:97
#, fuzzy
msgid ""
"In addition to the server-side strategy wrapper, the ``ClientApp`` needs "
"to configure the matching ``fixedclipping_mod`` to perform the client-"
"side clipping:"
msgstr ""
"除了服务器端策略包装器外，:code:`ClientApp` 还需要配置匹配的 :code:`fixedclipping_mod` "
"以执行客户端剪切："

#: ../../source/how-to-use-differential-privacy.rst:116
#, fuzzy
msgid ""
"To utilize local differential privacy (DP) and add noise to the client "
"model parameters before transmitting them to the server in Flower, you "
"can use the `LocalDpMod`. The following hyperparameters need to be set: "
"clipping norm value, sensitivity, epsilon, and delta."
msgstr ""
"要利用本地差分隐私（DP）并在将客户端模型参数传输到 Flower 服务器之前为其添加噪声，可以使用 "
"`LocalDpMod`。需要设置以下超参数：剪切规范值、灵敏度、ε 和 delta。"

#: ../../source/how-to-use-differential-privacy.rst:-1
#, fuzzy
msgid "local DP mod"
msgstr "本地 DP 模式"

#: ../../source/how-to-use-differential-privacy.rst:126
#, fuzzy
msgid "Below is a code example that shows how to use ``LocalDpMod``:"
msgstr "下面的代码示例展示了如何使用 :code:`LocalDpMod`："

#: ../../source/how-to-use-differential-privacy.rst:144
#, fuzzy
msgid ""
"Please note that the order of mods, especially those that modify "
"parameters, is important when using multiple modifiers. Typically, "
"differential privacy (DP) modifiers should be the last to operate on "
"parameters."
msgstr "请注意，在使用多个修改器时，修改器（尤其是修改参数的修改器）的顺序非常重要。通常情况下，差分隐私 (DP) 修改器应最后对参数进行操作。"

#: ../../source/how-to-use-differential-privacy.rst:149
#, fuzzy
msgid "Local Training using Privacy Engines"
msgstr "使用隐私引擎进行本地培训"

#: ../../source/how-to-use-differential-privacy.rst:151
#, fuzzy
msgid ""
"For ensuring data instance-level privacy during local model training on "
"the client side, consider leveraging privacy engines such as Opacus and "
"TensorFlow Privacy. For examples of using Flower with these engines, "
"please refer to the Flower examples directory (`Opacus "
"<https://github.com/adap/flower/tree/main/examples/opacus>`_, `Tensorflow"
" Privacy <https://github.com/adap/flower/tree/main/examples/tensorflow-"
"privacy>`_)."
msgstr ""
"要在客户端本地模型训练期间确保数据实例级隐私，可考虑利用 Opacus 和 TensorFlow Privacy 等隐私引擎。有关将 Flower"
" 与这些引擎结合使用的示例，请参阅 Flower 示例目录（`Opacus "
"<https://github.com/adap/flower/tree/main/examples/opacus>`_, `Tensorflow"
" Privacy <https://github.com/adap/flower/tree/main/examples/dp-sgd-"
"mnist>`_）。"

#: ../../source/how-to-use-strategies.rst:2
msgid "Use strategies"
msgstr "使用策略"

#: ../../source/how-to-use-strategies.rst:4
#, fuzzy
msgid ""
"Flower allows full customization of the learning process through the "
"``Strategy`` abstraction. A number of built-in strategies are provided in"
" the core framework."
msgstr "Flower 允许通过 :code:`Strategy` 抽象类对学习过程进行完全定制。核心框架中提供了许多内置策略。"

#: ../../source/how-to-use-strategies.rst:7
msgid ""
"There are three ways to customize the way Flower orchestrates the "
"learning process on the server side:"
msgstr "有三种方法可以自定义 Flower 在服务器端协调学习过程的方式："

#: ../../source/how-to-use-strategies.rst:10
#, fuzzy
msgid "Use an existing strategy, for example, ``FedAvg``"
msgstr "使用现有策略，例如 :code:`FedAvg`"

#: ../../source/how-to-use-strategies.rst:11
#: ../../source/how-to-use-strategies.rst:66
msgid "Customize an existing strategy with callback functions"
msgstr "使用回调函数定制现有策略"

#: ../../source/how-to-use-strategies.rst:12
#: ../../source/how-to-use-strategies.rst:139
msgid "Implement a novel strategy"
msgstr "实施新策略"

#: ../../source/how-to-use-strategies.rst:15
msgid "Use an existing strategy"
msgstr "使用现有策略"

#: ../../source/how-to-use-strategies.rst:17
#, fuzzy
msgid ""
"Flower comes with a number of popular federated learning Strategies which"
" can be instantiated as follows:"
msgstr "Flower 内置了许多流行的联邦学习策略。内置策略的实例化方法如下："

#: ../../source/how-to-use-strategies.rst:45
msgid ""
"To make the ``ServerApp`` use this strategy, pass a ``server_fn`` "
"function to the ``ServerApp`` constructor. The ``server_fn`` function "
"should return a ``ServerAppComponents`` object that contains the strategy"
" instance and a ``ServerConfig`` instance."
msgstr ""

#: ../../source/how-to-use-strategies.rst:50
msgid ""
"Both ``Strategy`` and ``ServerConfig`` classes can be configured with "
"parameters. The ``Context`` object passed to ``server_fn`` contains the "
"values specified in the ``[tool.flwr.app.config]`` table in your "
"``pyproject.toml`` (a snippet is shown below). To access these values, "
"use ``context.run_config``."
msgstr ""

#: ../../source/how-to-use-strategies.rst:68
#, fuzzy
msgid ""
"Existing strategies provide several ways to customize their behavior. "
"Callback functions allow strategies to call user-provided code during "
"execution. This approach enables you to modify the strategy's partial "
"behavior without rewriting the whole class from zero."
msgstr "现有的策略提供了多种自定义行为的方法。回调函数允许策略在执行过程中调用用户提供的代码。"

#: ../../source/how-to-use-strategies.rst:73
msgid "Configuring client fit and client evaluate"
msgstr "配置客户匹配和客户评估"

#: ../../source/how-to-use-strategies.rst:75
#, fuzzy
msgid ""
"The server can pass new configuration values to the client each round by "
"providing a function to ``on_fit_config_fn``. The provided function will "
"be called by the strategy and must return a dictionary of configuration "
"key value pairs that will be sent to the client. It must return a "
"dictionary of arbitrary configuration values ``client.fit`` and "
"``client.evaluate`` functions during each round of federated learning."
msgstr ""
"服务器可以通过向 :code:`on_fit_config_fn` "
"提供一个函数，在每一轮向客户端传递新的配置值。提供的函数将被策略调用，并且必须返回一个配置键值对的字典，该字典将被发送到客户端。在每一轮联邦学习期间，它必须返回一个任意配置值"
" dictionary :code:`client.fit`和 :code:`client.evaluate`函数。"

#: ../../source/how-to-use-strategies.rst:121
#, fuzzy
msgid ""
"The ``on_fit_config_fn`` can be used to pass arbitrary configuration "
"values from server to client and potentially change these values each "
"round, for example, to adjust the learning rate. The client will receive "
"the dictionary returned by the ``on_fit_config_fn`` in its own "
"``client.fit()`` function. And while the values can be also passed "
"directly via the context this function can be a place to implement finer "
"control over the `fit` behaviour that may not be achieved by the context,"
" which sets fixed values."
msgstr ""
":code:`on_fit_config_fn`可用于将任意配置值从服务器传递到客户端，并在每一轮改变这些值，例如，调整学习率。客户端将在自己的 "
":code:`client.fit()` 函数中接收 :code:`on_fit_config_fn` 返回的字典。"

#: ../../source/how-to-use-strategies.rst:129
#, fuzzy
msgid ""
"Similar to ``on_fit_config_fn``, there is also ``on_evaluate_config_fn`` "
"to customize the configuration sent to ``client.evaluate()``"
msgstr ""
"与 :code:`on_fit_config_fn` 类似，还有 :code:`on_evaluate_config_fn` 用于定制发送到 "
":code:`client.evaluate()` 的配置"

#: ../../source/how-to-use-strategies.rst:133
msgid "Configuring server-side evaluation"
msgstr "配置服务器端评估"

#: ../../source/how-to-use-strategies.rst:135
#, fuzzy
msgid ""
"Server-side evaluation can be enabled by passing an evaluation function "
"to ``evaluate_fn``."
msgstr "服务器端评估可通过向 :code:`evaluate_fn` 传递评估函数来启用。"

#: ../../source/how-to-use-strategies.rst:141
msgid ""
"Writing a fully custom strategy is a bit more involved, but it provides "
"the most flexibility. Read the `Implementing Strategies <how-to-"
"implement-strategies.html>`_ guide to learn more."
msgstr ""
"编写完全自定义的策略涉及的内容较多，但灵活性最高。阅读 `实施策略 <how-to-implement-strategies.html>_ "
"指南，了解更多信息。"

#: ../../source/index.rst:34
msgid "Tutorial"
msgstr "教程"

#: ../../source/index.rst:44
msgid "Quickstart tutorials"
msgstr "快速入门教程"

#: ../../source/index.rst:81 ../../source/index.rst:85
msgid "How-to guides"
msgstr "操作指南"

#: ../../source/index.rst:107 ../../source/index.rst:112
msgid "Explanations"
msgstr "说明"

#: None:-1
msgid "API reference"
msgstr "应用程序接口参考"

#: ../../source/index.rst:138
msgid "Reference docs"
msgstr "参考文档"

#: ../../source/index.rst:153
msgid "Contributor tutorials"
msgstr "贡献者教程"

#: ../../source/index.rst:160
msgid "Contributor how-to guides"
msgstr "投稿指南"

#: ../../source/index.rst:172
msgid "Contributor explanations"
msgstr "贡献者解释"

#: ../../source/index.rst:178
msgid "Contributor references"
msgstr "贡献者参考资料"

#: ../../source/index.rst:-1
msgid ""
"Check out the documentation of the main Flower Framework enabling easy "
"Python development for Federated Learning."
msgstr "查看主 Flower Framework 的文档，轻松实现联邦学习的 Python 开发。"

#: ../../source/index.rst:2
msgid "Flower Framework Documentation"
msgstr "Flower 框架文档"

#: ../../source/index.rst:7
#, fuzzy
msgid ""
"Welcome to Flower's documentation. `Flower <https://flower.ai>`_ is a "
"friendly federated learning framework."
msgstr "欢迎访问 Flower 文档。`Flower <https://flower.ai>`_ 是一个友好的联邦学习框架。"

#: ../../source/index.rst:11
msgid "Join the Flower Community"
msgstr "加入 Flower 社区"

#: ../../source/index.rst:13
msgid ""
"The Flower Community is growing quickly - we're a friendly group of "
"researchers, engineers, students, professionals, academics, and other "
"enthusiasts."
msgstr "Flower 社区发展迅速--我们是一个由研究人员、工程师、学生、专业人士、学者和其他爱好者组成的友好团体。"

#: ../../source/index.rst:16
msgid "Join us on Slack"
msgstr "在 Slack 上加入我们"

#: ../../source/index.rst:23
msgid "Flower Framework"
msgstr "Flower 框架"

#: ../../source/index.rst:25
msgid ""
"The user guide is targeted at researchers and developers who want to use "
"Flower to bring existing machine learning workloads into a federated "
"setting. One of Flower's design goals was to make this simple. Read on to"
" learn more."
msgstr ""
"该用户指南面向希望使用 Flower 将现有机器学习工作负载引入联邦环境的研究人员和开发人员。Flower "
"的设计目标之一就是让这一切变得简单。请继续阅读，了解更多信息。"

#: ../../source/index.rst:30
msgid "Tutorials"
msgstr "教程"

#: ../../source/index.rst:32
msgid ""
"A learning-oriented series of federated learning tutorials, the best "
"place to start."
msgstr "以学习为导向的联邦学习教程系列，最好的起点。"

#: ../../source/index.rst:62
#, fuzzy
msgid ""
"QUICKSTART TUTORIALS: :doc:`PyTorch <tutorial-quickstart-pytorch>` | "
":doc:`TensorFlow <tutorial-quickstart-tensorflow>` | :doc:`MLX <tutorial-"
"quickstart-mlx>` | :doc:`🤗 Transformers <tutorial-quickstart-"
"huggingface>` | :doc:`JAX <tutorial-quickstart-jax>` | :doc:`Pandas "
"<tutorial-quickstart-pandas>` | :doc:`fastai <tutorial-quickstart-"
"fastai>` | :doc:`PyTorch Lightning <tutorial-quickstart-pytorch-"
"lightning>` | :doc:`scikit-learn <tutorial-quickstart-scikitlearn>` | "
":doc:`XGBoost <tutorial-quickstart-xgboost>` | :doc:`Android <tutorial-"
"quickstart-android>` | :doc:`iOS <tutorial-quickstart-ios>`"
msgstr ""
"快速入门教程: :doc:`PyTorch <tutorial-quickstart-pytorch>` | :doc:`TensorFlow "
"<tutorial-quickstart-tensorflow>` | :doc:`🤗 Transformers <tutorial-"
"quickstart-huggingface>` | :doc:`JAX <tutorial-quickstart-jax>` | "
":doc:`Pandas <tutorial-quickstart-pandas>` | :doc:`fastai <tutorial-"
"quickstart-fastai>` | :doc:`PyTorch Lightning <tutorial-quickstart-"
"pytorch-lightning>` | :doc:`MXNet <tutorial-quickstart-mxnet>` | :doc"
":`scikit-learn <tutorial-quickstart-scikitlearn>` | :doc:`XGBoost "
"<tutorial-quickstart-xgboost>` | :doc:`Android <tutorial-quickstart-"
"android>` | :doc:`iOS <tutorial-quickstart-ios>`"

#: ../../source/index.rst:70
msgid "We also made video tutorials for PyTorch:"
msgstr "我们还为 PyTorch 制作了视频教程："

#: ../../source/index.rst:75
msgid "And TensorFlow:"
msgstr "还有 TensorFlow："

#: ../../source/index.rst:83
msgid ""
"Problem-oriented how-to guides show step-by-step how to achieve a "
"specific goal."
msgstr "以问题为导向的 \"如何做 \"指南逐步展示如何实现特定目标。"

#: ../../source/index.rst:109
msgid ""
"Understanding-oriented concept guides explain and discuss key topics and "
"underlying ideas behind Flower and collaborative AI."
msgstr "以理解为导向的概念指南解释并讨论了Flower和协作式人工智能背后的关键主题和基本思想。"

#: ../../source/index.rst:121
msgid "References"
msgstr "参考资料"

#: ../../source/index.rst:123
msgid "Information-oriented API reference and other reference material."
msgstr "以信息为导向的 API 参考资料和其他参考资料。"

#: ../../source/index.rst:132:<autosummary>:1
#, fuzzy
msgid ":py:obj:`flwr <flwr>`\\"
msgstr ":py:obj:`flwr <flwr>`\\"

#: ../../source/index.rst:132:<autosummary>:1 flwr:1 of
#, fuzzy
msgid "Flower main package."
msgstr "Flower 主包装。"

#: ../../source/index.rst:148
msgid "Contributor docs"
msgstr "贡献者文档"

#: ../../source/index.rst:150
msgid ""
"The Flower community welcomes contributions. The following docs are "
"intended to help along the way."
msgstr "Flower 社区欢迎您的贡献。以下文档旨在为您提供帮助。"

#: ../../source/ref-api-cli.rst:2
msgid "Flower CLI reference"
msgstr "Flower CLI 参考"

#: ../../source/ref-api-cli.rst:5
#, fuzzy
msgid "Basic Commands"
msgstr "命令示例"

#: ../../source/ref-api-cli.rst:10
#, fuzzy
msgid "``flwr`` CLI"
msgstr "Flower 客户端"

#: ../../source/ref-api-cli.rst:19
#, fuzzy
msgid "``flower-superlink``"
msgstr "flower-superlink"

#: ../../source/ref-api-cli.rst:29
#, fuzzy
msgid "``flower-supernode``"
msgstr "Flower 服务器"

#: ../../source/ref-api-cli.rst:37
#, fuzzy
msgid "Advanced Commands"
msgstr "高级安装选项"

#: ../../source/ref-api-cli.rst:42
#, fuzzy
msgid "``flwr-serverapp``"
msgstr "flower-driver-api"

#: ../../source/ref-api-cli.rst:52
#, fuzzy
msgid "``flwr-clientapp``"
msgstr "Flower 客户端。"

#: ../../source/ref-api-cli.rst:60
#, fuzzy
msgid "Technical Commands"
msgstr "命令示例"

#: ../../source/ref-api-cli.rst:65
#, fuzzy
msgid "``flower-simulation``"
msgstr "运行模拟"

#: ../../source/ref-api-cli.rst:73
#, fuzzy
msgid "Deprecated Commands"
msgstr "停用"

#: ../../source/ref-api-cli.rst:78
#, fuzzy
msgid "``flower-server-app``"
msgstr "flower-driver-api"

#: ../../source/ref-api-cli.rst:82
msgid ""
"Note that from version ``1.13.0``, ``flower-server-app`` is deprecated. "
"Instead, you only need to execute |flwr_run_link|_ to start the run."
msgstr ""

#: ../../source/ref-api-cli.rst:88
#, fuzzy
msgid "``flower-superexec``"
msgstr "flower-superlink"

#: ../../source/ref-api-cli.rst:92
msgid ""
"Note that from version ``1.13.0``, ``flower-superexec`` is deprecated. "
"Instead, you only need to execute |flower_superlink_link|_."
msgstr ""

#: ../../source/ref-api/flwr.rst:2
#, fuzzy
msgid "flwr"
msgstr "Flower"

#: ../../source/ref-api/flwr.client.rst:43 ../../source/ref-api/flwr.rst:25
#: ../../source/ref-api/flwr.server.rst:48
#, fuzzy
msgid "Modules"
msgstr "模块"

#: ../../source/ref-api/flwr.rst:35:<autosummary>:1
#, fuzzy
msgid ":py:obj:`client <flwr.client>`\\"
msgstr ":py:obj:`flwr.client <flwr.client>`\\"

#: ../../source/ref-api/flwr.rst:35:<autosummary>:1 flwr.client:1 of
msgid "Flower client."
msgstr "Flower 客户端。"

#: ../../source/ref-api/flwr.rst:35:<autosummary>:1
#, fuzzy
msgid ":py:obj:`common <flwr.common>`\\"
msgstr ":py:obj:`flwr.common <flwr.common>`\\"

#: ../../source/ref-api/flwr.rst:35:<autosummary>:1 flwr.common:1 of
msgid "Common components shared between server and client."
msgstr "服务器和客户端共享的通用组件。"

#: ../../source/ref-api/flwr.rst:35:<autosummary>:1
#, fuzzy
msgid ":py:obj:`server <flwr.server>`\\"
msgstr ":py:obj:`flwr.server <flwr.server>`\\"

#: ../../source/ref-api/flwr.rst:35:<autosummary>:1
#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1 flwr.server:1
#: flwr.server.server.Server:1 of
msgid "Flower server."
msgstr "Flower 服务器。"

#: ../../source/ref-api/flwr.rst:35:<autosummary>:1
#, fuzzy
msgid ":py:obj:`simulation <flwr.simulation>`\\"
msgstr ":py:obj:`flwr.simulation <flwr.simulation>`\\"

#: ../../source/ref-api/flwr.rst:35:<autosummary>:1 flwr.simulation:1 of
#, fuzzy
msgid "Flower simulation."
msgstr "运行模拟"

#: ../../source/ref-api/flwr.client.rst:2
msgid "client"
msgstr "客户端"

#: ../../source/ref-api/flwr.client.mod.rst:13
#: ../../source/ref-api/flwr.client.rst:13
#: ../../source/ref-api/flwr.common.rst:13
#: ../../source/ref-api/flwr.server.rst:13
#: ../../source/ref-api/flwr.simulation.rst:13
#, fuzzy
msgid "Functions"
msgstr "四种函数："

#: ../../source/ref-api/flwr.client.rst:23:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`start_client <flwr.client.start_client>`\\ \\(\\*\\, "
"server\\_address\\[\\, client\\_fn\\, ...\\]\\)"
msgstr ""
":py:obj:`start_client <flwr.client.start_client>`\\ \\(\\*\\, "
"server\\_address\\[\\, client\\_fn\\, ...\\]\\)"

#: ../../source/ref-api/flwr.client.rst:23:<autosummary>:1
#: flwr.client.app.start_client:1 of
msgid "Start a Flower client node which connects to a Flower server."
msgstr "启动一个 Flower 客户节点，连接到 Flower 服务器。"

#: ../../source/ref-api/flwr.client.rst:23:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`start_numpy_client <flwr.client.start_numpy_client>`\\ \\(\\*\\,"
" server\\_address\\, client\\)"
msgstr ""
":py:obj:`start_numpy_client <flwr.client.start_numpy_client>`\\ \\(\\*\\,"
" server\\_address\\, client\\)"

#: ../../source/ref-api/flwr.client.rst:23:<autosummary>:1
#: flwr.client.app.start_numpy_client:1 of
msgid "Start a Flower NumPyClient which connects to a gRPC server."
msgstr "启动 Flower NumPyClient，连接到 gRPC 服务器。"

#: ../../source/ref-api/flwr.client.mod.rst:30
#: ../../source/ref-api/flwr.client.rst:25
#: ../../source/ref-api/flwr.common.rst:32
#: ../../source/ref-api/flwr.server.rst:24
#: ../../source/ref-api/flwr.server.strategy.rst:17
#: ../../source/ref-api/flwr.server.workflow.rst:17
#: ../../source/ref-api/flwr.simulation.rst:26
#, fuzzy
msgid "Classes"
msgstr "类别"

#: ../../source/ref-api/flwr.client.rst:32:<autosummary>:1
#, fuzzy
msgid ":py:obj:`Client <flwr.client.Client>`\\ \\(\\)"
msgstr ":py:obj:`Client <flwr.client.Client>`\\ \\(\\)"

#: ../../source/ref-api/flwr.client.rst:32:<autosummary>:1
#: flwr.client.client.Client:1 of
msgid "Abstract base class for Flower clients."
msgstr "Flower 客户端的抽象基类。"

#: ../../source/ref-api/flwr.client.rst:32:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`ClientApp <flwr.client.ClientApp>`\\ \\(\\[client\\_fn\\, "
"mods\\]\\)"
msgstr ""
":py:obj:`ClientApp <flwr.client.ClientApp>`\\ \\(\\[client\\_fn\\, "
"mods\\]\\)"

#: ../../source/ref-api/flwr.client.rst:32:<autosummary>:1
#: flwr.client.client_app.ClientApp:1 of
#, fuzzy
msgid "Flower ClientApp."
msgstr "Flower 客户端。"

#: ../../source/ref-api/flwr.client.rst:32:<autosummary>:1
#, fuzzy
msgid ":py:obj:`NumPyClient <flwr.client.NumPyClient>`\\ \\(\\)"
msgstr ":py:obj:`NumPyClient <flwr.client.NumPyClient>`\\ \\(\\)"

#: ../../source/ref-api/flwr.client.rst:32:<autosummary>:1
#: flwr.client.numpy_client.NumPyClient:1 of
msgid "Abstract base class for Flower clients using NumPy."
msgstr "使用 NumPy 的 Flower 客户端的抽象基类。"

#: ../../source/ref-api/flwr.client.rst:50:<autosummary>:1
#, fuzzy
msgid ":py:obj:`mod <flwr.client.mod>`\\"
msgstr ":py:obj:`flwr.client <flwr.client>`\\"

#: ../../source/ref-api/flwr.client.rst:50:<autosummary>:1 flwr.client.mod:1 of
#, fuzzy
msgid "Flower Built-in Mods."
msgstr "使用内置调制器"

#: flwr.client.client.Client:1 flwr.client.numpy_client.NumPyClient:1
#: flwr.server.client_manager.ClientManager:1
#: flwr.server.driver.driver.Driver:1 flwr.server.strategy.strategy.Strategy:1
#: of
#, fuzzy
msgid "Bases: :py:class:`~abc.ABC`"
msgstr "Bases: :py:class:`~abc.ABC`"

#: ../../source/ref-api/flwr.client.Client.rst:15
#: ../../source/ref-api/flwr.client.ClientApp.rst:15
#: ../../source/ref-api/flwr.client.NumPyClient.rst:15
#: ../../source/ref-api/flwr.client.mod.LocalDpMod.rst:15
#: ../../source/ref-api/flwr.common.Array.rst:15
#: ../../source/ref-api/flwr.common.ClientMessage.rst:15
#: ../../source/ref-api/flwr.common.ConfigsRecord.rst:15
#: ../../source/ref-api/flwr.common.Context.rst:15
#: ../../source/ref-api/flwr.common.DisconnectRes.rst:15
#: ../../source/ref-api/flwr.common.Error.rst:15
#: ../../source/ref-api/flwr.common.EvaluateIns.rst:15
#: ../../source/ref-api/flwr.common.EvaluateRes.rst:15
#: ../../source/ref-api/flwr.common.EventType.rst:15
#: ../../source/ref-api/flwr.common.FitIns.rst:15
#: ../../source/ref-api/flwr.common.FitRes.rst:15
#: ../../source/ref-api/flwr.common.GetParametersIns.rst:15
#: ../../source/ref-api/flwr.common.GetParametersRes.rst:15
#: ../../source/ref-api/flwr.common.GetPropertiesIns.rst:15
#: ../../source/ref-api/flwr.common.GetPropertiesRes.rst:15
#: ../../source/ref-api/flwr.common.Message.rst:15
#: ../../source/ref-api/flwr.common.MessageType.rst:15
#: ../../source/ref-api/flwr.common.MessageTypeLegacy.rst:15
#: ../../source/ref-api/flwr.common.Metadata.rst:15
#: ../../source/ref-api/flwr.common.MetricsRecord.rst:15
#: ../../source/ref-api/flwr.common.Parameters.rst:15
#: ../../source/ref-api/flwr.common.ParametersRecord.rst:15
#: ../../source/ref-api/flwr.common.ReconnectIns.rst:15
#: ../../source/ref-api/flwr.common.RecordSet.rst:15
#: ../../source/ref-api/flwr.common.ServerMessage.rst:15
#: ../../source/ref-api/flwr.common.Status.rst:15
#: ../../source/ref-api/flwr.server.ClientManager.rst:15
#: ../../source/ref-api/flwr.server.Driver.rst:15
#: ../../source/ref-api/flwr.server.History.rst:15
#: ../../source/ref-api/flwr.server.LegacyContext.rst:15
#: ../../source/ref-api/flwr.server.Server.rst:15
#: ../../source/ref-api/flwr.server.ServerApp.rst:15
#: ../../source/ref-api/flwr.server.ServerAppComponents.rst:15
#: ../../source/ref-api/flwr.server.ServerConfig.rst:15
#: ../../source/ref-api/flwr.server.SimpleClientManager.rst:15
#: ../../source/ref-api/flwr.server.strategy.Bulyan.rst:15
#: ../../source/ref-api/flwr.server.strategy.DPFedAvgAdaptive.rst:15
#: ../../source/ref-api/flwr.server.strategy.DPFedAvgFixed.rst:15
#: ../../source/ref-api/flwr.server.strategy.DifferentialPrivacyClientSideAdaptiveClipping.rst:15
#: ../../source/ref-api/flwr.server.strategy.DifferentialPrivacyClientSideFixedClipping.rst:15
#: ../../source/ref-api/flwr.server.strategy.DifferentialPrivacyServerSideAdaptiveClipping.rst:15
#: ../../source/ref-api/flwr.server.strategy.DifferentialPrivacyServerSideFixedClipping.rst:15
#: ../../source/ref-api/flwr.server.strategy.FaultTolerantFedAvg.rst:15
#: ../../source/ref-api/flwr.server.strategy.FedAdagrad.rst:15
#: ../../source/ref-api/flwr.server.strategy.FedAdam.rst:15
#: ../../source/ref-api/flwr.server.strategy.FedAvg.rst:15
#: ../../source/ref-api/flwr.server.strategy.FedAvgAndroid.rst:15
#: ../../source/ref-api/flwr.server.strategy.FedAvgM.rst:15
#: ../../source/ref-api/flwr.server.strategy.FedMedian.rst:15
#: ../../source/ref-api/flwr.server.strategy.FedOpt.rst:15
#: ../../source/ref-api/flwr.server.strategy.FedProx.rst:15
#: ../../source/ref-api/flwr.server.strategy.FedTrimmedAvg.rst:15
#: ../../source/ref-api/flwr.server.strategy.FedXgbBagging.rst:15
#: ../../source/ref-api/flwr.server.strategy.FedXgbCyclic.rst:15
#: ../../source/ref-api/flwr.server.strategy.FedXgbNnAvg.rst:15
#: ../../source/ref-api/flwr.server.strategy.FedYogi.rst:15
#: ../../source/ref-api/flwr.server.strategy.Krum.rst:15
#: ../../source/ref-api/flwr.server.strategy.QFedAvg.rst:15
#: ../../source/ref-api/flwr.server.strategy.Strategy.rst:15
#: ../../source/ref-api/flwr.server.workflow.DefaultWorkflow.rst:15
#: ../../source/ref-api/flwr.server.workflow.SecAggPlusWorkflow.rst:15
#: ../../source/ref-api/flwr.server.workflow.SecAggWorkflow.rst:15
#: ../../source/ref-api/flwr.simulation.SimulationIoConnection.rst:15
#, fuzzy
msgid "Methods"
msgstr "方法"

#: ../../source/ref-api/flwr.client.Client.rst:44:<autosummary>:1
#, fuzzy
msgid ":py:obj:`evaluate <flwr.client.Client.evaluate>`\\ \\(ins\\)"
msgstr ":py:obj:`evaluate <flwr.client.Client.evaluate>`\\ \\(ins\\)"

#: ../../source/ref-api/flwr.client.Client.rst:44:<autosummary>:1
#: ../../source/ref-api/flwr.client.NumPyClient.rst:44:<autosummary>:1
#: flwr.client.client.Client.evaluate:1
#: flwr.client.numpy_client.NumPyClient.evaluate:1 of
msgid "Evaluate the provided parameters using the locally held dataset."
msgstr "使用本地数据集评估所提供的参数。"

#: ../../source/ref-api/flwr.client.Client.rst:44:<autosummary>:1
#, fuzzy
msgid ":py:obj:`fit <flwr.client.Client.fit>`\\ \\(ins\\)"
msgstr ":py:obj:`fit <flwr.client.Client.fit>`\\ \\(ins\\)"

#: ../../source/ref-api/flwr.client.Client.rst:44:<autosummary>:1
#: flwr.client.client.Client.fit:1 of
msgid "Refine the provided parameters using the locally held dataset."
msgstr "利用本地数据集完善所提供的参数。"

#: ../../source/ref-api/flwr.client.Client.rst:44:<autosummary>:1
#, fuzzy
msgid ":py:obj:`get_context <flwr.client.Client.get_context>`\\ \\(\\)"
msgstr ":py:obj:`get_context <flwr.client.Client.get_context>`\\ \\(\\)"

#: ../../source/ref-api/flwr.client.Client.rst:44:<autosummary>:1
#: ../../source/ref-api/flwr.client.NumPyClient.rst:44:<autosummary>:1
#: flwr.client.client.Client.get_context:1
#: flwr.client.numpy_client.NumPyClient.get_context:1 of
#, fuzzy
msgid "Get the run context from this client."
msgstr "评估客户端的反应。"

#: ../../source/ref-api/flwr.client.Client.rst:44:<autosummary>:1
#, fuzzy
msgid ":py:obj:`get_parameters <flwr.client.Client.get_parameters>`\\ \\(ins\\)"
msgstr ":py:obj:`get_parameters <flwr.client.Client.get_parameters>`\\ \\(ins\\)"

#: ../../source/ref-api/flwr.client.Client.rst:44:<autosummary>:1
#: ../../source/ref-api/flwr.client.NumPyClient.rst:44:<autosummary>:1
#: flwr.client.client.Client.get_parameters:1
#: flwr.client.numpy_client.NumPyClient.get_parameters:1 of
msgid "Return the current local model parameters."
msgstr "返回当前本地模型参数。"

#: ../../source/ref-api/flwr.client.Client.rst:44:<autosummary>:1
#, fuzzy
msgid ":py:obj:`get_properties <flwr.client.Client.get_properties>`\\ \\(ins\\)"
msgstr ":py:obj:`get_properties <flwr.client.Client.get_properties>`\\ \\(ins\\)"

#: ../../source/ref-api/flwr.client.Client.rst:44:<autosummary>:1
#: flwr.client.client.Client.get_properties:1 of
msgid "Return set of client's properties."
msgstr "返回客户端的属性集。"

#: ../../source/ref-api/flwr.client.Client.rst:44:<autosummary>:1
#, fuzzy
msgid ":py:obj:`set_context <flwr.client.Client.set_context>`\\ \\(context\\)"
msgstr ":py:obj:`set_context <flwr.client.Client.set_context>`\\ \\(context\\)"

#: ../../source/ref-api/flwr.client.Client.rst:44:<autosummary>:1
#: ../../source/ref-api/flwr.client.NumPyClient.rst:44:<autosummary>:1
#: flwr.client.client.Client.set_context:1
#: flwr.client.numpy_client.NumPyClient.set_context:1 of
#, fuzzy
msgid "Apply a run context to this client."
msgstr "将运行上下文应用于该客户端。"

#: ../../source/ref-api/flwr.client.Client.rst:44:<autosummary>:1
#, fuzzy
msgid ":py:obj:`to_client <flwr.client.Client.to_client>`\\ \\(\\)"
msgstr ":py:obj:`to_client <flwr.client.Client.to_client>`\\ \\(\\)"

#: ../../source/ref-api/flwr.client.Client.rst:44:<autosummary>:1
#: flwr.client.client.Client.to_client:1 of
msgid "Return client (itself)."
msgstr "返回客户端（本身）。"

#: ../../source/ref-api/flwr.client.Client.rst:46
#: ../../source/ref-api/flwr.client.NumPyClient.rst:46
#: ../../source/ref-api/flwr.common.Array.rst:28
#: ../../source/ref-api/flwr.common.ClientMessage.rst:25
#: ../../source/ref-api/flwr.common.Code.rst:19
#: ../../source/ref-api/flwr.common.Context.rst:25
#: ../../source/ref-api/flwr.common.DisconnectRes.rst:25
#: ../../source/ref-api/flwr.common.Error.rst:25
#: ../../source/ref-api/flwr.common.EvaluateIns.rst:25
#: ../../source/ref-api/flwr.common.EvaluateRes.rst:25
#: ../../source/ref-api/flwr.common.EventType.rst:165
#: ../../source/ref-api/flwr.common.FitIns.rst:25
#: ../../source/ref-api/flwr.common.FitRes.rst:25
#: ../../source/ref-api/flwr.common.GetParametersIns.rst:25
#: ../../source/ref-api/flwr.common.GetParametersRes.rst:25
#: ../../source/ref-api/flwr.common.GetPropertiesIns.rst:25
#: ../../source/ref-api/flwr.common.GetPropertiesRes.rst:25
#: ../../source/ref-api/flwr.common.Message.rst:37
#: ../../source/ref-api/flwr.common.MessageType.rst:25
#: ../../source/ref-api/flwr.common.MessageTypeLegacy.rst:25
#: ../../source/ref-api/flwr.common.Metadata.rst:25
#: ../../source/ref-api/flwr.common.Parameters.rst:25
#: ../../source/ref-api/flwr.common.ReconnectIns.rst:25
#: ../../source/ref-api/flwr.common.RecordSet.rst:25
#: ../../source/ref-api/flwr.common.ServerMessage.rst:25
#: ../../source/ref-api/flwr.common.Status.rst:25
#: ../../source/ref-api/flwr.server.Driver.rst:43
#: ../../source/ref-api/flwr.server.LegacyContext.rst:25
#: ../../source/ref-api/flwr.server.ServerAppComponents.rst:25
#: ../../source/ref-api/flwr.server.ServerConfig.rst:25
#, fuzzy
msgid "Attributes"
msgstr "属性"

#: flwr.client.Client.context:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`context <flwr.client.Client.context>`\\"
msgstr ":py:obj:`context <flwr.client.Client.context>`\\"

#: flwr.client.Client.context:1 flwr.client.Client.context:1:<autosummary>:1
#: flwr.client.NumPyClient.context:1
#: flwr.client.NumPyClient.context:1:<autosummary>:1 of
msgid "Getter for `Context` client attribute."
msgstr ""

#: ../../source/ref-api/flwr.client.Client.rst
#: ../../source/ref-api/flwr.client.NumPyClient.rst
#: ../../source/ref-api/flwr.client.mod.LocalDpMod.rst
#: ../../source/ref-api/flwr.common.Array.rst
#: ../../source/ref-api/flwr.common.ConfigsRecord.rst
#: ../../source/ref-api/flwr.common.Context.rst
#: ../../source/ref-api/flwr.common.Error.rst
#: ../../source/ref-api/flwr.common.Message.rst
#: ../../source/ref-api/flwr.common.Metadata.rst
#: ../../source/ref-api/flwr.common.MetricsRecord.rst
#: ../../source/ref-api/flwr.common.Parameters.rst:2
#: ../../source/ref-api/flwr.common.ParametersRecord.rst
#: ../../source/ref-api/flwr.common.RecordSet.rst
#: ../../source/ref-api/flwr.server.ClientManager.rst
#: ../../source/ref-api/flwr.server.Driver.rst
#: ../../source/ref-api/flwr.server.ServerAppComponents.rst
#: ../../source/ref-api/flwr.server.SimpleClientManager.rst
#: ../../source/ref-api/flwr.server.strategy.Bulyan.rst
#: ../../source/ref-api/flwr.server.strategy.DPFedAvgAdaptive.rst
#: ../../source/ref-api/flwr.server.strategy.DPFedAvgFixed.rst
#: ../../source/ref-api/flwr.server.strategy.DifferentialPrivacyClientSideAdaptiveClipping.rst
#: ../../source/ref-api/flwr.server.strategy.DifferentialPrivacyClientSideFixedClipping.rst
#: ../../source/ref-api/flwr.server.strategy.DifferentialPrivacyServerSideAdaptiveClipping.rst
#: ../../source/ref-api/flwr.server.strategy.DifferentialPrivacyServerSideFixedClipping.rst
#: ../../source/ref-api/flwr.server.strategy.FedAdagrad.rst
#: ../../source/ref-api/flwr.server.strategy.FedAdam.rst
#: ../../source/ref-api/flwr.server.strategy.FedAvg.rst
#: ../../source/ref-api/flwr.server.strategy.FedAvgAndroid.rst
#: ../../source/ref-api/flwr.server.strategy.FedAvgM.rst
#: ../../source/ref-api/flwr.server.strategy.FedOpt.rst
#: ../../source/ref-api/flwr.server.strategy.FedProx.rst
#: ../../source/ref-api/flwr.server.strategy.FedTrimmedAvg.rst
#: ../../source/ref-api/flwr.server.strategy.FedYogi.rst
#: ../../source/ref-api/flwr.server.strategy.Krum.rst
#: ../../source/ref-api/flwr.server.strategy.Strategy.rst
#: ../../source/ref-api/flwr.server.workflow.SecAggPlusWorkflow.rst
#: ../../source/ref-api/flwr.server.workflow.SecAggWorkflow.rst
#: ../../source/ref-api/flwr.simulation.SimulationIoConnection.rst
#: ../../source/ref-api/flwr.simulation.run_simulation.rst
#: ../../source/ref-api/flwr.simulation.start_simulation.rst
#: flwr.client.app.start_client flwr.client.app.start_numpy_client
#: flwr.server.app.start_server
#: flwr.server.driver.driver.Driver.send_and_receive of
msgid "Parameters"
msgstr "参数"

#: flwr.client.client.Client.evaluate:3 of
msgid ""
"The evaluation instructions containing (global) model parameters received"
" from the server and a dictionary of configuration values used to "
"customize the local evaluation process."
msgstr "评估指令包含从服务器接收的（全局）模型参数，以及用于定制本地评估流程的配置值字典。"

#: ../../source/ref-api/flwr.client.Client.rst
#: ../../source/ref-api/flwr.client.NumPyClient.rst
#: ../../source/ref-api/flwr.common.ConfigsRecord.rst
#: ../../source/ref-api/flwr.common.Message.rst
#: ../../source/ref-api/flwr.common.MetricsRecord.rst
#: ../../source/ref-api/flwr.common.ParametersRecord.rst
#: ../../source/ref-api/flwr.server.ClientManager.rst
#: ../../source/ref-api/flwr.server.Driver.rst
#: ../../source/ref-api/flwr.server.SimpleClientManager.rst
#: ../../source/ref-api/flwr.server.strategy.DPFedAvgAdaptive.rst
#: ../../source/ref-api/flwr.server.strategy.DPFedAvgFixed.rst
#: ../../source/ref-api/flwr.server.strategy.Strategy.rst
#: ../../source/ref-api/flwr.simulation.start_simulation.rst
#: flwr.server.app.start_server
#: flwr.server.driver.driver.Driver.send_and_receive of
msgid "Returns"
msgstr "返回"

#: flwr.client.client.Client.evaluate:8 of
msgid ""
"The evaluation result containing the loss on the local dataset and other "
"details such as the number of local data examples used for evaluation."
msgstr "评估结果包含本地数据集上的损失值和其他详细信息，如用于评估的本地数据的数量。"

#: ../../source/ref-api/flwr.client.Client.rst
#: ../../source/ref-api/flwr.client.NumPyClient.rst
#: ../../source/ref-api/flwr.common.Message.rst
#: ../../source/ref-api/flwr.server.ClientManager.rst
#: ../../source/ref-api/flwr.server.Driver.rst
#: ../../source/ref-api/flwr.server.SimpleClientManager.rst
#: ../../source/ref-api/flwr.server.strategy.DPFedAvgAdaptive.rst
#: ../../source/ref-api/flwr.server.strategy.DPFedAvgFixed.rst
#: ../../source/ref-api/flwr.server.strategy.Strategy.rst
#: ../../source/ref-api/flwr.simulation.start_simulation.rst
#: flwr.server.app.start_server
#: flwr.server.driver.driver.Driver.send_and_receive of
msgid "Return type"
msgstr "返回类型"

#: flwr.client.client.Client.fit:3 of
msgid ""
"The training instructions containing (global) model parameters received "
"from the server and a dictionary of configuration values used to "
"customize the local training process."
msgstr "训练指令，包含从服务器接收的（全局）模型参数，以及用于定制本地训练过程的配置值字典。"

#: flwr.client.client.Client.fit:8 of
msgid ""
"The training result containing updated parameters and other details such "
"as the number of local training examples used for training."
msgstr "训练结果包含更新的参数和其他详细信息，如用于训练的本地训练示例的数量。"

#: flwr.client.client.Client.get_parameters:3 of
msgid ""
"The get parameters instructions received from the server containing a "
"dictionary of configuration values."
msgstr "从服务器接收的获取参数指令包含配置值字典。"

#: flwr.client.client.Client.get_parameters:7 of
msgid "The current local model parameters."
msgstr "当前的本地模型参数。"

#: flwr.client.client.Client.get_properties:3 of
msgid ""
"The get properties instructions received from the server containing a "
"dictionary of configuration values."
msgstr "从服务器接收的获取属性指令包含配置值字典。"

#: flwr.client.client.Client.get_properties:7 of
msgid "The current client properties."
msgstr "当前客户端属性。"

#: ../../source/ref-api/flwr.client.ClientApp.rst:2
#, fuzzy
msgid "ClientApp"
msgstr "客户端"

#: flwr.client.client_app.ClientApp:1 flwr.client.mod.localdp_mod.LocalDpMod:1
#: flwr.common.constant.MessageType:1 flwr.common.constant.MessageTypeLegacy:1
#: flwr.common.context.Context:1 flwr.common.message.Error:1
#: flwr.common.message.Message:1 flwr.common.message.Metadata:1
#: flwr.common.record.parametersrecord.Array:1
#: flwr.common.record.recordset.RecordSet:1 flwr.common.typing.ClientMessage:1
#: flwr.common.typing.DisconnectRes:1 flwr.common.typing.EvaluateIns:1
#: flwr.common.typing.EvaluateRes:1 flwr.common.typing.FitIns:1
#: flwr.common.typing.FitRes:1 flwr.common.typing.GetParametersIns:1
#: flwr.common.typing.GetParametersRes:1 flwr.common.typing.GetPropertiesIns:1
#: flwr.common.typing.GetPropertiesRes:1 flwr.common.typing.Parameters:1
#: flwr.common.typing.ReconnectIns:1 flwr.common.typing.ServerMessage:1
#: flwr.common.typing.Status:1 flwr.server.history.History:1
#: flwr.server.server.Server:1 flwr.server.server_app.ServerApp:1
#: flwr.server.server_config.ServerConfig:1
#: flwr.server.serverapp_components.ServerAppComponents:1
#: flwr.server.workflow.default_workflows.DefaultWorkflow:1
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:1
#: flwr.simulation.simulationio_connection.SimulationIoConnection:1 of
#, fuzzy
msgid "Bases: :py:class:`object`"
msgstr "Bases: :py:class:`object`"

#: flwr.client.app.start_client:51 flwr.client.app.start_numpy_client:36
#: flwr.client.client_app.ClientApp:4
#: flwr.client.client_app.ClientApp.evaluate:4
#: flwr.client.client_app.ClientApp.query:4
#: flwr.client.client_app.ClientApp.train:4
#: flwr.client.mod.localdp_mod.LocalDpMod:22
#: flwr.common.record.configsrecord.ConfigsRecord:20
#: flwr.common.record.metricsrecord.MetricsRecord:19
#: flwr.common.record.parametersrecord.ParametersRecord:22
#: flwr.common.record.recordset.RecordSet:23 flwr.server.app.start_server:46
#: flwr.server.server_app.ServerApp:4 flwr.server.server_app.ServerApp.main:4
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping:29
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping:22
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping:21
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping:14
#: of
msgid "Examples"
msgstr "实例"

#: flwr.client.client_app.ClientApp:5 of
#, fuzzy
msgid ""
"Assuming a typical `Client` implementation named `FlowerClient`, you can "
"wrap it in a `ClientApp` as follows:"
msgstr "假定有一个名为 `FlowerClient` 的典型 `Client` 实现，可以将其封装在一个 `ClientApp` 中，如下所示："

#: flwr.client.client_app.ClientApp:16 of
#, fuzzy
msgid ""
"If the above code is in a Python module called `client`, it can be "
"started as follows:"
msgstr "如果上述代码位于一个名为 \"客户端 \"的 Python 模块中，则可以按如下方式启动它："

#: flwr.client.client_app.ClientApp:21 of
#, fuzzy
msgid ""
"In this `client:app` example, `client` refers to the Python module "
"`client.py` in which the previous code lives in and `app` refers to the "
"global attribute `app` that points to an object of type `ClientApp`."
msgstr ""
"在这个 `client:app` 例子中，`client` 指的是前面代码所在的 Python 模块 `client.py`，而 `app` "
"指的是指向 `ClientApp` 类型对象的全局属性 `app` 。"

#: flwr.client.client_app.ClientApp.evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`evaluate <flwr.client.ClientApp.evaluate>`\\ \\(\\)"
msgstr ":py:obj:`evaluate <flwr.client.ClientApp.evaluate>`\\ \\(\\)"

#: flwr.client.client_app.ClientApp.evaluate:1
#: flwr.client.client_app.ClientApp.evaluate:1:<autosummary>:1 of
#, fuzzy
msgid "Return a decorator that registers the evaluate fn with the client app."
msgstr "返回一个装饰器，用于向客户端程序注册评估 fn。"

#: flwr.client.client_app.ClientApp.evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`query <flwr.client.ClientApp.query>`\\ \\(\\)"
msgstr ":py:obj:`query <flwr.client.ClientApp.query>`\\ \\(\\)"

#: flwr.client.client_app.ClientApp.evaluate:1:<autosummary>:1
#: flwr.client.client_app.ClientApp.query:1 of
#, fuzzy
msgid "Return a decorator that registers the query fn with the client app."
msgstr "返回一个向客户端应用程序注册查询 fn 的装饰器。"

#: flwr.client.client_app.ClientApp.evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`train <flwr.client.ClientApp.train>`\\ \\(\\)"
msgstr "server.strategy.Strategy"

#: flwr.client.client_app.ClientApp.evaluate:1:<autosummary>:1
#: flwr.client.client_app.ClientApp.train:1 of
#, fuzzy
msgid "Return a decorator that registers the train fn with the client app."
msgstr "返回一个装饰器，用于在客户端应用程序中注册火车 fn。"

#: ../../source/ref-api/flwr.client.NumPyClient.rst:2
msgid "NumPyClient"
msgstr "NumPyClient"

#: ../../source/ref-api/flwr.client.NumPyClient.rst:44:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`evaluate <flwr.client.NumPyClient.evaluate>`\\ \\(parameters\\, "
"config\\)"
msgstr ""
":py:obj:`evaluate <flwr.client.NumPyClient.evaluate>`\\ \\(parameters\\, "
"config\\)"

#: ../../source/ref-api/flwr.client.NumPyClient.rst:44:<autosummary>:1
#, fuzzy
msgid ":py:obj:`fit <flwr.client.NumPyClient.fit>`\\ \\(parameters\\, config\\)"
msgstr ":py:obj:`fit <flwr.client.NumPyClient.fit>`\\ \\(parameters\\, config\\)"

#: ../../source/ref-api/flwr.client.NumPyClient.rst:44:<autosummary>:1
#: flwr.client.numpy_client.NumPyClient.fit:1 of
msgid "Train the provided parameters using the locally held dataset."
msgstr "使用本地数据集训练所提供的参数。"

#: ../../source/ref-api/flwr.client.NumPyClient.rst:44:<autosummary>:1
#, fuzzy
msgid ":py:obj:`get_context <flwr.client.NumPyClient.get_context>`\\ \\(\\)"
msgstr ":py:obj:`get_context <flwr.client.NumPyClient.get_context>`\\ \\(\\)"

#: ../../source/ref-api/flwr.client.NumPyClient.rst:44:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`get_parameters <flwr.client.NumPyClient.get_parameters>`\\ "
"\\(config\\)"
msgstr ""
":py:obj:`get_parameters <flwr.client.NumPyClient.get_parameters>`\\ "
"\\(config\\)"

#: ../../source/ref-api/flwr.client.NumPyClient.rst:44:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`get_properties <flwr.client.NumPyClient.get_properties>`\\ "
"\\(config\\)"
msgstr ""
":py:obj:`get_properties <flwr.client.NumPyClient.get_properties>`\\ "
"\\(config\\)"

#: ../../source/ref-api/flwr.client.NumPyClient.rst:44:<autosummary>:1
#: flwr.client.numpy_client.NumPyClient.get_properties:1 of
msgid "Return a client's set of properties."
msgstr "返回客户端的属性集。"

#: ../../source/ref-api/flwr.client.NumPyClient.rst:44:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`set_context <flwr.client.NumPyClient.set_context>`\\ "
"\\(context\\)"
msgstr ""
":py:obj:`set_context <flwr.client.NumPyClient.set_context>`\\ "
"\\(context\\)"

#: ../../source/ref-api/flwr.client.NumPyClient.rst:44:<autosummary>:1
#, fuzzy
msgid ":py:obj:`to_client <flwr.client.NumPyClient.to_client>`\\ \\(\\)"
msgstr ":py:obj:`to_client <flwr.client.NumPyClient.to_client>`\\ \\(\\)"

#: ../../source/ref-api/flwr.client.NumPyClient.rst:44:<autosummary>:1
#: flwr.client.numpy_client.NumPyClient.to_client:1 of
msgid "Convert to object to Client type and return it."
msgstr "将对象转换为客户类型并返回。"

#: flwr.client.NumPyClient.context:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`context <flwr.client.NumPyClient.context>`\\"
msgstr ":py:obj:`context <flwr.client.NumPyClient.context>`\\"

#: flwr.client.numpy_client.NumPyClient.evaluate:3
#: flwr.client.numpy_client.NumPyClient.fit:3
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_evaluate:5
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_fit:8
#: flwr.server.strategy.strategy.Strategy.configure_evaluate:5
#: flwr.server.strategy.strategy.Strategy.configure_fit:5
#: flwr.server.strategy.strategy.Strategy.evaluate:8 of
msgid "The current (global) model parameters."
msgstr "当前（全局）模型参数。"

#: flwr.client.numpy_client.NumPyClient.evaluate:5 of
msgid ""
"Configuration parameters which allow the server to influence evaluation "
"on the client. It can be used to communicate arbitrary values from the "
"server to the client, for example, to influence the number of examples "
"used for evaluation."
msgstr "允许服务器影响客户端评估的配置参数。它可用于将任意值从服务器传送到客户端，例如，影响用于评估的示例数量。"

#: flwr.client.numpy_client.NumPyClient.evaluate:11 of
msgid ""
"* **loss** (*float*) -- The evaluation loss of the model on the local "
"dataset. * **num_examples** (*int*) -- The number of examples used for "
"evaluation. * **metrics** (*Dict[str, Scalar]*) -- A dictionary mapping "
"arbitrary string keys to values of   type bool, bytes, float, int, or "
"str. It can be used to   communicate arbitrary values back to the server."
msgstr ""
"**loss** (*float*) -- 模型在本地数据集上的评估损失值。**num_examples** (*int*) -- "
"用于评估的示例数量。**metrics** (*Dict[str, Scalar]*) -- 将任意字符串键映射到 "
"bool、bytes、float、int 或 str 类型值的字典。它可用于将任意值传回服务器。"

#: flwr.client.numpy_client.NumPyClient.evaluate:11 of
msgid ""
"**loss** (*float*) -- The evaluation loss of the model on the local "
"dataset."
msgstr "**loss** (*float*) -- 模型在本地数据集上的评估损失值。"

#: flwr.client.numpy_client.NumPyClient.evaluate:12 of
msgid "**num_examples** (*int*) -- The number of examples used for evaluation."
msgstr "**num_examples** (*int*) -- 用于评估的示例数量。"

#: flwr.client.numpy_client.NumPyClient.evaluate:13
#: flwr.client.numpy_client.NumPyClient.fit:13 of
msgid ""
"**metrics** (*Dict[str, Scalar]*) -- A dictionary mapping arbitrary "
"string keys to values of type bool, bytes, float, int, or str. It can be "
"used to communicate arbitrary values back to the server."
msgstr ""
"**metrics** (*Dict[str, Scalar]*) -- 将任意字符串键映射到 bool、bytes、float、int 或 "
"str 类型值的字典。它可用于将任意值传回服务器。"

#: flwr.client.numpy_client.NumPyClient.evaluate:19 of
msgid ""
"The previous return type format (int, float, float) and the extended "
"format (int, float, float, Dict[str, Scalar]) have been deprecated and "
"removed since Flower 0.19."
msgstr ""
"自 Flower 0.19 起，之前的返回类型格式（int、float、float）和扩展格式（int、float、float、Dict[str,"
" Scalar]）已被弃用和移除。"

#: flwr.client.numpy_client.NumPyClient.fit:5 of
msgid ""
"Configuration parameters which allow the server to influence training on "
"the client. It can be used to communicate arbitrary values from the "
"server to the client, for example, to set the number of (local) training "
"epochs."
msgstr "允许服务器影响客户端训练的配置参数。它可用于将任意值从服务器传送到客户端，例如设置（本地）训练遍历数。"

#: flwr.client.numpy_client.NumPyClient.fit:11 of
msgid ""
"* **parameters** (*NDArrays*) -- The locally updated model parameters. * "
"**num_examples** (*int*) -- The number of examples used for training. * "
"**metrics** (*Dict[str, Scalar]*) -- A dictionary mapping arbitrary "
"string keys to values of type   bool, bytes, float, int, or str. It can "
"be used to communicate   arbitrary values back to the server."
msgstr ""
"**parameters** (*NDArrays*) -- 本地更新的模型参数。**num_examples** (*int*) -- "
"用于训练的示例数量。**metrics** (*Dict[str, Scalar]*) -- 将任意字符串键映射到 "
"bool、bytes、float、int 或 str 类型值的字典。它可用于将任意值传回服务器。"

#: flwr.client.numpy_client.NumPyClient.fit:11 of
msgid "**parameters** (*NDArrays*) -- The locally updated model parameters."
msgstr "**parameters** (*NDArrays*) -- 本地更新的模型参数。"

#: flwr.client.numpy_client.NumPyClient.fit:12 of
msgid "**num_examples** (*int*) -- The number of examples used for training."
msgstr "**num_examples** (*int*) -- 用于训练的数据数量。"

#: flwr.client.numpy_client.NumPyClient.get_parameters:3 of
msgid ""
"Configuration parameters requested by the server. This can be used to "
"tell the client which parameters are needed along with some Scalar "
"attributes."
msgstr "服务器请求的配置参数。这可以用来告诉客户端需要哪些参数以及一些标量属性。"

#: flwr.client.numpy_client.NumPyClient.get_parameters:8 of
msgid "**parameters** -- The local model parameters as a list of NumPy ndarrays."
msgstr "**parameters** -- NumPy ndarrays 的本地模型参数列表。"

#: flwr.client.numpy_client.NumPyClient.get_properties:3 of
msgid ""
"Configuration parameters requested by the server. This can be used to "
"tell the client which properties are needed along with some Scalar "
"attributes."
msgstr "服务器请求的配置参数。这可以用来告诉客户端需要哪些属性以及一些标量属性。"

#: flwr.client.numpy_client.NumPyClient.get_properties:8 of
msgid ""
"**properties** -- A dictionary mapping arbitrary string keys to values of"
" type bool, bytes, float, int, or str. It can be used to communicate "
"arbitrary property values back to the server."
msgstr ""
"**properties** -- 将任意字符串键映射到 bool、bytes、float、int 或 str "
"类型值的字典。它可用于将任意属性值传回服务器。"

#: ../../source/ref-api/flwr.client.mod.rst:2
#, fuzzy
msgid "mod"
msgstr "模块"

#: ../../source/ref-api/flwr.client.mod.rst:28:<autosummary>:1
msgid ""
":py:obj:`adaptiveclipping_mod <flwr.client.mod.adaptiveclipping_mod>`\\ "
"\\(msg\\, ctxt\\, call\\_next\\)"
msgstr ""

#: ../../source/ref-api/flwr.client.mod.rst:28:<autosummary>:1
#: flwr.client.mod.centraldp_mods.adaptiveclipping_mod:1 of
#, fuzzy
msgid "Client-side adaptive clipping modifier."
msgstr "客户端逻辑"

#: ../../source/ref-api/flwr.client.mod.rst:28:<autosummary>:1
msgid ""
":py:obj:`fixedclipping_mod <flwr.client.mod.fixedclipping_mod>`\\ "
"\\(msg\\, ctxt\\, call\\_next\\)"
msgstr ""

#: ../../source/ref-api/flwr.client.mod.rst:28:<autosummary>:1
#: flwr.client.mod.centraldp_mods.fixedclipping_mod:1 of
#, fuzzy
msgid "Client-side fixed clipping modifier."
msgstr "客户端逻辑"

#: ../../source/ref-api/flwr.client.mod.rst:28:<autosummary>:1
#, fuzzy
msgid ":py:obj:`make_ffn <flwr.client.mod.make_ffn>`\\ \\(ffn\\, mods\\)"
msgstr ":py:obj:`Client <flwr.client.Client>`\\ \\(\\)"

#: ../../source/ref-api/flwr.client.mod.rst:28:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`message_size_mod <flwr.client.mod.message_size_mod>`\\ \\(msg\\,"
" ctxt\\, call\\_next\\)"
msgstr ""
":py:obj:`Message <flwr.common.Message>`\\ \\(metadata\\[\\, content\\, "
"error\\]\\)"

#: ../../source/ref-api/flwr.client.mod.rst:28:<autosummary>:1
#: flwr.client.mod.comms_mods.message_size_mod:1 of
#, fuzzy
msgid "Message size mod."
msgstr "信息类型。"

#: ../../source/ref-api/flwr.client.mod.rst:28:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`parameters_size_mod <flwr.client.mod.parameters_size_mod>`\\ "
"\\(msg\\, ctxt\\, call\\_next\\)"
msgstr ""
":py:obj:`ParametersRecord <flwr.common.ParametersRecord>`\\ "
"\\(\\[array\\_dict\\, keep\\_input\\]\\)"

#: ../../source/ref-api/flwr.client.mod.rst:28:<autosummary>:1
#: flwr.client.mod.comms_mods.parameters_size_mod:1 of
#, fuzzy
msgid "Parameters size mod."
msgstr "参数"

#: ../../source/ref-api/flwr.client.mod.rst:28:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`secagg_mod <flwr.client.mod.secagg_mod>`\\ \\(msg\\, ctxt\\, "
"call\\_next\\)"
msgstr ":py:obj:`set_context <flwr.client.Client.set_context>`\\ \\(context\\)"

#: ../../source/ref-api/flwr.client.mod.rst:28:<autosummary>:1
#: flwr.client.mod.secure_aggregation.secagg_mod.secagg_mod:1 of
msgid "Handle incoming message and return results, following the SecAgg protocol."
msgstr ""

#: ../../source/ref-api/flwr.client.mod.rst:28:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`secaggplus_mod <flwr.client.mod.secaggplus_mod>`\\ \\(msg\\, "
"ctxt\\, call\\_next\\)"
msgstr ""
":py:obj:`SecAggPlusWorkflow <flwr.server.workflow.SecAggPlusWorkflow>`\\ "
"\\(num\\_shares\\, ...\\[\\, ...\\]\\)"

#: ../../source/ref-api/flwr.client.mod.rst:28:<autosummary>:1
#: flwr.client.mod.secure_aggregation.secaggplus_mod.secaggplus_mod:1 of
msgid ""
"Handle incoming message and return results, following the SecAgg+ "
"protocol."
msgstr ""

#: ../../source/ref-api/flwr.client.mod.rst:35:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`LocalDpMod <flwr.client.mod.LocalDpMod>`\\ \\(clipping\\_norm\\,"
" sensitivity\\, ...\\)"
msgstr ""
":py:obj:`ClientApp <flwr.client.ClientApp>`\\ \\(\\[client\\_fn\\, "
"mods\\]\\)"

#: ../../source/ref-api/flwr.client.mod.rst:35:<autosummary>:1
#: flwr.client.mod.localdp_mod.LocalDpMod:1 of
#, fuzzy
msgid "Modifier for local differential privacy."
msgstr "差分隐私"

#: ../../source/ref-api/flwr.client.mod.LocalDpMod.rst:2
#, fuzzy
msgid "LocalDpMod"
msgstr "本地 DP 模式"

#: flwr.client.mod.localdp_mod.LocalDpMod:3 of
msgid ""
"This mod clips the client model updates and adds noise to the params "
"before sending them to the server."
msgstr ""

#: flwr.client.mod.centraldp_mods.adaptiveclipping_mod:12
#: flwr.client.mod.centraldp_mods.fixedclipping_mod:10
#: flwr.client.mod.localdp_mod.LocalDpMod:6 of
msgid "It operates on messages of type `MessageType.TRAIN`."
msgstr ""

#: flwr.client.mod.localdp_mod.LocalDpMod:8
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping:15
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping:8
#: of
#, fuzzy
msgid "The value of the clipping norm."
msgstr "削波法线的值。"

#: flwr.client.mod.localdp_mod.LocalDpMod:10 of
msgid "The sensitivity of the client model."
msgstr ""

#: flwr.client.mod.localdp_mod.LocalDpMod:12 of
msgid ""
"The privacy budget. Smaller value of epsilon indicates a higher level of "
"privacy protection."
msgstr ""

#: flwr.client.mod.localdp_mod.LocalDpMod:15 of
msgid ""
"The failure probability. The probability that the privacy mechanism fails"
" to provide the desired level of privacy. A smaller value of delta "
"indicates a stricter privacy guarantee."
msgstr ""

#: flwr.client.mod.localdp_mod.LocalDpMod:23 of
msgid "Create an instance of the local DP mod and add it to the client-side mods:"
msgstr ""

#: ../../source/ref-api/flwr.client.mod.adaptiveclipping_mod.rst:2
msgid "adaptiveclipping\\_mod"
msgstr ""

#: flwr.client.mod.centraldp_mods.adaptiveclipping_mod:3 of
#, fuzzy
msgid ""
"This mod needs to be used with the "
"DifferentialPrivacyClientSideAdaptiveClipping server-side strategy "
"wrapper."
msgstr "用 \"DifferentialPrivacyClientSideAdaptiveClipping \"包装器对策略进行包装："

#: flwr.client.mod.centraldp_mods.adaptiveclipping_mod:6
#: flwr.client.mod.centraldp_mods.fixedclipping_mod:6 of
#, fuzzy
msgid "The wrapper sends the clipping_norm value to the client."
msgstr "向客户发送近端因子mu"

#: flwr.client.mod.centraldp_mods.adaptiveclipping_mod:8
#: flwr.client.mod.centraldp_mods.fixedclipping_mod:8 of
msgid "This mod clips the client model updates before sending them to the server."
msgstr ""

#: flwr.client.mod.centraldp_mods.adaptiveclipping_mod:10 of
msgid ""
"It also sends KEY_NORM_BIT to the server for computing the new clipping "
"value."
msgstr ""

#: flwr.client.mod.centraldp_mods.adaptiveclipping_mod:15
#: flwr.client.mod.centraldp_mods.fixedclipping_mod:13
#: flwr.server.driver.driver.Driver.send_and_receive:18
#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:54
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:61
#: of
#, fuzzy
msgid "Notes"
msgstr "无"

#: flwr.client.mod.centraldp_mods.adaptiveclipping_mod:16
#: flwr.client.mod.centraldp_mods.fixedclipping_mod:14 of
msgid "Consider the order of mods when using multiple."
msgstr ""

#: flwr.client.mod.centraldp_mods.adaptiveclipping_mod:18 of
msgid "Typically, adaptiveclipping_mod should be the last to operate on params."
msgstr ""

#: ../../source/ref-api/flwr.client.mod.fixedclipping_mod.rst:2
#, fuzzy
msgid "fixedclipping\\_mod"
msgstr "剪贴"

#: flwr.client.mod.centraldp_mods.fixedclipping_mod:3 of
#, fuzzy
msgid ""
"This mod needs to be used with the "
"DifferentialPrivacyClientSideFixedClipping server-side strategy wrapper."
msgstr "用 \"DifferentialPrivacyClientSideFixedClipping \"包装器包装策略："

#: flwr.client.mod.centraldp_mods.fixedclipping_mod:16 of
msgid "Typically, fixedclipping_mod should be the last to operate on params."
msgstr ""

#: ../../source/ref-api/flwr.client.mod.make_ffn.rst:2
msgid "make\\_ffn"
msgstr ""

#: flwr.client.mod.utils.make_ffn:1 of
msgid "."
msgstr ""

#: ../../source/ref-api/flwr.client.mod.message_size_mod.rst:2
msgid "message\\_size\\_mod"
msgstr ""

#: flwr.client.mod.comms_mods.message_size_mod:3 of
msgid "This mod logs the size in bytes of the message being transmited."
msgstr ""

#: ../../source/ref-api/flwr.client.mod.parameters_size_mod.rst:2
#, fuzzy
msgid "parameters\\_size\\_mod"
msgstr "参数"

#: flwr.client.mod.comms_mods.parameters_size_mod:3 of
msgid ""
"This mod logs the number of parameters transmitted in the message as well"
" as their size in bytes."
msgstr ""

#: ../../source/ref-api/flwr.client.mod.secagg_mod.rst:2
msgid "secagg\\_mod"
msgstr ""

#: ../../source/ref-api/flwr.client.mod.secaggplus_mod.rst:2
#, fuzzy
msgid "secaggplus\\_mod"
msgstr "工作流程"

#: ../../source/ref-api/flwr.client.run_client_app.rst:2
#, fuzzy
msgid "run\\_client\\_app"
msgstr "客户端"

#: ../../source/ref-api/flwr.client.run_supernode.rst:2
#, fuzzy
msgid "run\\_supernode"
msgstr "flower-superlink"

#: ../../source/ref-api/flwr.client.start_client.rst:2
#, fuzzy
msgid "start\\_client"
msgstr "启动客户端"

#: flwr.client.app.start_client:5 of
msgid ""
"This function is deprecated since 1.13.0. Use :code:`flower-supernode` "
"command instead to start a SuperNode."
msgstr ""

#: flwr.client.app.start_client:8 flwr.client.app.start_numpy_client:9 of
msgid ""
"The IPv4 or IPv6 address of the server. If the Flower server runs on the "
"same machine on port 8080, then `server_address` would be "
"`\"[::]:8080\"`."
msgstr ""
"服务器的 IPv4 或 IPv6 地址：如果 Flower 服务器在同一台机器上运行，端口为 "
"8080，则`server_address`应为`\"[::]:8080\"`。"

#: flwr.client.app.start_client:12 of
msgid "A callable that instantiates a Client. (default: None)"
msgstr "用于实例化客户端的可调用程序。(默认值：无）"

#: flwr.client.app.start_client:14 of
msgid ""
"An implementation of the abstract base class `flwr.client.Client` "
"(default: None)"
msgstr "抽象基类 `flwr.client.Client` 的实现（默认值：无）"

#: flwr.client.app.start_client:17 flwr.client.app.start_numpy_client:15 of
msgid ""
"The maximum length of gRPC messages that can be exchanged with the Flower"
" server. The default should be sufficient for most models. Users who "
"train very large models might need to increase this value. Note that the "
"Flower server needs to be started with the same value (see "
"`flwr.server.start_server`), otherwise it will not know about the "
"increased limit and block larger messages."
msgstr ""
"可与 Flower 服务器交换的 gRPC 信息的最大长度：默认值对大多数模型都足够了。训练超大模型的用户可能需要增加该值。请注意，Flower "
"服务器需要以相同的值启动（请参阅 `flwr.server.start_server`），否则它将不知道增加的限制并阻止更大的消息。"

#: flwr.client.app.start_client:24 flwr.client.app.start_numpy_client:22 of
msgid ""
"The PEM-encoded root certificates as a byte string or a path string. If "
"provided, a secure connection using the certificates will be established "
"to an SSL-enabled Flower server."
msgstr "字节字符串或路径字符串形式的 PEM 编码根证书。如果提供，将使用这些证书与启用 SSL 的 Flower 服务器建立安全连接。"

#: flwr.client.app.start_client:28 flwr.client.app.start_numpy_client:26 of
#, fuzzy
msgid ""
"Starts an insecure gRPC connection when True. Enables HTTPS connection "
"when False, using system certificates if `root_certificates` is None."
msgstr ""
"为 True 时启动不安全的 gRPC 连接。False 时启用 HTTPS 连接，如果 `root_certificates` 为 "
"None，则使用系统证书。"

#: flwr.client.app.start_client:31 flwr.client.app.start_numpy_client:29 of
msgid ""
"Configure the transport layer. Allowed values: - 'grpc-bidi': gRPC, "
"bidirectional streaming - 'grpc-rere': gRPC, request-response "
"(experimental) - 'rest': HTTP (experimental)"
msgstr ""
"配置传输层：允许的值包括 - 'grpc-bidi': gRPC，双向流 - 'grpc-rere': gRPC，请求-响应（实验性） - "
"'rest': HTTP（实验性）"

#: flwr.client.app.start_client:36 of
msgid ""
"Tuple containing the elliptic curve private key and public key for "
"authentication from the cryptography library. Source: "
"https://cryptography.io/en/latest/hazmat/primitives/asymmetric/ec/ Used "
"to establish an authenticated connection with the server."
msgstr ""

#: flwr.client.app.start_client:41 of
#, fuzzy
msgid ""
"The maximum number of times the client will try to connect to the server "
"before giving up in case of a connection error. If set to None, there is "
"no limit to the number of tries."
msgstr "客户端在出现连接错误时放弃连接服务器的最大尝试次数。如果设置为 \"无\"，则不限制尝试次数。"

#: flwr.client.app.start_client:45 of
#, fuzzy
msgid ""
"The maximum duration before the client stops trying to connect to the "
"server in case of connection error. If set to None, there is no limit to "
"the total time."
msgstr "在出现连接错误时，客户端停止尝试连接服务器之前的最长持续时间。如果设置为 \"无\"，则总时间没有限制。"

#: flwr.client.app.start_client:52 flwr.client.app.start_numpy_client:37 of
msgid "Starting a gRPC client with an insecure server connection:"
msgstr "使用不安全的服务器连接启动 gRPC 客户端："

#: flwr.client.app.start_client:59 flwr.client.app.start_numpy_client:44 of
#, fuzzy
msgid "Starting an SSL-enabled gRPC client using system certificates:"
msgstr "启动支持 SSL 的 gRPC 客户端："

#: flwr.client.app.start_client:70 flwr.client.app.start_numpy_client:52 of
#, fuzzy
msgid "Starting an SSL-enabled gRPC client using provided certificates:"
msgstr "启动支持 SSL 的 gRPC 客户端："

#: ../../source/ref-api/flwr.client.start_numpy_client.rst:2
#, fuzzy
msgid "start\\_numpy\\_client"
msgstr "start_numpy_client"

#: flwr.client.app.start_numpy_client:5 of
#, fuzzy
msgid ""
"This function is deprecated since 1.7.0. Use "
":code:`flwr.client.start_client` instead and first convert your "
":code:`NumPyClient` to type :code:`flwr.client.Client` by executing its "
":code:`to_client()` method."
msgstr ""
"自 1.7.0 起该函数已被弃用。请使用 :code:`flwr.client.start_client`，并首先通过执行 "
":code:`to_client()`方法将 :code:`NumPyClient`转换为 :code:`flwr.client.Client`。"

#: flwr.client.app.start_numpy_client:13 of
msgid "An implementation of the abstract base class `flwr.client.NumPyClient`."
msgstr "抽象基类 `flwr.client.NumPyClient` 的实现。"

#: ../../source/ref-api/flwr.common.rst:2
msgid "common"
msgstr "常见"

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
#, fuzzy
msgid ":py:obj:`array_from_numpy <flwr.common.array_from_numpy>`\\ \\(ndarray\\)"
msgstr ":py:obj:`array_from_numpy <flwr.common.array_from_numpy>`\\ \\(ndarray\\)"

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
#: flwr.common.record.conversion_utils.array_from_numpy:1 of
#, fuzzy
msgid "Create Array from NumPy ndarray."
msgstr "将参数对象转换为 NumPy ndarrays。"

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
#, fuzzy
msgid ":py:obj:`bytes_to_ndarray <flwr.common.bytes_to_ndarray>`\\ \\(tensor\\)"
msgstr ":py:obj:`bytes_to_ndarray <flwr.common.bytes_to_ndarray>`\\ \\(tensor\\)"

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
#: flwr.common.parameter.bytes_to_ndarray:1 of
msgid "Deserialize NumPy ndarray from bytes."
msgstr "从字节反序列化 NumPy ndarray。"

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`configure <flwr.common.configure>`\\ \\(identifier\\[\\, "
"filename\\, host\\]\\)"
msgstr ""
":py:obj:`configure <flwr.common.configure>`\\ \\(identifier\\[\\, "
"filename\\, host\\]\\)"

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
#: flwr.common.logger.configure:1 of
msgid "Configure logging to file and/or remote log server."
msgstr "配置将日志记录到文件和/或远程日志服务器。"

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`event <flwr.common.event>`\\ \\(event\\_type\\[\\, "
"event\\_details\\]\\)"
msgstr ""
":py:obj:`event <flwr.common.event>`\\ \\(event\\_type\\[\\, "
"event\\_details\\]\\)"

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
#: flwr.common.telemetry.event:1 of
#, fuzzy
msgid "Submit create_event to ThreadPoolExecutor to avoid blocking."
msgstr "将 create_event 提交给 ThreadPoolExecutor 以避免阻塞。"

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`log <flwr.common.log>`\\ \\(level\\, msg\\, \\*args\\, "
"\\*\\*kwargs\\)"
msgstr ""
":py:obj:`log <flwr.common.log>`\\ \\(level\\, msg\\, \\*args\\, "
"\\*\\*kwargs\\)"

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1 logging.Logger.log:1
#: of
msgid "Log 'msg % args' with the integer severity 'level'."
msgstr "以整数严重性 \"级别 \"记录 \"msg % args\"。"

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
#, fuzzy
msgid ":py:obj:`ndarray_to_bytes <flwr.common.ndarray_to_bytes>`\\ \\(ndarray\\)"
msgstr ":py:obj:`ndarray_to_bytes <flwr.common.ndarray_to_bytes>`\\ \\(ndarray\\)"

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
#: flwr.common.parameter.ndarray_to_bytes:1 of
msgid "Serialize NumPy ndarray to bytes."
msgstr "将 NumPy ndarray 序列化为字节。"

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`ndarrays_to_parameters <flwr.common.ndarrays_to_parameters>`\\ "
"\\(ndarrays\\)"
msgstr ""
":py:obj:`ndarrays_to_parameters <flwr.common.ndarrays_to_parameters>`\\ "
"\\(ndarrays\\)"

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
#: flwr.common.parameter.ndarrays_to_parameters:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.ndarrays_to_parameters:1
#: of
msgid "Convert NumPy ndarrays to parameters object."
msgstr "将 NumPy ndarrays 转换为参数对象。"

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
#, fuzzy
msgid ":py:obj:`now <flwr.common.now>`\\ \\(\\)"
msgstr ":py:obj:`now <flwr.common.now>`\\ \\(\\)"

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
#: flwr.common.date.now:1 of
msgid "Construct a datetime from time.time() with time zone set to UTC."
msgstr "从 time.time() 生成日期时间，时区设置为 UTC。"

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`parameters_to_ndarrays <flwr.common.parameters_to_ndarrays>`\\ "
"\\(parameters\\)"
msgstr ""
":py:obj:`parameters_to_ndarrays <flwr.common.parameters_to_ndarrays>`\\ "
"\\(parameters\\)"

#: ../../source/ref-api/flwr.common.rst:30:<autosummary>:1
#: flwr.common.parameter.parameters_to_ndarrays:1 of
msgid "Convert parameters object to NumPy ndarrays."
msgstr "将参数对象转换为 NumPy ndarrays。"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`Array <flwr.common.Array>`\\ \\(dtype\\, shape\\, stype\\, "
"data\\)"
msgstr ""
":py:obj:`Array <flwr.common.Array>`\\ \\(dtype\\, shape\\, stype\\, "
"data\\)"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.record.parametersrecord.Array:1 of
#, fuzzy
msgid "Array type."
msgstr "返回类型"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`ClientMessage <flwr.common.ClientMessage>`\\ "
"\\(\\[get\\_properties\\_res\\, ...\\]\\)"
msgstr ""
":py:obj:`ClientMessage <flwr.common.ClientMessage>`\\ "
"\\(\\[get\\_properties\\_res\\, ...\\]\\)"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.typing.ClientMessage:1 of
msgid "ClientMessage is a container used to hold one result message."
msgstr "ClientMessage 是用于容纳一条结果信息的容器。"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ":py:obj:`Code <flwr.common.Code>`\\ \\(value\\)"
msgstr ":py:obj:`Code <flwr.common.Code>`\\ \\(value\\)"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.typing.Code:1 of
msgid "Client status codes."
msgstr "客户端状态代码。"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ":py:obj:`Config <flwr.common.Config>`\\"
msgstr ":py:obj:`config <flwr.common.FitIns.config>`\\"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ""
"alias of :py:class:`dict`\\ [:py:class:`str`, :py:class:`bool` | "
":py:class:`bytes` | :py:class:`float` | :py:class:`int` | "
":py:class:`str`]"
msgstr ""
"Bases: :py:class:`~flwr.common.record.typeddict.TypedDict`\\ "
"[:py:class:`str`, :py:obj:`~typing.Union`\\ [:py:class:`int`, "
":py:class:`float`, :py:class:`~typing.List`\\ [:py:class:`int`], "
":py:class:`~typing.List`\\ [:py:class:`float`]]]"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`ConfigsRecord <flwr.common.ConfigsRecord>`\\ "
"\\(\\[configs\\_dict\\, keep\\_input\\]\\)"
msgstr ""
"Flower 1.0: ``start_server(..., "
"config=flwr.server.ServerConfig(num_rounds=3, round_timeout=600.0), "
"...)``"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.record.configsrecord.ConfigsRecord:1 of
#, fuzzy
msgid "Configs record."
msgstr "配置日志记录"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`Context <flwr.common.Context>`\\ \\(run\\_id\\, node\\_id\\, "
"node\\_config\\, state\\, ...\\)"
msgstr ":py:obj:`Context <flwr.common.Context>`\\ \\(state\\)"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.context.Context:1 of
#, fuzzy
msgid "Context of your run."
msgstr "您的运行状态。"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ":py:obj:`DisconnectRes <flwr.common.DisconnectRes>`\\ \\(reason\\)"
msgstr ":py:obj:`DisconnectRes <flwr.common.DisconnectRes>`\\ \\(reason\\)"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.typing.DisconnectRes:1 of
msgid "DisconnectRes message from client to server."
msgstr "客户端向服务器发送 DisconnectRes 信息。"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ":py:obj:`Error <flwr.common.Error>`\\ \\(code\\[\\, reason\\]\\)"
msgstr ":py:obj:`Error <flwr.common.Error>`\\ \\(code\\[\\, reason\\]\\)"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.message.Error:1 of
#, fuzzy
msgid "A dataclass that stores information about an error that occurred."
msgstr "数据类，用于存储所发生错误的相关信息。"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`EvaluateIns <flwr.common.EvaluateIns>`\\ \\(parameters\\, "
"config\\)"
msgstr ""
":py:obj:`EvaluateIns <flwr.common.EvaluateIns>`\\ \\(parameters\\, "
"config\\)"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.typing.EvaluateIns:1 of
msgid "Evaluate instructions for a client."
msgstr "评估客户端的指示。"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`EvaluateRes <flwr.common.EvaluateRes>`\\ \\(status\\, loss\\, "
"num\\_examples\\, metrics\\)"
msgstr ""
":py:obj:`EvaluateRes <flwr.common.EvaluateRes>`\\ \\(status\\, loss\\, "
"num\\_examples\\, metrics\\)"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.typing.EvaluateRes:1 of
msgid "Evaluate response from a client."
msgstr "评估客户端的反应。"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ":py:obj:`EventType <flwr.common.EventType>`\\ \\(value\\)"
msgstr ":py:obj:`EventType <flwr.common.EventType>`\\ \\(value\\)"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.telemetry.EventType:1 of
msgid "Types of telemetry events."
msgstr "遥测事件类型。"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ":py:obj:`FitIns <flwr.common.FitIns>`\\ \\(parameters\\, config\\)"
msgstr ":py:obj:`FitIns <flwr.common.FitIns>`\\ \\(parameters\\, config\\)"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.typing.FitIns:1 of
msgid "Fit instructions for a client."
msgstr "为客户提供安装说明。"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`FitRes <flwr.common.FitRes>`\\ \\(status\\, parameters\\, "
"num\\_examples\\, metrics\\)"
msgstr ""
":py:obj:`FitRes <flwr.common.FitRes>`\\ \\(status\\, parameters\\, "
"num\\_examples\\, metrics\\)"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.typing.FitRes:1 of
msgid "Fit response from a client."
msgstr "来自客户端的合适回复。"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ":py:obj:`GetParametersIns <flwr.common.GetParametersIns>`\\ \\(config\\)"
msgstr ":py:obj:`GetParametersIns <flwr.common.GetParametersIns>`\\ \\(config\\)"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.typing.GetParametersIns:1 of
msgid "Parameters request for a client."
msgstr "客户端的参数请求。"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`GetParametersRes <flwr.common.GetParametersRes>`\\ \\(status\\, "
"parameters\\)"
msgstr ""
":py:obj:`GetParametersRes <flwr.common.GetParametersRes>`\\ \\(status\\, "
"parameters\\)"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.typing.GetParametersRes:1 of
msgid "Response when asked to return parameters."
msgstr "要求返回参数时的响应。"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ":py:obj:`GetPropertiesIns <flwr.common.GetPropertiesIns>`\\ \\(config\\)"
msgstr ":py:obj:`GetPropertiesIns <flwr.common.GetPropertiesIns>`\\ \\(config\\)"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.typing.GetPropertiesIns:1 of
msgid "Properties request for a client."
msgstr "客户端的属性请求。"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`GetPropertiesRes <flwr.common.GetPropertiesRes>`\\ \\(status\\, "
"properties\\)"
msgstr ""
":py:obj:`GetPropertiesRes <flwr.common.GetPropertiesRes>`\\ \\(status\\, "
"properties\\)"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.typing.GetPropertiesRes:1 of
msgid "Properties response from a client."
msgstr "来自客户端的属性响应。"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`Message <flwr.common.Message>`\\ \\(metadata\\[\\, content\\, "
"error\\]\\)"
msgstr ""
":py:obj:`Message <flwr.common.Message>`\\ \\(metadata\\[\\, content\\, "
"error\\]\\)"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.message.Message:1 of
#, fuzzy
msgid "State of your application from the viewpoint of the entity using it."
msgstr "从使用实体的角度看应用程序的状态。"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ":py:obj:`MessageType <flwr.common.MessageType>`\\ \\(\\)"
msgstr ":py:obj:`MessageType <flwr.common.MessageType>`\\ \\(\\)"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.constant.MessageType:1 of
#, fuzzy
msgid "Message type."
msgstr "信息类型。"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ":py:obj:`MessageTypeLegacy <flwr.common.MessageTypeLegacy>`\\ \\(\\)"
msgstr ":py:obj:`MessageTypeLegacy <flwr.common.MessageTypeLegacy>`\\ \\(\\)"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.constant.MessageTypeLegacy:1 of
#, fuzzy
msgid "Legacy message type."
msgstr "传统信息类型。"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`Metadata <flwr.common.Metadata>`\\ \\(run\\_id\\, "
"message\\_id\\, src\\_node\\_id\\, ...\\)"
msgstr ""
":py:obj:`Metadata <flwr.common.Metadata>`\\ \\(run\\_id\\, "
"message\\_id\\, src\\_node\\_id\\, ...\\)"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.message.Metadata:1 of
#, fuzzy
msgid "A dataclass holding metadata associated with the current message."
msgstr "数据类型，包含与当前报文相关的元数据。"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ":py:obj:`Metrics <flwr.common.Metrics>`\\"
msgstr ":py:obj:`metrics <flwr.common.FitRes.metrics>`\\"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`MetricsRecord <flwr.common.MetricsRecord>`\\ "
"\\(\\[metrics\\_dict\\, keep\\_input\\]\\)"
msgstr ""
":py:obj:`MetricsRecord <flwr.common.MetricsRecord>`\\ "
"\\(\\[metrics\\_dict\\, keep\\_input\\]\\)"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.record.metricsrecord.MetricsRecord:1 of
#, fuzzy
msgid "Metrics recod."
msgstr "指标记录。"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ":py:obj:`NDArray <flwr.common.NDArray>`\\"
msgstr ":py:obj:`NDArray <flwr.common.NDArray>`\\"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ""
"alias of :py:class:`~numpy.ndarray`\\ [:py:obj:`~typing.Any`, "
":py:class:`~numpy.dtype`\\ [:py:obj:`~typing.Any`]]"
msgstr ""
"alias of :py:class:`~numpy.ndarray`\\ [:py:obj:`~typing.Any`, "
":py:class:`~numpy.dtype`\\ [:py:obj:`~typing.Any`]]"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ":py:obj:`NDArrays <flwr.common.NDArrays>`\\"
msgstr ":py:obj:`NDArray <flwr.common.NDArray>`\\"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ""
"alias of :py:class:`list`\\ [:py:class:`~numpy.ndarray`\\ "
"[:py:obj:`~typing.Any`, :py:class:`~numpy.dtype`\\ "
"[:py:obj:`~typing.Any`]]]"
msgstr ""
"alias of :py:class:`~numpy.ndarray`\\ [:py:obj:`~typing.Any`, "
":py:class:`~numpy.dtype`\\ [:py:obj:`~typing.Any`]]"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`Parameters <flwr.common.Parameters>`\\ \\(tensors\\, "
"tensor\\_type\\)"
msgstr ""
":py:obj:`Parameters <flwr.common.Parameters>`\\ \\(tensors\\, "
"tensor\\_type\\)"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.typing.Parameters:1 of
msgid "Model parameters."
msgstr "模型参数。"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`ParametersRecord <flwr.common.ParametersRecord>`\\ "
"\\(\\[array\\_dict\\, keep\\_input\\]\\)"
msgstr ""
":py:obj:`ParametersRecord <flwr.common.ParametersRecord>`\\ "
"\\(\\[array\\_dict\\, keep\\_input\\]\\)"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.record.parametersrecord.ParametersRecord:1 of
#, fuzzy
msgid "Parameters record."
msgstr "参数"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ":py:obj:`Properties <flwr.common.Properties>`\\"
msgstr ":py:obj:`properties <flwr.common.GetPropertiesRes.properties>`\\"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ":py:obj:`ReconnectIns <flwr.common.ReconnectIns>`\\ \\(seconds\\)"
msgstr ":py:obj:`ReconnectIns <flwr.common.ReconnectIns>`\\ \\(seconds\\)"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.typing.ReconnectIns:1 of
msgid "ReconnectIns message from server to client."
msgstr "服务器发送给客户端的重新连接信息。"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`RecordSet <flwr.common.RecordSet>`\\ "
"\\(\\[parameters\\_records\\, ...\\]\\)"
msgstr ""
":py:obj:`RecordSet <flwr.common.RecordSet>`\\ "
"\\(\\[parameters\\_records\\, ...\\]\\)"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.record.recordset.RecordSet:1 of
#, fuzzy
msgid "RecordSet stores groups of parameters, metrics and configs."
msgstr "RecordSet 可存储参数、指标和配置组。"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`ServerMessage <flwr.common.ServerMessage>`\\ "
"\\(\\[get\\_properties\\_ins\\, ...\\]\\)"
msgstr ""
":py:obj:`ServerMessage <flwr.common.ServerMessage>`\\ "
"\\(\\[get\\_properties\\_ins\\, ...\\]\\)"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.typing.ServerMessage:1 of
msgid "ServerMessage is a container used to hold one instruction message."
msgstr "ServerMessage 是用于容纳一条指令信息的容器。"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#, fuzzy
msgid ":py:obj:`Status <flwr.common.Status>`\\ \\(code\\, message\\)"
msgstr ":py:obj:`Status <flwr.common.Status>`\\ \\(code\\, message\\)"

#: ../../source/ref-api/flwr.common.rst:68:<autosummary>:1
#: flwr.common.typing.Status:1 of
msgid "Client status."
msgstr "客户端状态。"

#: ../../source/ref-api/flwr.common.Array.rst:2
#, fuzzy
msgid "Array"
msgstr "数组"

#: flwr.common.record.parametersrecord.Array:3 of
#, fuzzy
msgid ""
"A dataclass containing serialized data from an array-like or tensor-like "
"object along with some metadata about it."
msgstr "数据类，包含数组类或张量类对象的序列化数据以及相关元数据。"

#: flwr.common.record.parametersrecord.Array:6 of
#, fuzzy
msgid ""
"A string representing the data type of the serialised object (e.g. "
"`np.float32`)"
msgstr "表示序列化对象数据类型的字符串（例如 `np.float32`)"

#: flwr.common.record.parametersrecord.Array:8 of
#, fuzzy
msgid ""
"A list representing the shape of the unserialized array-like object. This"
" is used to deserialize the data (depending on the serialization method) "
"or simply as a metadata field."
msgstr "代表未序列化数组对象形状的列表。它可用于反序列化数据（取决于序列化方法），或仅作为元数据字段使用。"

#: flwr.common.record.parametersrecord.Array:12 of
#, fuzzy
msgid ""
"A string indicating the type of serialisation mechanism used to generate "
"the bytes in `data` from an array-like or tensor-like object."
msgstr "表示序列化机制类型的字符串，用于从类似数组或类似张量的对象中生成 `data` 中的字节。"

#: flwr.common.record.parametersrecord.Array:15 of
#, fuzzy
msgid "A buffer of bytes containing the data."
msgstr "包含数据的字节缓冲区。"

#: ../../source/ref-api/flwr.common.Array.rst:26:<autosummary>:1
#, fuzzy
msgid ":py:obj:`numpy <flwr.common.Array.numpy>`\\ \\(\\)"
msgstr "server.strategy.Strategy"

#: ../../source/ref-api/flwr.common.Array.rst:26:<autosummary>:1
#: flwr.common.record.parametersrecord.Array.numpy:1 of
#, fuzzy
msgid "Return the array as a NumPy array."
msgstr "以 NumPy ndarrays 列表形式返回模型参数"

#: flwr.common.record.parametersrecord.Array.numpy:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`dtype <flwr.common.Array.dtype>`\\"
msgstr ":py:obj:`dtype <flwr.common.Array.dtype>`\\"

#: flwr.common.record.parametersrecord.Array.numpy:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`shape <flwr.common.Array.shape>`\\"
msgstr "server.strategy.Strategy"

#: flwr.common.record.parametersrecord.Array.numpy:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`stype <flwr.common.Array.stype>`\\"
msgstr "server.strategy.Strategy"

#: flwr.common.record.parametersrecord.Array.numpy:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`data <flwr.common.Array.data>`\\"
msgstr ":py:obj:`data <flwr.common.Array.data>`\\"

#: ../../source/ref-api/flwr.common.ClientMessage.rst:2
#, fuzzy
msgid "ClientMessage"
msgstr "客户端"

#: ../../source/ref-api/flwr.common.ClientMessage.rst:31:<autosummary>:1
#, fuzzy
msgid ":py:obj:`evaluate_res <flwr.common.ClientMessage.evaluate_res>`\\"
msgstr ":py:obj:`evaluate_res <flwr.common.ClientMessage.evaluate_res>`\\"

#: ../../source/ref-api/flwr.common.ClientMessage.rst:31:<autosummary>:1
#, fuzzy
msgid ":py:obj:`fit_res <flwr.common.ClientMessage.fit_res>`\\"
msgstr ":py:obj:`fit_res <flwr.common.ClientMessage.fit_res>`\\"

#: ../../source/ref-api/flwr.common.ClientMessage.rst:31:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`get_parameters_res "
"<flwr.common.ClientMessage.get_parameters_res>`\\"
msgstr ""
":py:obj:`get_parameters_res "
"<flwr.common.ClientMessage.get_parameters_res>`\\"

#: ../../source/ref-api/flwr.common.ClientMessage.rst:31:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`get_properties_res "
"<flwr.common.ClientMessage.get_properties_res>`\\"
msgstr ""
":py:obj:`get_properties_res "
"<flwr.common.ClientMessage.get_properties_res>`\\"

#: ../../source/ref-api/flwr.common.Code.rst:2
#, fuzzy
msgid "Code"
msgstr "代码"

#: flwr.common.typing.Code:1 of
#, fuzzy
msgid "Bases: :py:class:`~enum.Enum`"
msgstr "Bases: :py:class:`~enum.Enum`"

#: ../../source/ref-api/flwr.common.Code.rst:26:<autosummary>:1
#, fuzzy
msgid ":py:obj:`OK <flwr.common.Code.OK>`\\"
msgstr ":py:obj:`OK <flwr.common.Code.OK>`\\"

#: ../../source/ref-api/flwr.common.Code.rst:26:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`GET_PROPERTIES_NOT_IMPLEMENTED "
"<flwr.common.Code.GET_PROPERTIES_NOT_IMPLEMENTED>`\\"
msgstr ""
":py:obj:`GET_PROPERTIES_NOT_IMPLEMENTED "
"<flwr.common.Code.GET_PROPERTIES_NOT_IMPLEMENTED>`\\"

#: ../../source/ref-api/flwr.common.Code.rst:26:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`GET_PARAMETERS_NOT_IMPLEMENTED "
"<flwr.common.Code.GET_PARAMETERS_NOT_IMPLEMENTED>`\\"
msgstr ""
":py:obj:`GET_PARAMETERS_NOT_IMPLEMENTED "
"<flwr.common.Code.GET_PARAMETERS_NOT_IMPLEMENTED>`\\"

#: ../../source/ref-api/flwr.common.Code.rst:26:<autosummary>:1
#, fuzzy
msgid ":py:obj:`FIT_NOT_IMPLEMENTED <flwr.common.Code.FIT_NOT_IMPLEMENTED>`\\"
msgstr ":py:obj:`FIT_NOT_IMPLEMENTED <flwr.common.Code.FIT_NOT_IMPLEMENTED>`\\"

#: ../../source/ref-api/flwr.common.Code.rst:26:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`EVALUATE_NOT_IMPLEMENTED "
"<flwr.common.Code.EVALUATE_NOT_IMPLEMENTED>`\\"
msgstr ""
":py:obj:`EVALUATE_NOT_IMPLEMENTED "
"<flwr.common.Code.EVALUATE_NOT_IMPLEMENTED>`\\"

#: ../../source/ref-api/flwr.common.Config.rst:2
#, fuzzy
msgid "Config"
msgstr "配置日志记录"

#: ../../source/ref-api/flwr.common.ConfigsRecord.rst:2
#, fuzzy
msgid "ConfigsRecord"
msgstr "配置日志记录"

#: flwr.common.record.configsrecord.ConfigsRecord:1 of
#, fuzzy
msgid ""
"Bases: :py:class:`~flwr.common.record.typeddict.TypedDict`\\ "
"[:py:class:`str`, :py:class:`int` | :py:class:`float` | :py:class:`str` |"
" :py:class:`bytes` | :py:class:`bool` | :py:class:`list`\\ "
"[:py:class:`int`] | :py:class:`list`\\ [:py:class:`float`] | "
":py:class:`list`\\ [:py:class:`str`] | :py:class:`list`\\ "
"[:py:class:`bytes`] | :py:class:`list`\\ [:py:class:`bool`]]"
msgstr ""
"Bases: :py:class:`~flwr.common.record.typeddict.TypedDict`\\ "
"[:py:class:`str`, :py:obj:`~typing.Union`\\ [:py:class:`int`, "
":py:class:`float`, :py:class:`str`, :py:class:`bytes`, :py:class:`bool`, "
":py:class:`~typing.List`\\ [:py:class:`int`], :py:class:`~typing.List`\\ "
"[:py:class:`float`], :py:class:`~typing.List`\\ [:py:class:`str`], "
":py:class:`~typing.List`\\ [:py:class:`bytes`], "
":py:class:`~typing.List`\\ [:py:class:`bool`]]]"

#: flwr.common.record.configsrecord.ConfigsRecord:3 of
msgid ""
"A :code:`ConfigsRecord` is a Python dictionary designed to ensure that "
"each key-value pair adheres to specified data types. A "
":code:`ConfigsRecord` is one of the types of records that a "
"`flwr.common.RecordSet <flwr.common.RecordSet.html#recordset>`_ supports "
"and can therefore be used to construct :code:`common.Message` objects."
msgstr ""

#: flwr.common.record.configsrecord.ConfigsRecord:9 of
msgid ""
"A dictionary that stores basic types (i.e. `str`, `int`, `float`, `bytes`"
" as defined in `ConfigsScalar`) and lists of such types (see "
"`ConfigsScalarList`)."
msgstr ""

#: flwr.common.record.configsrecord.ConfigsRecord:13 of
msgid ""
"A boolean indicating whether config passed should be deleted from the "
"input dictionary immediately after adding them to the record. When set to"
" True, the data is duplicated in memory. If memory is a concern, set it "
"to False."
msgstr ""

#: flwr.common.record.configsrecord.ConfigsRecord:21 of
msgid ""
"The usage of a :code:`ConfigsRecord` is envisioned for sending "
"configuration values telling the target node how to perform a certain "
"action (e.g. train/evaluate a model ). You can use standard Python built-"
"in types such as :code:`float`, :code:`str` , :code:`bytes`. All types "
"allowed are defined in :code:`flwr.common.ConfigsRecordValues`. While "
"lists are supported, we encourage you to use a :code:`ParametersRecord` "
"instead if these are of high dimensionality."
msgstr ""

#: flwr.common.record.configsrecord.ConfigsRecord:29 of
msgid ""
"Let's see some examples of how to construct a :code:`ConfigsRecord` from "
"scratch:"
msgstr ""

#: flwr.common.record.configsrecord.ConfigsRecord:42 of
msgid ""
"Just like the other types of records in a :code:`flwr.common.RecordSet`, "
"types are enforced. If you need to add a custom data structure or object,"
" we recommend to serialise it into bytes and save it as such (bytes are "
"allowed in a :code:`ConfigsRecord`)"
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`clear <flwr.common.ConfigsRecord.clear>`\\ \\(\\)"
msgstr ":py:obj:`clear <flwr.common.ConfigsRecord.clear>`\\ \\(\\)"

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`count_bytes <flwr.common.ConfigsRecord.count_bytes>`\\ \\(\\)"
msgstr ":py:obj:`count_bytes <flwr.common.ConfigsRecord.count_bytes>`\\ \\(\\)"

#: collections.abc.MutableMapping.clear:1:<autosummary>:1
#: flwr.common.record.configsrecord.ConfigsRecord.count_bytes:1
#: flwr.common.record.metricsrecord.MetricsRecord.count_bytes:1
#: flwr.common.record.parametersrecord.ParametersRecord.count_bytes:1 of
#, fuzzy
msgid "Return number of Bytes stored in this object."
msgstr "返回存储在此对象中的字节数。"

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`get <flwr.common.ConfigsRecord.get>`\\ \\(key\\[\\, default\\]\\)"
msgstr ":py:obj:`get <flwr.common.ConfigsRecord.get>`\\ \\(k\\[\\,d\\]\\)"

#: collections.abc.Mapping.get:1
#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
msgid "Retrieve the corresponding layout by the string key."
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`items <flwr.common.ConfigsRecord.items>`\\ \\(\\)"
msgstr ":py:obj:`items <flwr.common.ConfigsRecord.items>`\\ \\(\\)"

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`keys <flwr.common.ConfigsRecord.keys>`\\ \\(\\)"
msgstr ":py:obj:`keys <flwr.common.ConfigsRecord.keys>`\\ \\(\\)"

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`pop <flwr.common.ConfigsRecord.pop>`\\ \\(k\\[\\,d\\]\\)"
msgstr ":py:obj:`pop <flwr.common.ConfigsRecord.pop>`\\ \\(k\\[\\,d\\]\\)"

#: collections.abc.MutableMapping.clear:1:<autosummary>:1
#: collections.abc.MutableMapping.pop:1 of
#, fuzzy
msgid "If key is not found, d is returned if given, otherwise KeyError is raised."
msgstr "如果未找到 key，则返回 d（如果给定），否则引发 KeyError。"

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`popitem <flwr.common.ConfigsRecord.popitem>`\\ \\(\\)"
msgstr ":py:obj:`items <flwr.common.ConfigsRecord.items>`\\ \\(\\)"

#: collections.abc.MutableMapping.clear:1:<autosummary>:1
#: collections.abc.MutableMapping.popitem:1 of
msgid "as a 2-tuple; but raise KeyError if D is empty."
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`setdefault <flwr.common.ConfigsRecord.setdefault>`\\ "
"\\(k\\[\\,d\\]\\)"
msgstr ":py:obj:`get <flwr.common.ConfigsRecord.get>`\\ \\(k\\[\\,d\\]\\)"

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`update <flwr.common.ConfigsRecord.update>`\\ \\(\\[E\\, "
"\\]\\*\\*F\\)"
msgstr ""
":py:obj:`update <flwr.common.ConfigsRecord.update>`\\ \\(\\[E\\, "
"\\]\\*\\*F\\)"

#: collections.abc.MutableMapping.clear:1:<autosummary>:1
#: collections.abc.MutableMapping.update:1 of
msgid ""
"If E present and has a .keys() method, does:     for k in E: D[k] = E[k] "
"If E present and lacks .keys() method, does:     for (k, v) in E: D[k] = "
"v In either case, this is followed by: for k, v in F.items(): D[k] = v"
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`values <flwr.common.ConfigsRecord.values>`\\ \\(\\)"
msgstr ":py:obj:`values <flwr.common.ConfigsRecord.values>`\\ \\(\\)"

#: flwr.common.record.configsrecord.ConfigsRecord.count_bytes:3 of
#, fuzzy
msgid "This function counts booleans as occupying 1 Byte."
msgstr "该函数将布尔值计算为占用 1 个字节。"

#: collections.abc.Mapping.get:3 of
msgid ""
"When there isn't an exact match, all the existing keys in the layout map "
"will be treated as a regex and map against the input key again. The first"
" match will be returned, based on the key insertion order. Return None if"
" there isn't any match found."
msgstr ""

#: collections.abc.Mapping.get:8 of
msgid "the string key as the query for the layout."
msgstr ""

#: collections.abc.Mapping.get:10 of
msgid "Corresponding layout based on the query."
msgstr ""

#: ../../source/ref-api/flwr.common.Context.rst:2
#, fuzzy
msgid "Context"
msgstr "背景"

#: flwr.common.context.Context:3 of
#, fuzzy
msgid "The ID that identifies the run."
msgstr "错误的标识符。"

#: flwr.common.context.Context:5 of
#, fuzzy
msgid "The ID that identifies the node."
msgstr "错误的标识符。"

#: flwr.common.context.Context:7 of
msgid ""
"A config (key/value mapping) unique to the node and independent of the "
"`run_config`. This config persists across all runs this node participates"
" in."
msgstr ""

#: flwr.common.context.Context:10 of
#, fuzzy
msgid ""
"Holds records added by the entity in a given `run_id` and that will stay "
"local. This means that the data it holds will never leave the system it's"
" running from. This can be used as an intermediate storage or scratchpad "
"when executing mods. It can also be used as a memory to access at "
"different points during the lifecycle of this entity (e.g. across "
"multiple rounds)"
msgstr "保存实体在给定运行中添加的记录，这些记录将保留在本地。这意味着它保存的数据永远不会离开运行的系统。在执行模式时，它可用作中间存储或抓取板。它还可以作为存储器，在实体生命周期的不同阶段（如多轮）进行访问。"

#: flwr.common.context.Context:17 of
msgid ""
"A config (key/value mapping) held by the entity in a given `run_id` and "
"that will stay local. It can be used at any point during the lifecycle of"
" this entity (e.g. across multiple rounds)"
msgstr ""

#: ../../source/ref-api/flwr.common.Context.rst:32:<autosummary>:1
#, fuzzy
msgid ":py:obj:`run_id <flwr.common.Context.run_id>`\\"
msgstr ":py:obj:`src_node_id <flwr.common.Metadata.src_node_id>`\\"

#: ../../source/ref-api/flwr.common.Context.rst:32:<autosummary>:1
#, fuzzy
msgid ":py:obj:`node_id <flwr.common.Context.node_id>`\\"
msgstr ":py:obj:`src_node_id <flwr.common.Metadata.src_node_id>`\\"

#: ../../source/ref-api/flwr.common.Context.rst:32:<autosummary>:1
#, fuzzy
msgid ":py:obj:`node_config <flwr.common.Context.node_config>`\\"
msgstr ":py:obj:`config <flwr.common.FitIns.config>`\\"

#: ../../source/ref-api/flwr.common.Context.rst:32:<autosummary>:1
#, fuzzy
msgid ":py:obj:`state <flwr.common.Context.state>`\\"
msgstr "server.strategy.Strategy"

#: ../../source/ref-api/flwr.common.Context.rst:32:<autosummary>:1
#, fuzzy
msgid ":py:obj:`run_config <flwr.common.Context.run_config>`\\"
msgstr ":py:obj:`config <flwr.common.FitIns.config>`\\"

#: ../../source/ref-api/flwr.common.DisconnectRes.rst:2
#, fuzzy
msgid "DisconnectRes"
msgstr "断开Res"

#: ../../source/ref-api/flwr.common.DisconnectRes.rst:28:<autosummary>:1
#, fuzzy
msgid ":py:obj:`reason <flwr.common.DisconnectRes.reason>`\\"
msgstr ":py:obj:`reason <flwr.common.DisconnectRes.reason>`\\"

#: ../../source/ref-api/flwr.common.Error.rst:2
#, fuzzy
msgid "Error"
msgstr "错误"

#: flwr.common.message.Error:3 of
#, fuzzy
msgid "An identifier for the error."
msgstr "错误的标识符。"

#: flwr.common.message.Error:5 of
#, fuzzy
msgid "A reason for why the error arose (e.g. an exception stack-trace)"
msgstr "出错原因（如异常堆栈跟踪）"

#: flwr.common.Error.code:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`code <flwr.common.Error.code>`\\"
msgstr ":py:obj:`code <flwr.common.Error.code>`\\"

#: flwr.common.Error.code:1 flwr.common.Error.code:1:<autosummary>:1 of
#, fuzzy
msgid "Error code."
msgstr "错误代码。"

#: flwr.common.Error.code:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`reason <flwr.common.Error.reason>`\\"
msgstr ":py:obj:`reason <flwr.common.Error.reason>`\\"

#: flwr.common.Error.code:1:<autosummary>:1 flwr.common.Error.reason:1 of
#, fuzzy
msgid "Reason reported about the error."
msgstr "报告的错误原因。"

#: ../../source/ref-api/flwr.common.EvaluateIns.rst:2
#, fuzzy
msgid "EvaluateIns"
msgstr "说明"

#: ../../source/ref-api/flwr.common.EvaluateIns.rst:29:<autosummary>:1
#, fuzzy
msgid ":py:obj:`parameters <flwr.common.EvaluateIns.parameters>`\\"
msgstr ":py:obj:`parameters <flwr.common.EvaluateIns.parameters>`\\"

#: ../../source/ref-api/flwr.common.EvaluateIns.rst:29:<autosummary>:1
#, fuzzy
msgid ":py:obj:`config <flwr.common.EvaluateIns.config>`\\"
msgstr ":py:obj:`config <flwr.common.EvaluateIns.config>`\\"

#: ../../source/ref-api/flwr.common.EvaluateRes.rst:2
#, fuzzy
msgid "EvaluateRes"
msgstr "评估Res"

#: ../../source/ref-api/flwr.common.EvaluateRes.rst:31:<autosummary>:1
#, fuzzy
msgid ":py:obj:`status <flwr.common.EvaluateRes.status>`\\"
msgstr ":py:obj:`status <flwr.common.EvaluateRes.status>`\\"

#: ../../source/ref-api/flwr.common.EvaluateRes.rst:31:<autosummary>:1
#, fuzzy
msgid ":py:obj:`loss <flwr.common.EvaluateRes.loss>`\\"
msgstr ":py:obj:`loss <flwr.common.EvaluateRes.loss>`\\"

#: ../../source/ref-api/flwr.common.EvaluateRes.rst:31:<autosummary>:1
#, fuzzy
msgid ":py:obj:`num_examples <flwr.common.EvaluateRes.num_examples>`\\"
msgstr ":py:obj:`num_examples <flwr.common.EvaluateRes.num_examples>`\\"

#: ../../source/ref-api/flwr.common.EvaluateRes.rst:31:<autosummary>:1
#, fuzzy
msgid ":py:obj:`metrics <flwr.common.EvaluateRes.metrics>`\\"
msgstr ":py:obj:`metrics <flwr.common.EvaluateRes.metrics>`\\"

#: ../../source/ref-api/flwr.common.EventType.rst:2
#, fuzzy
msgid "EventType"
msgstr "返回类型"

#: flwr.common.telemetry.EventType:1 of
#, fuzzy
msgid "Bases: :py:class:`str`, :py:class:`~enum.Enum`"
msgstr "Bases: :py:class:`str`, :py:class:`~enum.Enum`"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`encode <flwr.common.EventType.encode>`\\ \\(\\[encoding\\, "
"errors\\]\\)"
msgstr ":py:obj:`EventType <flwr.common.EventType>`\\ \\(value\\)"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.encode:1 of
#, fuzzy
msgid "Encode the string using the codec registered for encoding."
msgstr "使用注册的编码解码器对字符串进行编码。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`replace <flwr.common.EventType.replace>`\\ \\(old\\, new\\[\\, "
"count\\]\\)"
msgstr ":py:obj:`EventType <flwr.common.EventType>`\\ \\(value\\)"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.replace:1 of
#, fuzzy
msgid "Return a copy with all occurrences of substring old replaced by new."
msgstr "返回用 new 替换子串 old 的所有出现次数的副本。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`split <flwr.common.EventType.split>`\\ \\(\\[sep\\, "
"maxsplit\\]\\)"
msgstr ":py:obj:`PING <flwr.common.EventType.PING>`\\"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.rsplit:1 flwr.common.EventType.split:1 of
#, fuzzy
msgid ""
"Return a list of the substrings in the string, using sep as the separator"
" string."
msgstr "使用 sep 作为分隔符，返回字符串中的子字符串列表。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`rsplit <flwr.common.EventType.rsplit>`\\ \\(\\[sep\\, "
"maxsplit\\]\\)"
msgstr ":py:obj:`PING <flwr.common.EventType.PING>`\\"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ":py:obj:`join <flwr.common.EventType.join>`\\ \\(iterable\\, \\/\\)"
msgstr ":py:obj:`EventType <flwr.common.EventType>`\\ \\(value\\)"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.join:1 of
#, fuzzy
msgid "Concatenate any number of strings."
msgstr "连接任意数量的字符串。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ":py:obj:`capitalize <flwr.common.EventType.capitalize>`\\ \\(\\)"
msgstr ":py:obj:`PING <flwr.common.EventType.PING>`\\"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.capitalize:1 of
#, fuzzy
msgid "Return a capitalized version of the string."
msgstr "返回字符串的大写版本。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ":py:obj:`casefold <flwr.common.EventType.casefold>`\\ \\(\\)"
msgstr ":py:obj:`EventType <flwr.common.EventType>`\\ \\(value\\)"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.casefold:1 of
#, fuzzy
msgid "Return a version of the string suitable for caseless comparisons."
msgstr "返回适合无例比较的字符串版本。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ":py:obj:`title <flwr.common.EventType.title>`\\ \\(\\)"
msgstr ":py:obj:`EventType <flwr.common.EventType>`\\ \\(value\\)"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.title:1 of
#, fuzzy
msgid "Return a version of the string where each word is titlecased."
msgstr "返回字符串的版本，其中每个单词都使用了标题大小写。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`center <flwr.common.EventType.center>`\\ \\(width\\[\\, "
"fillchar\\]\\)"
msgstr ":py:obj:`EventType <flwr.common.EventType>`\\ \\(value\\)"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.center:1 of
#, fuzzy
msgid "Return a centered string of length width."
msgstr "返回客户端的属性集。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`count <flwr.common.EventType.count>`\\ \\(sub\\[\\, start\\[\\, "
"end\\]\\]\\)"
msgstr ":py:obj:`Context <flwr.common.Context>`\\ \\(state\\)"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ""
"Return the number of non-overlapping occurrences of substring sub in "
"string S[start:end]."
msgstr "返回子字符串 sub 在字符串 S[start:end] 中非重叠出现的次数。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`expandtabs <flwr.common.EventType.expandtabs>`\\ "
"\\(\\[tabsize\\]\\)"
msgstr ":py:obj:`EventType <flwr.common.EventType>`\\ \\(value\\)"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.expandtabs:1 of
#, fuzzy
msgid "Return a copy where all tab characters are expanded using spaces."
msgstr "返回使用空格扩展所有制表符的副本。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`find <flwr.common.EventType.find>`\\ \\(sub\\[\\, start\\[\\, "
"end\\]\\]\\)"
msgstr ":py:obj:`PING <flwr.common.EventType.PING>`\\"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ""
"Return the lowest index in S where substring sub is found, such that sub "
"is contained within S[start:end]."
msgstr "返回在 S 中找到子串 sub 的最低索引，且 sub 包含在 S[start:end] 中。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ":py:obj:`partition <flwr.common.EventType.partition>`\\ \\(sep\\, \\/\\)"
msgstr ":py:obj:`partition_id <flwr.common.Metadata.partition_id>`\\"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.partition:1 flwr.common.EventType.rpartition:1 of
#, fuzzy
msgid "Partition the string into three parts using the given separator."
msgstr "使用给定的分隔符将字符串分为三部分。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`index <flwr.common.EventType.index>`\\ \\(sub\\[\\, start\\[\\, "
"end\\]\\]\\)"
msgstr ":py:obj:`Context <flwr.common.Context>`\\ \\(state\\)"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`ljust <flwr.common.EventType.ljust>`\\ \\(width\\[\\, "
"fillchar\\]\\)"
msgstr ":py:obj:`EventType <flwr.common.EventType>`\\ \\(value\\)"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.ljust:1 of
#, fuzzy
msgid "Return a left-justified string of length width."
msgstr "返回长度为 width 的左对齐字符串。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ":py:obj:`lower <flwr.common.EventType.lower>`\\ \\(\\)"
msgstr ":py:obj:`now <flwr.common.now>`\\ \\(\\)"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.lower:1 of
#, fuzzy
msgid "Return a copy of the string converted to lowercase."
msgstr "返回转换为小写的字符串副本。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ":py:obj:`lstrip <flwr.common.EventType.lstrip>`\\ \\(\\[chars\\]\\)"
msgstr ":py:obj:`EventType <flwr.common.EventType>`\\ \\(value\\)"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.lstrip:1 of
#, fuzzy
msgid "Return a copy of the string with leading whitespace removed."
msgstr "返回去掉前导空白的字符串副本。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`rfind <flwr.common.EventType.rfind>`\\ \\(sub\\[\\, start\\[\\, "
"end\\]\\]\\)"
msgstr ":py:obj:`PING <flwr.common.EventType.PING>`\\"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ""
"Return the highest index in S where substring sub is found, such that sub"
" is contained within S[start:end]."
msgstr "返回在 S 中找到子串 sub 的最高索引，且 sub 包含在 S[start:end] 中。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`rindex <flwr.common.EventType.rindex>`\\ \\(sub\\[\\, "
"start\\[\\, end\\]\\]\\)"
msgstr ":py:obj:`Context <flwr.common.Context>`\\ \\(state\\)"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`rjust <flwr.common.EventType.rjust>`\\ \\(width\\[\\, "
"fillchar\\]\\)"
msgstr ":py:obj:`EventType <flwr.common.EventType>`\\ \\(value\\)"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.rjust:1 of
#, fuzzy
msgid "Return a right-justified string of length width."
msgstr "返回长度为 width 的右对齐字符串。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ":py:obj:`rstrip <flwr.common.EventType.rstrip>`\\ \\(\\[chars\\]\\)"
msgstr ":py:obj:`EventType <flwr.common.EventType>`\\ \\(value\\)"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.rstrip:1 of
#, fuzzy
msgid "Return a copy of the string with trailing whitespace removed."
msgstr "返回去掉尾部空白的字符串副本。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ":py:obj:`rpartition <flwr.common.EventType.rpartition>`\\ \\(sep\\, \\/\\)"
msgstr ":py:obj:`partition_id <flwr.common.Metadata.partition_id>`\\"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`splitlines <flwr.common.EventType.splitlines>`\\ "
"\\(\\[keepends\\]\\)"
msgstr ":py:obj:`PING <flwr.common.EventType.PING>`\\"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.splitlines:1 of
#, fuzzy
msgid "Return a list of the lines in the string, breaking at line boundaries."
msgstr "返回字符串中的行列表，以行为分界线。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ":py:obj:`strip <flwr.common.EventType.strip>`\\ \\(\\[chars\\]\\)"
msgstr ":py:obj:`EventType <flwr.common.EventType>`\\ \\(value\\)"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.strip:1 of
#, fuzzy
msgid "Return a copy of the string with leading and trailing whitespace removed."
msgstr "返回去掉前导和尾部空白的字符串副本。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ":py:obj:`swapcase <flwr.common.EventType.swapcase>`\\ \\(\\)"
msgstr ":py:obj:`EventType <flwr.common.EventType>`\\ \\(value\\)"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.swapcase:1 of
#, fuzzy
msgid ""
"Convert uppercase characters to lowercase and lowercase characters to "
"uppercase."
msgstr "将大写字母转换为小写字母，将小写字母转换为大写字母。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ":py:obj:`translate <flwr.common.EventType.translate>`\\ \\(table\\, \\/\\)"
msgstr ":py:obj:`EventType <flwr.common.EventType>`\\ \\(value\\)"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.translate:1 of
#, fuzzy
msgid "Replace each character in the string using the given translation table."
msgstr "使用给定的翻译表替换字符串中的每个字符。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ":py:obj:`upper <flwr.common.EventType.upper>`\\ \\(\\)"
msgstr ":py:obj:`PING <flwr.common.EventType.PING>`\\"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.upper:1 of
#, fuzzy
msgid "Return a copy of the string converted to uppercase."
msgstr "返回转换为大写字符串的副本。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`startswith <flwr.common.EventType.startswith>`\\ \\(prefix\\[\\,"
" start\\[\\, end\\]\\]\\)"
msgstr ":py:obj:`Status <flwr.common.Status>`\\ \\(code\\, message\\)"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid "Return True if S starts with the specified prefix, False otherwise."
msgstr "如果 S 以指定前缀开头，则返回 True，否则返回 False。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`endswith <flwr.common.EventType.endswith>`\\ \\(suffix\\[\\, "
"start\\[\\, end\\]\\]\\)"
msgstr ":py:obj:`EventType <flwr.common.EventType>`\\ \\(value\\)"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid "Return True if S ends with the specified suffix, False otherwise."
msgstr "如果 S 以指定后缀结束，则返回 True，否则返回 False。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`removeprefix <flwr.common.EventType.removeprefix>`\\ "
"\\(prefix\\, \\/\\)"
msgstr ":py:obj:`EventType <flwr.common.EventType>`\\ \\(value\\)"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.removeprefix:1 of
#, fuzzy
msgid "Return a str with the given prefix string removed if present."
msgstr "返回一个字符串，如果存在，则去掉给定的前缀字符串。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`removesuffix <flwr.common.EventType.removesuffix>`\\ "
"\\(suffix\\, \\/\\)"
msgstr ":py:obj:`EventType <flwr.common.EventType>`\\ \\(value\\)"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.removesuffix:1 of
#, fuzzy
msgid "Return a str with the given suffix string removed if present."
msgstr "返回一个字符串，如果存在给定的后缀字符串，则将其删除。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ":py:obj:`isascii <flwr.common.EventType.isascii>`\\ \\(\\)"
msgstr ":py:obj:`PING <flwr.common.EventType.PING>`\\"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.isascii:1 of
#, fuzzy
msgid "Return True if all characters in the string are ASCII, False otherwise."
msgstr "如果字符串中的所有字符都是 ASCII 码，则返回 True，否则返回 False。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ":py:obj:`islower <flwr.common.EventType.islower>`\\ \\(\\)"
msgstr ":py:obj:`now <flwr.common.now>`\\ \\(\\)"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.islower:1 of
#, fuzzy
msgid "Return True if the string is a lowercase string, False otherwise."
msgstr "如果字符串是小写字符串，则返回 True，否则返回 False。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ":py:obj:`isupper <flwr.common.EventType.isupper>`\\ \\(\\)"
msgstr ":py:obj:`EventType <flwr.common.EventType>`\\ \\(value\\)"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.isupper:1 of
#, fuzzy
msgid "Return True if the string is an uppercase string, False otherwise."
msgstr "如果字符串是大写字符串，则返回 True，否则返回 False。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ":py:obj:`istitle <flwr.common.EventType.istitle>`\\ \\(\\)"
msgstr ":py:obj:`EventType <flwr.common.EventType>`\\ \\(value\\)"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.istitle:1 of
#, fuzzy
msgid "Return True if the string is a title-cased string, False otherwise."
msgstr "如果字符串是带标题的字符串，则返回 True，否则返回 False。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ":py:obj:`isspace <flwr.common.EventType.isspace>`\\ \\(\\)"
msgstr ":py:obj:`EventType <flwr.common.EventType>`\\ \\(value\\)"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.isspace:1 of
#, fuzzy
msgid "Return True if the string is a whitespace string, False otherwise."
msgstr "如果字符串是空白字符串，则返回 True，否则返回 False。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ":py:obj:`isdecimal <flwr.common.EventType.isdecimal>`\\ \\(\\)"
msgstr ":py:obj:`PING <flwr.common.EventType.PING>`\\"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.isdecimal:1 of
#, fuzzy
msgid "Return True if the string is a decimal string, False otherwise."
msgstr "如果字符串是十进制字符串，则返回 True，否则返回 False。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ":py:obj:`isdigit <flwr.common.EventType.isdigit>`\\ \\(\\)"
msgstr ":py:obj:`PING <flwr.common.EventType.PING>`\\"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.isdigit:1 of
#, fuzzy
msgid "Return True if the string is a digit string, False otherwise."
msgstr "如果字符串是数字字符串，则返回 True，否则返回 False。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ":py:obj:`isnumeric <flwr.common.EventType.isnumeric>`\\ \\(\\)"
msgstr ":py:obj:`PING <flwr.common.EventType.PING>`\\"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.isnumeric:1 of
#, fuzzy
msgid "Return True if the string is a numeric string, False otherwise."
msgstr "如果字符串是数字字符串，则返回 True，否则返回 False。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ":py:obj:`isalpha <flwr.common.EventType.isalpha>`\\ \\(\\)"
msgstr ":py:obj:`PING <flwr.common.EventType.PING>`\\"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.isalpha:1 of
#, fuzzy
msgid "Return True if the string is an alphabetic string, False otherwise."
msgstr "如果字符串是字母字符串，则返回 True，否则返回 False。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ":py:obj:`isalnum <flwr.common.EventType.isalnum>`\\ \\(\\)"
msgstr ":py:obj:`PING <flwr.common.EventType.PING>`\\"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.isalnum:1 of
#, fuzzy
msgid "Return True if the string is an alpha-numeric string, False otherwise."
msgstr "如果字符串是字母数字字符串，则返回 True，否则返回 False。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ":py:obj:`isidentifier <flwr.common.EventType.isidentifier>`\\ \\(\\)"
msgstr ":py:obj:`EventType <flwr.common.EventType>`\\ \\(value\\)"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.isidentifier:1 of
#, fuzzy
msgid "Return True if the string is a valid Python identifier, False otherwise."
msgstr "如果字符串是有效的 Python 标识符，则返回 True，否则返回 False。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ":py:obj:`isprintable <flwr.common.EventType.isprintable>`\\ \\(\\)"
msgstr ":py:obj:`PING <flwr.common.EventType.PING>`\\"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.isprintable:1 of
#, fuzzy
msgid "Return True if the string is printable, False otherwise."
msgstr "如果字符串可打印，则返回 True，否则返回 False。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ":py:obj:`zfill <flwr.common.EventType.zfill>`\\ \\(width\\, \\/\\)"
msgstr ":py:obj:`PING <flwr.common.EventType.PING>`\\"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.zfill:1 of
#, fuzzy
msgid ""
"Pad a numeric string with zeros on the left, to fill a field of the given"
" width."
msgstr "在数字字符串左侧填充零，以填满给定宽度的字段。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`format <flwr.common.EventType.format>`\\ \\(\\*args\\, "
"\\*\\*kwargs\\)"
msgstr ""
":py:obj:`log <flwr.common.log>`\\ \\(level\\, msg\\, \\*args\\, "
"\\*\\*kwargs\\)"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid "Return a formatted version of S, using substitutions from args and kwargs."
msgstr "使用 args 和 kwargs 的替换，返回 S 的格式化版本。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ":py:obj:`format_map <flwr.common.EventType.format_map>`\\ \\(mapping\\)"
msgstr ":py:obj:`EventType <flwr.common.EventType>`\\ \\(value\\)"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid "Return a formatted version of S, using substitutions from mapping."
msgstr "使用映射中的替换，返回 S 的格式化版本。"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#, fuzzy
msgid ":py:obj:`maketrans <flwr.common.EventType.maketrans>`\\"
msgstr ":py:obj:`TRAIN <flwr.common.MessageType.TRAIN>`\\"

#: ../../source/ref-api/flwr.common.EventType.rst:163:<autosummary>:1
#: flwr.common.EventType.maketrans:1 of
#, fuzzy
msgid "Return a translation table usable for str.translate()."
msgstr "返回可用于 str.translate() 的翻译表。"

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`PING <flwr.common.EventType.PING>`\\"
msgstr ":py:obj:`PING <flwr.common.EventType.PING>`\\"

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`START_CLIENT_ENTER <flwr.common.EventType.START_CLIENT_ENTER>`\\"
msgstr ":py:obj:`START_CLIENT_ENTER <flwr.common.EventType.START_CLIENT_ENTER>`\\"

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`START_CLIENT_LEAVE <flwr.common.EventType.START_CLIENT_LEAVE>`\\"
msgstr ":py:obj:`START_CLIENT_LEAVE <flwr.common.EventType.START_CLIENT_LEAVE>`\\"

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`START_SERVER_ENTER <flwr.common.EventType.START_SERVER_ENTER>`\\"
msgstr ":py:obj:`START_SERVER_ENTER <flwr.common.EventType.START_SERVER_ENTER>`\\"

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`START_SERVER_LEAVE <flwr.common.EventType.START_SERVER_LEAVE>`\\"
msgstr ":py:obj:`START_SERVER_LEAVE <flwr.common.EventType.START_SERVER_LEAVE>`\\"

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`START_SIMULATION_ENTER "
"<flwr.common.EventType.START_SIMULATION_ENTER>`\\"
msgstr ""
":py:obj:`START_SIMULATION_ENTER "
"<flwr.common.EventType.START_SIMULATION_ENTER>`\\"

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`START_SIMULATION_LEAVE "
"<flwr.common.EventType.START_SIMULATION_LEAVE>`\\"
msgstr ""
":py:obj:`START_SIMULATION_LEAVE "
"<flwr.common.EventType.START_SIMULATION_LEAVE>`\\"

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`CLI_FLOWER_SIMULATION_ENTER "
"<flwr.common.EventType.CLI_FLOWER_SIMULATION_ENTER>`\\"
msgstr ""
":py:obj:`START_SIMULATION_ENTER "
"<flwr.common.EventType.START_SIMULATION_ENTER>`\\"

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`CLI_FLOWER_SIMULATION_LEAVE "
"<flwr.common.EventType.CLI_FLOWER_SIMULATION_LEAVE>`\\"
msgstr ""
":py:obj:`START_SIMULATION_LEAVE "
"<flwr.common.EventType.START_SIMULATION_LEAVE>`\\"

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`PYTHON_API_RUN_SIMULATION_ENTER "
"<flwr.common.EventType.PYTHON_API_RUN_SIMULATION_ENTER>`\\"
msgstr ""
":py:obj:`START_SIMULATION_ENTER "
"<flwr.common.EventType.START_SIMULATION_ENTER>`\\"

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`PYTHON_API_RUN_SIMULATION_LEAVE "
"<flwr.common.EventType.PYTHON_API_RUN_SIMULATION_LEAVE>`\\"
msgstr ""
":py:obj:`START_SIMULATION_LEAVE "
"<flwr.common.EventType.START_SIMULATION_LEAVE>`\\"

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`RUN_SUPERLINK_ENTER "
"<flwr.common.EventType.RUN_SUPERLINK_ENTER>`\\"
msgstr ""
":py:obj:`RUN_SUPERLINK_ENTER "
"<flwr.common.EventType.RUN_SUPERLINK_ENTER>`\\"

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`RUN_SUPERLINK_LEAVE "
"<flwr.common.EventType.RUN_SUPERLINK_LEAVE>`\\"
msgstr ""
":py:obj:`RUN_SUPERLINK_LEAVE "
"<flwr.common.EventType.RUN_SUPERLINK_LEAVE>`\\"

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`RUN_SUPERNODE_ENTER "
"<flwr.common.EventType.RUN_SUPERNODE_ENTER>`\\"
msgstr ""
":py:obj:`RUN_SUPERLINK_ENTER "
"<flwr.common.EventType.RUN_SUPERLINK_ENTER>`\\"

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`RUN_SUPERNODE_LEAVE "
"<flwr.common.EventType.RUN_SUPERNODE_LEAVE>`\\"
msgstr ""
":py:obj:`RUN_SUPERLINK_LEAVE "
"<flwr.common.EventType.RUN_SUPERLINK_LEAVE>`\\"

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`RUN_SERVER_APP_ENTER "
"<flwr.common.EventType.RUN_SERVER_APP_ENTER>`\\"
msgstr ""
":py:obj:`RUN_SERVER_APP_ENTER "
"<flwr.common.EventType.RUN_SERVER_APP_ENTER>`\\"

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`RUN_SERVER_APP_LEAVE "
"<flwr.common.EventType.RUN_SERVER_APP_LEAVE>`\\"
msgstr ""
":py:obj:`RUN_SERVER_APP_LEAVE "
"<flwr.common.EventType.RUN_SERVER_APP_LEAVE>`\\"

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`RUN_CLIENT_APP_ENTER "
"<flwr.common.EventType.RUN_CLIENT_APP_ENTER>`\\"
msgstr ""
":py:obj:`RUN_CLIENT_APP_ENTER "
"<flwr.common.EventType.RUN_CLIENT_APP_ENTER>`\\"

#: flwr.common.EventType.capitalize:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`RUN_CLIENT_APP_LEAVE "
"<flwr.common.EventType.RUN_CLIENT_APP_LEAVE>`\\"
msgstr ""
":py:obj:`RUN_CLIENT_APP_LEAVE "
"<flwr.common.EventType.RUN_CLIENT_APP_LEAVE>`\\"

#: flwr.common.EventType.capitalize:3 of
#, fuzzy
msgid ""
"More specifically, make the first character have upper case and the rest "
"lower case."
msgstr "更具体地说，让第一个字符大写，其余字符小写。"

#: flwr.common.EventType.center:3 flwr.common.EventType.ljust:3
#: flwr.common.EventType.rjust:3 of
#, fuzzy
msgid "Padding is done using the specified fill character (default is a space)."
msgstr "使用指定的填充字符（默认为空格）进行填充。"

#: flwr.common.EventType.count:1 of
#, fuzzy
msgid ""
"Return the number of non-overlapping occurrences of substring sub in "
"string S[start:end].  Optional arguments start and end are interpreted as"
" in slice notation."
msgstr "返回子串 sub 在字符串 S[start:end] 中非重叠出现的次数。 可选参数 start 和 end 按切分符号解释。"

#: flwr.common.EventType.encode:3 of
#, fuzzy
msgid "encoding"
msgstr "编码"

#: flwr.common.EventType.encode:4 of
#, fuzzy
msgid "The encoding in which to encode the string."
msgstr "字符串的编码。"

#: flwr.common.EventType.encode:9 of
#, fuzzy
msgid "errors"
msgstr "错误"

#: flwr.common.EventType.encode:6 of
#, fuzzy
msgid ""
"The error handling scheme to use for encoding errors. The default is "
"'strict' meaning that encoding errors raise a UnicodeEncodeError.  Other "
"possible values are 'ignore', 'replace' and 'xmlcharrefreplace' as well "
"as any other name registered with codecs.register_error that can handle "
"UnicodeEncodeErrors."
msgstr ""
"编码错误的错误处理方案。默认值为 \"strict\"，即编码错误会引发 UnicodeEncodeError。 其他可能的值包括 "
"\"ignore\"、\"replace \"和 \"xmlcharrefreplace\"，以及通过 codecs.register_error"
" 注册的、可处理 UnicodeEncodeErrror 的其他名称。"

#: flwr.common.EventType.endswith:1 of
#, fuzzy
msgid ""
"Return True if S ends with the specified suffix, False otherwise. With "
"optional start, test S beginning at that position. With optional end, "
"stop comparing S at that position. suffix can also be a tuple of strings "
"to try."
msgstr ""
"如果 S 以指定后缀结束，则返回 True，否则返回 False。如果起始位置可选，则从该位置开始测试 S。如果使用可选的 "
"end，则在该位置停止比较 S。后缀也可以是要尝试的字符串元组。"

#: flwr.common.EventType.expandtabs:3 of
#, fuzzy
msgid "If tabsize is not given, a tab size of 8 characters is assumed."
msgstr "如果未给出制表符大小，则假定制表符大小为 8 个字符。"

#: flwr.common.EventType.find:1 flwr.common.EventType.index:1 of
#, fuzzy
msgid ""
"Return the lowest index in S where substring sub is found, such that sub "
"is contained within S[start:end].  Optional arguments start and end are "
"interpreted as in slice notation."
msgstr "返回在 S 中找到子串 sub 的最低索引，即 sub 包含在 S[start:end] 中。 可选参数 start 和 end 按切分符号解释。"

#: flwr.common.EventType.find:5 flwr.common.EventType.rfind:5 of
#, fuzzy
msgid "Return -1 on failure."
msgstr "失败时返回-1。"

#: flwr.common.EventType.format:1 of
#, fuzzy
msgid ""
"Return a formatted version of S, using substitutions from args and "
"kwargs. The substitutions are identified by braces ('{' and '}')."
msgstr "使用来自 args 和 kwargs 的替换，返回 S 的格式化版本。替换用大括号（'{'和'}'）标识。"

#: flwr.common.EventType.format_map:1 of
#, fuzzy
msgid ""
"Return a formatted version of S, using substitutions from mapping. The "
"substitutions are identified by braces ('{' and '}')."
msgstr "使用映射中的替换，返回 S 的格式化版本。替换用大括号（'{'和'}'）标识。"

#: flwr.common.EventType.index:5 flwr.common.EventType.rindex:5 of
#, fuzzy
msgid "Raises ValueError when the substring is not found."
msgstr "如果未找到子串，则引发 ValueError。"

#: flwr.common.EventType.isalnum:3 of
#, fuzzy
msgid ""
"A string is alpha-numeric if all characters in the string are alpha-"
"numeric and there is at least one character in the string."
msgstr "如果字符串中的所有字符都是字母数字，且字符串中至少有一个字符，则该字符串为字母数字字符串。"

#: flwr.common.EventType.isalpha:3 of
#, fuzzy
msgid ""
"A string is alphabetic if all characters in the string are alphabetic and"
" there is at least one character in the string."
msgstr "如果字符串中的所有字符都是字母，并且字符串中至少有一个字符，那么该字符串就是字母字符串。"

#: flwr.common.EventType.isascii:3 of
#, fuzzy
msgid ""
"ASCII characters have code points in the range U+0000-U+007F. Empty "
"string is ASCII too."
msgstr "ASCII 字符的码位范围为 U+0000-U+007F。空字符串也是 ASCII 字符。"

#: flwr.common.EventType.isdecimal:3 of
#, fuzzy
msgid ""
"A string is a decimal string if all characters in the string are decimal "
"and there is at least one character in the string."
msgstr "如果字符串中的所有字符都是十进制，并且字符串中至少有一个字符是十进制，那么该字符串就是十进制字符串。"

#: flwr.common.EventType.isdigit:3 of
#, fuzzy
msgid ""
"A string is a digit string if all characters in the string are digits and"
" there is at least one character in the string."
msgstr "如果字符串中的所有字符都是数字，并且字符串中至少有一个字符，那么该字符串就是数字字符串。"

#: flwr.common.EventType.isidentifier:3 of
#, fuzzy
msgid ""
"Call keyword.iskeyword(s) to test whether string s is a reserved "
"identifier, such as \"def\" or \"class\"."
msgstr "调用 keyword.iskeyword(s) 测试字符串 s 是否为保留标识符，如 \"def \"或 \"class\"。"

#: flwr.common.EventType.islower:3 of
#, fuzzy
msgid ""
"A string is lowercase if all cased characters in the string are lowercase"
" and there is at least one cased character in the string."
msgstr "如果字符串中的所有大小写字符都是小写，且字符串中至少有一个大小写字符，则该字符串为小写字符串。"

#: flwr.common.EventType.isnumeric:3 of
#, fuzzy
msgid ""
"A string is numeric if all characters in the string are numeric and there"
" is at least one character in the string."
msgstr "如果字符串中的所有字符都是数字，且字符串中至少有一个字符，则该字符串为数字字符串。"

#: flwr.common.EventType.isprintable:3 of
#, fuzzy
msgid ""
"A string is printable if all of its characters are considered printable "
"in repr() or if it is empty."
msgstr "如果字符串的所有字符在 repr() 中都被认为是可打印的，或者字符串为空，那么该字符串就是可打印的。"

#: flwr.common.EventType.isspace:3 of
#, fuzzy
msgid ""
"A string is whitespace if all characters in the string are whitespace and"
" there is at least one character in the string."
msgstr "如果字符串中的所有字符都是空格，且字符串中至少有一个字符，则该字符串为空格。"

#: flwr.common.EventType.istitle:3 of
#, fuzzy
msgid ""
"In a title-cased string, upper- and title-case characters may only follow"
" uncased characters and lowercase characters only cased ones."
msgstr "在标题大小写字符串中，大写和标题大小写字符只能跟在无大小写字符之后，小写字符只能跟在有大小写字符之后。"

#: flwr.common.EventType.isupper:3 of
#, fuzzy
msgid ""
"A string is uppercase if all cased characters in the string are uppercase"
" and there is at least one cased character in the string."
msgstr "如果字符串中所有带大小写的字符都是大写，并且字符串中至少有一个带大小写的字符，则该字符串为大写字符串。"

#: flwr.common.EventType.join:3 of
#, fuzzy
msgid ""
"The string whose method is called is inserted in between each given "
"string. The result is returned as a new string."
msgstr "方法被调用的字符串会被插入每个给定的字符串之间。结果将以新字符串的形式返回。"

#: flwr.common.EventType.join:6 of
#, fuzzy
msgid "Example: '.'.join(['ab', 'pq', 'rs']) -> 'ab.pq.rs'"
msgstr "示例：'.'.join(['ab', 'pq', 'rs']) -> 'ab.pq.rs'"

#: flwr.common.EventType.lstrip:3 flwr.common.EventType.rstrip:3
#: flwr.common.EventType.strip:3 of
#, fuzzy
msgid "If chars is given and not None, remove characters in chars instead."
msgstr "如果给定的是 chars 而不是 None，则删除 chars 中的字符。"

#: flwr.common.EventType.maketrans:3 of
#, fuzzy
msgid ""
"If there is only one argument, it must be a dictionary mapping Unicode "
"ordinals (integers) or characters to Unicode ordinals, strings or None. "
"Character keys will be then converted to ordinals. If there are two "
"arguments, they must be strings of equal length, and in the resulting "
"dictionary, each character in x will be mapped to the character at the "
"same position in y. If there is a third argument, it must be a string, "
"whose characters will be mapped to None in the result."
msgstr ""
"如果只有一个参数，则必须是一个将 Unicode 序号（整数）或字符映射到 Unicode 序号、字符串或 None "
"的字典。字符键将被转换为序号。如果有两个参数，它们必须是长度相等的字符串，在生成的字典中，x 中的每个字符将被映射到 y 中相同位置的字符。"

#: flwr.common.EventType.partition:3 of
#, fuzzy
msgid ""
"This will search for the separator in the string.  If the separator is "
"found, returns a 3-tuple containing the part before the separator, the "
"separator itself, and the part after it."
msgstr "它会在字符串中搜索分隔符。 如果找到分隔符，则返回一个包含分隔符前部分、分隔符本身和分隔符后部分的 3 元组。"

#: flwr.common.EventType.partition:7 of
#, fuzzy
msgid ""
"If the separator is not found, returns a 3-tuple containing the original "
"string and two empty strings."
msgstr "如果找不到分隔符，则返回一个包含原始字符串和两个空字符串的 3 元组。"

#: flwr.common.EventType.removeprefix:3 of
#, fuzzy
msgid ""
"If the string starts with the prefix string, return string[len(prefix):]."
" Otherwise, return a copy of the original string."
msgstr "如果字符串以前缀字符串开始，则返回 string[len(prefix):]。否则，返回原始字符串的副本。"

#: flwr.common.EventType.removesuffix:3 of
#, fuzzy
msgid ""
"If the string ends with the suffix string and that suffix is not empty, "
"return string[:-len(suffix)]. Otherwise, return a copy of the original "
"string."
msgstr "如果字符串以后缀字符串结尾，且后缀不为空，则返回 string[:-len(suffix)]。否则，返回原始字符串的副本。"

#: flwr.common.EventType.replace:5 of
#, fuzzy
msgid "count"
msgstr "背景"

#: flwr.common.EventType.replace:4 of
#, fuzzy
msgid ""
"Maximum number of occurrences to replace. -1 (the default value) means "
"replace all occurrences."
msgstr "要替换的最大出现次数。-1（默认值）表示替换所有出现次数。"

#: flwr.common.EventType.replace:7 of
#, fuzzy
msgid ""
"If the optional argument count is given, only the first count occurrences"
" are replaced."
msgstr "如果给出可选参数 count，则只替换第一个计数出现的次数。"

#: flwr.common.EventType.rfind:1 flwr.common.EventType.rindex:1 of
#, fuzzy
msgid ""
"Return the highest index in S where substring sub is found, such that sub"
" is contained within S[start:end].  Optional arguments start and end are "
"interpreted as in slice notation."
msgstr "返回在 S 中找到子串 sub 且 sub 包含在 S[start:end] 中的最高索引。 可选参数 start 和 end 按切分符号解释。"

#: flwr.common.EventType.rpartition:3 of
#, fuzzy
msgid ""
"This will search for the separator in the string, starting at the end. If"
" the separator is found, returns a 3-tuple containing the part before the"
" separator, the separator itself, and the part after it."
msgstr "它会从字符串的末尾开始搜索分隔符。如果找到分隔符，则返回一个包含分隔符前部分、分隔符本身和分隔符后部分的 3 元组。"

#: flwr.common.EventType.rpartition:7 of
#, fuzzy
msgid ""
"If the separator is not found, returns a 3-tuple containing two empty "
"strings and the original string."
msgstr "如果找不到分隔符，则返回一个包含两个空字符串和原始字符串的 3 元组。"

#: flwr.common.EventType.rsplit:7 flwr.common.EventType.split:7 of
#, fuzzy
msgid "sep"
msgstr "sep"

#: flwr.common.EventType.rsplit:4 flwr.common.EventType.split:4 of
#, fuzzy
msgid "The separator used to split the string."
msgstr "用于分割字符串的分隔符。"

#: flwr.common.EventType.rsplit:6 flwr.common.EventType.split:6 of
#, fuzzy
msgid ""
"When set to None (the default value), will split on any whitespace "
"character (including \\\\n \\\\r \\\\t \\\\f and spaces) and will discard"
" empty strings from the result."
msgstr "当设置为 \"无\"（默认值）时，将对任何空白字符（包括 \\n \\r \\t \\f 和空格）进行分割，并从结果中剔除空字符串。"

#: flwr.common.EventType.rsplit:11 flwr.common.EventType.split:11 of
#, fuzzy
msgid "maxsplit"
msgstr "最大分割"

#: flwr.common.EventType.rsplit:10 flwr.common.EventType.split:10 of
#, fuzzy
msgid ""
"Maximum number of splits (starting from the left). -1 (the default value)"
" means no limit."
msgstr "最大分割次数（从左边开始）。-1（默认值）表示没有限制。"

#: flwr.common.EventType.rsplit:13 of
#, fuzzy
msgid "Splitting starts at the end of the string and works to the front."
msgstr "从琴弦末端开始分弦，一直到琴弦前端。"

#: flwr.common.EventType.split:13 of
#, fuzzy
msgid ""
"Note, str.split() is mainly useful for data that has been intentionally "
"delimited.  With natural text that includes punctuation, consider using "
"the regular expression module."
msgstr "注意，str.split() 主要适用于有意分隔的数据。 对于包含标点符号的自然文本，可以考虑使用正则表达式模块。"

#: flwr.common.EventType.splitlines:3 of
#, fuzzy
msgid ""
"Line breaks are not included in the resulting list unless keepends is "
"given and true."
msgstr "除非指定 keepends 为 true，否则换行符不会包含在生成的列表中。"

#: flwr.common.EventType.startswith:1 of
#, fuzzy
msgid ""
"Return True if S starts with the specified prefix, False otherwise. With "
"optional start, test S beginning at that position. With optional end, "
"stop comparing S at that position. prefix can also be a tuple of strings "
"to try."
msgstr ""
"如果 S 以指定的前缀开始，则返回 True，否则返回 False。如果选择 start，则从该位置开始测试 S。如果使用可选的 "
"end，则在该位置停止比较 S。"

#: flwr.common.EventType.title:3 of
#, fuzzy
msgid ""
"More specifically, words start with uppercased characters and all "
"remaining cased characters have lower case."
msgstr "更具体地说，单词以大写字母开头，其余所有大小写字符均为小写。"

#: flwr.common.EventType.translate:5 of
#, fuzzy
msgid "table"
msgstr "数据库"

#: flwr.common.EventType.translate:4 of
#, fuzzy
msgid ""
"Translation table, which must be a mapping of Unicode ordinals to Unicode"
" ordinals, strings, or None."
msgstr "翻译表，必须是 Unicode 序号到 Unicode 序号、字符串或无的映射。"

#: flwr.common.EventType.translate:7 of
#, fuzzy
msgid ""
"The table must implement lookup/indexing via __getitem__, for instance a "
"dictionary or list.  If this operation raises LookupError, the character "
"is left untouched.  Characters mapped to None are deleted."
msgstr ""
"表必须通过 __getitem__ 实现查找/索引，例如字典或列表。 如果该操作引发 LookupError，该字符将保持不变。 映射为 None"
" 的字符将被删除。"

#: flwr.common.EventType.zfill:3 of
#, fuzzy
msgid "The string is never truncated."
msgstr "字符串不会被截断。"

#: ../../source/ref-api/flwr.common.FitIns.rst:2
#, fuzzy
msgid "FitIns"
msgstr "FitIns"

#: ../../source/ref-api/flwr.common.FitIns.rst:29:<autosummary>:1
#, fuzzy
msgid ":py:obj:`parameters <flwr.common.FitIns.parameters>`\\"
msgstr ":py:obj:`parameters <flwr.common.FitIns.parameters>`\\"

#: ../../source/ref-api/flwr.common.FitIns.rst:29:<autosummary>:1
#, fuzzy
msgid ":py:obj:`config <flwr.common.FitIns.config>`\\"
msgstr ":py:obj:`config <flwr.common.FitIns.config>`\\"

#: ../../source/ref-api/flwr.common.FitRes.rst:2
#, fuzzy
msgid "FitRes"
msgstr "FitRes"

#: ../../source/ref-api/flwr.common.FitRes.rst:31:<autosummary>:1
#, fuzzy
msgid ":py:obj:`status <flwr.common.FitRes.status>`\\"
msgstr ":py:obj:`status <flwr.common.FitRes.status>`\\"

#: ../../source/ref-api/flwr.common.FitRes.rst:31:<autosummary>:1
#, fuzzy
msgid ":py:obj:`parameters <flwr.common.FitRes.parameters>`\\"
msgstr ":py:obj:`parameters <flwr.common.FitRes.parameters>`\\"

#: ../../source/ref-api/flwr.common.FitRes.rst:31:<autosummary>:1
#, fuzzy
msgid ":py:obj:`num_examples <flwr.common.FitRes.num_examples>`\\"
msgstr ":py:obj:`num_examples <flwr.common.FitRes.num_examples>`\\"

#: ../../source/ref-api/flwr.common.FitRes.rst:31:<autosummary>:1
#, fuzzy
msgid ":py:obj:`metrics <flwr.common.FitRes.metrics>`\\"
msgstr ":py:obj:`metrics <flwr.common.FitRes.metrics>`\\"

#: ../../source/ref-api/flwr.common.GetParametersIns.rst:2
#, fuzzy
msgid "GetParametersIns"
msgstr "参数"

#: ../../source/ref-api/flwr.common.GetParametersIns.rst:28:<autosummary>:1
#, fuzzy
msgid ":py:obj:`config <flwr.common.GetParametersIns.config>`\\"
msgstr ":py:obj:`config <flwr.common.GetParametersIns.config>`\\"

#: ../../source/ref-api/flwr.common.GetParametersRes.rst:2
#, fuzzy
msgid "GetParametersRes"
msgstr "参数"

#: ../../source/ref-api/flwr.common.GetParametersRes.rst:29:<autosummary>:1
#, fuzzy
msgid ":py:obj:`status <flwr.common.GetParametersRes.status>`\\"
msgstr ":py:obj:`status <flwr.common.GetParametersRes.status>`\\"

#: ../../source/ref-api/flwr.common.GetParametersRes.rst:29:<autosummary>:1
#, fuzzy
msgid ":py:obj:`parameters <flwr.common.GetParametersRes.parameters>`\\"
msgstr ":py:obj:`parameters <flwr.common.GetParametersRes.parameters>`\\"

#: ../../source/ref-api/flwr.common.GetPropertiesIns.rst:2
#, fuzzy
msgid "GetPropertiesIns"
msgstr "GetPropertiesIns"

#: ../../source/ref-api/flwr.common.GetPropertiesIns.rst:28:<autosummary>:1
#, fuzzy
msgid ":py:obj:`config <flwr.common.GetPropertiesIns.config>`\\"
msgstr ":py:obj:`config <flwr.common.GetPropertiesIns.config>`\\"

#: ../../source/ref-api/flwr.common.GetPropertiesRes.rst:2
#, fuzzy
msgid "GetPropertiesRes"
msgstr "GetPropertiesRes"

#: ../../source/ref-api/flwr.common.GetPropertiesRes.rst:29:<autosummary>:1
#, fuzzy
msgid ":py:obj:`status <flwr.common.GetPropertiesRes.status>`\\"
msgstr ":py:obj:`status <flwr.common.GetPropertiesRes.status>`\\"

#: ../../source/ref-api/flwr.common.GetPropertiesRes.rst:29:<autosummary>:1
#, fuzzy
msgid ":py:obj:`properties <flwr.common.GetPropertiesRes.properties>`\\"
msgstr ":py:obj:`properties <flwr.common.GetPropertiesRes.properties>`\\"

#: ../../source/ref-api/flwr.common.Message.rst:2
#, fuzzy
msgid "Message"
msgstr "服务器端"

#: flwr.common.Message.content:1:<autosummary>:1 flwr.common.Message.metadata:1
#: flwr.common.message.Message:3 of
#, fuzzy
msgid "A dataclass including information about the message to be executed."
msgstr "数据类型，包括要执行的信息的相关信息。"

#: flwr.common.message.Message:5 of
#, fuzzy
msgid ""
"Holds records either sent by another entity (e.g. sent by the server-side"
" logic to a client, or vice-versa) or that will be sent to it."
msgstr "保存由其他实体发送的记录（如由服务器端逻辑发送到客户端，反之亦然）或将发送到该实体的记录。"

#: flwr.common.message.Message:8 of
#, fuzzy
msgid ""
"A dataclass that captures information about an error that took place when"
" processing another message."
msgstr "数据类，用于捕捉处理其他报文时发生的错误信息。"

#: ../../source/ref-api/flwr.common.Message.rst:35:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`create_error_reply <flwr.common.Message.create_error_reply>`\\ "
"\\(error\\[\\, ttl\\]\\)"
msgstr ""
":py:obj:`create_error_reply <flwr.common.Message.create_error_reply>`\\ "
"\\(error\\, ttl\\)"

#: ../../source/ref-api/flwr.common.Message.rst:35:<autosummary>:1
#: flwr.common.message.Message.create_error_reply:1 of
#, fuzzy
msgid "Construct a reply message indicating an error happened."
msgstr "构建一条回复信息，说明发生了错误。"

#: ../../source/ref-api/flwr.common.Message.rst:35:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`create_reply <flwr.common.Message.create_reply>`\\ "
"\\(content\\[\\, ttl\\]\\)"
msgstr ""
":py:obj:`create_reply <flwr.common.Message.create_reply>`\\ \\(content\\,"
" ttl\\)"

#: ../../source/ref-api/flwr.common.Message.rst:35:<autosummary>:1
#: flwr.common.message.Message.create_reply:1 of
#, fuzzy
msgid "Create a reply to this message with specified content and TTL."
msgstr "以指定的内容和 TTL 创建对该信息的回复。"

#: ../../source/ref-api/flwr.common.Message.rst:35:<autosummary>:1
#, fuzzy
msgid ":py:obj:`has_content <flwr.common.Message.has_content>`\\ \\(\\)"
msgstr ":py:obj:`has_content <flwr.common.Message.has_content>`\\ \\(\\)"

#: ../../source/ref-api/flwr.common.Message.rst:35:<autosummary>:1
#: flwr.common.message.Message.has_content:1 of
#, fuzzy
msgid "Return True if message has content, else False."
msgstr "如果信息有内容，则返回 True，否则返回 False。"

#: ../../source/ref-api/flwr.common.Message.rst:35:<autosummary>:1
#, fuzzy
msgid ":py:obj:`has_error <flwr.common.Message.has_error>`\\ \\(\\)"
msgstr ":py:obj:`has_error <flwr.common.Message.has_error>`\\ \\(\\)"

#: ../../source/ref-api/flwr.common.Message.rst:35:<autosummary>:1
#: flwr.common.message.Message.has_error:1 of
#, fuzzy
msgid "Return True if message has an error, else False."
msgstr "如果信息有错误，则返回 True，否则返回 False。"

#: flwr.common.Message.content:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`content <flwr.common.Message.content>`\\"
msgstr ":py:obj:`content <flwr.common.Message.content>`\\"

#: flwr.common.Message.content:1 flwr.common.Message.content:1:<autosummary>:1
#: of
#, fuzzy
msgid "The content of this message."
msgstr "评估客户端的反应。"

#: flwr.common.Message.content:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`error <flwr.common.Message.error>`\\"
msgstr ":py:obj:`error <flwr.common.Message.error>`\\"

#: flwr.common.Message.content:1:<autosummary>:1 flwr.common.Message.error:1 of
#, fuzzy
msgid "Error captured by this message."
msgstr "该信息捕捉到的错误。"

#: flwr.common.Message.content:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`metadata <flwr.common.Message.metadata>`\\"
msgstr ":py:obj:`metadata <flwr.common.Message.metadata>`\\"

#: flwr.common.message.Message.create_error_reply:3 of
#, fuzzy
msgid "The error that was encountered."
msgstr "遇到的错误。"

#: flwr.common.message.Message.create_error_reply:5
#: flwr.common.message.Message.create_reply:9 of
#, fuzzy
msgid ""
"Time-to-live for this message in seconds. If unset, it will be set based "
"on the remaining time for the received message before it expires. This "
"follows the equation:  ttl = msg.meta.ttl - (reply.meta.created_at - "
"msg.meta.created_at)"
msgstr ""
"该信息的有效时间（秒）。如果未设置，则将根据收到的信息过期前的剩余时间来设置。其计算公式为：ttl = msg.meta.ttl - "
"(reply.meta.created_at - msg.meta.created_at)"

#: flwr.common.message.Message.create_error_reply:5
#: flwr.common.message.Message.create_reply:9 of
#, fuzzy
msgid ""
"Time-to-live for this message in seconds. If unset, it will be set based "
"on the remaining time for the received message before it expires. This "
"follows the equation:"
msgstr "该信息的有效时间（秒）。如果未设置，则将根据接收到的信息过期前的剩余时间来设置。其计算公式如下"

#: flwr.common.message.Message.create_error_reply:9
#: flwr.common.message.Message.create_reply:13 of
#, fuzzy
msgid "ttl = msg.meta.ttl - (reply.meta.created_at - msg.meta.created_at)"
msgstr "ttl = msg.meta.ttl - (reply.meta.created_at - msg.meta.created_at)"

#: flwr.common.message.Message.create_error_reply:12 of
#, fuzzy
msgid "**message** -- A Message containing only the relevant error and metadata."
msgstr "**message** -- 具有指定内容和元数据的新 \"信息 \"实例。"

#: flwr.common.message.Message.create_reply:3 of
#, fuzzy
msgid ""
"The method generates a new `Message` as a reply to this message. It "
"inherits 'run_id', 'src_node_id', 'dst_node_id', and 'message_type' from "
"this message and sets 'reply_to_message' to the ID of this message."
msgstr ""
"该方法会生成一条新的 \"信息\"，作为对该信息的回复。该方法继承了该消息的 "
"\"run_id\"、\"src_node_id\"、\"dst_node_id \"和 \"message_type\"，并将 "
"\"reply_to_message \"设置为该消息的 ID。"

#: flwr.common.message.Message.create_reply:7 of
#, fuzzy
msgid "The content for the reply message."
msgstr "回复信息的内容。"

#: flwr.common.message.Message.create_reply:16 of
#, fuzzy
msgid "A new `Message` instance representing the reply."
msgstr "代表回复的新的 `Message` 实例。"

#: ../../source/ref-api/flwr.common.MessageType.rst:2
#, fuzzy
msgid "MessageType"
msgstr "返回类型"

#: ../../source/ref-api/flwr.common.MessageType.rst:30:<autosummary>:1
#, fuzzy
msgid ":py:obj:`EVALUATE <flwr.common.MessageType.EVALUATE>`\\"
msgstr ":py:obj:`EVALUATE <flwr.common.MessageType.EVALUATE>`\\"

#: ../../source/ref-api/flwr.common.MessageType.rst:30:<autosummary>:1
#, fuzzy
msgid ":py:obj:`QUERY <flwr.common.MessageType.QUERY>`\\"
msgstr ":py:obj:`QUERY <flwr.common.MessageType.QUERY>`\\"

#: ../../source/ref-api/flwr.common.MessageType.rst:30:<autosummary>:1
#, fuzzy
msgid ":py:obj:`TRAIN <flwr.common.MessageType.TRAIN>`\\"
msgstr ":py:obj:`TRAIN <flwr.common.MessageType.TRAIN>`\\"

#: ../../source/ref-api/flwr.common.MessageTypeLegacy.rst:2
#, fuzzy
msgid "MessageTypeLegacy"
msgstr "MessageTypeLegacy"

#: ../../source/ref-api/flwr.common.MessageTypeLegacy.rst:29:<autosummary>:1
#, fuzzy
msgid ":py:obj:`GET_PARAMETERS <flwr.common.MessageTypeLegacy.GET_PARAMETERS>`\\"
msgstr ":py:obj:`GET_PARAMETERS <flwr.common.MessageTypeLegacy.GET_PARAMETERS>`\\"

#: ../../source/ref-api/flwr.common.MessageTypeLegacy.rst:29:<autosummary>:1
#, fuzzy
msgid ":py:obj:`GET_PROPERTIES <flwr.common.MessageTypeLegacy.GET_PROPERTIES>`\\"
msgstr ":py:obj:`GET_PROPERTIES <flwr.common.MessageTypeLegacy.GET_PROPERTIES>`\\"

#: ../../source/ref-api/flwr.common.Metadata.rst:2
msgid "Metadata"
msgstr "描述数据"

#: flwr.common.Metadata.created_at:1:<autosummary>:1
#: flwr.common.Metadata.run_id:1 flwr.common.message.Metadata:3 of
#, fuzzy
msgid "An identifier for the current run."
msgstr "当前运行的标识符。"

#: flwr.common.Metadata.created_at:1:<autosummary>:1
#: flwr.common.Metadata.message_id:1 flwr.common.message.Metadata:5 of
#, fuzzy
msgid "An identifier for the current message."
msgstr "当前信息的标识符。"

#: flwr.common.Metadata.created_at:1:<autosummary>:1
#: flwr.common.Metadata.src_node_id:1 flwr.common.message.Metadata:7 of
#, fuzzy
msgid "An identifier for the node sending this message."
msgstr "发送此信息的节点的标识符。"

#: flwr.common.Metadata.created_at:1:<autosummary>:1
#: flwr.common.Metadata.dst_node_id:1 flwr.common.message.Metadata:9 of
#, fuzzy
msgid "An identifier for the node receiving this message."
msgstr "接收此信息的节点的标识符。"

#: flwr.common.Metadata.created_at:1:<autosummary>:1
#: flwr.common.Metadata.reply_to_message:1 flwr.common.message.Metadata:11 of
#, fuzzy
msgid "An identifier for the message this message replies to."
msgstr "该信息回复的信息的标识符。"

#: flwr.common.message.Metadata:13 of
#, fuzzy
msgid ""
"An identifier for grouping messages. In some settings, this is used as "
"the FL round."
msgstr "用于分组报文的标识符。在某些设置中，它被用作 FL 轮。"

#: flwr.common.message.Metadata:16 of
#, fuzzy
msgid "Time-to-live for this message in seconds."
msgstr "该信息的有效时间。"

#: flwr.common.Metadata.created_at:1:<autosummary>:1
#: flwr.common.Metadata.message_type:1 flwr.common.message.Metadata:18 of
#, fuzzy
msgid "A string that encodes the action to be executed on the receiving end."
msgstr "编码接收端要执行的操作的字符串。"

#: flwr.common.Metadata.created_at:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`created_at <flwr.common.Metadata.created_at>`\\"
msgstr ":py:obj:`ttl <flwr.common.Metadata.ttl>`\\"

#: flwr.common.Metadata.created_at:1
#: flwr.common.Metadata.created_at:1:<autosummary>:1 of
#, fuzzy
msgid "Unix timestamp when the message was created."
msgstr "创建信息时的 Unix 时间戳。"

#: flwr.common.Metadata.created_at:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`dst_node_id <flwr.common.Metadata.dst_node_id>`\\"
msgstr ":py:obj:`dst_node_id <flwr.common.Metadata.dst_node_id>`\\"

#: flwr.common.Metadata.created_at:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`group_id <flwr.common.Metadata.group_id>`\\"
msgstr ":py:obj:`group_id <flwr.common.Metadata.group_id>`\\"

#: flwr.common.Metadata.created_at:1:<autosummary>:1
#: flwr.common.Metadata.group_id:1 of
#, fuzzy
msgid "An identifier for grouping messages."
msgstr "用于分组信息的标识符。"

#: flwr.common.Metadata.created_at:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`message_id <flwr.common.Metadata.message_id>`\\"
msgstr ":py:obj:`message_id <flwr.common.Metadata.message_id>`\\"

#: flwr.common.Metadata.created_at:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`message_type <flwr.common.Metadata.message_type>`\\"
msgstr ":py:obj:`message_type <flwr.common.Metadata.message_type>`\\"

#: flwr.common.Metadata.created_at:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`reply_to_message <flwr.common.Metadata.reply_to_message>`\\"
msgstr ":py:obj:`reply_to_message <flwr.common.Metadata.reply_to_message>`\\"

#: flwr.common.Metadata.created_at:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`run_id <flwr.common.Metadata.run_id>`\\"
msgstr ":py:obj:`run_id <flwr.common.Metadata.run_id>`\\"

#: flwr.common.Metadata.created_at:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`src_node_id <flwr.common.Metadata.src_node_id>`\\"
msgstr ":py:obj:`src_node_id <flwr.common.Metadata.src_node_id>`\\"

#: flwr.common.Metadata.created_at:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`ttl <flwr.common.Metadata.ttl>`\\"
msgstr ":py:obj:`ttl <flwr.common.Metadata.ttl>`\\"

#: flwr.common.Metadata.created_at:1:<autosummary>:1 flwr.common.Metadata.ttl:1
#: of
#, fuzzy
msgid "Time-to-live for this message."
msgstr "该信息的有效时间。"

#: ../../source/ref-api/flwr.common.Metrics.rst:2
#, fuzzy
msgid "Metrics"
msgstr "MetricsRecord"

#: ../../source/ref-api/flwr.common.MetricsRecord.rst:2
#, fuzzy
msgid "MetricsRecord"
msgstr "MetricsRecord"

#: flwr.common.record.metricsrecord.MetricsRecord:1 of
#, fuzzy
msgid ""
"Bases: :py:class:`~flwr.common.record.typeddict.TypedDict`\\ "
"[:py:class:`str`, :py:class:`int` | :py:class:`float` | "
":py:class:`list`\\ [:py:class:`int`] | :py:class:`list`\\ "
"[:py:class:`float`]]"
msgstr ""
"Bases: :py:class:`~flwr.common.record.typeddict.TypedDict`\\ "
"[:py:class:`str`, :py:obj:`~typing.Union`\\ [:py:class:`int`, "
":py:class:`float`, :py:class:`~typing.List`\\ [:py:class:`int`], "
":py:class:`~typing.List`\\ [:py:class:`float`]]]"

#: flwr.common.record.metricsrecord.MetricsRecord:3 of
msgid ""
"A :code:`MetricsRecord` is a Python dictionary designed to ensure that "
"each key-value pair adheres to specified data types. A "
":code:`MetricsRecord` is one of the types of records that a "
"`flwr.common.RecordSet <flwr.common.RecordSet.html#recordset>`_ supports "
"and can therefore be used to construct :code:`common.Message` objects."
msgstr ""

#: flwr.common.record.metricsrecord.MetricsRecord:9 of
msgid ""
"A dictionary that stores basic types (i.e. `int`, `float` as defined in "
"`MetricsScalar`) and list of such types (see `MetricsScalarList`)."
msgstr ""

#: flwr.common.record.metricsrecord.MetricsRecord:12 of
msgid ""
"A boolean indicating whether metrics should be deleted from the input "
"dictionary immediately after adding them to the record. When set to True,"
" the data is duplicated in memory. If memory is a concern, set it to "
"False."
msgstr ""

#: flwr.common.record.metricsrecord.MetricsRecord:20 of
msgid ""
"The usage of a :code:`MetricsRecord` is envisioned for communicating "
"results obtained when a node performs an action. A few typical examples "
"include: communicating the training accuracy after a model is trained "
"locally by a :code:`ClientApp`, reporting the validation loss obtained at"
" a :code:`ClientApp`, or, more generally, the output of executing a query"
" by the :code:`ClientApp`. Common to these examples is that the output "
"can be typically represented by a single scalar (:code:`int`, "
":code:`float`) or list of scalars."
msgstr ""

#: flwr.common.record.metricsrecord.MetricsRecord:28 of
msgid ""
"Let's see some examples of how to construct a :code:`MetricsRecord` from "
"scratch:"
msgstr ""

#: flwr.common.record.metricsrecord.MetricsRecord:39 of
msgid ""
"Since types are enforced, the types of the objects inserted are checked. "
"For a :code:`MetricsRecord`, value types allowed are those in defined in "
":code:`flwr.common.MetricsRecordValues`. Similarly, only :code:`str` keys"
" are allowed."
msgstr ""

#: flwr.common.record.metricsrecord.MetricsRecord:50 of
msgid ""
"If you need a more versatily type of record try :code:`ConfigsRecord` or "
":code:`ParametersRecord`."
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`clear <flwr.common.MetricsRecord.clear>`\\ \\(\\)"
msgstr ":py:obj:`clear <flwr.common.MetricsRecord.clear>`\\ \\(\\)"

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`count_bytes <flwr.common.MetricsRecord.count_bytes>`\\ \\(\\)"
msgstr ":py:obj:`count_bytes <flwr.common.MetricsRecord.count_bytes>`\\ \\(\\)"

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`get <flwr.common.MetricsRecord.get>`\\ \\(key\\[\\, default\\]\\)"
msgstr ":py:obj:`get <flwr.common.MetricsRecord.get>`\\ \\(k\\[\\,d\\]\\)"

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`items <flwr.common.MetricsRecord.items>`\\ \\(\\)"
msgstr ":py:obj:`items <flwr.common.MetricsRecord.items>`\\ \\(\\)"

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`keys <flwr.common.MetricsRecord.keys>`\\ \\(\\)"
msgstr ":py:obj:`keys <flwr.common.MetricsRecord.keys>`\\ \\(\\)"

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`pop <flwr.common.MetricsRecord.pop>`\\ \\(k\\[\\,d\\]\\)"
msgstr ":py:obj:`pop <flwr.common.MetricsRecord.pop>`\\ \\(k\\[\\,d\\]\\)"

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`popitem <flwr.common.MetricsRecord.popitem>`\\ \\(\\)"
msgstr ":py:obj:`items <flwr.common.MetricsRecord.items>`\\ \\(\\)"

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`setdefault <flwr.common.MetricsRecord.setdefault>`\\ "
"\\(k\\[\\,d\\]\\)"
msgstr ":py:obj:`get <flwr.common.MetricsRecord.get>`\\ \\(k\\[\\,d\\]\\)"

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`update <flwr.common.MetricsRecord.update>`\\ \\(\\[E\\, "
"\\]\\*\\*F\\)"
msgstr ""
":py:obj:`update <flwr.common.MetricsRecord.update>`\\ \\(\\[E\\, "
"\\]\\*\\*F\\)"

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`values <flwr.common.MetricsRecord.values>`\\ \\(\\)"
msgstr ":py:obj:`values <flwr.common.MetricsRecord.values>`\\ \\(\\)"

#: ../../source/ref-api/flwr.common.NDArray.rst:2
#, fuzzy
msgid "NDArray"
msgstr "NDArray"

#: ../../source/ref-api/flwr.common.NDArrays.rst:2
#, fuzzy
msgid "NDArrays"
msgstr "NDArray"

#: ../../source/ref-api/flwr.common.Parameters.rst:29:<autosummary>:1
#, fuzzy
msgid ":py:obj:`tensors <flwr.common.Parameters.tensors>`\\"
msgstr ":py:obj:`tensors <flwr.common.Parameters.tensors>`\\"

#: ../../source/ref-api/flwr.common.Parameters.rst:29:<autosummary>:1
#, fuzzy
msgid ":py:obj:`tensor_type <flwr.common.Parameters.tensor_type>`\\"
msgstr ":py:obj:`tensor_type <flwr.common.Parameters.tensor_type>`\\"

#: ../../source/ref-api/flwr.common.ParametersRecord.rst:2
#, fuzzy
msgid "ParametersRecord"
msgstr "参数"

#: flwr.common.record.parametersrecord.ParametersRecord:1 of
#, fuzzy
msgid ""
"Bases: :py:class:`~flwr.common.record.typeddict.TypedDict`\\ "
"[:py:class:`str`, :py:class:`~flwr.common.record.parametersrecord.Array`]"
msgstr ""
"Bases: :py:class:`~flwr.common.record.typeddict.TypedDict`\\ "
"[:py:class:`str`, :py:class:`~flwr.common.record.parametersrecord.Array`]"

#: flwr.common.record.parametersrecord.ParametersRecord:3 of
#, fuzzy
msgid ""
"A dataclass storing named Arrays in order. This means that it holds "
"entries as an OrderedDict[str, Array]. ParametersRecord objects can be "
"viewed as an equivalent to PyTorch's state_dict, but holding serialised "
"tensors instead. A :code:`ParametersRecord`  is one of the types of "
"records that a `flwr.common.RecordSet "
"<flwr.common.RecordSet.html#recordset>`_ supports and can therefore be "
"used to construct :code:`common.Message` objects."
msgstr ""
"按顺序存储命名数组的数据类。这意味着它以 OrderedDict[str, Array] 的形式保存条目。ParametersRecord "
"对象相当于 PyTorch 的 state_dict，但它保存的是序列化的张量。"

#: flwr.common.record.parametersrecord.ParametersRecord:10 of
msgid "A dictionary that stores serialized array-like or tensor-like objects."
msgstr ""

#: flwr.common.record.parametersrecord.ParametersRecord:12 of
msgid ""
"A boolean indicating whether parameters should be deleted from the input "
"dictionary immediately after adding them to the record. If False, the "
"dictionary passed to `set_parameters()` will be empty once exiting from "
"that function. This is the desired behaviour when working with very large"
" models/tensors/arrays. However, if you plan to continue working with "
"your parameters after adding it to the record, set this flag to True. "
"When set to True, the data is duplicated in memory."
msgstr ""

#: flwr.common.record.parametersrecord.ParametersRecord:23 of
msgid ""
"The usage of :code:`ParametersRecord` is envisioned for storing data "
"arrays (e.g. parameters of a machine learning model). These first need to"
" be serialized into a :code:`flwr.common.Array` data structure."
msgstr ""

#: flwr.common.record.parametersrecord.ParametersRecord:27 of
#, fuzzy
msgid "Let's see some examples:"
msgstr "让我们来看几个例子："

#: flwr.common.record.parametersrecord.ParametersRecord:50 of
msgid ""
"Now that the NumPy array is embedded into a :code:`ParametersRecord` it "
"could be sent if added as part of a :code:`common.Message` or it could be"
" saved as a persistent state of a :code:`ClientApp` via its context. "
"Regardless of the usecase, we will sooner or later want to recover the "
"array in its original NumPy representation. For the example above, where "
"the array was serialized using the built-in utility function, "
"deserialization can be done as follows:"
msgstr ""

#: flwr.common.record.parametersrecord.ParametersRecord:65 of
msgid ""
"If you need finer control on how your arrays are serialized and "
"deserialized, you can construct :code:`Array` objects directly like this:"
msgstr ""

#: flwr.common.record.parametersrecord.ParametersRecord:83 of
msgid ""
"Note that different arrays (e.g. from PyTorch, Tensorflow) might require "
"different serialization mechanism. Howerver, they often support a "
"conversion to NumPy, therefore allowing to use the same or similar steps "
"as in the example above."
msgstr ""

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`clear <flwr.common.ParametersRecord.clear>`\\ \\(\\)"
msgstr ":py:obj:`clear <flwr.common.ParametersRecord.clear>`\\ \\(\\)"

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`count_bytes <flwr.common.ParametersRecord.count_bytes>`\\ \\(\\)"
msgstr ":py:obj:`count_bytes <flwr.common.ParametersRecord.count_bytes>`\\ \\(\\)"

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`get <flwr.common.ParametersRecord.get>`\\ \\(key\\[\\, "
"default\\]\\)"
msgstr ":py:obj:`get <flwr.common.ParametersRecord.get>`\\ \\(k\\[\\,d\\]\\)"

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`items <flwr.common.ParametersRecord.items>`\\ \\(\\)"
msgstr ":py:obj:`items <flwr.common.ParametersRecord.items>`\\ \\(\\)"

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`keys <flwr.common.ParametersRecord.keys>`\\ \\(\\)"
msgstr ":py:obj:`keys <flwr.common.ParametersRecord.keys>`\\ \\(\\)"

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`pop <flwr.common.ParametersRecord.pop>`\\ \\(k\\[\\,d\\]\\)"
msgstr ":py:obj:`pop <flwr.common.ParametersRecord.pop>`\\ \\(k\\[\\,d\\]\\)"

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`popitem <flwr.common.ParametersRecord.popitem>`\\ \\(\\)"
msgstr ":py:obj:`items <flwr.common.ParametersRecord.items>`\\ \\(\\)"

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`setdefault <flwr.common.ParametersRecord.setdefault>`\\ "
"\\(k\\[\\,d\\]\\)"
msgstr ":py:obj:`get <flwr.common.ParametersRecord.get>`\\ \\(k\\[\\,d\\]\\)"

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`update <flwr.common.ParametersRecord.update>`\\ \\(\\[E\\, "
"\\]\\*\\*F\\)"
msgstr ""
":py:obj:`update <flwr.common.ParametersRecord.update>`\\ \\(\\[E\\, "
"\\]\\*\\*F\\)"

#: collections.abc.MutableMapping.clear:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`values <flwr.common.ParametersRecord.values>`\\ \\(\\)"
msgstr ":py:obj:`values <flwr.common.ParametersRecord.values>`\\ \\(\\)"

#: flwr.common.record.parametersrecord.ParametersRecord.count_bytes:3 of
#, fuzzy
msgid ""
"Note that a small amount of Bytes might also be included in this counting"
" that correspond to metadata of the serialized object (e.g. of NumPy "
"array) needed for deseralization."
msgstr "请注意，该计数中还可能包含少量字节，这些字节与序列化对象（如 NumPy 数组）的元数据相对应，需要进行去eralization。"

#: ../../source/ref-api/flwr.common.Properties.rst:2
#, fuzzy
msgid "Properties"
msgstr "GetPropertiesRes"

#: ../../source/ref-api/flwr.common.ReconnectIns.rst:2
#, fuzzy
msgid "ReconnectIns"
msgstr "启用 SSL 连接"

#: ../../source/ref-api/flwr.common.ReconnectIns.rst:28:<autosummary>:1
#, fuzzy
msgid ":py:obj:`seconds <flwr.common.ReconnectIns.seconds>`\\"
msgstr ":py:obj:`seconds <flwr.common.ReconnectIns.seconds>`\\"

#: ../../source/ref-api/flwr.common.RecordSet.rst:2
#, fuzzy
msgid "RecordSet"
msgstr "RecordSet"

#: flwr.common.record.recordset.RecordSet:3 of
msgid ""
"A :code:`RecordSet` is the unified mechanism by which parameters, metrics"
" and configs can be either stored as part of a `flwr.common.Context "
"<flwr.common.Context.html>`_ in your apps or communicated as part of a "
"`flwr.common.Message <flwr.common.Message.html>`_ between your apps."
msgstr ""

#: flwr.common.record.recordset.RecordSet:9 of
msgid ""
"A dictionary of :code:`ParametersRecords` that can be used to record and "
"communicate model parameters and high-dimensional arrays."
msgstr ""

#: flwr.common.record.recordset.RecordSet:12 of
msgid ""
"A dictionary of :code:`MetricsRecord` that can be used to record and "
"communicate scalar-valued metrics that are the result of performing and "
"action, for example, by a :code:`ClientApp`."
msgstr ""

#: flwr.common.record.recordset.RecordSet:16 of
msgid ""
"A dictionary of :code:`ConfigsRecord` that can be used to record and "
"communicate configuration values to an entity (e.g. to a "
":code:`ClientApp`) for it to adjust how an action is performed."
msgstr ""

#: flwr.common.record.recordset.RecordSet:24 of
msgid ""
"A :code:`RecordSet` can hold three types of records, each designed with "
"an specific purpose. What is common to all of them is that they are "
"Python dictionaries designed to ensure that each key-value pair adheres "
"to specified data types."
msgstr ""

#: flwr.common.record.recordset.RecordSet:29 of
#, fuzzy
msgid "Let's see an example."
msgstr "让我们来看几个例子："

#: flwr.common.record.recordset.RecordSet:47 of
msgid ""
"Adding a :code:`ParametersRecord` follows the same steps as above but "
"first, the array needs to be serialized and represented as a "
":code:`flwr.common.Array`. If the array is a :code:`NumPy` array, you can"
" use the built-in utility function `array_from_numpy "
"<flwr.common.array_from_numpy.html>`_. It is often possible to convert an"
" array first to :code:`NumPy` and then use the aforementioned function."
msgstr ""

#: flwr.common.record.recordset.RecordSet:66 of
msgid ""
"For additional examples on how to construct each of the records types "
"shown above, please refer to the documentation for :code:`ConfigsRecord`,"
" :code:`MetricsRecord` and :code:`ParametersRecord`."
msgstr ""

#: flwr.common.RecordSet.configs_records:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`configs_records <flwr.common.RecordSet.configs_records>`\\"
msgstr ":py:obj:`configs_records <flwr.common.RecordSet.configs_records>`\\"

#: flwr.common.RecordSet.configs_records:1
#: flwr.common.RecordSet.configs_records:1:<autosummary>:1 of
#, fuzzy
msgid "Dictionary holding ConfigsRecord instances."
msgstr "包含 ConfigsRecord 实例的字典。"

#: flwr.common.RecordSet.configs_records:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`metrics_records <flwr.common.RecordSet.metrics_records>`\\"
msgstr ":py:obj:`metrics_records <flwr.common.RecordSet.metrics_records>`\\"

#: flwr.common.RecordSet.configs_records:1:<autosummary>:1
#: flwr.common.RecordSet.metrics_records:1 of
#, fuzzy
msgid "Dictionary holding MetricsRecord instances."
msgstr "保存 MetricsRecord 实例的字典。"

#: flwr.common.RecordSet.configs_records:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`parameters_records <flwr.common.RecordSet.parameters_records>`\\"
msgstr ":py:obj:`parameters_records <flwr.common.RecordSet.parameters_records>`\\"

#: flwr.common.RecordSet.configs_records:1:<autosummary>:1
#: flwr.common.RecordSet.parameters_records:1 of
#, fuzzy
msgid "Dictionary holding ParametersRecord instances."
msgstr "存放 ParametersRecord 实例的字典。"

#: ../../source/ref-api/flwr.common.ServerMessage.rst:2
#, fuzzy
msgid "ServerMessage"
msgstr "服务器端"

#: ../../source/ref-api/flwr.common.ServerMessage.rst:31:<autosummary>:1
#, fuzzy
msgid ":py:obj:`evaluate_ins <flwr.common.ServerMessage.evaluate_ins>`\\"
msgstr ":py:obj:`evaluate_ins <flwr.common.ServerMessage.evaluate_ins>`\\"

#: ../../source/ref-api/flwr.common.ServerMessage.rst:31:<autosummary>:1
#, fuzzy
msgid ":py:obj:`fit_ins <flwr.common.ServerMessage.fit_ins>`\\"
msgstr ":py:obj:`fit_ins <flwr.common.ServerMessage.fit_ins>`\\"

#: ../../source/ref-api/flwr.common.ServerMessage.rst:31:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`get_parameters_ins "
"<flwr.common.ServerMessage.get_parameters_ins>`\\"
msgstr ""
":py:obj:`get_parameters_ins "
"<flwr.common.ServerMessage.get_parameters_ins>`\\"

#: ../../source/ref-api/flwr.common.ServerMessage.rst:31:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`get_properties_ins "
"<flwr.common.ServerMessage.get_properties_ins>`\\"
msgstr ""
":py:obj:`get_properties_ins "
"<flwr.common.ServerMessage.get_properties_ins>`\\"

#: ../../source/ref-api/flwr.common.Status.rst:2
#, fuzzy
msgid "Status"
msgstr "客户端状态。"

#: ../../source/ref-api/flwr.common.Status.rst:29:<autosummary>:1
#, fuzzy
msgid ":py:obj:`code <flwr.common.Status.code>`\\"
msgstr ":py:obj:`code <flwr.common.Status.code>`\\"

#: ../../source/ref-api/flwr.common.Status.rst:29:<autosummary>:1
#, fuzzy
msgid ":py:obj:`message <flwr.common.Status.message>`\\"
msgstr ":py:obj:`message <flwr.common.Status.message>`\\"

#: ../../source/ref-api/flwr.common.array_from_numpy.rst:2
#, fuzzy
msgid "array\\_from\\_numpy"
msgstr "array\\_from\\_numpy"

#: ../../source/ref-api/flwr.common.bytes_to_ndarray.rst:2
#, fuzzy
msgid "bytes\\_to\\_ndarray"
msgstr "bytes\\_to\\_ndarray"

#: ../../source/ref-api/flwr.common.configure.rst:2
#, fuzzy
msgid "configure"
msgstr "配置日志记录"

#: ../../source/ref-api/flwr.common.event.rst:2
#, fuzzy
msgid "event"
msgstr "事件"

#: ../../source/ref-api/flwr.common.log.rst:2
#, fuzzy
msgid "log"
msgstr "登录"

#: logging.Logger.log:3 of
msgid ""
"To pass exception information, use the keyword argument exc_info with a "
"true value, e.g."
msgstr "要传递异常信息，请使用带 true 值的关键字参数 exc_info，例如。"

#: logging.Logger.log:6 of
#, python-format
msgid "logger.log(level, \"We have a %s\", \"mysterious problem\", exc_info=1)"
msgstr "logger.log(level, \"We have a %s\", \"mysterious problem\", exc_info=1)"

#: ../../source/ref-api/flwr.common.ndarray_to_bytes.rst:2
#, fuzzy
msgid "ndarray\\_to\\_bytes"
msgstr "ndarray\\_to\\_bytes"

#: ../../source/ref-api/flwr.common.ndarrays_to_parameters.rst:2
#, fuzzy
msgid "ndarrays\\_to\\_parameters"
msgstr "ndarrays\\_to\\_parameters"

#: ../../source/ref-api/flwr.common.now.rst:2
#, fuzzy
msgid "now"
msgstr "现在"

#: ../../source/ref-api/flwr.common.parameters_to_ndarrays.rst:2
#, fuzzy
msgid "parameters\\_to\\_ndarrays"
msgstr "parameters\\_to\\_ndarrays"

#: ../../source/ref-api/flwr.server.rst:2
msgid "server"
msgstr "服务器"

#: ../../source/ref-api/flwr.server.rst:22:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`start_server <flwr.server.start_server>`\\ \\(\\*\\[\\, "
"server\\_address\\, server\\, ...\\]\\)"
msgstr ""
":py:obj:`start_server <flwr.server.start_server>`\\ \\(\\*\\[\\, "
"server\\_address\\, server\\, ...\\]\\)"

#: ../../source/ref-api/flwr.server.rst:22:<autosummary>:1
#: flwr.server.app.start_server:1 of
msgid "Start a Flower server using the gRPC transport layer."
msgstr "使用 gRPC 传输层启动 Flower 服务器。"

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
#, fuzzy
msgid ":py:obj:`ClientManager <flwr.server.ClientManager>`\\ \\(\\)"
msgstr ":py:obj:`ClientManager <flwr.server.ClientManager>`\\ \\(\\)"

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
#: flwr.server.client_manager.ClientManager:1 of
#, fuzzy
msgid "Abstract base class for managing Flower clients."
msgstr "Flower 客户端的抽象基类。"

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
#, fuzzy
msgid ":py:obj:`Driver <flwr.server.Driver>`\\ \\(\\)"
msgstr ":py:obj:`run_driver_api <flwr.server.run_driver_api>`\\ \\(\\)"

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
#: flwr.server.driver.driver.Driver:1 of
#, fuzzy
msgid "Abstract base Driver class for the ServerAppIo API."
msgstr "Flower 客户端的抽象基类。"

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
#, fuzzy
msgid ":py:obj:`History <flwr.server.History>`\\ \\(\\)"
msgstr ":py:obj:`History <flwr.server.History>`\\ \\(\\)"

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
#: flwr.server.history.History:1 of
#, fuzzy
msgid "History class for training and/or evaluation metrics collection."
msgstr "**hist** -- 包含训练和评估指标的对象。"

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`LegacyContext <flwr.server.LegacyContext>`\\ \\(context\\[\\, "
"config\\, strategy\\, ...\\]\\)"
msgstr ""
":py:obj:`LegacyContext <flwr.server.LegacyContext>`\\ \\(state\\[\\, "
"config\\, strategy\\, ...\\]\\)"

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
#: flwr.server.compat.legacy_context.LegacyContext:1 of
#, fuzzy
msgid "Legacy Context."
msgstr "传承背景。"

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`Server <flwr.server.Server>`\\ \\(\\*\\, client\\_manager\\[\\, "
"strategy\\]\\)"
msgstr ""
":py:obj:`Server <flwr.server.Server>`\\ \\(\\*\\, client\\_manager\\[\\, "
"strategy\\]\\)"

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`ServerApp <flwr.server.ServerApp>`\\ \\(\\[server\\, config\\, "
"strategy\\, ...\\]\\)"
msgstr "server.strategy.Strategy"

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
#: flwr.server.server_app.ServerApp:1 of
#, fuzzy
msgid "Flower ServerApp."
msgstr "Flower 服务器。"

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`ServerAppComponents <flwr.server.ServerAppComponents>`\\ "
"\\(\\[server\\, config\\, ...\\]\\)"
msgstr "server.strategy.Strategy"

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
#: flwr.server.serverapp_components.ServerAppComponents:1 of
msgid "Components to construct a ServerApp."
msgstr ""

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`ServerConfig <flwr.server.ServerConfig>`\\ \\(\\[num\\_rounds\\,"
" round\\_timeout\\]\\)"
msgstr ""
"Flower 1.0: ``start_server(..., "
"config=flwr.server.ServerConfig(num_rounds=3, round_timeout=600.0), "
"...)``"

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
#: flwr.server.server_config.ServerConfig:1 of
#, fuzzy
msgid "Flower server config."
msgstr "Flower 服务器。"

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
#, fuzzy
msgid ":py:obj:`SimpleClientManager <flwr.server.SimpleClientManager>`\\ \\(\\)"
msgstr ":py:obj:`SimpleClientManager <flwr.server.SimpleClientManager>`\\ \\(\\)"

#: ../../source/ref-api/flwr.server.rst:37:<autosummary>:1
#: flwr.server.client_manager.SimpleClientManager:1 of
#, fuzzy
msgid "Provides a pool of available clients."
msgstr "使用部分可用客户进行评估。"

#: ../../source/ref-api/flwr.server.rst:56:<autosummary>:1
#, fuzzy
msgid ":py:obj:`strategy <flwr.server.strategy>`\\"
msgstr "server.strategy.Strategy"

#: ../../source/ref-api/flwr.server.rst:56:<autosummary>:1
#: flwr.server.strategy:1 of
msgid "Contains the strategy abstraction and different implementations."
msgstr "包含策略抽象和不同的实现方法。"

#: ../../source/ref-api/flwr.server.rst:56:<autosummary>:1
#, fuzzy
msgid ":py:obj:`workflow <flwr.server.workflow>`\\"
msgstr "server.strategy.Strategy"

#: ../../source/ref-api/flwr.server.rst:56:<autosummary>:1
#: flwr.server.workflow:1 of
#, fuzzy
msgid "Workflows."
msgstr "工作流程"

#: ../../source/ref-api/flwr.server.ClientManager.rst:2
#, fuzzy
msgid "ClientManager"
msgstr "客户端"

#: flwr.server.client_manager.ClientManager.all:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`all <flwr.server.ClientManager.all>`\\ \\(\\)"
msgstr ":py:obj:`all <flwr.server.ClientManager.all>`\\ \\(\\)"

#: flwr.server.client_manager.ClientManager.all:1
#: flwr.server.client_manager.ClientManager.all:1:<autosummary>:1
#: flwr.server.client_manager.SimpleClientManager.all:1
#: flwr.server.client_manager.SimpleClientManager.all:1:<autosummary>:1 of
#, fuzzy
msgid "Return all available clients."
msgstr "返回所有可用客户。"

#: flwr.server.client_manager.ClientManager.all:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`num_available <flwr.server.ClientManager.num_available>`\\ \\(\\)"
msgstr ":py:obj:`num_available <flwr.server.ClientManager.num_available>`\\ \\(\\)"

#: flwr.server.client_manager.ClientManager.all:1:<autosummary>:1
#: flwr.server.client_manager.ClientManager.num_available:1
#: flwr.server.client_manager.SimpleClientManager.all:1:<autosummary>:1
#: flwr.server.client_manager.SimpleClientManager.num_available:1 of
#, fuzzy
msgid "Return the number of available clients."
msgstr "返回样本大小和所需的可用客户数量。"

#: flwr.server.client_manager.ClientManager.all:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`register <flwr.server.ClientManager.register>`\\ \\(client\\)"
msgstr ":py:obj:`register <flwr.server.ClientManager.register>`\\ \\(client\\)"

#: flwr.server.client_manager.ClientManager.all:1:<autosummary>:1
#: flwr.server.client_manager.ClientManager.register:1
#: flwr.server.client_manager.SimpleClientManager.all:1:<autosummary>:1
#: flwr.server.client_manager.SimpleClientManager.register:1 of
#, fuzzy
msgid "Register Flower ClientProxy instance."
msgstr "注册 Flower ClientProxy 实例。"

#: flwr.server.client_manager.ClientManager.all:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`sample <flwr.server.ClientManager.sample>`\\ "
"\\(num\\_clients\\[\\, min\\_num\\_clients\\, criterion\\]\\)"
msgstr ""
":py:obj:`sample <flwr.server.ClientManager.sample>`\\ "
"\\(num\\_clients\\[\\, min\\_num\\_clients\\, criterion\\]\\)"

#: flwr.server.client_manager.ClientManager.all:1:<autosummary>:1
#: flwr.server.client_manager.ClientManager.sample:1
#: flwr.server.client_manager.SimpleClientManager.all:1:<autosummary>:1
#: flwr.server.client_manager.SimpleClientManager.sample:1 of
#, fuzzy
msgid "Sample a number of Flower ClientProxy instances."
msgstr "取样若干 Flower ClientProxy 实例。"

#: flwr.server.client_manager.ClientManager.all:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`unregister <flwr.server.ClientManager.unregister>`\\ \\(client\\)"
msgstr ":py:obj:`unregister <flwr.server.ClientManager.unregister>`\\ \\(client\\)"

#: flwr.server.client_manager.ClientManager.all:1:<autosummary>:1
#: flwr.server.client_manager.ClientManager.unregister:1
#: flwr.server.client_manager.SimpleClientManager.all:1:<autosummary>:1
#: flwr.server.client_manager.SimpleClientManager.unregister:1 of
#, fuzzy
msgid "Unregister Flower ClientProxy instance."
msgstr "取消注册 Flower ClientProxy 实例。"

#: flwr.server.client_manager.ClientManager.all:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`wait_for <flwr.server.ClientManager.wait_for>`\\ "
"\\(num\\_clients\\, timeout\\)"
msgstr ""
":py:obj:`wait_for <flwr.server.ClientManager.wait_for>`\\ "
"\\(num\\_clients\\, timeout\\)"

#: flwr.server.client_manager.ClientManager.all:1:<autosummary>:1
#: flwr.server.client_manager.ClientManager.wait_for:1
#: flwr.server.client_manager.SimpleClientManager.all:1:<autosummary>:1
#: flwr.server.client_manager.SimpleClientManager.wait_for:1 of
#, fuzzy
msgid "Wait until at least `num_clients` are available."
msgstr "等待至少 `num_clients` 可用。"

#: flwr.server.client_manager.ClientManager.num_available:3
#: flwr.server.client_manager.SimpleClientManager.num_available:3 of
#, fuzzy
msgid "**num_available** -- The number of currently available clients."
msgstr "**num_available** -- 当前可用客户端的数量。"

#: flwr.server.client_manager.ClientManager.register:3 of
msgid "The ClientProxy of the Client to register."
msgstr ""

#: flwr.server.client_manager.ClientManager.register:6
#: flwr.server.client_manager.SimpleClientManager.register:6 of
#, fuzzy
msgid ""
"**success** -- Indicating if registration was successful. False if "
"ClientProxy is already registered or can not be registered for any "
"reason."
msgstr "**success** -- 表示注册是否成功。如果 ClientProxy 已注册或因故无法注册，则为 False。"

#: flwr.server.client_manager.ClientManager.unregister:3
#: flwr.server.client_manager.SimpleClientManager.unregister:3 of
#, fuzzy
msgid "This method is idempotent."
msgstr "这种方法是幂等的。"

#: flwr.server.client_manager.ClientManager.unregister:5 of
msgid "The ClientProxy of the Client to unregister."
msgstr ""

#: ../../source/ref-api/flwr.server.Driver.rst:2
#, fuzzy
msgid "Driver"
msgstr "服务器"

#: ../../source/ref-api/flwr.server.Driver.rst:41:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`create_message <flwr.server.Driver.create_message>`\\ "
"\\(content\\, message\\_type\\, ...\\[\\, ttl\\]\\)"
msgstr ""
":py:obj:`create_message <flwr.server.Driver.create_message>`\\ "
"\\(content\\, message\\_type\\, ...\\)"

#: ../../source/ref-api/flwr.server.Driver.rst:41:<autosummary>:1
#: flwr.server.driver.driver.Driver.create_message:1 of
#, fuzzy
msgid "Create a new message with specified parameters."
msgstr "使用指定参数创建新信息。"

#: ../../source/ref-api/flwr.server.Driver.rst:41:<autosummary>:1
#, fuzzy
msgid ":py:obj:`get_node_ids <flwr.server.Driver.get_node_ids>`\\ \\(\\)"
msgstr ":py:obj:`get_node_ids <flwr.server.Driver.get_node_ids>`\\ \\(\\)"

#: ../../source/ref-api/flwr.server.Driver.rst:41:<autosummary>:1
#: flwr.server.driver.driver.Driver.get_node_ids:1 of
#, fuzzy
msgid "Get node IDs."
msgstr "获取节点 ID。"

#: ../../source/ref-api/flwr.server.Driver.rst:41:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`pull_messages <flwr.server.Driver.pull_messages>`\\ "
"\\(message\\_ids\\)"
msgstr ""
":py:obj:`pull_messages <flwr.server.Driver.pull_messages>`\\ "
"\\(message\\_ids\\)"

#: ../../source/ref-api/flwr.server.Driver.rst:41:<autosummary>:1
#: flwr.server.driver.driver.Driver.pull_messages:1 of
#, fuzzy
msgid "Pull messages based on message IDs."
msgstr "根据信息 ID 提取信息。"

#: ../../source/ref-api/flwr.server.Driver.rst:41:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`push_messages <flwr.server.Driver.push_messages>`\\ "
"\\(messages\\)"
msgstr ""
":py:obj:`push_messages <flwr.server.Driver.push_messages>`\\ "
"\\(messages\\)"

#: ../../source/ref-api/flwr.server.Driver.rst:41:<autosummary>:1
#: flwr.server.driver.driver.Driver.push_messages:1 of
#, fuzzy
msgid "Push messages to specified node IDs."
msgstr "向指定的节点 ID 推送信息。"

#: ../../source/ref-api/flwr.server.Driver.rst:41:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`send_and_receive <flwr.server.Driver.send_and_receive>`\\ "
"\\(messages\\, \\*\\[\\, timeout\\]\\)"
msgstr ""
"Flower 1.0: ``start_server(..., "
"config=flwr.server.ServerConfig(num_rounds=3, round_timeout=600.0), "
"...)``"

#: ../../source/ref-api/flwr.server.Driver.rst:41:<autosummary>:1
#: flwr.server.driver.driver.Driver.send_and_receive:1 of
#, fuzzy
msgid "Push messages to specified node IDs and pull the reply messages."
msgstr "向指定的节点 ID 推送信息并提取回复信息。"

#: ../../source/ref-api/flwr.server.Driver.rst:41:<autosummary>:1
#, fuzzy
msgid ":py:obj:`set_run <flwr.server.Driver.set_run>`\\ \\(run\\_id\\)"
msgstr ":py:obj:`run_driver_api <flwr.server.run_driver_api>`\\ \\(\\)"

#: ../../source/ref-api/flwr.server.Driver.rst:41:<autosummary>:1
#: flwr.server.driver.driver.Driver.set_run:1 of
msgid "Request a run to the SuperLink with a given `run_id`."
msgstr ""

#: flwr.server.driver.driver.Driver.create_message:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`run <flwr.server.Driver.run>`\\"
msgstr ":py:obj:`run_driver_api <flwr.server.run_driver_api>`\\ \\(\\)"

#: flwr.server.Driver.run:1
#: flwr.server.driver.driver.Driver.create_message:1:<autosummary>:1 of
#, fuzzy
msgid "Run information."
msgstr "运行模拟"

#: flwr.server.driver.driver.Driver.create_message:3 of
#, fuzzy
msgid ""
"This method constructs a new `Message` with given content and metadata. "
"The `run_id` and `src_node_id` will be set automatically."
msgstr "本方法使用给定的内容和元数据构建新的 `Message` 。run_id \"和 \"src_node_id \"将自动设置。"

#: flwr.server.driver.driver.Driver.create_message:6 of
#, fuzzy
msgid ""
"The content for the new message. This holds records that are to be sent "
"to the destination node."
msgstr "新信息的内容。其中包含要发送到目的节点的记录。"

#: flwr.server.driver.driver.Driver.create_message:9 of
#, fuzzy
msgid ""
"The type of the message, defining the action to be executed on the "
"receiving end."
msgstr "信息类型，定义接收端要执行的操作。"

#: flwr.server.driver.driver.Driver.create_message:12 of
#, fuzzy
msgid "The ID of the destination node to which the message is being sent."
msgstr "信息发送目的地节点的 ID。"

#: flwr.server.driver.driver.Driver.create_message:14 of
#, fuzzy
msgid ""
"The ID of the group to which this message is associated. In some "
"settings, this is used as the FL round."
msgstr "与该信息相关联的组的 ID。在某些设置中，它被用作 FL 轮。"

#: flwr.server.driver.driver.Driver.create_message:17 of
#, fuzzy
msgid ""
"Time-to-live for the round trip of this message, i.e., the time from "
"sending this message to receiving a reply. It specifies in seconds the "
"duration for which the message and its potential reply are considered "
"valid. If unset, the default TTL (i.e., `common.DEFAULT_TTL`) will be "
"used."
msgstr "此报文往返的有效时间，即从发送此报文到收到回复的时间。它规定了信息及其潜在回复被视为有效的持续时间。"

#: flwr.server.driver.driver.Driver.create_message:23 of
#, fuzzy
msgid ""
"**message** -- A new `Message` instance with the specified content and "
"metadata."
msgstr "**message** -- 具有指定内容和元数据的新 \"信息 \"实例。"

#: flwr.server.driver.driver.Driver.pull_messages:3 of
#, fuzzy
msgid ""
"This method is used to collect messages from the SuperLink that "
"correspond to a set of given message IDs."
msgstr "该方法用于从超级链接中收集与一组给定消息 ID 相对应的消息。"

#: flwr.server.driver.driver.Driver.pull_messages:6 of
#, fuzzy
msgid "An iterable of message IDs for which reply messages are to be retrieved."
msgstr "要检索回复信息的信息 ID 的可迭代项。"

#: flwr.server.driver.driver.Driver.pull_messages:9 of
#, fuzzy
msgid "**messages** -- An iterable of messages received."
msgstr "**messages** -- 收到的信息迭代。"

#: flwr.server.driver.driver.Driver.push_messages:3 of
#, fuzzy
msgid ""
"This method takes an iterable of messages and sends each message to the "
"node specified in `dst_node_id`."
msgstr "该方法接收一个可迭代的消息，并将每条消息发送到 `dst_node_id` 中指定的节点。"

#: flwr.server.driver.driver.Driver.push_messages:6
#: flwr.server.driver.driver.Driver.send_and_receive:7 of
#, fuzzy
msgid "An iterable of messages to be sent."
msgstr "要发送的信息迭代。"

#: flwr.server.driver.driver.Driver.push_messages:9 of
#, fuzzy
msgid ""
"**message_ids** -- An iterable of IDs for the messages that were sent, "
"which can be used to pull replies."
msgstr "**message_ids** -- 已发送信息的可迭代 ID，可用于提取回复信息。"

#: flwr.server.driver.driver.Driver.send_and_receive:3 of
#, fuzzy
msgid ""
"This method sends a list of messages to their destination node IDs and "
"then waits for the replies. It continues to pull replies until either all"
" replies are received or the specified timeout duration is exceeded."
msgstr "该方法会向目标节点 ID 发送信息列表，然后等待回复。它会继续提取回复，直到收到所有回复或超过指定的超时时间。"

#: flwr.server.driver.driver.Driver.send_and_receive:9 of
#, fuzzy
msgid ""
"The timeout duration in seconds. If specified, the method will wait for "
"replies for this duration. If `None`, there is no time limit and the "
"method will wait until replies for all messages are received."
msgstr "超时时间（秒）。如果指定，该方法将在此期限内等待回复。如果指定为 \"无\"，则没有时间限制，该方法将等待直到收到所有信息的回复。"

#: flwr.server.driver.driver.Driver.send_and_receive:14 of
#, fuzzy
msgid "**replies** -- An iterable of reply messages received from the SuperLink."
msgstr "**replies** -- 从超级链接收到的回复信息的迭代。"

#: flwr.server.driver.driver.Driver.send_and_receive:19 of
#, fuzzy
msgid ""
"This method uses `push_messages` to send the messages and `pull_messages`"
" to collect the replies. If `timeout` is set, the method may not return "
"replies for all sent messages. A message remains valid until its TTL, "
"which is not affected by `timeout`."
msgstr ""
"该方法使用 `push_messages` 发送信息，并使用 `pull_messages` 收集回复。如果设置了 "
"`timeout`，该方法可能不会返回所有已发送消息的回复。消息在其 TTL 之前一直有效，不受 `timeout` 影响。"

#: flwr.server.driver.driver.Driver.set_run:3 of
msgid ""
"If a Run with the specified `run_id` exists, a local Run object will be "
"created. It enables further functionality in the driver, such as sending "
"`Messages`."
msgstr ""

#: flwr.server.driver.driver.Driver.set_run:7 of
msgid "The `run_id` of the Run this Driver object operates in."
msgstr ""

#: ../../source/ref-api/flwr.server.History.rst:2
#, fuzzy
msgid "History"
msgstr "历史"

#: flwr.server.history.History.add_loss_centralized:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`add_loss_centralized "
"<flwr.server.History.add_loss_centralized>`\\ \\(server\\_round\\, "
"loss\\)"
msgstr ""
":py:obj:`add_loss_centralized "
"<flwr.server.History.add_loss_centralized>`\\ \\(server\\_round\\, "
"loss\\)"

#: flwr.server.history.History.add_loss_centralized:1
#: flwr.server.history.History.add_loss_centralized:1:<autosummary>:1 of
#, fuzzy
msgid "Add one loss entry (from centralized evaluation)."
msgstr "集中评估"

#: flwr.server.history.History.add_loss_centralized:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`add_loss_distributed "
"<flwr.server.History.add_loss_distributed>`\\ \\(server\\_round\\, "
"loss\\)"
msgstr ""
":py:obj:`add_loss_distributed "
"<flwr.server.History.add_loss_distributed>`\\ \\(server\\_round\\, "
"loss\\)"

#: flwr.server.history.History.add_loss_centralized:1:<autosummary>:1
#: flwr.server.history.History.add_loss_distributed:1 of
#, fuzzy
msgid "Add one loss entry (from distributed evaluation)."
msgstr "增加一个损失条目（来自分布式评估）。"

#: flwr.server.history.History.add_loss_centralized:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`add_metrics_centralized "
"<flwr.server.History.add_metrics_centralized>`\\ \\(server\\_round\\, "
"metrics\\)"
msgstr ""
":py:obj:`add_metrics_centralized "
"<flwr.server.History.add_metrics_centralized>`\\ \\(server\\_round\\, "
"metrics\\)"

#: flwr.server.history.History.add_loss_centralized:1:<autosummary>:1
#: flwr.server.history.History.add_metrics_centralized:1 of
#, fuzzy
msgid "Add metrics entries (from centralized evaluation)."
msgstr "集中评估"

#: flwr.server.history.History.add_loss_centralized:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`add_metrics_distributed "
"<flwr.server.History.add_metrics_distributed>`\\ \\(server\\_round\\, "
"metrics\\)"
msgstr ""
":py:obj:`add_metrics_distributed "
"<flwr.server.History.add_metrics_distributed>`\\ \\(server\\_round\\, "
"metrics\\)"

#: flwr.server.history.History.add_loss_centralized:1:<autosummary>:1
#: flwr.server.history.History.add_metrics_distributed:1 of
#, fuzzy
msgid "Add metrics entries (from distributed evaluation)."
msgstr "定制的集中/分布式评估"

#: flwr.server.history.History.add_loss_centralized:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`add_metrics_distributed_fit "
"<flwr.server.History.add_metrics_distributed_fit>`\\ \\(server\\_round\\,"
" ...\\)"
msgstr ""
":py:obj:`add_metrics_distributed_fit "
"<flwr.server.History.add_metrics_distributed_fit>`\\ \\(server\\_round\\,"
" ...\\)"

#: flwr.server.history.History.add_loss_centralized:1:<autosummary>:1
#: flwr.server.history.History.add_metrics_distributed_fit:1 of
#, fuzzy
msgid "Add metrics entries (from distributed fit)."
msgstr "添加度量条目（来自分布式拟合）。"

#: ../../source/ref-api/flwr.server.LegacyContext.rst:2
#, fuzzy
msgid "LegacyContext"
msgstr "遗留上下文"

#: flwr.server.compat.legacy_context.LegacyContext:1 of
#, fuzzy
msgid "Bases: :py:class:`~flwr.common.context.Context`"
msgstr "Bases: :py:class:`~flwr.common.context.Context`"

#: ../../source/ref-api/flwr.server.LegacyContext.rst:36:<autosummary>:1
#, fuzzy
msgid ":py:obj:`config <flwr.server.LegacyContext.config>`\\"
msgstr "server.strategy.Strategy"

#: ../../source/ref-api/flwr.server.LegacyContext.rst:36:<autosummary>:1
#, fuzzy
msgid ":py:obj:`strategy <flwr.server.LegacyContext.strategy>`\\"
msgstr "server.strategy.Strategy"

#: ../../source/ref-api/flwr.server.LegacyContext.rst:36:<autosummary>:1
#, fuzzy
msgid ":py:obj:`client_manager <flwr.server.LegacyContext.client_manager>`\\"
msgstr ":py:obj:`client_manager <flwr.server.LegacyContext.client_manager>`\\"

#: ../../source/ref-api/flwr.server.LegacyContext.rst:36:<autosummary>:1
#, fuzzy
msgid ":py:obj:`history <flwr.server.LegacyContext.history>`\\"
msgstr "server.strategy.Strategy"

#: ../../source/ref-api/flwr.server.LegacyContext.rst:36:<autosummary>:1
#, fuzzy
msgid ":py:obj:`run_id <flwr.server.LegacyContext.run_id>`\\"
msgstr "server.strategy.Strategy"

#: ../../source/ref-api/flwr.server.LegacyContext.rst:36:<autosummary>:1
#, fuzzy
msgid ":py:obj:`node_id <flwr.server.LegacyContext.node_id>`\\"
msgstr "server.strategy.Strategy"

#: ../../source/ref-api/flwr.server.LegacyContext.rst:36:<autosummary>:1
#, fuzzy
msgid ":py:obj:`node_config <flwr.server.LegacyContext.node_config>`\\"
msgstr "server.strategy.Strategy"

#: ../../source/ref-api/flwr.server.LegacyContext.rst:36:<autosummary>:1
#, fuzzy
msgid ":py:obj:`state <flwr.server.LegacyContext.state>`\\"
msgstr "server.strategy.Strategy"

#: ../../source/ref-api/flwr.server.LegacyContext.rst:36:<autosummary>:1
#, fuzzy
msgid ":py:obj:`run_config <flwr.server.LegacyContext.run_config>`\\"
msgstr "server.strategy.Strategy"

#: ../../source/ref-api/flwr.server.Server.rst:2
msgid "Server"
msgstr "服务器"

#: flwr.server.server.Server.client_manager:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`client_manager <flwr.server.Server.client_manager>`\\ \\(\\)"
msgstr ":py:obj:`client_manager <flwr.server.Server.client_manager>`\\ \\(\\)"

#: flwr.server.server.Server.client_manager:1
#: flwr.server.server.Server.client_manager:1:<autosummary>:1 of
#, fuzzy
msgid "Return ClientManager."
msgstr "返回客户端（本身）。"

#: flwr.server.server.Server.client_manager:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`disconnect_all_clients "
"<flwr.server.Server.disconnect_all_clients>`\\ \\(timeout\\)"
msgstr ""
":py:obj:`disconnect_all_clients "
"<flwr.server.Server.disconnect_all_clients>`\\ \\(timeout\\)"

#: flwr.server.server.Server.client_manager:1:<autosummary>:1
#: flwr.server.server.Server.disconnect_all_clients:1 of
#, fuzzy
msgid "Send shutdown signal to all clients."
msgstr "向所有客户端发送关闭信号。"

#: flwr.server.server.Server.client_manager:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`evaluate_round <flwr.server.Server.evaluate_round>`\\ "
"\\(server\\_round\\, timeout\\)"
msgstr ""
":py:obj:`evaluate_round <flwr.server.Server.evaluate_round>`\\ "
"\\(server\\_round\\, timeout\\)"

#: flwr.server.server.Server.client_manager:1:<autosummary>:1
#: flwr.server.server.Server.evaluate_round:1 of
#, fuzzy
msgid "Validate current global model on a number of clients."
msgstr "当前（全局）模型参数。"

#: flwr.server.server.Server.client_manager:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`fit <flwr.server.Server.fit>`\\ \\(num\\_rounds\\, timeout\\)"
msgstr ":py:obj:`fit <flwr.server.Server.fit>`\\ \\(num\\_rounds\\, timeout\\)"

#: flwr.server.server.Server.client_manager:1:<autosummary>:1
#: flwr.server.server.Server.fit:1 of
#, fuzzy
msgid "Run federated averaging for a number of rounds."
msgstr "联邦平均动量策略。"

#: flwr.server.server.Server.client_manager:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`fit_round <flwr.server.Server.fit_round>`\\ \\(server\\_round\\,"
" timeout\\)"
msgstr ""
":py:obj:`fit_round <flwr.server.Server.fit_round>`\\ \\(server\\_round\\,"
" timeout\\)"

#: flwr.server.server.Server.client_manager:1:<autosummary>:1
#: flwr.server.server.Server.fit_round:1 of
#, fuzzy
msgid "Perform a single round of federated averaging."
msgstr "本轮联邦学习。"

#: flwr.server.server.Server.client_manager:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`set_max_workers <flwr.server.Server.set_max_workers>`\\ "
"\\(max\\_workers\\)"
msgstr ""
":py:obj:`set_max_workers <flwr.server.Server.set_max_workers>`\\ "
"\\(max\\_workers\\)"

#: flwr.server.server.Server.client_manager:1:<autosummary>:1
#: flwr.server.server.Server.set_max_workers:1 of
#, fuzzy
msgid "Set the max_workers used by ThreadPoolExecutor."
msgstr "设置 ThreadPoolExecutor 使用的最大工作器数。"

#: flwr.server.server.Server.client_manager:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`set_strategy <flwr.server.Server.set_strategy>`\\ \\(strategy\\)"
msgstr ":py:obj:`set_strategy <flwr.server.Server.set_strategy>`\\ \\(strategy\\)"

#: flwr.server.server.Server.client_manager:1:<autosummary>:1
#: flwr.server.server.Server.set_strategy:1 of
#, fuzzy
msgid "Replace server strategy."
msgstr "server.strategy"

#: ../../source/ref-api/flwr.server.ServerApp.rst:2
#, fuzzy
msgid "ServerApp"
msgstr "服务器"

#: flwr.server.server_app.ServerApp:5 of
#, fuzzy
msgid "Use the `ServerApp` with an existing `Strategy`:"
msgstr "使用现有策略"

#: flwr.server.server_app.ServerApp:17 of
#, fuzzy
msgid "Use the `ServerApp` with a custom main function:"
msgstr "使用带有自定义主函数的 `ServerApp`："

#: flwr.server.server_app.ServerApp.main:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`main <flwr.server.ServerApp.main>`\\ \\(\\)"
msgstr "server.strategy.Strategy"

#: flwr.server.server_app.ServerApp.main:1
#: flwr.server.server_app.ServerApp.main:1:<autosummary>:1 of
#, fuzzy
msgid "Return a decorator that registers the main fn with the server app."
msgstr "返回向服务器应用程序注册 main fn 的装饰器。"

#: ../../source/ref-api/flwr.server.ServerAppComponents.rst:2
#, fuzzy
msgid "ServerAppComponents"
msgstr "服务器"

#: flwr.server.serverapp_components.ServerAppComponents:3 of
#, fuzzy
msgid ""
"A server implementation, either `flwr.server.Server` or a subclass "
"thereof. If no instance is provided, one will be created internally."
msgstr "服务器实现，可以是 `flwr.server.Server` 或其子类。如果没有提供实例，`start_server` 将创建一个。"

#: flwr.server.app.start_server:14
#: flwr.server.serverapp_components.ServerAppComponents:6
#: flwr.simulation.legacy_app.start_simulation:34 of
msgid ""
"Currently supported values are `num_rounds` (int, default: 1) and "
"`round_timeout` in seconds (float, default: None)."
msgstr "目前支持的值有：`num_rounds`（int，默认值：1）和以秒为单位的`round_timeout`（float，默认值：无）。"

#: flwr.server.serverapp_components.ServerAppComponents:9 of
#, fuzzy
msgid ""
"An implementation of the abstract base class "
"`flwr.server.strategy.Strategy`. If no strategy is provided, then "
"`flwr.server.strategy.FedAvg` will be used."
msgstr ""
"抽象基类 `flwr.server.strategy.Strategy` 的实现。如果没有提供策略，`start_server` 将使用 "
"`flwr.server.strategy.FedAvg`。"

#: flwr.server.serverapp_components.ServerAppComponents:13 of
#, fuzzy
msgid ""
"An implementation of the class `flwr.server.ClientManager`. If no "
"implementation is provided, then `flwr.server.SimpleClientManager` will "
"be used."
msgstr ""
"抽象基类 `flwr.server.ClientManager` 的实现。如果没有提供实现，`start_server` 将使用 "
"`flwr.server.client_manager.SimpleClientManager`。"

#: ../../source/ref-api/flwr.server.ServerAppComponents.rst:31:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`client_manager "
"<flwr.server.ServerAppComponents.client_manager>`\\"
msgstr ":py:obj:`client_manager <flwr.server.Server.client_manager>`\\ \\(\\)"

#: ../../source/ref-api/flwr.server.ServerAppComponents.rst:31:<autosummary>:1
#, fuzzy
msgid ":py:obj:`config <flwr.server.ServerAppComponents.config>`\\"
msgstr "server.strategy.Strategy"

#: ../../source/ref-api/flwr.server.ServerAppComponents.rst:31:<autosummary>:1
#, fuzzy
msgid ":py:obj:`server <flwr.server.ServerAppComponents.server>`\\"
msgstr ":py:obj:`run_server_app <flwr.server.run_server_app>`\\ \\(\\)"

#: ../../source/ref-api/flwr.server.ServerAppComponents.rst:31:<autosummary>:1
#, fuzzy
msgid ":py:obj:`strategy <flwr.server.ServerAppComponents.strategy>`\\"
msgstr "server.strategy.Strategy"

#: ../../source/ref-api/flwr.server.ServerConfig.rst:2
#, fuzzy
msgid "ServerConfig"
msgstr "服务器"

#: flwr.server.server_config.ServerConfig:3 of
#, fuzzy
msgid ""
"All attributes have default values which allows users to configure just "
"the ones they care about."
msgstr "所有属性都有默认值，用户只需配置自己关心的属性即可。"

#: ../../source/ref-api/flwr.server.ServerConfig.rst:29:<autosummary>:1
#, fuzzy
msgid ":py:obj:`num_rounds <flwr.server.ServerConfig.num_rounds>`\\"
msgstr ":py:obj:`num_rounds <flwr.server.ServerConfig.num_rounds>`\\"

#: ../../source/ref-api/flwr.server.ServerConfig.rst:29:<autosummary>:1
#, fuzzy
msgid ":py:obj:`round_timeout <flwr.server.ServerConfig.round_timeout>`\\"
msgstr ":py:obj:`round_timeout <flwr.server.ServerConfig.round_timeout>`\\"

#: ../../source/ref-api/flwr.server.SimpleClientManager.rst:2
#, fuzzy
msgid "SimpleClientManager"
msgstr "SimpleClientManager"

#: flwr.server.client_manager.SimpleClientManager:1 of
#, fuzzy
msgid "Bases: :py:class:`~flwr.server.client_manager.ClientManager`"
msgstr "Bases: :py:class:`~flwr.server.client_manager.ClientManager`"

#: flwr.server.client_manager.SimpleClientManager.all:1:<autosummary>:1 of
#, fuzzy
msgid ":py:obj:`all <flwr.server.SimpleClientManager.all>`\\ \\(\\)"
msgstr ":py:obj:`all <flwr.server.SimpleClientManager.all>`\\ \\(\\)"

#: flwr.server.client_manager.SimpleClientManager.all:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`num_available <flwr.server.SimpleClientManager.num_available>`\\"
" \\(\\)"
msgstr ""
":py:obj:`num_available <flwr.server.SimpleClientManager.num_available>`\\"
" \\(\\)"

#: flwr.server.client_manager.SimpleClientManager.all:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`register <flwr.server.SimpleClientManager.register>`\\ "
"\\(client\\)"
msgstr ""
":py:obj:`register <flwr.server.SimpleClientManager.register>`\\ "
"\\(client\\)"

#: flwr.server.client_manager.SimpleClientManager.all:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`sample <flwr.server.SimpleClientManager.sample>`\\ "
"\\(num\\_clients\\[\\, min\\_num\\_clients\\, criterion\\]\\)"
msgstr ""
":py:obj:`sample <flwr.server.SimpleClientManager.sample>`\\ "
"\\(num\\_clients\\[\\, min\\_num\\_clients\\, criterion\\]\\)"

#: flwr.server.client_manager.SimpleClientManager.all:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`unregister <flwr.server.SimpleClientManager.unregister>`\\ "
"\\(client\\)"
msgstr ""
":py:obj:`unregister <flwr.server.SimpleClientManager.unregister>`\\ "
"\\(client\\)"

#: flwr.server.client_manager.SimpleClientManager.all:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`wait_for <flwr.server.SimpleClientManager.wait_for>`\\ "
"\\(num\\_clients\\[\\, timeout\\]\\)"
msgstr ""
":py:obj:`wait_for <flwr.server.SimpleClientManager.wait_for>`\\ "
"\\(num\\_clients\\[\\, timeout\\]\\)"

#: flwr.server.client_manager.SimpleClientManager.wait_for:3 of
#, fuzzy
msgid ""
"Blocks until the requested number of clients is available or until a "
"timeout is reached. Current timeout default: 1 day."
msgstr "阻塞，直到请求的客户端数量可用或达到超时为止。当前超时默认值：1 天。"

#: flwr.server.client_manager.SimpleClientManager.wait_for:6 of
#, fuzzy
msgid "The number of clients to wait for."
msgstr "需要等待的客户数量。"

#: flwr.server.client_manager.SimpleClientManager.wait_for:8 of
#, fuzzy
msgid "The time in seconds to wait for, defaults to 86400 (24h)."
msgstr "以秒为单位的等待时间，默认为 86400（24 小时）。"

#: flwr.server.client_manager.SimpleClientManager.wait_for:11 of
#, fuzzy
msgid "**success**"
msgstr "**success**"

#: ../../source/ref-api/flwr.server.run_server_app.rst:2
#, fuzzy
msgid "run\\_server\\_app"
msgstr "服务器"

#: ../../source/ref-api/flwr.server.run_superlink.rst:2
#, fuzzy
msgid "run\\_superlink"
msgstr "flower-superlink"

#: ../../source/ref-api/flwr.server.start_server.rst:2
#, fuzzy
msgid "start\\_server"
msgstr "server.start_server"

#: flwr.server.app.start_server:5 of
msgid ""
"This function is deprecated since 1.13.0. Use the :code:`flower-"
"superlink` command instead to start a SuperLink."
msgstr ""

#: flwr.server.app.start_server:8 of
msgid "The IPv4 or IPv6 address of the server. Defaults to `\"[::]:8080\"`."
msgstr "服务器的 IPv4 或 IPv6 地址。默认为 `\"[::]:8080\"。"

#: flwr.server.app.start_server:10 of
msgid ""
"A server implementation, either `flwr.server.Server` or a subclass "
"thereof. If no instance is provided, then `start_server` will create one."
msgstr "服务器实现，可以是 `flwr.server.Server` 或其子类。如果没有提供实例，`start_server` 将创建一个。"

#: flwr.server.app.start_server:17 of
msgid ""
"An implementation of the abstract base class "
"`flwr.server.strategy.Strategy`. If no strategy is provided, then "
"`start_server` will use `flwr.server.strategy.FedAvg`."
msgstr ""
"抽象基类 `flwr.server.strategy.Strategy` 的实现。如果没有提供策略，`start_server` 将使用 "
"`flwr.server.strategy.FedAvg`。"

#: flwr.server.app.start_server:21 of
msgid ""
"An implementation of the abstract base class `flwr.server.ClientManager`."
" If no implementation is provided, then `start_server` will use "
"`flwr.server.client_manager.SimpleClientManager`."
msgstr ""
"抽象基类 `flwr.server.ClientManager` 的实现。如果没有提供实现，`start_server` 将使用 "
"`flwr.server.client_manager.SimpleClientManager`。"

#: flwr.server.app.start_server:26 of
msgid ""
"The maximum length of gRPC messages that can be exchanged with the Flower"
" clients. The default should be sufficient for most models. Users who "
"train very large models might need to increase this value. Note that the "
"Flower clients need to be started with the same value (see "
"`flwr.client.start_client`), otherwise clients will not know about the "
"increased limit and block larger messages."
msgstr ""
"可与 Flower 客户端交换的 gRPC 消息的最大长度：默认值对大多数模型都足够了。训练超大模型的用户可能需要增加该值。请注意，Flower "
"客户端需要以相同的值启动（请参阅 `flwr.client.start_client`），否则客户端将不知道已增加的限制并阻止更大的消息。"

#: flwr.server.app.start_server:33 of
msgid ""
"Tuple containing root certificate, server certificate, and private key to"
" start a secure SSL-enabled server. The tuple is expected to have three "
"bytes elements in the following order:      * CA certificate.     * "
"server certificate.     * server private key."
msgstr ""
"包含根证书、服务器证书和私钥的元组，用于启动启用 SSL 的安全服务器。元组应按以下顺序包含三个字节元素： * CA 证书，* 服务器证书， * "
"服务器私钥。"

#: flwr.server.app.start_server:33 of
msgid ""
"Tuple containing root certificate, server certificate, and private key to"
" start a secure SSL-enabled server. The tuple is expected to have three "
"bytes elements in the following order:"
msgstr "包含根证书、服务器证书和私钥的元组，用于启动启用 SSL 的安全服务器。元组应按以下顺序包含三个字节元素："

#: flwr.server.app.start_server:37 of
msgid "CA certificate."
msgstr "CA 证书。"

#: flwr.server.app.start_server:38 of
msgid "server certificate."
msgstr "服务器证书。"

#: flwr.server.app.start_server:39 of
msgid "server private key."
msgstr "服务器私人密钥。"

#: flwr.server.app.start_server:42 of
msgid "**hist** -- Object containing training and evaluation metrics."
msgstr "**hist** -- 包含训练和评估指标的对象。"

#: flwr.server.app.start_server:47 of
msgid "Starting an insecure server:"
msgstr "启动不安全的服务器："

#: flwr.server.app.start_server:51 of
msgid "Starting an SSL-enabled server:"
msgstr "启动支持 SSL 的服务器："

#: ../../source/ref-api/flwr.server.strategy.rst:2
#, fuzzy
msgid "strategy"
msgstr "Krum 策略。"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`Bulyan <flwr.server.strategy.Bulyan>`\\ \\(\\*\\, "
"fraction\\_fit\\, fraction\\_evaluate\\, ...\\)"
msgstr ""
":py:obj:`Bulyan <flwr.server.strategy.Bulyan>`\\ \\(\\*\\, "
"fraction\\_fit\\, fraction\\_evaluate\\, ...\\)"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.bulyan.Bulyan:1 of
msgid "Bulyan strategy."
msgstr "Bulyan 策略。"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`DPFedAvgAdaptive <flwr.server.strategy.DPFedAvgAdaptive>`\\ "
"\\(strategy\\, num\\_sampled\\_clients\\)"
msgstr ""
":py:obj:`DPFedAvgAdaptive <flwr.server.strategy.DPFedAvgAdaptive>`\\ "
"\\(strategy\\, num\\_sampled\\_clients\\)"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.dpfedavg_adaptive.DPFedAvgAdaptive:1 of
msgid "Wrapper for configuring a Strategy for DP with Adaptive Clipping."
msgstr "用于配置具有自适应剪切功能的 DP 策略的包装器。"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`DPFedAvgFixed <flwr.server.strategy.DPFedAvgFixed>`\\ "
"\\(strategy\\, num\\_sampled\\_clients\\, ...\\)"
msgstr ""
":py:obj:`DPFedAvgFixed <flwr.server.strategy.DPFedAvgFixed>`\\ "
"\\(strategy\\, num\\_sampled\\_clients\\, ...\\)"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed:1 of
msgid "Wrapper for configuring a Strategy for DP with Fixed Clipping."
msgstr "封装器，用于为具有固定剪切功能的 DP 配置策略。"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`DifferentialPrivacyClientSideAdaptiveClipping "
"<flwr.server.strategy.DifferentialPrivacyClientSideAdaptiveClipping>`\\ "
"\\(...\\)"
msgstr ""
":py:obj:`DifferentialPrivacyClientSideAdaptiveClipping "
"<flwr.server.strategy.DifferentialPrivacyClientSideAdaptiveClipping>`\\ "
"\\(...\\)"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping:1
#: of
#, fuzzy
msgid "Strategy wrapper for central DP with client-side adaptive clipping."
msgstr "用于配置具有自适应剪切功能的 DP 策略的包装器。"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`DifferentialPrivacyClientSideFixedClipping "
"<flwr.server.strategy.DifferentialPrivacyClientSideFixedClipping>`\\ "
"\\(...\\)"
msgstr ""
":py:obj:`DifferentialPrivacyClientSideFixedClipping "
"<flwr.server.strategy.DifferentialPrivacyClientSideFixedClipping>`\\ "
"\\(...\\)"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping:1
#: of
#, fuzzy
msgid "Strategy wrapper for central DP with client-side fixed clipping."
msgstr "封装器，用于为具有固定剪切功能的 DP 配置策略。"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`DifferentialPrivacyServerSideAdaptiveClipping "
"<flwr.server.strategy.DifferentialPrivacyServerSideAdaptiveClipping>`\\ "
"\\(...\\)"
msgstr ""
":py:obj:`DifferentialPrivacyServerSideAdaptiveClipping "
"<flwr.server.strategy.DifferentialPrivacyServerSideAdaptiveClipping>`\\ "
"\\(...\\)"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping:1
#: of
#, fuzzy
msgid "Strategy wrapper for central DP with server-side adaptive clipping."
msgstr "用于配置具有自适应剪切功能的 DP 策略的包装器。"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`DifferentialPrivacyServerSideFixedClipping "
"<flwr.server.strategy.DifferentialPrivacyServerSideFixedClipping>`\\ "
"\\(...\\)"
msgstr ""
":py:obj:`DifferentialPrivacyServerSideFixedClipping "
"<flwr.server.strategy.DifferentialPrivacyServerSideFixedClipping>`\\ "
"\\(...\\)"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping:1
#: of
#, fuzzy
msgid "Strategy wrapper for central DP with server-side fixed clipping."
msgstr "封装器，用于为具有固定剪切功能的 DP 配置策略。"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`FaultTolerantFedAvg "
"<flwr.server.strategy.FaultTolerantFedAvg>`\\ \\(\\*\\[\\, "
"fraction\\_fit\\, ...\\]\\)"
msgstr ""
":py:obj:`FaultTolerantFedAvg "
"<flwr.server.strategy.FaultTolerantFedAvg>`\\ \\(\\*\\[\\, "
"fraction\\_fit\\, ...\\]\\)"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg:1 of
msgid "Configurable fault-tolerant FedAvg strategy implementation."
msgstr "可配置的容错 FedAvg 策略实施。"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`FedAdagrad <flwr.server.strategy.FedAdagrad>`\\ \\(\\*\\[\\, "
"fraction\\_fit\\, ...\\]\\)"
msgstr ""
":py:obj:`FedAdagrad <flwr.server.strategy.FedAdagrad>`\\ \\(\\*\\[\\, "
"fraction\\_fit\\, ...\\]\\)"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.fedadagrad.FedAdagrad:1 of
msgid "FedAdagrad strategy - Adaptive Federated Optimization using Adagrad."
msgstr "FedAdagrad 策略 - 使用 Adagrad 进行自适应联合优化。"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`FedAdam <flwr.server.strategy.FedAdam>`\\ \\(\\*\\[\\, "
"fraction\\_fit\\, ...\\]\\)"
msgstr ""
":py:obj:`FedAdam <flwr.server.strategy.FedAdam>`\\ \\(\\*\\[\\, "
"fraction\\_fit\\, ...\\]\\)"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.fedadam.FedAdam:1 of
msgid "FedAdam - Adaptive Federated Optimization using Adam."
msgstr "FedAdam - 使用 Adam 进行自适应联合优化。"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`FedAvg <flwr.server.strategy.FedAvg>`\\ \\(\\*\\[\\, "
"fraction\\_fit\\, fraction\\_evaluate\\, ...\\]\\)"
msgstr ""
":py:obj:`FedAvg <flwr.server.strategy.FedAvg>`\\ \\(\\*\\[\\, "
"fraction\\_fit\\, fraction\\_evaluate\\, ...\\]\\)"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.fedavg.FedAvg:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid:1 of
msgid "Federated Averaging strategy."
msgstr "联邦平均策略。"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`FedAvgAndroid <flwr.server.strategy.FedAvgAndroid>`\\ "
"\\(\\*\\[\\, fraction\\_fit\\, ...\\]\\)"
msgstr ""
":py:obj:`FedAvgAndroid <flwr.server.strategy.FedAvgAndroid>`\\ "
"\\(\\*\\[\\, fraction\\_fit\\, ...\\]\\)"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`FedAvgM <flwr.server.strategy.FedAvgM>`\\ \\(\\*\\[\\, "
"fraction\\_fit\\, ...\\]\\)"
msgstr ""
":py:obj:`FedAvgM <flwr.server.strategy.FedAvgM>`\\ \\(\\*\\[\\, "
"fraction\\_fit\\, ...\\]\\)"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.fedavgm.FedAvgM:1 of
msgid "Federated Averaging with Momentum strategy."
msgstr "联邦平均动量策略。"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`FedMedian <flwr.server.strategy.FedMedian>`\\ \\(\\*\\[\\, "
"fraction\\_fit\\, ...\\]\\)"
msgstr ""
":py:obj:`FedMedian <flwr.server.strategy.FedMedian>`\\ \\(\\*\\[\\, "
"fraction\\_fit\\, ...\\]\\)"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.fedmedian.FedMedian:1 of
#, fuzzy
msgid "Configurable FedMedian strategy implementation."
msgstr "可配置的 FedAvg 策略实施。"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`FedOpt <flwr.server.strategy.FedOpt>`\\ \\(\\*\\[\\, "
"fraction\\_fit\\, fraction\\_evaluate\\, ...\\]\\)"
msgstr ""
":py:obj:`FedOpt <flwr.server.strategy.FedOpt>`\\ \\(\\*\\[\\, "
"fraction\\_fit\\, fraction\\_evaluate\\, ...\\]\\)"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.fedopt.FedOpt:1 of
#, fuzzy
msgid "Federated Optim strategy."
msgstr "联邦优化策略。"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`FedProx <flwr.server.strategy.FedProx>`\\ \\(\\*\\[\\, "
"fraction\\_fit\\, ...\\]\\)"
msgstr ""
":py:obj:`FedProx <flwr.server.strategy.FedProx>`\\ \\(\\*\\[\\, "
"fraction\\_fit\\, ...\\]\\)"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.fedprox.FedProx:1 of
msgid "Federated Optimization strategy."
msgstr "联邦优化策略。"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`FedTrimmedAvg <flwr.server.strategy.FedTrimmedAvg>`\\ "
"\\(\\*\\[\\, fraction\\_fit\\, ...\\]\\)"
msgstr ""
":py:obj:`FedTrimmedAvg <flwr.server.strategy.FedTrimmedAvg>`\\ "
"\\(\\*\\[\\, fraction\\_fit\\, ...\\]\\)"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg:1 of
msgid "Federated Averaging with Trimmed Mean [Dong Yin, et al., 2021]."
msgstr "带修剪均值的联邦平均法[Dong Yin 等，2021]。"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`FedXgbBagging <flwr.server.strategy.FedXgbBagging>`\\ "
"\\(\\[evaluate\\_function\\]\\)"
msgstr ""
":py:obj:`FedXgbBagging <flwr.server.strategy.FedXgbBagging>`\\ "
"\\(\\[evaluate\\_function\\]\\)"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging:1 of
#, fuzzy
msgid "Configurable FedXgbBagging strategy implementation."
msgstr "可配置的 FedXgbNAvg 策略实施。"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`FedXgbCyclic <flwr.server.strategy.FedXgbCyclic>`\\ "
"\\(\\*\\*kwargs\\)"
msgstr ""
":py:obj:`FedXgbCyclic <flwr.server.strategy.FedXgbCyclic>`\\ "
"\\(\\*\\*kwargs\\)"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic:1 of
#, fuzzy
msgid "Configurable FedXgbCyclic strategy implementation."
msgstr "可配置的 FedAvg 策略实施。"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`FedXgbNnAvg <flwr.server.strategy.FedXgbNnAvg>`\\ \\(\\*args\\, "
"\\*\\*kwargs\\)"
msgstr ""
":py:obj:`FedXgbNnAvg <flwr.server.strategy.FedXgbNnAvg>`\\ \\(\\*args\\, "
"\\*\\*kwargs\\)"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.fedxgb_nn_avg.FedXgbNnAvg:1 of
msgid "Configurable FedXgbNnAvg strategy implementation."
msgstr "可配置的 FedXgbNAvg 策略实施。"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`FedYogi <flwr.server.strategy.FedYogi>`\\ \\(\\*\\[\\, "
"fraction\\_fit\\, ...\\]\\)"
msgstr ""
":py:obj:`FedYogi <flwr.server.strategy.FedYogi>`\\ \\(\\*\\[\\, "
"fraction\\_fit\\, ...\\]\\)"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.fedyogi.FedYogi:1 of
msgid "FedYogi [Reddi et al., 2020] strategy."
msgstr "FedYogi [Reddi 等人，2020] 策略。"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`Krum <flwr.server.strategy.Krum>`\\ \\(\\*\\[\\, "
"fraction\\_fit\\, fraction\\_evaluate\\, ...\\]\\)"
msgstr ""
":py:obj:`Krum <flwr.server.strategy.Krum>`\\ \\(\\*\\[\\, "
"fraction\\_fit\\, fraction\\_evaluate\\, ...\\]\\)"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.krum.Krum:1 of
#, fuzzy
msgid "Krum [Blanchard et al., 2017] strategy."
msgstr "FedYogi [Reddi 等人，2020] 策略。"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`QFedAvg <flwr.server.strategy.QFedAvg>`\\ \\(\\*\\[\\, "
"q\\_param\\, qffl\\_learning\\_rate\\, ...\\]\\)"
msgstr ""
":py:obj:`QFedAvg <flwr.server.strategy.QFedAvg>`\\ \\(\\*\\[\\, "
"q\\_param\\, qffl\\_learning\\_rate\\, ...\\]\\)"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.qfedavg.QFedAvg:1 of
msgid "Configurable QFedAvg strategy implementation."
msgstr "可配置的 QFedAvg 策略实施。"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#, fuzzy
msgid ":py:obj:`Strategy <flwr.server.strategy.Strategy>`\\ \\(\\)"
msgstr "server.strategy.Strategy"

#: ../../source/ref-api/flwr.server.strategy.rst:45:<autosummary>:1
#: flwr.server.strategy.strategy.Strategy:1 of
msgid "Abstract base class for server strategy implementations."
msgstr "服务器策略实现的抽象基类。"

#: ../../source/ref-api/flwr.server.strategy.Bulyan.rst:2
#, fuzzy
msgid "Bulyan"
msgstr "Bulyan"

#: flwr.server.strategy.bulyan.Bulyan:1
#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg:1
#: flwr.server.strategy.fedavgm.FedAvgM:1
#: flwr.server.strategy.fedmedian.FedMedian:1
#: flwr.server.strategy.fedopt.FedOpt:1 flwr.server.strategy.fedprox.FedProx:1
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg:1
#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging:1
#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic:1
#: flwr.server.strategy.fedxgb_nn_avg.FedXgbNnAvg:1
#: flwr.server.strategy.krum.Krum:1 flwr.server.strategy.qfedavg.QFedAvg:1 of
#, fuzzy
msgid "Bases: :py:class:`~flwr.server.strategy.fedavg.FedAvg`"
msgstr "server.strategy.DPFedAvgFixed"

#: flwr.server.strategy.bulyan.Bulyan:3 of
msgid "Implementation based on https://arxiv.org/abs/1802.07927."
msgstr "实施基于 https://arxiv.org/abs/1802.07927。"

#: flwr.server.strategy.bulyan.Bulyan:5
#: flwr.server.strategy.fedadagrad.FedAdagrad:5
#: flwr.server.strategy.fedadam.FedAdam:5
#: flwr.server.strategy.fedavg_android.FedAvgAndroid:5
#: flwr.server.strategy.fedavgm.FedAvgM:5 flwr.server.strategy.fedopt.FedOpt:5
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg:5
#: flwr.server.strategy.fedyogi.FedYogi:5 flwr.server.strategy.krum.Krum:5 of
msgid "Fraction of clients used during training. Defaults to 1.0."
msgstr "训练期间使用客户的比例。默认为 1.0。"

#: flwr.server.strategy.bulyan.Bulyan:7
#: flwr.server.strategy.fedadagrad.FedAdagrad:7
#: flwr.server.strategy.fedadam.FedAdam:7
#: flwr.server.strategy.fedavg_android.FedAvgAndroid:7
#: flwr.server.strategy.fedavgm.FedAvgM:7 flwr.server.strategy.fedopt.FedOpt:7
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg:7
#: flwr.server.strategy.fedyogi.FedYogi:7 flwr.server.strategy.krum.Krum:7 of
msgid "Fraction of clients used during validation. Defaults to 1.0."
msgstr "验证过程中使用的客户端比例。默认为 1.0。"

#: flwr.server.strategy.bulyan.Bulyan:9
#: flwr.server.strategy.fedadagrad.FedAdagrad:9
#: flwr.server.strategy.fedadam.FedAdam:9 flwr.server.strategy.fedavg.FedAvg:13
#: flwr.server.strategy.fedavg_android.FedAvgAndroid:9
#: flwr.server.strategy.fedavgm.FedAvgM:9 flwr.server.strategy.fedopt.FedOpt:9
#: flwr.server.strategy.fedprox.FedProx:45
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg:9
#: flwr.server.strategy.fedyogi.FedYogi:9 flwr.server.strategy.krum.Krum:9 of
msgid "Minimum number of clients used during training. Defaults to 2."
msgstr "训练期间使用的最少客户数。默认为 2。"

#: flwr.server.strategy.bulyan.Bulyan:11
#: flwr.server.strategy.fedadagrad.FedAdagrad:11
#: flwr.server.strategy.fedadam.FedAdam:11
#: flwr.server.strategy.fedavg.FedAvg:15
#: flwr.server.strategy.fedavg_android.FedAvgAndroid:11
#: flwr.server.strategy.fedavgm.FedAvgM:11
#: flwr.server.strategy.fedopt.FedOpt:11
#: flwr.server.strategy.fedprox.FedProx:47
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg:11
#: flwr.server.strategy.fedyogi.FedYogi:11 flwr.server.strategy.krum.Krum:11 of
msgid "Minimum number of clients used during validation. Defaults to 2."
msgstr "验证过程中使用的最少客户端数量。默认为 2。"

#: flwr.server.strategy.bulyan.Bulyan:13
#: flwr.server.strategy.fedadagrad.FedAdagrad:13
#: flwr.server.strategy.fedadam.FedAdam:13
#: flwr.server.strategy.fedavg.FedAvg:17
#: flwr.server.strategy.fedavg_android.FedAvgAndroid:13
#: flwr.server.strategy.fedavgm.FedAvgM:13
#: flwr.server.strategy.fedopt.FedOpt:13
#: flwr.server.strategy.fedprox.FedProx:49
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg:13
#: flwr.server.strategy.fedyogi.FedYogi:13 flwr.server.strategy.krum.Krum:13 of
msgid "Minimum number of total clients in the system. Defaults to 2."
msgstr "系统中客户总数的最小值。默认为 2。"

#: flwr.server.strategy.bulyan.Bulyan:15 flwr.server.strategy.krum.Krum:15 of
msgid "Number of malicious clients in the system. Defaults to 0."
msgstr "系统中恶意客户端的数量。默认为 0。"

#: flwr.server.strategy.bulyan.Bulyan:17
#: flwr.server.strategy.fedadagrad.FedAdagrad:15
#: flwr.server.strategy.fedadam.FedAdam:15
#: flwr.server.strategy.fedavg.FedAvg:19
#: flwr.server.strategy.fedavg_android.FedAvgAndroid:15
#: flwr.server.strategy.fedavgm.FedAvgM:15
#: flwr.server.strategy.fedopt.FedOpt:15
#: flwr.server.strategy.fedprox.FedProx:51
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg:15
#: flwr.server.strategy.fedyogi.FedYogi:17
#: flwr.server.strategy.fedyogi.FedYogi:18
#: flwr.server.strategy.fedyogi.FedYogi:19 flwr.server.strategy.krum.Krum:20 of
msgid "Optional function used for validation. Defaults to None."
msgstr "用于验证的可选函数。默认为 \"无\"。"

#: flwr.server.strategy.bulyan.Bulyan:19
#: flwr.server.strategy.fedadagrad.FedAdagrad:17
#: flwr.server.strategy.fedadam.FedAdam:17
#: flwr.server.strategy.fedavg.FedAvg:21
#: flwr.server.strategy.fedavg_android.FedAvgAndroid:17
#: flwr.server.strategy.fedavgm.FedAvgM:17
#: flwr.server.strategy.fedopt.FedOpt:17
#: flwr.server.strategy.fedprox.FedProx:53
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg:17
#: flwr.server.strategy.fedyogi.FedYogi:20 flwr.server.strategy.krum.Krum:22 of
msgid "Function used to configure training. Defaults to None."
msgstr "用于配置训练的功能。默认为 \"无\"。"

#: flwr.server.strategy.bulyan.Bulyan:21
#: flwr.server.strategy.fedadagrad.FedAdagrad:19
#: flwr.server.strategy.fedadam.FedAdam:19
#: flwr.server.strategy.fedavg.FedAvg:23
#: flwr.server.strategy.fedavg_android.FedAvgAndroid:19
#: flwr.server.strategy.fedavgm.FedAvgM:19
#: flwr.server.strategy.fedopt.FedOpt:19
#: flwr.server.strategy.fedprox.FedProx:55
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg:19
#: flwr.server.strategy.fedyogi.FedYogi:22 flwr.server.strategy.krum.Krum:24 of
msgid "Function used to configure validation. Defaults to None."
msgstr "用于配置验证的函数。默认为 \"无\"。"

#: flwr.server.strategy.bulyan.Bulyan:23
#: flwr.server.strategy.fedadagrad.FedAdagrad:25
#: flwr.server.strategy.fedadam.FedAdam:21
#: flwr.server.strategy.fedavg.FedAvg:25
#: flwr.server.strategy.fedavg_android.FedAvgAndroid:21
#: flwr.server.strategy.fedavgm.FedAvgM:21
#: flwr.server.strategy.fedopt.FedOpt:21
#: flwr.server.strategy.fedprox.FedProx:57
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg:21
#: flwr.server.strategy.fedyogi.FedYogi:24 flwr.server.strategy.krum.Krum:26 of
msgid "Whether or not accept rounds containing failures. Defaults to True."
msgstr "是否接受包含失败的轮。默认为 True。"

#: flwr.server.strategy.bulyan.Bulyan:25
#: flwr.server.strategy.fedadagrad.FedAdagrad:27
#: flwr.server.strategy.fedadam.FedAdam:23
#: flwr.server.strategy.fedavg.FedAvg:27
#: flwr.server.strategy.fedavg_android.FedAvgAndroid:24
#: flwr.server.strategy.fedavgm.FedAvgM:23
#: flwr.server.strategy.fedopt.FedOpt:23
#: flwr.server.strategy.fedprox.FedProx:59
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg:23
#: flwr.server.strategy.fedyogi.FedYogi:26 flwr.server.strategy.krum.Krum:28 of
msgid "Initial global model parameters."
msgstr "初始全局模型参数。"

#: flwr.server.strategy.bulyan.Bulyan:27 of
msgid ""
"Byzantine resilient aggregation rule that is used as the first step of "
"the Bulyan (e.g., Krum)"
msgstr "Byzantine弹性聚合规则，用作 Bulyan 的第一步（如 Krum）"

#: flwr.server.strategy.bulyan.Bulyan:29 of
msgid "arguments to the first_aggregation rule"
msgstr "第一聚类规则的参数"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.Bulyan.aggregate_evaluate>`\\ \\(server\\_round\\, "
"results\\, ...\\)"
msgstr ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.Bulyan.aggregate_evaluate>`\\ \\(server\\_round\\, "
"results\\, ...\\)"

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1
#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1
#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1
#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid "Aggregate evaluation losses using weighted average."
msgstr "采用加权平均法计算评估损失总额。"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`aggregate_fit <flwr.server.strategy.Bulyan.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""
":py:obj:`aggregate_fit <flwr.server.strategy.Bulyan.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"

#: flwr.server.strategy.bulyan.Bulyan.aggregate_fit:1
#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid "Aggregate fit results using Bulyan."
msgstr "使用 Bulyan 技术汇总拟合结果。"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.Bulyan.configure_evaluate>`\\ \\(server\\_round\\, "
"parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.Bulyan.configure_evaluate>`\\ \\(server\\_round\\, "
"parameters\\, ...\\)"

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.configure_evaluate:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.configure_evaluate:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.configure_evaluate:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.configure_evaluate:1
#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg.FedAvg.configure_evaluate:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.configure_evaluate:1
#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.configure_evaluate:1
#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.qfedavg.QFedAvg.configure_evaluate:1
#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.strategy.Strategy.configure_evaluate:1 of
msgid "Configure the next round of evaluation."
msgstr "配置下一轮评估。"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`configure_fit <flwr.server.strategy.Bulyan.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_fit <flwr.server.strategy.Bulyan.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.configure_fit:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.configure_fit:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.configure_fit:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.configure_fit:1
#: flwr.server.strategy.dpfedavg_adaptive.DPFedAvgAdaptive.configure_fit:1
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg.FedAvg.configure_fit:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.configure_fit:1
#: flwr.server.strategy.fedprox.FedProx.configure_fit:1
#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.configure_fit:1
#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.qfedavg.QFedAvg.configure_fit:1
#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.strategy.Strategy.configure_fit:1 of
msgid "Configure the next round of training."
msgstr "配置下一轮训练。"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`evaluate <flwr.server.strategy.Bulyan.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""
":py:obj:`evaluate <flwr.server.strategy.Bulyan.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg.FedAvg.evaluate:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.evaluate:1
#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.evaluate:1
#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedxgb_nn_avg.FedXgbNnAvg.evaluate:1
#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid "Evaluate model parameters using an evaluation function."
msgstr "使用评估函数评估模型参数。"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.Bulyan.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.Bulyan.initialize_parameters>`\\ "
"\\(client\\_manager\\)"

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg.FedAvg.initialize_parameters:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.initialize_parameters:1
#: flwr.server.strategy.fedavgm.FedAvgM.initialize_parameters:1
#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1 of
msgid "Initialize global model parameters."
msgstr "初始化全局模型参数。"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.Bulyan.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.Bulyan.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg.FedAvg.num_evaluation_clients:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.num_evaluation_clients:1
#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.qfedavg.QFedAvg.num_evaluation_clients:1 of
msgid "Use a fraction of available clients for evaluation."
msgstr "使用部分可用客户进行评估。"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`num_fit_clients <flwr.server.strategy.Bulyan.num_fit_clients>`\\"
" \\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_fit_clients <flwr.server.strategy.Bulyan.num_fit_clients>`\\"
" \\(num\\_available\\_clients\\)"

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg.FedAvg.num_fit_clients:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.num_fit_clients:1
#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.qfedavg.QFedAvg.num_fit_clients:1 of
msgid "Return the sample size and the required number of available clients."
msgstr "返回样本大小和所需的可用客户数量。"

#: ../../source/ref-api/flwr.server.strategy.DPFedAvgAdaptive.rst:2
msgid "DPFedAvgAdaptive"
msgstr "DPFedAvgAdaptive"

#: flwr.server.strategy.dpfedavg_adaptive.DPFedAvgAdaptive:1 of
#, fuzzy
msgid "Bases: :py:class:`~flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed`"
msgstr "Bases: :py:class:`~flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed`"

#: flwr.server.strategy.dpfedavg_adaptive.DPFedAvgAdaptive:3
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed:3 of
#, fuzzy
msgid "This class is deprecated and will be removed in a future release."
msgstr "该类已被弃用，将在以后的版本中删除。"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.DPFedAvgAdaptive.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"
msgstr ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.DPFedAvgAdaptive.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_evaluate:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_evaluate:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.aggregate_evaluate:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.aggregate_evaluate:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: of
msgid "Aggregate evaluation losses using the given strategy."
msgstr "使用给定的策略汇总评估损失。"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.DPFedAvgAdaptive.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.DPFedAvgAdaptive.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"

#: flwr.server.strategy.dpfedavg_adaptive.DPFedAvgAdaptive.aggregate_fit:1
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: of
msgid "Aggregate training results as in DPFedAvgFixed and update clip norms."
msgstr "汇总 DPFedAvgFixed 中的训练结果并更新片段标准。"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.DPFedAvgAdaptive.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.DPFedAvgAdaptive.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_evaluate:1 of
msgid "Configure the next round of evaluation using the specified strategy."
msgstr "使用指定策略配置下一轮评估。"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`configure_fit "
"<flwr.server.strategy.DPFedAvgAdaptive.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_fit "
"<flwr.server.strategy.DPFedAvgAdaptive.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`evaluate <flwr.server.strategy.DPFedAvgAdaptive.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""
":py:obj:`evaluate <flwr.server.strategy.DPFedAvgAdaptive.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.evaluate:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.evaluate:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.evaluate:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.evaluate:1
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.evaluate:1 of
msgid "Evaluate model parameters using an evaluation function from the strategy."
msgstr "使用策略中的评估函数评估模型参数。"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.DPFedAvgAdaptive.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.DPFedAvgAdaptive.initialize_parameters>`\\ "
"\\(client\\_manager\\)"

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.initialize_parameters:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.initialize_parameters:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.initialize_parameters:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.initialize_parameters:1
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.initialize_parameters:1 of
msgid "Initialize global model parameters using given strategy."
msgstr "使用给定的策略初始化全局模型参数。"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_evaluate:3
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_fit:6
#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:3
#: flwr.server.strategy.strategy.Strategy.aggregate_fit:3
#: flwr.server.strategy.strategy.Strategy.configure_evaluate:3
#: flwr.server.strategy.strategy.Strategy.configure_fit:3
#: flwr.server.strategy.strategy.Strategy.evaluate:6 of
msgid "The current round of federated learning."
msgstr "本轮联邦学习。"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_evaluate:7
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_fit:10
#: flwr.server.strategy.strategy.Strategy.configure_evaluate:7
#: flwr.server.strategy.strategy.Strategy.configure_fit:7
#: flwr.server.strategy.strategy.Strategy.initialize_parameters:3 of
msgid "The client manager which holds all currently connected clients."
msgstr "客户端管理器，用于管理当前连接的所有客户端。"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_evaluate:10
#: flwr.server.strategy.strategy.Strategy.configure_evaluate:10 of
msgid ""
"**evaluate_configuration** -- A list of tuples. Each tuple in the list "
"identifies a `ClientProxy` and the `EvaluateIns` for this particular "
"`ClientProxy`. If a particular `ClientProxy` is not included in this "
"list, it means that this `ClientProxy` will not participate in the next "
"round of federated evaluation."
msgstr ""
"**evaluate_configuration** -- "
"一个元组列表。列表中的每个元组都标识了一个`ClientProxy`和该特定`ClientProxy`的`EvaluateIns`。如果某个特定的"
" `ClientProxy` 未包含在此列表中，则表示该 `ClientProxy` 将不参与下一轮联合评估。"

#: ../../source/ref-api/flwr.server.strategy.DPFedAvgFixed.rst:2
msgid "DPFedAvgFixed"
msgstr "DPFedAvgFixed"

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping:1
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed:1
#: flwr.server.strategy.fedavg.FedAvg:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid:1 of
#, fuzzy
msgid "Bases: :py:class:`~flwr.server.strategy.strategy.Strategy`"
msgstr "Bases: :py:class:`~flwr.server.strategy.strategy.Strategy`"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.DPFedAvgFixed.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"
msgstr ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.DPFedAvgFixed.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.DPFedAvgFixed.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.DPFedAvgFixed.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_fit:1 of
msgid "Aggregate training results using unweighted aggregation."
msgstr "使用非加权汇总法汇总训练结果。"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.DPFedAvgFixed.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.DPFedAvgFixed.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`configure_fit "
"<flwr.server.strategy.DPFedAvgFixed.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_fit "
"<flwr.server.strategy.DPFedAvgFixed.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_fit:1 of
msgid ""
"Configure the next round of training incorporating Differential Privacy "
"(DP)."
msgstr "配置包含差分隐私 (DP) 的下一轮训练。"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`evaluate <flwr.server.strategy.DPFedAvgFixed.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""
":py:obj:`evaluate <flwr.server.strategy.DPFedAvgFixed.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.DPFedAvgFixed.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.DPFedAvgFixed.initialize_parameters>`\\ "
"\\(client\\_manager\\)"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_fit:3 of
msgid ""
"Configuration of the next training round includes information related to "
"DP, such as clip norm and noise stddev."
msgstr "下一轮训练的配置包括与 DP 相关的信息，如片段规范和噪声 stddev。"

#: flwr.server.strategy.dpfedavg_fixed.DPFedAvgFixed.configure_fit:13
#: flwr.server.strategy.strategy.Strategy.configure_fit:10 of
msgid ""
"**fit_configuration** -- A list of tuples. Each tuple in the list "
"identifies a `ClientProxy` and the `FitIns` for this particular "
"`ClientProxy`. If a particular `ClientProxy` is not included in this "
"list, it means that this `ClientProxy` will not participate in the next "
"round of federated learning."
msgstr ""
"**fit_configuration** -- "
"一个元组列表。列表中的每个元组都标识了一个`ClientProxy`和该特定`ClientProxy`的`FitIns'。如果某个特定的`ClientProxy`不在此列表中，则表示该`ClientProxy`将不参加下一轮联合学习。"

#: ../../source/ref-api/flwr.server.strategy.DifferentialPrivacyClientSideAdaptiveClipping.rst:2
#, fuzzy
msgid "DifferentialPrivacyClientSideAdaptiveClipping"
msgstr "DifferentialPrivacyClientSideAdaptiveClipping"

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping:3
#: of
#, fuzzy
msgid "Use `adaptiveclipping_mod` modifier at the client side."
msgstr "在客户端使用 \"adaptiveclipping_mod \"修改器。"

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping:5
#: of
#, fuzzy
msgid ""
"In comparison to `DifferentialPrivacyServerSideAdaptiveClipping`, which "
"performs clipping on the server-side, "
"`DifferentialPrivacyClientSideAdaptiveClipping` expects clipping to "
"happen on the client-side, usually by using the built-in "
"`adaptiveclipping_mod`."
msgstr ""
"与在服务器端执行剪切的 `DifferentialPrivacyServerSideAdaptiveClipping` "
"相比，`DifferentialPrivacyClientSideAdaptiveClipping` 希望在客户端进行剪切，通常使用内置的 "
"`adaptiveclipping_mod`。"

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping:10
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping:3
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping:10
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping:3
#: of
#, fuzzy
msgid "The strategy to which DP functionalities will be added by this wrapper."
msgstr "该包装器将添加 DP 功能的策略。"

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping:12
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping:5
#: of
#, fuzzy
msgid "The noise multiplier for the Gaussian mechanism for model updates."
msgstr "用于模型更新的高斯机制的噪声乘数。"

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping:14
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping:7
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping:17
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping:10
#: of
#, fuzzy
msgid "The number of clients that are sampled on each round."
msgstr "每轮取样的客户数。"

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping:16
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping:9
#: of
#, fuzzy
msgid ""
"The initial value of clipping norm. Defaults to 0.1. Andrew et al. "
"recommends to set to 0.1."
msgstr "剪切规范的初始值。默认为 0.1。安德鲁等人建议设置为 0.1。"

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping:19
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping:12
#: of
#, fuzzy
msgid "The desired quantile of updates which should be clipped. Defaults to 0.5."
msgstr "需要剪切的更新量化值。默认为 0.5。"

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping:21
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping:14
#: of
#, fuzzy
msgid ""
"The learning rate for the clipping norm adaptation. Defaults to 0.2. "
"Andrew et al. recommends to set to 0.2."
msgstr "剪切规范适应的学习率。默认为 0.2。安德鲁等人建议设置为 0.2。"

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping:24
#: of
#, fuzzy
msgid ""
"The stddev of the noise added to the count of updates currently below the"
" estimate. Andrew et al. recommends to set to `expected_num_records/20`"
msgstr "添加到当前低于估计值的更新计数中的噪声的 stddev。安德鲁等人建议设置为 \"expected_num_records/20"

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping:30
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping:23
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping:22
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping:15
#: of
#, fuzzy
msgid "Create a strategy:"
msgstr "server.strategy"

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping:34
#: of
#, fuzzy
msgid ""
"Wrap the strategy with the "
"`DifferentialPrivacyClientSideAdaptiveClipping` wrapper:"
msgstr "用 \"DifferentialPrivacyClientSideAdaptiveClipping \"包装器对策略进行包装："

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping:40
#: of
#, fuzzy
msgid "On the client, add the `adaptiveclipping_mod` to the client-side mods:"
msgstr "在客户端，将 \"adaptiveclipping_mod \"添加到客户端模块中："

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_evaluate>`\\"
" \\(server\\_round\\, results\\, ...\\)"
msgstr ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_evaluate>`\\"
" \\(server\\_round\\, results\\, ...\\)"

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_fit>`\\"
" \\(server\\_round\\, results\\, failures\\)"
msgstr ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_fit>`\\"
" \\(server\\_round\\, results\\, failures\\)"

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_fit:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_fit:1
#: of
#, fuzzy
msgid "Aggregate training results and update clip norms."
msgstr "汇总 DPFedAvgFixed 中的训练结果并更新片段标准。"

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.DifferentialPrivacyClientSideAdaptiveClipping.configure_evaluate>`\\"
" \\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.DifferentialPrivacyClientSideAdaptiveClipping.configure_evaluate>`\\"
" \\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`configure_fit "
"<flwr.server.strategy.DifferentialPrivacyClientSideAdaptiveClipping.configure_fit>`\\"
" \\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_fit "
"<flwr.server.strategy.DifferentialPrivacyClientSideAdaptiveClipping.configure_fit>`\\"
" \\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`evaluate "
"<flwr.server.strategy.DifferentialPrivacyClientSideAdaptiveClipping.evaluate>`\\"
" \\(server\\_round\\, parameters\\)"
msgstr ""
":py:obj:`evaluate "
"<flwr.server.strategy.DifferentialPrivacyClientSideAdaptiveClipping.evaluate>`\\"
" \\(server\\_round\\, parameters\\)"

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyClientSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.DifferentialPrivacyClientSideAdaptiveClipping.initialize_parameters>`\\"
" \\(client\\_manager\\)"
msgstr ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.DifferentialPrivacyClientSideAdaptiveClipping.initialize_parameters>`\\"
" \\(client\\_manager\\)"

#: ../../source/ref-api/flwr.server.strategy.DifferentialPrivacyClientSideFixedClipping.rst:2
#, fuzzy
msgid "DifferentialPrivacyClientSideFixedClipping"
msgstr "差分隐私"

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping:3
#: of
#, fuzzy
msgid "Use `fixedclipping_mod` modifier at the client side."
msgstr "在客户端使用 `fixedclipping_mod` 修改器。"

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping:5
#: of
#, fuzzy
msgid ""
"In comparison to `DifferentialPrivacyServerSideFixedClipping`, which "
"performs clipping on the server-side, "
"`DifferentialPrivacyClientSideFixedClipping` expects clipping to happen "
"on the client-side, usually by using the built-in `fixedclipping_mod`."
msgstr ""
"与在服务器端执行剪切的 \"DifferentialPrivacyServerSideFixedClipping "
"\"相比，\"DifferentialPrivacyClientSideFixedClipping \"希望在客户端进行剪切，通常是使用内置的 "
"\"fixedclipping_mod\"。"

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping:12
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping:5
#: of
#, fuzzy
msgid ""
"The noise multiplier for the Gaussian mechanism for model updates. A "
"value of 1.0 or higher is recommended for strong privacy."
msgstr "模型更新高斯机制的噪声乘数。建议使用 1.0 或更高的值，以获得较强的隐私性。"

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping:26
#: of
#, fuzzy
msgid ""
"Wrap the strategy with the `DifferentialPrivacyClientSideFixedClipping` "
"wrapper:"
msgstr "用 \"DifferentialPrivacyClientSideFixedClipping \"包装器包装策略："

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping:32
#: of
#, fuzzy
msgid "On the client, add the `fixedclipping_mod` to the client-side mods:"
msgstr "在客户端，将 \"fixedclipping_mod \"添加到客户端模块中："

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.DifferentialPrivacyClientSideFixedClipping.aggregate_evaluate>`\\"
" \\(server\\_round\\, results\\, ...\\)"
msgstr ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.DifferentialPrivacyClientSideFixedClipping.aggregate_evaluate>`\\"
" \\(server\\_round\\, results\\, ...\\)"

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.DifferentialPrivacyClientSideFixedClipping.aggregate_fit>`\\"
" \\(server\\_round\\, results\\, failures\\)"
msgstr ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.DifferentialPrivacyClientSideFixedClipping.aggregate_fit>`\\"
" \\(server\\_round\\, results\\, failures\\)"

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.aggregate_fit:1
#: of
#, fuzzy
msgid "Add noise to the aggregated parameters."
msgstr "然后将汇总结果序列化："

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.DifferentialPrivacyClientSideFixedClipping.configure_evaluate>`\\"
" \\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.DifferentialPrivacyClientSideFixedClipping.configure_evaluate>`\\"
" \\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`configure_fit "
"<flwr.server.strategy.DifferentialPrivacyClientSideFixedClipping.configure_fit>`\\"
" \\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_fit "
"<flwr.server.strategy.DifferentialPrivacyClientSideFixedClipping.configure_fit>`\\"
" \\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`evaluate "
"<flwr.server.strategy.DifferentialPrivacyClientSideFixedClipping.evaluate>`\\"
" \\(server\\_round\\, parameters\\)"
msgstr ""
":py:obj:`evaluate "
"<flwr.server.strategy.DifferentialPrivacyClientSideFixedClipping.evaluate>`\\"
" \\(server\\_round\\, parameters\\)"

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyClientSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.DifferentialPrivacyClientSideFixedClipping.initialize_parameters>`\\"
" \\(client\\_manager\\)"
msgstr ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.DifferentialPrivacyClientSideFixedClipping.initialize_parameters>`\\"
" \\(client\\_manager\\)"

#: ../../source/ref-api/flwr.server.strategy.DifferentialPrivacyServerSideAdaptiveClipping.rst:2
#, fuzzy
msgid "DifferentialPrivacyServerSideAdaptiveClipping"
msgstr "DifferentialPrivacyServerSideAdaptiveClipping"

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping:17
#: of
#, fuzzy
msgid ""
"The standard deviation of the noise added to the count of updates below "
"the estimate. Andrew et al. recommends to set to "
"`expected_num_records/20`"
msgstr "添加到低于估计值的更新计数中的噪声标准偏差。安德鲁等人建议设置为 \"expected_num_records/20"

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping:27
#: of
#, fuzzy
msgid ""
"Wrap the strategy with the DifferentialPrivacyServerSideAdaptiveClipping "
"wrapper"
msgstr "用 DifferentialPrivacyServerSideAdaptiveClipping 封装器封装策略"

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_evaluate>`\\"
" \\(server\\_round\\, results\\, ...\\)"
msgstr ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_evaluate>`\\"
" \\(server\\_round\\, results\\, ...\\)"

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_fit>`\\"
" \\(server\\_round\\, results\\, failures\\)"
msgstr ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_fit>`\\"
" \\(server\\_round\\, results\\, failures\\)"

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.DifferentialPrivacyServerSideAdaptiveClipping.configure_evaluate>`\\"
" \\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.DifferentialPrivacyServerSideAdaptiveClipping.configure_evaluate>`\\"
" \\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`configure_fit "
"<flwr.server.strategy.DifferentialPrivacyServerSideAdaptiveClipping.configure_fit>`\\"
" \\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_fit "
"<flwr.server.strategy.DifferentialPrivacyServerSideAdaptiveClipping.configure_fit>`\\"
" \\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`evaluate "
"<flwr.server.strategy.DifferentialPrivacyServerSideAdaptiveClipping.evaluate>`\\"
" \\(server\\_round\\, parameters\\)"
msgstr ""
":py:obj:`evaluate "
"<flwr.server.strategy.DifferentialPrivacyServerSideAdaptiveClipping.evaluate>`\\"
" \\(server\\_round\\, parameters\\)"

#: flwr.server.strategy.dp_adaptive_clipping.DifferentialPrivacyServerSideAdaptiveClipping.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.DifferentialPrivacyServerSideAdaptiveClipping.initialize_parameters>`\\"
" \\(client\\_manager\\)"
msgstr ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.DifferentialPrivacyServerSideAdaptiveClipping.initialize_parameters>`\\"
" \\(client\\_manager\\)"

#: ../../source/ref-api/flwr.server.strategy.DifferentialPrivacyServerSideFixedClipping.rst:2
#, fuzzy
msgid "DifferentialPrivacyServerSideFixedClipping"
msgstr "差分隐私"

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping:19
#: of
#, fuzzy
msgid ""
"Wrap the strategy with the DifferentialPrivacyServerSideFixedClipping "
"wrapper"
msgstr "用 DifferentialPrivacyServerSideFixedClipping 封装器封装策略"

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.DifferentialPrivacyServerSideFixedClipping.aggregate_evaluate>`\\"
" \\(server\\_round\\, results\\, ...\\)"
msgstr ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.DifferentialPrivacyServerSideFixedClipping.aggregate_evaluate>`\\"
" \\(server\\_round\\, results\\, ...\\)"

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.DifferentialPrivacyServerSideFixedClipping.aggregate_fit>`\\"
" \\(server\\_round\\, results\\, failures\\)"
msgstr ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.DifferentialPrivacyServerSideFixedClipping.aggregate_fit>`\\"
" \\(server\\_round\\, results\\, failures\\)"

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.aggregate_fit:1
#: of
#, fuzzy
msgid "Compute the updates, clip, and pass them for aggregation."
msgstr "计算更新、剪辑并将其传递给聚合。"

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.DifferentialPrivacyServerSideFixedClipping.configure_evaluate>`\\"
" \\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.DifferentialPrivacyServerSideFixedClipping.configure_evaluate>`\\"
" \\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`configure_fit "
"<flwr.server.strategy.DifferentialPrivacyServerSideFixedClipping.configure_fit>`\\"
" \\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_fit "
"<flwr.server.strategy.DifferentialPrivacyServerSideFixedClipping.configure_fit>`\\"
" \\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`evaluate "
"<flwr.server.strategy.DifferentialPrivacyServerSideFixedClipping.evaluate>`\\"
" \\(server\\_round\\, parameters\\)"
msgstr ""
":py:obj:`evaluate "
"<flwr.server.strategy.DifferentialPrivacyServerSideFixedClipping.evaluate>`\\"
" \\(server\\_round\\, parameters\\)"

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.DifferentialPrivacyServerSideFixedClipping.initialize_parameters>`\\"
" \\(client\\_manager\\)"
msgstr ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.DifferentialPrivacyServerSideFixedClipping.initialize_parameters>`\\"
" \\(client\\_manager\\)"

#: flwr.server.strategy.dp_fixed_clipping.DifferentialPrivacyServerSideFixedClipping.aggregate_fit:3
#: of
#, fuzzy
msgid "Afterward, add noise to the aggregated parameters."
msgstr "然后，在汇总参数中添加噪声。"

#: ../../source/ref-api/flwr.server.strategy.FaultTolerantFedAvg.rst:2
#, fuzzy
msgid "FaultTolerantFedAvg"
msgstr "server.strategy.FaultTolerantFedAvg"

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FaultTolerantFedAvg.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"
msgstr ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FaultTolerantFedAvg.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.FaultTolerantFedAvg.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.FaultTolerantFedAvg.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_fit:1
#: flwr.server.strategy.fedadagrad.FedAdagrad.aggregate_fit:1
#: flwr.server.strategy.fedadam.FedAdam.aggregate_fit:1
#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg.FedAvg.aggregate_fit:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_fit:1
#: flwr.server.strategy.fedavgm.FedAvgM.aggregate_fit:1
#: flwr.server.strategy.fedxgb_nn_avg.FedXgbNnAvg.aggregate_fit:1
#: flwr.server.strategy.fedyogi.FedYogi.aggregate_fit:1
#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_fit:1 of
msgid "Aggregate fit results using weighted average."
msgstr "使用加权平均法汇总拟合结果。"

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FaultTolerantFedAvg.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FaultTolerantFedAvg.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`configure_fit "
"<flwr.server.strategy.FaultTolerantFedAvg.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_fit "
"<flwr.server.strategy.FaultTolerantFedAvg.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`evaluate <flwr.server.strategy.FaultTolerantFedAvg.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""
":py:obj:`evaluate <flwr.server.strategy.FaultTolerantFedAvg.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FaultTolerantFedAvg.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FaultTolerantFedAvg.initialize_parameters>`\\ "
"\\(client\\_manager\\)"

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FaultTolerantFedAvg.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FaultTolerantFedAvg.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"

#: flwr.server.strategy.fault_tolerant_fedavg.FaultTolerantFedAvg.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FaultTolerantFedAvg.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FaultTolerantFedAvg.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"

#: ../../source/ref-api/flwr.server.strategy.FedAdagrad.rst:2
#: ../../source/ref-changelog.md:1301
msgid "FedAdagrad"
msgstr "FedAdagrad"

#: flwr.server.strategy.fedadagrad.FedAdagrad:1
#: flwr.server.strategy.fedadam.FedAdam:1
#: flwr.server.strategy.fedyogi.FedYogi:1 of
#, fuzzy
msgid "Bases: :py:class:`~flwr.server.strategy.fedopt.FedOpt`"
msgstr "Bases: :py:class:`~flwr.server.strategy.fedopt.FedOpt`"

#: flwr.server.strategy.fedadagrad.FedAdagrad:3
#: flwr.server.strategy.fedadam.FedAdam:3 flwr.server.strategy.fedopt.FedOpt:3
#: flwr.server.strategy.fedyogi.FedYogi:3 of
msgid "Implementation based on https://arxiv.org/abs/2003.00295v5"
msgstr "实施基于 https://arxiv.org/abs/2003.00295v5"

#: flwr.server.strategy.fedadagrad.FedAdagrad:21
#: flwr.server.strategy.fedadagrad.FedAdagrad:23
#: flwr.server.strategy.fedadam.FedAdam:25
#: flwr.server.strategy.fedadam.FedAdam:27
#: flwr.server.strategy.fedavg.FedAvg:29 flwr.server.strategy.fedavg.FedAvg:31
#: flwr.server.strategy.fedopt.FedOpt:25 flwr.server.strategy.fedopt.FedOpt:27
#: flwr.server.strategy.fedprox.FedProx:61
#: flwr.server.strategy.fedprox.FedProx:63
#: flwr.server.strategy.fedyogi.FedYogi:28
#: flwr.server.strategy.fedyogi.FedYogi:30 of
msgid "Metrics aggregation function, optional."
msgstr "指标汇总功能，可选。"

#: flwr.server.strategy.fedadagrad.FedAdagrad:29
#: flwr.server.strategy.fedadam.FedAdam:29
#: flwr.server.strategy.fedopt.FedOpt:29 of
msgid "Server-side learning rate. Defaults to 1e-1."
msgstr "服务器端学习率。默认为 1e-1。"

#: flwr.server.strategy.fedadagrad.FedAdagrad:31
#: flwr.server.strategy.fedadam.FedAdam:31
#: flwr.server.strategy.fedopt.FedOpt:31 of
msgid "Client-side learning rate. Defaults to 1e-1."
msgstr "客户端学习率。默认为 1e-1。"

#: flwr.server.strategy.fedadagrad.FedAdagrad:33
#: flwr.server.strategy.fedadam.FedAdam:37
#: flwr.server.strategy.fedopt.FedOpt:37 of
msgid "Controls the algorithm's degree of adaptability. Defaults to 1e-9."
msgstr "控制算法的适应度。默认为 1e-9。"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedAdagrad.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"
msgstr ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedAdagrad.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`aggregate_fit <flwr.server.strategy.FedAdagrad.aggregate_fit>`\\"
" \\(server\\_round\\, results\\, failures\\)"
msgstr ""
":py:obj:`aggregate_fit <flwr.server.strategy.FedAdagrad.aggregate_fit>`\\"
" \\(server\\_round\\, results\\, failures\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedAdagrad.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedAdagrad.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`configure_fit <flwr.server.strategy.FedAdagrad.configure_fit>`\\"
" \\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_fit <flwr.server.strategy.FedAdagrad.configure_fit>`\\"
" \\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`evaluate <flwr.server.strategy.FedAdagrad.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""
":py:obj:`evaluate <flwr.server.strategy.FedAdagrad.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedAdagrad.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedAdagrad.initialize_parameters>`\\ "
"\\(client\\_manager\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedAdagrad.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedAdagrad.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedAdagrad.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedAdagrad.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"

#: ../../source/ref-api/flwr.server.strategy.FedAdam.rst:2
#, fuzzy
msgid "FedAdam"
msgstr "FedAdagrad"

#: flwr.server.strategy.fedadam.FedAdam:33
#: flwr.server.strategy.fedyogi.FedYogi:36 of
msgid "Momentum parameter. Defaults to 0.9."
msgstr "动量参数。默认为 0.9。"

#: flwr.server.strategy.fedadam.FedAdam:35
#: flwr.server.strategy.fedyogi.FedYogi:38 of
msgid "Second moment parameter. Defaults to 0.99."
msgstr "第二动量参数。默认为 0.99。"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedAdam.aggregate_evaluate>`\\ \\(server\\_round\\,"
" results\\, ...\\)"
msgstr ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedAdam.aggregate_evaluate>`\\ \\(server\\_round\\,"
" results\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`aggregate_fit <flwr.server.strategy.FedAdam.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""
":py:obj:`aggregate_fit <flwr.server.strategy.FedAdam.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedAdam.configure_evaluate>`\\ \\(server\\_round\\,"
" parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedAdam.configure_evaluate>`\\ \\(server\\_round\\,"
" parameters\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`configure_fit <flwr.server.strategy.FedAdam.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_fit <flwr.server.strategy.FedAdam.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`evaluate <flwr.server.strategy.FedAdam.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""
":py:obj:`evaluate <flwr.server.strategy.FedAdam.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedAdam.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedAdam.initialize_parameters>`\\ "
"\\(client\\_manager\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedAdam.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedAdam.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedAdam.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedAdam.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"

#: ../../source/ref-api/flwr.server.strategy.FedAvg.rst:2
#, fuzzy
msgid "FedAvg"
msgstr "DP-FedAvg"

#: flwr.server.strategy.fedavg.FedAvg:3
#: flwr.server.strategy.fedavg_android.FedAvgAndroid:3 of
msgid "Implementation based on https://arxiv.org/abs/1602.05629"
msgstr "实施基于 https://arxiv.org/abs/1602.05629"

#: flwr.server.strategy.fedavg.FedAvg:5 flwr.server.strategy.fedprox.FedProx:37
#: of
msgid ""
"Fraction of clients used during training. In case `min_fit_clients` is "
"larger than `fraction_fit * available_clients`, `min_fit_clients` will "
"still be sampled. Defaults to 1.0."
msgstr ""
"训练过程中使用的客户端比例。如果 `min_fit_clients` 大于 `fraction_fit * "
"available_clients`，则仍会对 `min_fit_clients` 进行采样。默认为 1.0。"

#: flwr.server.strategy.fedavg.FedAvg:9 flwr.server.strategy.fedprox.FedProx:41
#: of
msgid ""
"Fraction of clients used during validation. In case "
"`min_evaluate_clients` is larger than `fraction_evaluate * "
"available_clients`, `min_evaluate_clients` will still be sampled. "
"Defaults to 1.0."
msgstr ""
"验证过程中使用的客户端的比例。如果 `min_evaluate_clients` 大于 `fraction_evaluate * "
"available_clients`，则仍会对 `min_evaluate_clients` 进行采样。默认为 1.0。"

#: flwr.server.strategy.fedavg.FedAvg:33 of
#, fuzzy
msgid "Enable (True) or disable (False) in-place aggregation of model updates."
msgstr "启用（真）或禁用（假）模型更新的就地聚合。"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedAvg.aggregate_evaluate>`\\ \\(server\\_round\\, "
"results\\, ...\\)"
msgstr ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedAvg.aggregate_evaluate>`\\ \\(server\\_round\\, "
"results\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`aggregate_fit <flwr.server.strategy.FedAvg.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""
":py:obj:`aggregate_fit <flwr.server.strategy.FedAvg.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedAvg.configure_evaluate>`\\ \\(server\\_round\\, "
"parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedAvg.configure_evaluate>`\\ \\(server\\_round\\, "
"parameters\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`configure_fit <flwr.server.strategy.FedAvg.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_fit <flwr.server.strategy.FedAvg.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`evaluate <flwr.server.strategy.FedAvg.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""
":py:obj:`evaluate <flwr.server.strategy.FedAvg.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedAvg.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedAvg.initialize_parameters>`\\ "
"\\(client\\_manager\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedAvg.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedAvg.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`num_fit_clients <flwr.server.strategy.FedAvg.num_fit_clients>`\\"
" \\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_fit_clients <flwr.server.strategy.FedAvg.num_fit_clients>`\\"
" \\(num\\_available\\_clients\\)"

#: ../../source/ref-api/flwr.server.strategy.FedAvgAndroid.rst:2
#, fuzzy
msgid "FedAvgAndroid"
msgstr "DPFedAvgAdaptive"

#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedAvgAndroid.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"
msgstr ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedAvgAndroid.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"

#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.FedAvgAndroid.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.FedAvgAndroid.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"

#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`bytes_to_ndarray "
"<flwr.server.strategy.FedAvgAndroid.bytes_to_ndarray>`\\ \\(tensor\\)"
msgstr ""
":py:obj:`bytes_to_ndarray "
"<flwr.server.strategy.FedAvgAndroid.bytes_to_ndarray>`\\ \\(tensor\\)"

#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.bytes_to_ndarray:1 of
#, fuzzy
msgid "Deserialize NumPy array from bytes."
msgstr "从字节反序列化 NumPy ndarray。"

#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedAvgAndroid.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedAvgAndroid.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`configure_fit "
"<flwr.server.strategy.FedAvgAndroid.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_fit "
"<flwr.server.strategy.FedAvgAndroid.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`evaluate <flwr.server.strategy.FedAvgAndroid.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""
":py:obj:`evaluate <flwr.server.strategy.FedAvgAndroid.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"

#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedAvgAndroid.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedAvgAndroid.initialize_parameters>`\\ "
"\\(client\\_manager\\)"

#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`ndarray_to_bytes "
"<flwr.server.strategy.FedAvgAndroid.ndarray_to_bytes>`\\ \\(ndarray\\)"
msgstr ""
":py:obj:`ndarray_to_bytes "
"<flwr.server.strategy.FedAvgAndroid.ndarray_to_bytes>`\\ \\(ndarray\\)"

#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.ndarray_to_bytes:1 of
#, fuzzy
msgid "Serialize NumPy array to bytes."
msgstr "将 NumPy ndarray 序列化为字节。"

#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`ndarrays_to_parameters "
"<flwr.server.strategy.FedAvgAndroid.ndarrays_to_parameters>`\\ "
"\\(ndarrays\\)"
msgstr ""
":py:obj:`ndarrays_to_parameters "
"<flwr.server.strategy.FedAvgAndroid.ndarrays_to_parameters>`\\ "
"\\(ndarrays\\)"

#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedAvgAndroid.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedAvgAndroid.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"

#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedAvgAndroid.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedAvgAndroid.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"

#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`parameters_to_ndarrays "
"<flwr.server.strategy.FedAvgAndroid.parameters_to_ndarrays>`\\ "
"\\(parameters\\)"
msgstr ""
":py:obj:`parameters_to_ndarrays "
"<flwr.server.strategy.FedAvgAndroid.parameters_to_ndarrays>`\\ "
"\\(parameters\\)"

#: flwr.server.strategy.fedavg_android.FedAvgAndroid.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedavg_android.FedAvgAndroid.parameters_to_ndarrays:1
#: of
#, fuzzy
msgid "Convert parameters object to NumPy weights."
msgstr "将参数对象转换为 NumPy ndarrays。"

#: ../../source/ref-api/flwr.server.strategy.FedAvgM.rst:2
#, fuzzy
msgid "FedAvgM"
msgstr "DP-FedAvg"

#: flwr.server.strategy.fedavgm.FedAvgM:3 of
#, fuzzy
msgid "Implementation based on https://arxiv.org/abs/1909.06335"
msgstr "实施基于 https://arxiv.org/pdf/1909.06335.pdf"

#: flwr.server.strategy.fedavgm.FedAvgM:25 of
msgid ""
"Server-side learning rate used in server-side optimization. Defaults to "
"1.0."
msgstr "服务器端优化中使用的服务器端学习率。默认为 1.0。"

#: flwr.server.strategy.fedavgm.FedAvgM:28 of
msgid "Server-side momentum factor used for FedAvgM. Defaults to 0.0."
msgstr "用于 FedAvgM 的服务器端动量因子。默认为 0.0。"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedAvgM.aggregate_evaluate>`\\ \\(server\\_round\\,"
" results\\, ...\\)"
msgstr ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedAvgM.aggregate_evaluate>`\\ \\(server\\_round\\,"
" results\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`aggregate_fit <flwr.server.strategy.FedAvgM.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""
":py:obj:`aggregate_fit <flwr.server.strategy.FedAvgM.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedAvgM.configure_evaluate>`\\ \\(server\\_round\\,"
" parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedAvgM.configure_evaluate>`\\ \\(server\\_round\\,"
" parameters\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`configure_fit <flwr.server.strategy.FedAvgM.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_fit <flwr.server.strategy.FedAvgM.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`evaluate <flwr.server.strategy.FedAvgM.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""
":py:obj:`evaluate <flwr.server.strategy.FedAvgM.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedAvgM.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedAvgM.initialize_parameters>`\\ "
"\\(client\\_manager\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedAvgM.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedAvgM.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedAvgM.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedAvgM.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"

#: ../../source/ref-api/flwr.server.strategy.FedMedian.rst:2
#, fuzzy
msgid "FedMedian"
msgstr "联邦医保"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedMedian.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"
msgstr ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedMedian.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`aggregate_fit <flwr.server.strategy.FedMedian.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""
":py:obj:`aggregate_fit <flwr.server.strategy.FedMedian.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedmedian.FedMedian.aggregate_fit:1 of
msgid "Aggregate fit results using median."
msgstr "使用中位数汇总拟合结果。"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedMedian.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedMedian.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`configure_fit <flwr.server.strategy.FedMedian.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_fit <flwr.server.strategy.FedMedian.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`evaluate <flwr.server.strategy.FedMedian.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""
":py:obj:`evaluate <flwr.server.strategy.FedMedian.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedMedian.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedMedian.initialize_parameters>`\\ "
"\\(client\\_manager\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedMedian.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedMedian.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedMedian.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedMedian.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"

#: ../../source/ref-api/flwr.server.strategy.FedOpt.rst:2
#, fuzzy
msgid "FedOpt"
msgstr "FedOpt"

#: flwr.server.strategy.fedopt.FedOpt:33 of
msgid "Momentum parameter. Defaults to 0.0."
msgstr "动量参数。默认为 0.0。"

#: flwr.server.strategy.fedopt.FedOpt:35 of
msgid "Second moment parameter. Defaults to 0.0."
msgstr "第二动量参数。默认为 0.0。"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedOpt.aggregate_evaluate>`\\ \\(server\\_round\\, "
"results\\, ...\\)"
msgstr ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedOpt.aggregate_evaluate>`\\ \\(server\\_round\\, "
"results\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`aggregate_fit <flwr.server.strategy.FedOpt.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""
":py:obj:`aggregate_fit <flwr.server.strategy.FedOpt.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedOpt.configure_evaluate>`\\ \\(server\\_round\\, "
"parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedOpt.configure_evaluate>`\\ \\(server\\_round\\, "
"parameters\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`configure_fit <flwr.server.strategy.FedOpt.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_fit <flwr.server.strategy.FedOpt.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`evaluate <flwr.server.strategy.FedOpt.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""
":py:obj:`evaluate <flwr.server.strategy.FedOpt.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedOpt.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedOpt.initialize_parameters>`\\ "
"\\(client\\_manager\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedOpt.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedOpt.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`num_fit_clients <flwr.server.strategy.FedOpt.num_fit_clients>`\\"
" \\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_fit_clients <flwr.server.strategy.FedOpt.num_fit_clients>`\\"
" \\(num\\_available\\_clients\\)"

#: ../../source/ref-api/flwr.server.strategy.FedProx.rst:2
#, fuzzy
msgid "FedProx"
msgstr "FedProx"

#: flwr.server.strategy.fedprox.FedProx:3 of
msgid "Implementation based on https://arxiv.org/abs/1812.06127"
msgstr "实施基于 https://arxiv.org/abs/1812.06127"

#: flwr.server.strategy.fedprox.FedProx:5 of
msgid ""
"The strategy in itself will not be different than FedAvg, the client "
"needs to be adjusted. A proximal term needs to be added to the loss "
"function during the training:"
msgstr "策略本身与 FedAvg 并无不同，客户端需要进行调整。在训练过程中，需要在损失函数中添加一个近端项："

#: flwr.server.strategy.fedprox.FedProx:9 of
msgid ""
"\\\\frac{\\\\mu}{2} || w - w^t ||^2\n"
"\n"
msgstr ""
"\\\\frac{\\\\mu}{2} || w - w^t ||^2\n"
"\n"

#: flwr.server.strategy.fedprox.FedProx:12 of
msgid ""
"Where $w^t$ are the global parameters and $w$ are the local weights the "
"function will be optimized with."
msgstr "其中，$w^t$ 是全局参数，$w$ 是优化函数的局部权重。"

#: flwr.server.strategy.fedprox.FedProx:15 of
msgid "In PyTorch, for example, the loss would go from:"
msgstr "例如，在 PyTorch 中，损失将从："

#: flwr.server.strategy.fedprox.FedProx:21 of
msgid "To:"
msgstr "致："

#: flwr.server.strategy.fedprox.FedProx:30 of
msgid ""
"With `global_params` being a copy of the parameters before the training "
"takes place."
msgstr "其中，\"global_params \"是训练前的参数副本。"

#: flwr.server.strategy.fedprox.FedProx:65 of
msgid ""
"The weight of the proximal term used in the optimization. 0.0 makes this "
"strategy equivalent to FedAvg, and the higher the coefficient, the more "
"regularization will be used (that is, the client parameters will need to "
"be closer to the server parameters during training)."
msgstr ""
"优化中使用的近端项权重。0.0 使该策略等同于 "
"FedAvg，系数越大，使用的正则化就越多（也就是说，在训练过程中，客户端参数需要更接近服务器参数）。"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedProx.aggregate_evaluate>`\\ \\(server\\_round\\,"
" results\\, ...\\)"
msgstr ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedProx.aggregate_evaluate>`\\ \\(server\\_round\\,"
" results\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`aggregate_fit <flwr.server.strategy.FedProx.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""
":py:obj:`aggregate_fit <flwr.server.strategy.FedProx.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedProx.configure_evaluate>`\\ \\(server\\_round\\,"
" parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedProx.configure_evaluate>`\\ \\(server\\_round\\,"
" parameters\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`configure_fit <flwr.server.strategy.FedProx.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_fit <flwr.server.strategy.FedProx.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`evaluate <flwr.server.strategy.FedProx.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""
":py:obj:`evaluate <flwr.server.strategy.FedProx.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedProx.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedProx.initialize_parameters>`\\ "
"\\(client\\_manager\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedProx.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedProx.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedProx.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedProx.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"

#: flwr.server.strategy.fedprox.FedProx.configure_fit:3 of
msgid "Sends the proximal factor mu to the clients"
msgstr "向客户发送近端因子mu"

#: ../../source/ref-api/flwr.server.strategy.FedTrimmedAvg.rst:2
#, fuzzy
msgid "FedTrimmedAvg"
msgstr "server.strategy.FedTrimmedAvg"

#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg:3 of
#, fuzzy
msgid "Implemented based on: https://arxiv.org/abs/1803.01498"
msgstr "实施基于 https://arxiv.org/abs/1802.07927。"

#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg:25 of
msgid "Fraction to cut off of both tails of the distribution. Defaults to 0.2."
msgstr "截取分布两个尾部的分数。默认为 0.2。"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedTrimmedAvg.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"
msgstr ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedTrimmedAvg.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.FedTrimmedAvg.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.FedTrimmedAvg.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedtrimmedavg.FedTrimmedAvg.aggregate_fit:1 of
msgid "Aggregate fit results using trimmed average."
msgstr "使用修剪平均值汇总拟合结果。"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedTrimmedAvg.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedTrimmedAvg.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`configure_fit "
"<flwr.server.strategy.FedTrimmedAvg.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_fit "
"<flwr.server.strategy.FedTrimmedAvg.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`evaluate <flwr.server.strategy.FedTrimmedAvg.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""
":py:obj:`evaluate <flwr.server.strategy.FedTrimmedAvg.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedTrimmedAvg.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedTrimmedAvg.initialize_parameters>`\\ "
"\\(client\\_manager\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedTrimmedAvg.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedTrimmedAvg.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedTrimmedAvg.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedTrimmedAvg.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"

#: ../../source/ref-api/flwr.server.strategy.FedXgbBagging.rst:2
#, fuzzy
msgid "FedXgbBagging"
msgstr "FedXgbBagging"

#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedXgbBagging.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"
msgstr ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedXgbBagging.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"

#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1
#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1
#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid "Aggregate evaluation metrics using average."
msgstr "采用加权平均法计算评估损失总额。"

#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.FedXgbBagging.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.FedXgbBagging.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"

#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_fit:1
#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_fit:1 of
#, fuzzy
msgid "Aggregate fit results using bagging."
msgstr "使用 Bulyan 技术汇总拟合结果。"

#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedXgbBagging.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedXgbBagging.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`configure_fit "
"<flwr.server.strategy.FedXgbBagging.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_fit "
"<flwr.server.strategy.FedXgbBagging.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`evaluate <flwr.server.strategy.FedXgbBagging.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""
":py:obj:`evaluate <flwr.server.strategy.FedXgbBagging.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"

#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedXgbBagging.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedXgbBagging.initialize_parameters>`\\ "
"\\(client\\_manager\\)"

#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedXgbBagging.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedXgbBagging.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"

#: flwr.server.strategy.fedxgb_bagging.FedXgbBagging.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedXgbBagging.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedXgbBagging.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"

#: ../../source/ref-api/flwr.server.strategy.FedXgbCyclic.rst:2
#, fuzzy
msgid "FedXgbCyclic"
msgstr "FedXgbCyclic"

#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedXgbCyclic.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"
msgstr ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedXgbCyclic.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"

#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.FedXgbCyclic.aggregate_fit>`\\ \\(server\\_round\\,"
" results\\, failures\\)"
msgstr ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.FedXgbCyclic.aggregate_fit>`\\ \\(server\\_round\\,"
" results\\, failures\\)"

#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedXgbCyclic.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedXgbCyclic.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`configure_fit "
"<flwr.server.strategy.FedXgbCyclic.configure_fit>`\\ \\(server\\_round\\,"
" parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_fit "
"<flwr.server.strategy.FedXgbCyclic.configure_fit>`\\ \\(server\\_round\\,"
" parameters\\, ...\\)"

#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`evaluate <flwr.server.strategy.FedXgbCyclic.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""
":py:obj:`evaluate <flwr.server.strategy.FedXgbCyclic.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"

#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedXgbCyclic.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedXgbCyclic.initialize_parameters>`\\ "
"\\(client\\_manager\\)"

#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedXgbCyclic.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedXgbCyclic.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"

#: flwr.server.strategy.fedxgb_cyclic.FedXgbCyclic.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedXgbCyclic.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedXgbCyclic.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"

#: ../../source/ref-api/flwr.server.strategy.FedXgbNnAvg.rst:2
#, fuzzy
msgid "FedXgbNnAvg"
msgstr "DP-FedAvg"

#: flwr.server.strategy.fedxgb_nn_avg.FedXgbNnAvg:5 of
#, fuzzy
msgid ""
"This strategy is deprecated, but a copy of it is available in Flower "
"Baselines: "
"https://github.com/adap/flower/tree/main/baselines/hfedxgboost."
msgstr ""
"该策略已被弃用，但在 Flower Baselines: "
"https://github.com/adap/flower/tree/main/baselines/hfedxgboost 中有其副本。"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedXgbNnAvg.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"
msgstr ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedXgbNnAvg.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.FedXgbNnAvg.aggregate_fit>`\\ \\(server\\_round\\, "
"results\\, failures\\)"
msgstr ""
":py:obj:`aggregate_fit "
"<flwr.server.strategy.FedXgbNnAvg.aggregate_fit>`\\ \\(server\\_round\\, "
"results\\, failures\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedXgbNnAvg.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedXgbNnAvg.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`configure_fit "
"<flwr.server.strategy.FedXgbNnAvg.configure_fit>`\\ \\(server\\_round\\, "
"parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_fit "
"<flwr.server.strategy.FedXgbNnAvg.configure_fit>`\\ \\(server\\_round\\, "
"parameters\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`evaluate <flwr.server.strategy.FedXgbNnAvg.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""
":py:obj:`evaluate <flwr.server.strategy.FedXgbNnAvg.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedXgbNnAvg.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedXgbNnAvg.initialize_parameters>`\\ "
"\\(client\\_manager\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedXgbNnAvg.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedXgbNnAvg.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedXgbNnAvg.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedXgbNnAvg.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"

#: ../../source/ref-api/flwr.server.strategy.FedYogi.rst:2
#, fuzzy
msgid "FedYogi"
msgstr "FedYogi"

#: flwr.server.strategy.fedyogi.FedYogi:32 of
#, fuzzy
msgid "Server-side learning rate. Defaults to 1e-2."
msgstr "服务器端学习率。默认为 1e-1。"

#: flwr.server.strategy.fedyogi.FedYogi:34 of
#, fuzzy
msgid "Client-side learning rate. Defaults to 0.0316."
msgstr "客户端学习率。默认为 1e-1。"

#: flwr.server.strategy.fedyogi.FedYogi:40 of
#, fuzzy
msgid "Controls the algorithm's degree of adaptability. Defaults to 1e-3."
msgstr "控制算法的适应度。默认为 1e-9。"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedYogi.aggregate_evaluate>`\\ \\(server\\_round\\,"
" results\\, ...\\)"
msgstr ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.FedYogi.aggregate_evaluate>`\\ \\(server\\_round\\,"
" results\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`aggregate_fit <flwr.server.strategy.FedYogi.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""
":py:obj:`aggregate_fit <flwr.server.strategy.FedYogi.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedYogi.configure_evaluate>`\\ \\(server\\_round\\,"
" parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.FedYogi.configure_evaluate>`\\ \\(server\\_round\\,"
" parameters\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`configure_fit <flwr.server.strategy.FedYogi.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_fit <flwr.server.strategy.FedYogi.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`evaluate <flwr.server.strategy.FedYogi.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""
":py:obj:`evaluate <flwr.server.strategy.FedYogi.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedYogi.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.FedYogi.initialize_parameters>`\\ "
"\\(client\\_manager\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedYogi.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.FedYogi.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedYogi.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.FedYogi.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"

#: ../../source/ref-api/flwr.server.strategy.Krum.rst:2
#, fuzzy
msgid "Krum"
msgstr "Krum"

#: flwr.server.strategy.krum.Krum:3 of
#, fuzzy
msgid "Implementation based on https://arxiv.org/abs/1703.02757"
msgstr "实施基于 https://arxiv.org/abs/2304.07537。"

#: flwr.server.strategy.krum.Krum:17 of
msgid ""
"Number of clients to keep before averaging (MultiKrum). Defaults to 0, in"
" that case classical Krum is applied."
msgstr "求平均值前保留的客户端数量（MultiKrum）。默认值为 0，在这种情况下会应用经典 Krum。"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.Krum.aggregate_evaluate>`\\ \\(server\\_round\\, "
"results\\, ...\\)"
msgstr ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.Krum.aggregate_evaluate>`\\ \\(server\\_round\\, "
"results\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`aggregate_fit <flwr.server.strategy.Krum.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""
":py:obj:`aggregate_fit <flwr.server.strategy.Krum.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.krum.Krum.aggregate_fit:1 of
msgid "Aggregate fit results using Krum."
msgstr "使用 Krum 汇总拟合结果。"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.Krum.configure_evaluate>`\\ \\(server\\_round\\, "
"parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.Krum.configure_evaluate>`\\ \\(server\\_round\\, "
"parameters\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`configure_fit <flwr.server.strategy.Krum.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_fit <flwr.server.strategy.Krum.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`evaluate <flwr.server.strategy.Krum.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""
":py:obj:`evaluate <flwr.server.strategy.Krum.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.Krum.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.Krum.initialize_parameters>`\\ "
"\\(client\\_manager\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.Krum.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.Krum.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"

#: flwr.server.strategy.fedavg.FedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`num_fit_clients <flwr.server.strategy.Krum.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_fit_clients <flwr.server.strategy.Krum.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"

#: ../../source/ref-api/flwr.server.strategy.QFedAvg.rst:2
#, fuzzy
msgid "QFedAvg"
msgstr "DP-FedAvg"

#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.QFedAvg.aggregate_evaluate>`\\ \\(server\\_round\\,"
" results\\, ...\\)"
msgstr ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.QFedAvg.aggregate_evaluate>`\\ \\(server\\_round\\,"
" results\\, ...\\)"

#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`aggregate_fit <flwr.server.strategy.QFedAvg.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""
":py:obj:`aggregate_fit <flwr.server.strategy.QFedAvg.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"

#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.QFedAvg.configure_evaluate>`\\ \\(server\\_round\\,"
" parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.QFedAvg.configure_evaluate>`\\ \\(server\\_round\\,"
" parameters\\, ...\\)"

#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`configure_fit <flwr.server.strategy.QFedAvg.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_fit <flwr.server.strategy.QFedAvg.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`evaluate <flwr.server.strategy.QFedAvg.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""
":py:obj:`evaluate <flwr.server.strategy.QFedAvg.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"

#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.QFedAvg.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.QFedAvg.initialize_parameters>`\\ "
"\\(client\\_manager\\)"

#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.QFedAvg.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_evaluation_clients "
"<flwr.server.strategy.QFedAvg.num_evaluation_clients>`\\ "
"\\(num\\_available\\_clients\\)"

#: flwr.server.strategy.qfedavg.QFedAvg.aggregate_evaluate:1:<autosummary>:1 of
#, fuzzy
msgid ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.QFedAvg.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"
msgstr ""
":py:obj:`num_fit_clients "
"<flwr.server.strategy.QFedAvg.num_fit_clients>`\\ "
"\\(num\\_available\\_clients\\)"

#: ../../source/ref-api/flwr.server.strategy.Strategy.rst:2
#, fuzzy
msgid "Strategy"
msgstr "Krum 策略。"

#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.Strategy.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"
msgstr ""
":py:obj:`aggregate_evaluate "
"<flwr.server.strategy.Strategy.aggregate_evaluate>`\\ "
"\\(server\\_round\\, results\\, ...\\)"

#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:1
#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:1:<autosummary>:1
#: of
msgid "Aggregate evaluation results."
msgstr "聚合评估结果。"

#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`aggregate_fit <flwr.server.strategy.Strategy.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"
msgstr ""
":py:obj:`aggregate_fit <flwr.server.strategy.Strategy.aggregate_fit>`\\ "
"\\(server\\_round\\, results\\, failures\\)"

#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.strategy.Strategy.aggregate_fit:1 of
msgid "Aggregate training results."
msgstr "汇总训练结果。"

#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.Strategy.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_evaluate "
"<flwr.server.strategy.Strategy.configure_evaluate>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`configure_fit <flwr.server.strategy.Strategy.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"
msgstr ""
":py:obj:`configure_fit <flwr.server.strategy.Strategy.configure_fit>`\\ "
"\\(server\\_round\\, parameters\\, ...\\)"

#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`evaluate <flwr.server.strategy.Strategy.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"
msgstr ""
":py:obj:`evaluate <flwr.server.strategy.Strategy.evaluate>`\\ "
"\\(server\\_round\\, parameters\\)"

#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.strategy.Strategy.evaluate:1 of
msgid "Evaluate the current model parameters."
msgstr "评估当前的模型参数。"

#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.Strategy.initialize_parameters>`\\ "
"\\(client\\_manager\\)"
msgstr ""
":py:obj:`initialize_parameters "
"<flwr.server.strategy.Strategy.initialize_parameters>`\\ "
"\\(client\\_manager\\)"

#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:1:<autosummary>:1
#: flwr.server.strategy.strategy.Strategy.initialize_parameters:1 of
msgid "Initialize the (global) model parameters."
msgstr "初始化（全局）模型参数。"

#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:5 of
msgid ""
"Successful updates from the previously selected and configured clients. "
"Each pair of `(ClientProxy, FitRes` constitutes a successful update from "
"one of the previously selected clients. Not that not all previously "
"selected clients are necessarily included in this list: a client might "
"drop out and not submit a result. For each client that did not submit an "
"update, there should be an `Exception` in `failures`."
msgstr ""
"从先前选定和配置的客户端进行的成功更新。每一对`(ClientProxy, "
"FitRes)`都是来自先前选定客户端的一次成功更新。但并非所有先前选定的客户机都一定包含在此列表中：客户机可能会退出，不提交结果。对于每个没有提交更新的客户端，`failures`中都应该有一个`Exception`。"

#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:13
#: flwr.server.strategy.strategy.Strategy.aggregate_fit:13 of
msgid "Exceptions that occurred while the server was waiting for client updates."
msgstr "服务器等待客户端更新时发生的异常。"

#: flwr.server.strategy.strategy.Strategy.aggregate_evaluate:16 of
msgid ""
"**aggregation_result** -- The aggregated evaluation result. Aggregation "
"typically uses some variant of a weighted average."
msgstr "**aggregation_result** -- 汇总的评估结果。聚合通常使用某种加权平均值。"

#: flwr.server.strategy.strategy.Strategy.aggregate_fit:5 of
msgid ""
"Successful updates from the previously selected and configured clients. "
"Each pair of `(ClientProxy, FitRes)` constitutes a successful update from"
" one of the previously selected clients. Not that not all previously "
"selected clients are necessarily included in this list: a client might "
"drop out and not submit a result. For each client that did not submit an "
"update, there should be an `Exception` in `failures`."
msgstr ""
"来自先前选定和配置的客户端的成功更新。每一对`(ClientProxy, "
"FitRes)`都构成先前选定的客户端之一的一次成功更新。但并非所有先前选定的客户机都一定包含在此列表中：客户机可能会退出，不提交结果。对于每个没有提交更新的客户端，\"失败"
" \"中都应该有一个 \"异常\"。"

#: flwr.server.strategy.strategy.Strategy.aggregate_fit:17 of
msgid ""
"**parameters** -- If parameters are returned, then the server will treat "
"these as the new global model parameters (i.e., it will replace the "
"previous parameters with the ones returned from this method). If `None` "
"is returned (e.g., because there were only failures and no viable "
"results) then the server will no update the previous model parameters, "
"the updates received in this round are discarded, and the global model "
"parameters remain the same."
msgstr ""
"**parameters** -- 如果返回参数，那么服务器将把这些参数作为新的全局模型参数（即用本方法返回的参数替换之前的参数）。如果返回 "
"\"无\"（例如，因为只有失败而没有可行的结果），那么服务器将不再更新之前的模型参数，本轮收到的更新将被丢弃，全局模型参数保持不变。"

#: flwr.server.strategy.strategy.Strategy.evaluate:3 of
msgid ""
"This function can be used to perform centralized (i.e., server-side) "
"evaluation of model parameters."
msgstr "该函数可用于对模型参数进行集中（即服务器端）评估。"

#: flwr.server.strategy.strategy.Strategy.evaluate:11 of
msgid ""
"**evaluation_result** -- The evaluation result, usually a Tuple "
"containing loss and a dictionary containing task-specific metrics (e.g., "
"accuracy)."
msgstr "**evaluation_result** -- 评估结果，通常是一个元组，包含损失值和一个字典，字典中包含特定任务的指标（如准确率）。"

#: flwr.server.strategy.strategy.Strategy.initialize_parameters:6 of
msgid ""
"**parameters** -- If parameters are returned, then the server will treat "
"these as the initial global model parameters."
msgstr "**parameters** -- 如果返回参数，服务器将把这些参数视为初始全局模型参数。"

#: ../../source/ref-api/flwr.server.workflow.rst:2
#, fuzzy
msgid "workflow"
msgstr "工作流程"

#: ../../source/ref-api/flwr.server.workflow.rst:24:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`DefaultWorkflow <flwr.server.workflow.DefaultWorkflow>`\\ "
"\\(\\[fit\\_workflow\\, ...\\]\\)"
msgstr ""
":py:obj:`DefaultWorkflow <flwr.server.workflow.DefaultWorkflow>`\\ "
"\\(\\[fit\\_workflow\\, ...\\]\\)"

#: ../../source/ref-api/flwr.server.workflow.rst:24:<autosummary>:1
#: flwr.server.workflow.default_workflows.DefaultWorkflow:1 of
#, fuzzy
msgid "Default workflow in Flower."
msgstr "Flower 中的默认工作流程。"

#: ../../source/ref-api/flwr.server.workflow.rst:24:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`SecAggPlusWorkflow <flwr.server.workflow.SecAggPlusWorkflow>`\\ "
"\\(num\\_shares\\, ...\\[\\, ...\\]\\)"
msgstr ""
":py:obj:`SecAggPlusWorkflow <flwr.server.workflow.SecAggPlusWorkflow>`\\ "
"\\(num\\_shares\\, ...\\[\\, ...\\]\\)"

#: ../../source/ref-api/flwr.server.workflow.rst:24:<autosummary>:1
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:1
#: of
#, fuzzy
msgid "The workflow for the SecAgg+ protocol."
msgstr "SecAgg+ 协议的工作流程。"

#: ../../source/ref-api/flwr.server.workflow.rst:24:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`SecAggWorkflow <flwr.server.workflow.SecAggWorkflow>`\\ "
"\\(reconstruction\\_threshold\\, \\*\\)"
msgstr ""
":py:obj:`SecAggWorkflow <flwr.server.workflow.SecAggWorkflow>`\\ "
"\\(reconstruction\\_threshold\\, \\*\\)"

#: ../../source/ref-api/flwr.server.workflow.rst:24:<autosummary>:1
#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:1 of
#, fuzzy
msgid "The workflow for the SecAgg protocol."
msgstr "SecAgg 协议的工作流程。"

#: ../../source/ref-api/flwr.server.workflow.DefaultWorkflow.rst:2
#, fuzzy
msgid "DefaultWorkflow"
msgstr "工作流程"

#: ../../source/ref-api/flwr.server.workflow.SecAggPlusWorkflow.rst:2
#, fuzzy
msgid "SecAggPlusWorkflow"
msgstr "工作流程"

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:3
#: of
#, fuzzy
msgid ""
"The SecAgg+ protocol ensures the secure summation of integer vectors "
"owned by multiple parties, without accessing any individual integer "
"vector. This workflow allows the server to compute the weighted average "
"of model parameters across all clients, ensuring individual contributions"
" remain private. This is achieved by clients sending both, a weighting "
"factor and a weighted version of the locally updated parameters, both of "
"which are masked for privacy. Specifically, each client uploads \"[w, w *"
" params]\" with masks, where weighting factor 'w' is the number of "
"examples ('num_examples') and 'params' represents the model parameters "
"('parameters') from the client's `FitRes`. The server then aggregates "
"these contributions to compute the weighted average of model parameters."
msgstr ""
"SecAgg+ "
"协议可确保对多方拥有的整数向量进行安全求和，而不会访问任何单个整数向量。该工作流程允许服务器计算所有客户端模型参数的加权平均值，确保个人贡献保持私密。这可以通过客户端同时发送加权因子和本地更新参数的加权版本来实现，为了保护隐私，两者都会被屏蔽。具体来说，每个客户端都会上传带掩码的\"[w,"
" w * params]\"，其中加权因子 \"w \"是示例数（\"num_examples\"），\"params \"代表客户端 "
"\"FitRes \"中的模型参数（\"parameters\"）。然后，服务器会汇总这些贡献，计算模型参数的加权平均值。"

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:14
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:14
#: of
msgid "The protocol involves four main stages:"
msgstr ""

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:16
#: of
msgid ""
"'setup': Send SecAgg+ configuration to clients and collect their public "
"keys."
msgstr ""

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:17
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:17
#: of
msgid ""
"'share keys': Broadcast public keys among clients and collect encrypted "
"secret key shares."
msgstr ""

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:19
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:19
#: of
#, fuzzy
msgid ""
"'collect masked vectors': Forward encrypted secret key shares to target "
"clients and collect masked model parameters."
msgstr "收集屏蔽向量\"： 向目标客户端转发加密密钥共享，并收集屏蔽模型参数。"

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:21
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:21
#: of
#, fuzzy
msgid ""
"'unmask': Collect secret key shares to decrypt and aggregate the model "
"parameters."
msgstr "解密\"： 收集密钥共享，解密并汇总模型参数。"

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:23
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:23
#: of
#, fuzzy
msgid ""
"Only the aggregated model parameters are exposed and passed to "
"`Strategy.aggregate_fit`, ensuring individual data privacy."
msgstr "只有聚合模型参数才会公开并传递给 `Strategy.aggregate_fit`，从而确保个人数据隐私。"

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:26
#: of
#, fuzzy
msgid ""
"The number of shares into which each client's private key is split under "
"the SecAgg+ protocol. If specified as a float, it represents the "
"proportion of all selected clients, and the number of shares will be set "
"dynamically in the run time. A private key can be reconstructed from "
"these shares, allowing for the secure aggregation of model updates. Each "
"client sends one share to each of its neighbors while retaining one."
msgstr ""
"在 SecAgg+ "
"协议下，每个客户的私钥被分成的份数。如果指定为浮点数，则代表所有选定客户的比例，份额数将在运行时动态设置。私钥可以从这些份额中重建，从而实现模型更新的安全聚合。每个客户端向其每个邻居发送一份，同时保留一份。"

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:26
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:33
#: of
#, fuzzy
msgid ""
"The minimum number of shares required to reconstruct a client's private "
"key, or, if specified as a float, it represents the proportion of the "
"total number of shares needed for reconstruction. This threshold ensures "
"privacy by allowing for the recovery of contributions from dropped "
"clients during aggregation, without compromising individual client data."
msgstr "重建客户私钥所需的最小份数，如果指定为浮动，则表示重建所需的份数占总份数的比例。这个阈值允许在聚合过程中恢复掉线客户的贡献，从而确保隐私，而不会泄露单个客户的数据。"

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:32
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:39
#: of
#, fuzzy
msgid ""
"The maximum value of the weight that can be assigned to any single "
"client's update during the weighted average calculation on the server "
"side, e.g., in the FedAvg algorithm."
msgstr "在服务器端进行加权平均计算（如 FedAvg 算法）时，可分配给任何单个客户端更新的权重的最大值。"

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:36
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:43
#: of
#, fuzzy
msgid ""
"The range within which model parameters are clipped before quantization. "
"This parameter ensures each model parameter is bounded within "
"[-clipping_range, clipping_range], facilitating quantization."
msgstr "量化前模型参数的裁剪范围。该参数可确保每个模型参数都在 [-clipping_range, clipping_range] 范围内，便于量化。"

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:40
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:47
#: of
#, fuzzy
msgid ""
"The size of the range into which floating-point model parameters are "
"quantized, mapping each parameter to an integer in [0, "
"quantization_range-1]. This facilitates cryptographic operations on the "
"model updates."
msgstr "浮点模型参数量化范围的大小，将每个参数映射为 [0, quantization_range-1] 中的整数。这有助于对模型更新进行加密操作。"

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:44
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:51
#: of
#, fuzzy
msgid ""
"The range of values from which random mask entries are uniformly sampled "
"([0, modulus_range-1]). `modulus_range` must be less than 4294967296. "
"Please use 2**n values for `modulus_range` to prevent overflow issues."
msgstr ""
"对随机掩码条目进行均匀采样的数值范围（[0, modulus_range-1]）。modulus_range \"必须小于 "
"4294967296。为防止出现溢出问题，请为 `modulus_range` 使用 2**n 的值。"

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:48
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:55
#: of
#, fuzzy
msgid ""
"The timeout duration in seconds. If specified, the workflow will wait for"
" replies for this duration each time. If `None`, there is no time limit "
"and the workflow will wait until replies for all messages are received."
msgstr "超时时间（秒）。如果指定，工作流将在每次等待回复的时间内等待回复。如果指定为 \"无\"，则没有时间限制，工作流程将一直等待到收到所有信息的回复。"

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:62
#: of
#, fuzzy
msgid ""
"Generally, higher `num_shares` means more robust to dropouts while "
"increasing the computational costs; higher `reconstruction_threshold` "
"means better privacy guarantees but less tolerance to dropouts."
msgstr "一般来说，\"份额数 \"越高，意味着对丢弃的鲁棒性越强，同时计算成本也会增加；\"重构阈值 \"越高，意味着隐私保证越好，但对丢弃的容忍度越低。"

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:59
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:65
#: of
#, fuzzy
msgid "Too large `max_weight` may compromise the precision of the quantization."
msgstr "过大的 `max_weight` 可能会影响量化的精度。"

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:60
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:66
#: of
#, fuzzy
msgid "`modulus_range` must be 2**n and larger than `quantization_range`."
msgstr "modulus_range \"必须为 2**n，且大于 \"quantization_range\"。"

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:67
#: of
#, fuzzy
msgid ""
"When `num_shares` is a float, it is interpreted as the proportion of all "
"selected clients, and hence the number of shares will be determined in "
"the runtime. This allows for dynamic adjustment based on the total number"
" of participating clients."
msgstr "当 `num_shares` 为浮点数时，它被解释为所有选定客户端的比例，因此份额数将在运行时确定。这样就可以根据参与客户端的总数进行动态调整。"

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:70
#: of
#, fuzzy
msgid ""
"Similarly, when `reconstruction_threshold` is a float, it is interpreted "
"as the proportion of the number of shares needed for the reconstruction "
"of a private key. This feature enables flexibility in setting the "
"security threshold relative to the number of distributed shares."
msgstr ""
"同样，当 `reconstruction_threshold` "
"为浮点数时，它被解释为重建私钥所需的份额数比例。这一功能使我们可以根据分发的份额数灵活设置安全阈值。"

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow:74
#: of
#, fuzzy
msgid ""
"`num_shares`, `reconstruction_threshold`, and the quantization parameters"
" (`clipping_range`, `quantization_range`, `modulus_range`) play critical "
"roles in balancing privacy, robustness, and efficiency within the SecAgg+"
" protocol."
msgstr ""
"份额数\"、\"重建阈值 \"和量化参数（\"裁剪范围\"、\"量化范围\"、\"模数范围\"）在平衡 SecAgg+ "
"协议的隐私性、稳健性和效率方面发挥着关键作用。"

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.collect_masked_vectors_stage:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`collect_masked_vectors_stage "
"<flwr.server.workflow.SecAggPlusWorkflow.collect_masked_vectors_stage>`\\"
" \\(driver\\, ...\\)"
msgstr ""
":py:obj:`collect_masked_vectors_stage "
"<flwr.server.workflow.SecAggPlusWorkflow.collect_masked_vectors_stage>`\\"
" \\(driver\\, ...\\)"

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.collect_masked_vectors_stage:1
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.collect_masked_vectors_stage:1:<autosummary>:1
#: of
#, fuzzy
msgid "Execute the 'collect masked vectors' stage."
msgstr "执行 \"收集屏蔽向量 \"阶段。"

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.collect_masked_vectors_stage:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`setup_stage "
"<flwr.server.workflow.SecAggPlusWorkflow.setup_stage>`\\ \\(driver\\, "
"context\\, state\\)"
msgstr ""
":py:obj:`setup_stage "
"<flwr.server.workflow.SecAggPlusWorkflow.setup_stage>`\\ \\(driver\\, "
"context\\, state\\)"

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.collect_masked_vectors_stage:1:<autosummary>:1
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.setup_stage:1
#: of
#, fuzzy
msgid "Execute the 'setup' stage."
msgstr "执行 \"设置 \"阶段。"

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.collect_masked_vectors_stage:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`share_keys_stage "
"<flwr.server.workflow.SecAggPlusWorkflow.share_keys_stage>`\\ "
"\\(driver\\, context\\, state\\)"
msgstr ""
":py:obj:`share_keys_stage "
"<flwr.server.workflow.SecAggPlusWorkflow.share_keys_stage>`\\ "
"\\(driver\\, context\\, state\\)"

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.collect_masked_vectors_stage:1:<autosummary>:1
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.share_keys_stage:1
#: of
#, fuzzy
msgid "Execute the 'share keys' stage."
msgstr "执行 \"共享密钥 \"阶段。"

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.collect_masked_vectors_stage:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`unmask_stage "
"<flwr.server.workflow.SecAggPlusWorkflow.unmask_stage>`\\ \\(driver\\, "
"context\\, state\\)"
msgstr ""
":py:obj:`unmask_stage "
"<flwr.server.workflow.SecAggPlusWorkflow.unmask_stage>`\\ \\(driver\\, "
"context\\, state\\)"

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.collect_masked_vectors_stage:1:<autosummary>:1
#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.unmask_stage:1
#: of
#, fuzzy
msgid "Execute the 'unmask' stage."
msgstr "执行 \"解除屏蔽 \"阶段。"

#: ../../source/ref-api/flwr.server.workflow.SecAggWorkflow.rst:2
#, fuzzy
msgid "SecAggWorkflow"
msgstr "工作流程"

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:1 of
#, fuzzy
msgid ""
"Bases: "
":py:class:`~flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow`"
msgstr ""
"基础： "
":py:class:`~flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow`."

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:3 of
#, fuzzy
msgid ""
"The SecAgg protocol ensures the secure summation of integer vectors owned"
" by multiple parties, without accessing any individual integer vector. "
"This workflow allows the server to compute the weighted average of model "
"parameters across all clients, ensuring individual contributions remain "
"private. This is achieved by clients sending both, a weighting factor and"
" a weighted version of the locally updated parameters, both of which are "
"masked for privacy. Specifically, each client uploads \"[w, w * params]\""
" with masks, where weighting factor 'w' is the number of examples "
"('num_examples') and 'params' represents the model parameters "
"('parameters') from the client's `FitRes`. The server then aggregates "
"these contributions to compute the weighted average of model parameters."
msgstr ""
"SecAgg "
"协议可确保对多方拥有的整数向量进行安全求和，而不会访问任何单个整数向量。该工作流程允许服务器计算所有客户端模型参数的加权平均值，确保个人贡献保持私密。这可以通过客户端同时发送加权因子和本地更新参数的加权版本来实现，为了保护隐私，两者都会被屏蔽。具体来说，每个客户端都会上传带掩码的\"[w,"
" w * params]\"，其中加权因子 \"w \"是示例数（\"num_examples\"），\"params \"代表客户端 "
"\"FitRes \"中的模型参数（\"parameters\"）。然后，服务器会汇总这些贡献，计算模型参数的加权平均值。"

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:16 of
msgid ""
"'setup': Send SecAgg configuration to clients and collect their public "
"keys."
msgstr ""

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:55 of
#, fuzzy
msgid ""
"Each client's private key is split into N shares under the SecAgg "
"protocol, where N is the number of selected clients."
msgstr "根据 SecAgg 协议，每个客户的私人密钥被分成 N 份，其中 N 是所选客户的数量。"

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:57 of
#, fuzzy
msgid ""
"Generally, higher `reconstruction_threshold` means better privacy "
"guarantees but less tolerance to dropouts."
msgstr "一般来说，\"重建阈值 \"越高，隐私保证就越好，但对丢包的容忍度就越低。"

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:61 of
#, fuzzy
msgid ""
"When `reconstruction_threshold` is a float, it is interpreted as the "
"proportion of the number of all selected clients needed for the "
"reconstruction of a private key. This feature enables flexibility in "
"setting the security threshold relative to the number of selected "
"clients."
msgstr ""
"当 `reconstruction_threshold` "
"为浮点数时，它被解释为重建私钥所需的所有选定客户端数量的比例。此功能可根据所选客户端的数量灵活设置安全阈值。"

#: flwr.server.workflow.secure_aggregation.secagg_workflow.SecAggWorkflow:65 of
#, fuzzy
msgid ""
"`reconstruction_threshold`, and the quantization parameters "
"(`clipping_range`, `quantization_range`, `modulus_range`) play critical "
"roles in balancing privacy, robustness, and efficiency within the SecAgg "
"protocol."
msgstr ""
"重构阈值 \"和量化参数（\"裁剪范围\"、\"量化范围\"、\"模量范围\"）在 SecAgg "
"协议中平衡隐私性、鲁棒性和效率方面起着至关重要的作用。"

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.collect_masked_vectors_stage:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`collect_masked_vectors_stage "
"<flwr.server.workflow.SecAggWorkflow.collect_masked_vectors_stage>`\\ "
"\\(driver\\, ...\\)"
msgstr ""
":py:obj:`collect_masked_vectors_stage "
"<flwr.server.workflow.SecAggWorkflow.collect_masked_vectors_stage>`\\(driver\\,"
" ...\\)"

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.collect_masked_vectors_stage:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`setup_stage <flwr.server.workflow.SecAggWorkflow.setup_stage>`\\"
" \\(driver\\, context\\, state\\)"
msgstr ""
":py:obj:`setup_stage "
"<flwr.server.workflow.SecAggWorkflow.setup_stage>`\\(driver\\, context\\,"
" state\\)"

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.collect_masked_vectors_stage:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`share_keys_stage "
"<flwr.server.workflow.SecAggWorkflow.share_keys_stage>`\\ \\(driver\\, "
"context\\, state\\)"
msgstr ""
"py:obj:`share_keys_stage "
"<flwr.server.workflow.SecAggWorkflow.share_keys_stage>`\\(driver\\, "
"context\\, state\\)"

#: flwr.server.workflow.secure_aggregation.secaggplus_workflow.SecAggPlusWorkflow.collect_masked_vectors_stage:1:<autosummary>:1
#: of
#, fuzzy
msgid ""
":py:obj:`unmask_stage "
"<flwr.server.workflow.SecAggWorkflow.unmask_stage>`\\ \\(driver\\, "
"context\\, state\\)"
msgstr ""
":py:obj:`unmask_stage "
"<flwr.server.workflow.SecAggWorkflow.unmask_stage>`\\ \\(driver\\, "
"context\\, state\\)"

#: ../../source/ref-api/flwr.simulation.rst:2
#, fuzzy
msgid "simulation"
msgstr "运行模拟"

#: ../../source/ref-api/flwr.simulation.rst:24:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`run_simulation <flwr.simulation.run_simulation>`\\ "
"\\(server\\_app\\, client\\_app\\, ...\\)"
msgstr ""
":py:obj:`run_simulation <flwr.simulation.run_simulation>`\\ "
"\\(server\\_app\\, client\\_app\\, ...\\)"

#: ../../source/ref-api/flwr.simulation.rst:24:<autosummary>:1
#: flwr.simulation.run_simulation.run_simulation:1 of
#, fuzzy
msgid "Run a Flower App using the Simulation Engine."
msgstr "使用模拟引擎运行花朵应用程序。"

#: ../../source/ref-api/flwr.simulation.rst:24:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`run_simulation_process "
"<flwr.simulation.run_simulation_process>`\\ \\(...\\[\\, flwr\\_dir\\_\\,"
" ...\\]\\)"
msgstr ""
":py:obj:`run_simulation <flwr.simulation.run_simulation>`\\ "
"\\(server\\_app\\, client\\_app\\, ...\\)"

#: ../../source/ref-api/flwr.simulation.rst:24:<autosummary>:1
#: flwr.simulation.app.run_simulation_process:1 of
#, fuzzy
msgid "Run Flower Simulation process."
msgstr "运行模拟"

#: ../../source/ref-api/flwr.simulation.rst:24:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`start_simulation <flwr.simulation.start_simulation>`\\ \\(\\*\\,"
" client\\_fn\\, num\\_clients\\)"
msgstr ""
":py:obj:`start_simulation <flwr.simulation.start_simulation>`\\ \\(\\*\\,"
" client\\_fn\\[\\, ...\\]\\)"

#: ../../source/ref-api/flwr.simulation.rst:24:<autosummary>:1
#: flwr.simulation.legacy_app.start_simulation:1 of
#, fuzzy
msgid "Start a Ray-based Flower simulation server."
msgstr "多节点 Flower 模拟"

#: ../../source/ref-api/flwr.simulation.rst:31:<autosummary>:1
#, fuzzy
msgid ""
":py:obj:`SimulationIoConnection "
"<flwr.simulation.SimulationIoConnection>`\\ \\(\\[...\\]\\)"
msgstr ""
":py:obj:`start_simulation <flwr.simulation.start_simulation>`\\ \\(\\*\\,"
" client\\_fn\\[\\, ...\\]\\)"

#: ../../source/ref-api/flwr.simulation.rst:31:<autosummary>:1
#: flwr.simulation.simulationio_connection.SimulationIoConnection:1 of
msgid "`SimulationIoConnection` provides an interface to the SimulationIo API."
msgstr ""

#: ../../source/ref-api/flwr.simulation.SimulationIoConnection.rst:2
#, fuzzy
msgid "SimulationIoConnection"
msgstr "运行模拟"

#: flwr.simulation.simulationio_connection.SimulationIoConnection:3 of
msgid "The address (URL, IPv6, IPv4) of the SuperLink SimulationIo API service."
msgstr ""

#: flwr.simulation.simulationio_connection.SimulationIoConnection:5 of
#, fuzzy
msgid ""
"The PEM-encoded root certificates as a byte string. If provided, a secure"
" connection using the certificates will be established to an SSL-enabled "
"Flower server."
msgstr "字节字符串或路径字符串形式的 PEM 编码根证书。如果提供，将使用这些证书与启用 SSL 的 Flower 服务器建立安全连接。"

#: ../../source/ref-api/flwr.simulation.run_simulation.rst:2
#, fuzzy
msgid "run\\_simulation"
msgstr "运行模拟"

#: flwr.simulation.run_simulation.run_simulation:3 of
#, fuzzy
msgid ""
"The `ServerApp` to be executed. It will send messages to different "
"`ClientApp` instances running on different (virtual) SuperNodes."
msgstr "要执行的 `ServerApp`。它将向运行在不同（虚拟）超级节点上的不同 `ClientApp`实例发送消息。"

#: flwr.simulation.run_simulation.run_simulation:6 of
#, fuzzy
msgid ""
"The `ClientApp` to be executed by each of the SuperNodes. It will receive"
" messages sent by the `ServerApp`."
msgstr "由每个超级节点执行的 `ClientApp`。它将接收由 `ServerApp` 发送的信息。"

#: flwr.simulation.run_simulation.run_simulation:9 of
#, fuzzy
msgid ""
"Number of nodes that run a ClientApp. They can be sampled by a Driver in "
"the ServerApp and receive a Message describing what the ClientApp should "
"perform."
msgstr "运行 ClientApp 的节点数。它们可被 ServerApp 中的驱动程序采样，并接收描述 ClientApp 应执行的操作的信息。"

#: flwr.simulation.run_simulation.run_simulation:12 of
#, fuzzy
msgid "A simulation backend that runs `ClientApp`s."
msgstr "运行 \"客户端应用程序 \"的模拟后台。"

#: flwr.simulation.run_simulation.run_simulation:14 of
msgid ""
"'A dictionary to configure a backend. Separate dictionaries to configure "
"different elements of backend. Supported top-level keys are `init_args` "
"for values parsed to initialisation of backend, `client_resources` to "
"define the resources for clients, and `actor` to define the actor "
"parameters. Values supported in <value> are those included by "
"`flwr.common.typing.ConfigsRecordValues`."
msgstr ""

#: flwr.simulation.run_simulation.run_simulation:21 of
#, fuzzy
msgid ""
"A boolean to indicate whether to enable GPU growth on the main thread. "
"This is desirable if you make use of a TensorFlow model on your "
"`ServerApp` while having your `ClientApp` running on the same GPU. "
"Without enabling this, you might encounter an out-of-memory error because"
" TensorFlow, by default, allocates all GPU memory. Read more about how "
"`tf.config.experimental.set_memory_growth()` works in the TensorFlow "
"documentation: https://www.tensorflow.org/api/stable."
msgstr ""
"布尔值，用于指示是否在主线程上启用 GPU 增长。如果您在 \"ServerApp \"上使用 TensorFlow 模型，同时让 "
"\"ClientApp \"在同一 GPU 上运行，则最好启用此选项。如果不启用此功能，您可能会遇到内存不足的错误，因为 TensorFlow "
"默认会分配所有 GPU 内存。有关 `tf.config.experimental.set_memory_growth()` "
"如何工作的更多信息，请参阅 TensorFlow 文档：https://www.tensorflow.org/api/stable。"

#: flwr.simulation.run_simulation.run_simulation:28 of
#, fuzzy
msgid ""
"When disabled, only INFO, WARNING and ERROR log messages will be shown. "
"If enabled, DEBUG-level logs will be displayed."
msgstr "启用后，将只显示 INFO、WARNING 和 ERROR 日志信息。启用后，将显示 DEBUG 级日志。"

#: ../../source/ref-api/flwr.simulation.run_simulation_process.rst:2
#, fuzzy
msgid "run\\_simulation\\_process"
msgstr "运行模拟"

#: ../../source/ref-api/flwr.simulation.start_simulation.rst:2
#, fuzzy
msgid "start\\_simulation"
msgstr "start_simulation"

#: flwr.simulation.legacy_app.start_simulation:5 of
msgid ""
"This function is deprecated since 1.13.0. Use :code: `flwr run` to start "
"a Flower simulation."
msgstr ""

#: flwr.simulation.legacy_app.start_simulation:8 of
msgid ""
"A function creating `Client` instances. The function must have the "
"signature `client_fn(context: Context). It should return a single client "
"instance of type `Client`. Note that the created client instances are "
"ephemeral and will often be destroyed after a single method invocation. "
"Since client instances are not long-lived, they should not attempt to "
"carry state over method invocations. Any state required by the instance "
"(model, dataset, hyperparameters, ...) should be (re-)created in either "
"the call to `client_fn` or the call to any of the client methods (e.g., "
"load evaluation data in the `evaluate` method itself)."
msgstr ""

#: flwr.simulation.legacy_app.start_simulation:18 of
#, fuzzy
msgid "The total number of clients in this simulation."
msgstr "需要等待的客户数量。"

#: flwr.simulation.legacy_app.start_simulation:20 of
msgid ""
"UNSUPPORTED, WILL BE REMOVED. USE `num_clients` INSTEAD. List "
"`client_id`s for each client. This is only required if `num_clients` is "
"not set. Setting both `num_clients` and `clients_ids` with "
"`len(clients_ids)` not equal to `num_clients` generates an error. Using "
"this argument will raise an error."
msgstr ""

#: flwr.simulation.legacy_app.start_simulation:26 of
msgid ""
"CPU and GPU resources for a single client. Supported keys are `num_cpus` "
"and `num_gpus`. To understand the GPU utilization caused by `num_gpus`, "
"as well as using custom resources, please consult the Ray documentation."
msgstr ""

#: flwr.simulation.legacy_app.start_simulation:31 of
#, fuzzy
msgid ""
"An implementation of the abstract base class `flwr.server.Server`. If no "
"instance is provided, then `start_server` will create one."
msgstr ""
"抽象基类 `flwr.server.strategy.Strategy` 的实现。如果没有提供策略，`start_server` 将使用 "
"`flwr.server.strategy.FedAvg`。"

#: flwr.simulation.legacy_app.start_simulation:37 of
#, fuzzy
msgid ""
"An implementation of the abstract base class `flwr.server.Strategy`. If "
"no strategy is provided, then `start_server` will use "
"`flwr.server.strategy.FedAvg`."
msgstr ""
"抽象基类 `flwr.server.strategy.Strategy` 的实现。如果没有提供策略，`start_server` 将使用 "
"`flwr.server.strategy.FedAvg`。"

#: flwr.simulation.legacy_app.start_simulation:41 of
#, fuzzy
msgid ""
"An implementation of the abstract base class `flwr.server.ClientManager`."
" If no implementation is provided, then `start_simulation` will use "
"`flwr.server.client_manager.SimpleClientManager`."
msgstr ""
"抽象基类 `flwr.server.ClientManager` 的实现。如果没有提供实现，`start_server` 将使用 "
"`flwr.server.client_manager.SimpleClientManager`。"

#: flwr.simulation.legacy_app.start_simulation:45 of
msgid ""
"Optional dictionary containing arguments for the call to `ray.init`. If "
"ray_init_args is None (the default), Ray will be initialized with the "
"following default args:  { \"ignore_reinit_error\": True, "
"\"include_dashboard\": False }  An empty dictionary can be used "
"(ray_init_args={}) to prevent any arguments from being passed to "
"ray.init."
msgstr ""

#: flwr.simulation.legacy_app.start_simulation:45 of
msgid ""
"Optional dictionary containing arguments for the call to `ray.init`. If "
"ray_init_args is None (the default), Ray will be initialized with the "
"following default args:"
msgstr ""

#: flwr.simulation.legacy_app.start_simulation:49 of
msgid "{ \"ignore_reinit_error\": True, \"include_dashboard\": False }"
msgstr ""

#: flwr.simulation.legacy_app.start_simulation:51 of
msgid ""
"An empty dictionary can be used (ray_init_args={}) to prevent any "
"arguments from being passed to ray.init."
msgstr ""

#: flwr.simulation.legacy_app.start_simulation:54 of
msgid ""
"Set to True to prevent `ray.shutdown()` in case "
"`ray.is_initialized()=True`."
msgstr ""

#: flwr.simulation.legacy_app.start_simulation:56 of
msgid ""
"Optionally specify the type of actor to use. The actor object, which "
"persists throughout the simulation, will be the process in charge of "
"executing a ClientApp wrapping input argument `client_fn`."
msgstr ""

#: flwr.simulation.legacy_app.start_simulation:60 of
msgid ""
"If you want to create your own Actor classes, you might need to pass some"
" input argument. You can use this dictionary for such purpose."
msgstr ""

#: flwr.simulation.legacy_app.start_simulation:63 of
msgid ""
"(default: \"DEFAULT\") Optional string (\"DEFAULT\" or \"SPREAD\") for "
"the VCE to choose in which node the actor is placed. If you are an "
"advanced user needed more control you can use lower-level scheduling "
"strategies to pin actors to specific compute nodes (e.g. via "
"NodeAffinitySchedulingStrategy). Please note this is an advanced feature."
" For all details, please refer to the Ray documentation: "
"https://docs.ray.io/en/latest/ray-core/scheduling/index.html"
msgstr ""

#: flwr.simulation.legacy_app.start_simulation:72 of
#, fuzzy
msgid "**hist** -- Object containing metrics from training."
msgstr "**hist** -- 包含训练和评估指标的对象。"

#: ../../source/ref-changelog.md:1
msgid "Changelog"
msgstr "更新日志"

#: ../../source/ref-changelog.md:3
#, fuzzy
msgid "v1.12.0 (2024-10-14)"
msgstr "v1.1.0 (2022-10-31)"

#: ../../source/ref-changelog.md:5 ../../source/ref-changelog.md:75
#: ../../source/ref-changelog.md:107 ../../source/ref-changelog.md:211
#: ../../source/ref-changelog.md:309 ../../source/ref-changelog.md:409
#: ../../source/ref-changelog.md:473 ../../source/ref-changelog.md:566
#: ../../source/ref-changelog.md:666 ../../source/ref-changelog.md:750
#: ../../source/ref-changelog.md:814 ../../source/ref-changelog.md:872
#: ../../source/ref-changelog.md:941 ../../source/ref-changelog.md:1010
msgid "Thanks to our contributors"
msgstr "感谢我们的贡献者"

#: ../../source/ref-changelog.md:7 ../../source/ref-changelog.md:77
#: ../../source/ref-changelog.md:109 ../../source/ref-changelog.md:213
#: ../../source/ref-changelog.md:311 ../../source/ref-changelog.md:411
#: ../../source/ref-changelog.md:475 ../../source/ref-changelog.md:568
#: ../../source/ref-changelog.md:668 ../../source/ref-changelog.md:752
#: ../../source/ref-changelog.md:816 ../../source/ref-changelog.md:874
msgid ""
"We would like to give our special thanks to all the contributors who made"
" the new version of Flower possible (in `git shortlog` order):"
msgstr "在此，我们要特别感谢所有为 Flower 的新版本做出贡献的人员（按 `git shortlog` 顺序排列）："

#: ../../source/ref-changelog.md:9
#, fuzzy
msgid ""
"`Adam Narozniak`, `Audris`, `Charles Beauville`, `Chong Shen Ng`, `Daniel"
" J. Beutel`, `Daniel Nata Nugraha`, `Heng Pan`, `Javier`, `Jiahao Tan`, "
"`Julian Rußmeyer`, `Mohammad Naseri`, `Ray Sun`, `Robert Steiner`, `Yan "
"Gao`, `xiliguguagua` <!---TOKEN_v1.12.0-->"
msgstr ""
"`Adam Narozniak`, `Anass Anhari`, `Charles Beauville`, `Dana-Farber`, "
"`Daniel J. Beutel`, `Daniel Nata Nugraha`, `Edoardo Gabrielli`, `Gustavo "
"Bertoli`, `Heng Pan`, `Javier`, `Mahdi`, `Steven Hé (Sīchàng)`, `Taner "
"Topal`, `achiverram28`, `danielnugraha`, `eunchung`, `ruthgal` <!---"
"TOKEN_v1.5.0-->"

#: ../../source/ref-changelog.md:11 ../../source/ref-changelog.md:113
#: ../../source/ref-changelog.md:217 ../../source/ref-changelog.md:315
#: ../../source/ref-changelog.md:415 ../../source/ref-changelog.md:479
#: ../../source/ref-changelog.md:572 ../../source/ref-changelog.md:672
#: ../../source/ref-changelog.md:756 ../../source/ref-changelog.md:820
#: ../../source/ref-changelog.md:878 ../../source/ref-changelog.md:947
#: ../../source/ref-changelog.md:1076 ../../source/ref-changelog.md:1118
#: ../../source/ref-changelog.md:1185 ../../source/ref-changelog.md:1251
#: ../../source/ref-changelog.md:1296 ../../source/ref-changelog.md:1335
#: ../../source/ref-changelog.md:1368 ../../source/ref-changelog.md:1418
msgid "What's new?"
msgstr "有什么新内容？"

#: ../../source/ref-changelog.md:13
#, fuzzy
msgid ""
"**Introduce SuperExec log streaming** "
"([#3577](https://github.com/adap/flower/pull/3577), "
"[#3584](https://github.com/adap/flower/pull/3584), "
"[#4242](https://github.com/adap/flower/pull/4242), "
"[#3611](https://github.com/adap/flower/pull/3611), "
"[#3613](https://github.com/adap/flower/pull/3613))"
msgstr ""
"**移除对 Python 3.7 的支持** "
"([#2280](https://github.com/adap/flower/pull/2280), "
"[#2299](https://github.com/adap/flower/pull/2299), "
"[#2304](https://github.com/adap/flower/pull/2304), "
"[#2306](https://github.com/adap/flower/pull/2306), "
"[#2355](https://github.com/adap/flower/pull/2355), "
"[#2356](https://github.com/adap/flower/pull/2356))"

#: ../../source/ref-changelog.md:15
msgid ""
"Flower now supports log streaming from a remote SuperExec using the `flwr"
" log` command. This new feature allows you to monitor logs from SuperExec"
" in real time via `flwr log <run-id>` (or `flwr log <run-id> <app-dir> "
"<federation>`)."
msgstr ""

#: ../../source/ref-changelog.md:17
#, fuzzy
msgid ""
"**Improve `flwr new` templates** "
"([#4291](https://github.com/adap/flower/pull/4291), "
"[#4292](https://github.com/adap/flower/pull/4292), "
"[#4293](https://github.com/adap/flower/pull/4293), "
"[#4294](https://github.com/adap/flower/pull/4294), "
"[#4295](https://github.com/adap/flower/pull/4295))"
msgstr ""
"**改进教程** ([#1468](https://github.com/adap/flower/pull/1468), "
"[#1470](https://github.com/adap/flower/pull/1470), "
"[#1472](https://github.com/adap/flower/pull/1472), "
"[#1473](https://github.com/adap/flower/pull/1473), "
"[#1474](https://github.com/adap/flower/pull/1474), "
"[#1475](https://github.com/adap/flower/pull/1475)))"

#: ../../source/ref-changelog.md:19
msgid ""
"The `flwr new` command templates for MLX, NumPy, sklearn, JAX, and "
"PyTorch have been updated to improve usability and consistency across "
"frameworks."
msgstr ""

#: ../../source/ref-changelog.md:21
#, fuzzy
msgid ""
"**Migrate ID handling to use unsigned 64-bit integers** "
"([#4170](https://github.com/adap/flower/pull/4170), "
"[#4237](https://github.com/adap/flower/pull/4237), "
"[#4243](https://github.com/adap/flower/pull/4243))"
msgstr ""
"**更新代码示例** ([#1291](https://github.com/adap/flower/pull/1291), "
"[#1286](https://github.com/adap/flower/pull/1286), "
"[#1282](https://github.com/adap/flower/pull/1282))"

#: ../../source/ref-changelog.md:23
msgid ""
"Node IDs, run IDs, and related fields have been migrated from signed "
"64-bit integers (`sint64`) to unsigned 64-bit integers (`uint64`). To "
"support this change, the `uint64` type is fully supported in all "
"communications. You may now use `uint64` values in config and metric "
"dictionaries. For Python users, that means using `int` values larger than"
" the maximum value of `sint64` but less than the maximum value of "
"`uint64`."
msgstr ""

#: ../../source/ref-changelog.md:25
#, fuzzy
msgid ""
"**Add Flower architecture explanation** "
"([#3270](https://github.com/adap/flower/pull/3270))"
msgstr "**重构文档**（[#1387](https://github.com/adap/flower/pull/1387)）"

#: ../../source/ref-changelog.md:27
msgid ""
"A new [Flower architecture explainer](https://flower.ai/docs/framework"
"/explanation-flower-architecture.html) page introduces Flower components "
"step-by-step. Check out the `EXPLANATIONS` section of the Flower "
"documentation if you're interested."
msgstr ""

#: ../../source/ref-changelog.md:29
#, fuzzy
msgid ""
"**Introduce FedRep baseline** "
"([#3790](https://github.com/adap/flower/pull/3790))"
msgstr "**引入 start_driver**（[#1697](https://github.com/adap/flower/pull/1697)）"

#: ../../source/ref-changelog.md:31
msgid ""
"FedRep is a federated learning algorithm that learns shared data "
"representations across clients while allowing each to maintain "
"personalized local models, balancing collaboration and individual "
"adaptation. Read all the details in the paper: \"Exploiting Shared "
"Representations for Personalized Federated Learning\" "
"([arxiv](https://arxiv.org/abs/2102.07078))"
msgstr ""

#: ../../source/ref-changelog.md:33
#, fuzzy
msgid ""
"**Improve FlowerTune template and LLM evaluation pipelines** "
"([#4286](https://github.com/adap/flower/pull/4286), "
"[#3769](https://github.com/adap/flower/pull/3769), "
"[#4272](https://github.com/adap/flower/pull/4272), "
"[#4257](https://github.com/adap/flower/pull/4257), "
"[#4220](https://github.com/adap/flower/pull/4220), "
"[#4282](https://github.com/adap/flower/pull/4282), "
"[#4171](https://github.com/adap/flower/pull/4171), "
"[#4228](https://github.com/adap/flower/pull/4228), "
"[#4258](https://github.com/adap/flower/pull/4258), "
"[#4296](https://github.com/adap/flower/pull/4296), "
"[#4287](https://github.com/adap/flower/pull/4287), "
"[#4217](https://github.com/adap/flower/pull/4217), "
"[#4249](https://github.com/adap/flower/pull/4249), "
"[#4324](https://github.com/adap/flower/pull/4324), "
"[#4219](https://github.com/adap/flower/pull/4219), "
"[#4327](https://github.com/adap/flower/pull/4327))"
msgstr ""
"**更新文档** ([#1223](https://github.com/adap/flower/pull/1223), "
"[#1209](https://github.com/adap/flower/pull/1209), "
"[#1251](https://github.com/adap/flower/pull/1251), "
"[#1257](https://github.com/adap/flower/pull/1257), "
"[#1267](https://github.com/adap/flower/pull/1267), "
"[#1268](https://github.com/adap/flower/pull/1268), "
"[#1300](https://github.com/adap/flower/pull/1300), "
"[#1304](https://github.com/adap/flower/pull/1304), "
"[#1305](https://github.com/adap/flower/pull/1305), "
"[#1307](https://github.com/adap/flower/pull/1307))"

#: ../../source/ref-changelog.md:35
msgid ""
"Refined evaluation pipelines, metrics, and documentation for the upcoming"
" FlowerTune LLM Leaderboard across multiple domains including Finance, "
"Medical, and general NLP. Stay tuned for the official launch—we welcome "
"all federated learning and LLM enthusiasts to participate in this "
"exciting challenge!"
msgstr ""

#: ../../source/ref-changelog.md:37
#, fuzzy
msgid ""
"**Enhance Docker Support and Documentation** "
"([#4191](https://github.com/adap/flower/pull/4191), "
"[#4251](https://github.com/adap/flower/pull/4251), "
"[#4190](https://github.com/adap/flower/pull/4190), "
"[#3928](https://github.com/adap/flower/pull/3928), "
"[#4298](https://github.com/adap/flower/pull/4298), "
"[#4192](https://github.com/adap/flower/pull/4192), "
"[#4136](https://github.com/adap/flower/pull/4136), "
"[#4187](https://github.com/adap/flower/pull/4187), "
"[#4261](https://github.com/adap/flower/pull/4261), "
"[#4177](https://github.com/adap/flower/pull/4177), "
"[#4176](https://github.com/adap/flower/pull/4176), "
"[#4189](https://github.com/adap/flower/pull/4189), "
"[#4297](https://github.com/adap/flower/pull/4297), "
"[#4226](https://github.com/adap/flower/pull/4226))"
msgstr ""
"**改进教程** ([#1468](https://github.com/adap/flower/pull/1468), "
"[#1470](https://github.com/adap/flower/pull/1470), "
"[#1472](https://github.com/adap/flower/pull/1472), "
"[#1473](https://github.com/adap/flower/pull/1473), "
"[#1474](https://github.com/adap/flower/pull/1474), "
"[#1475](https://github.com/adap/flower/pull/1475)))"

#: ../../source/ref-changelog.md:39
msgid ""
"Upgraded Ubuntu base image to 24.04, added SBOM and gcc to Docker images,"
" and comprehensively updated [Docker "
"documentation](https://flower.ai/docs/framework/docker/index.html) "
"including quickstart guides and distributed Docker Compose instructions."
msgstr ""

#: ../../source/ref-changelog.md:41
#, fuzzy
msgid ""
"**Introduce Flower glossary** "
"([#4165](https://github.com/adap/flower/pull/4165), "
"[#4235](https://github.com/adap/flower/pull/4235))"
msgstr ""
"**介绍 Flower Swift SDK** "
"([#1858](https://github.com/adap/flower/pull/1858), "
"[#1897](https://github.com/adap/flower/pull/1897))"

#: ../../source/ref-changelog.md:43
msgid ""
"Added the [Federated Learning glossary](https://flower.ai/glossary/) to "
"the Flower repository, located under the `flower/glossary/` directory. "
"This resource aims to provide clear definitions and explanations of key "
"FL concepts. Community contributions are highly welcomed to help expand "
"and refine this knowledge base — this is probably the easiest way to "
"become a Flower contributor!"
msgstr ""

#: ../../source/ref-changelog.md:45
#, fuzzy
msgid ""
"**Implement Message Time-to-Live (TTL)** "
"([#3620](https://github.com/adap/flower/pull/3620), "
"[#3596](https://github.com/adap/flower/pull/3596), "
"[#3615](https://github.com/adap/flower/pull/3615), "
"[#3609](https://github.com/adap/flower/pull/3609), "
"[#3635](https://github.com/adap/flower/pull/3635))"
msgstr ""
"** 更新文档** ([#1629](https://github.com/adap/flower/pull/1629), "
"[#1628](https://github.com/adap/flower/pull/1628), "
"[#1620](https://github.com/adap/flower/pull/1620), "
"[#1618](https://github.com/adap/flower/pull/1618), "
"[#1617](https://github.com/adap/flower/pull/1617), "
"[#1613](https://github.com/adap/flower/pull/1613), "
"[#1614](https://github.com/adap/flower/pull/1614)))"

#: ../../source/ref-changelog.md:47
msgid ""
"Added comprehensive TTL support for messages in Flower's SuperLink. "
"Messages are now automatically expired and cleaned up based on "
"configurable TTL values, available through the low-level API (and used by"
" default in the high-level API)."
msgstr ""

#: ../../source/ref-changelog.md:49
#, fuzzy
msgid ""
"**Improve FAB handling** "
"([#4303](https://github.com/adap/flower/pull/4303), "
"[#4264](https://github.com/adap/flower/pull/4264), "
"[#4305](https://github.com/adap/flower/pull/4305), "
"[#4304](https://github.com/adap/flower/pull/4304))"
msgstr ""
"更新开发人员工具（[#1231](https://github.com/adap/flower/pull/1231), "
"[#1276](https://github.com/adap/flower/pull/1276), "
"[#1301](https://github.com/adap/flower/pull/1301), "
"[#1310](https://github.com/adap/flower/pull/1310)"

#: ../../source/ref-changelog.md:51
msgid ""
"An 8-character hash is now appended to the FAB file name. The `flwr "
"install` command installs FABs with a more flattened folder structure, "
"reducing it from 3 levels to 1."
msgstr ""

#: ../../source/ref-changelog.md:53
#, fuzzy
msgid ""
"**Update documentation** "
"([#3341](https://github.com/adap/flower/pull/3341), "
"[#3338](https://github.com/adap/flower/pull/3338), "
"[#3927](https://github.com/adap/flower/pull/3927), "
"[#4152](https://github.com/adap/flower/pull/4152), "
"[#4151](https://github.com/adap/flower/pull/4151), "
"[#3993](https://github.com/adap/flower/pull/3993))"
msgstr ""
"**移除对 Python 3.7 的支持** "
"([#2280](https://github.com/adap/flower/pull/2280), "
"[#2299](https://github.com/adap/flower/pull/2299), "
"[#2304](https://github.com/adap/flower/pull/2304), "
"[#2306](https://github.com/adap/flower/pull/2306), "
"[#2355](https://github.com/adap/flower/pull/2355), "
"[#2356](https://github.com/adap/flower/pull/2356))"

#: ../../source/ref-changelog.md:55
msgid ""
"Updated quickstart tutorials (PyTorch Lightning, TensorFlow, Hugging "
"Face, Fastai) to use the new `flwr run` command and removed default title"
" from documentation base template. A new blockchain example has been "
"added to FAQ."
msgstr ""

#: ../../source/ref-changelog.md:57
#, fuzzy
msgid ""
"**Update example projects** "
"([#3716](https://github.com/adap/flower/pull/3716), "
"[#4007](https://github.com/adap/flower/pull/4007), "
"[#4130](https://github.com/adap/flower/pull/4130), "
"[#4234](https://github.com/adap/flower/pull/4234), "
"[#4206](https://github.com/adap/flower/pull/4206), "
"[#4188](https://github.com/adap/flower/pull/4188), "
"[#4247](https://github.com/adap/flower/pull/4247), "
"[#4331](https://github.com/adap/flower/pull/4331))"
msgstr ""
"**普通改进**（[#1872](https://github.com/adap/flower/pull/1872), "
"[#1866](https://github.com/adap/flower/pull/1866), "
"[#1884](https://github.com/adap/flower/pull/1884), "
"[#1837](https://github.com/adap/flower/pull/1837), "
"[#1477](https://github.com/adap/flower/pull/1477), "
"[#2171](https://github.com/adap/flower/pull/2171))"

#: ../../source/ref-changelog.md:59
msgid ""
"Refreshed multiple example projects including vertical FL, PyTorch "
"(advanced), Pandas, Secure Aggregation, and XGBoost examples. Optimized "
"Hugging Face quickstart with a smaller language model and removed legacy "
"simulation examples."
msgstr ""

#: ../../source/ref-changelog.md:61
#, fuzzy
msgid ""
"**Update translations** "
"([#4070](https://github.com/adap/flower/pull/4070), "
"[#4316](https://github.com/adap/flower/pull/4316), "
"[#4252](https://github.com/adap/flower/pull/4252), "
"[#4256](https://github.com/adap/flower/pull/4256), "
"[#4210](https://github.com/adap/flower/pull/4210), "
"[#4263](https://github.com/adap/flower/pull/4263), "
"[#4259](https://github.com/adap/flower/pull/4259))"
msgstr ""
"** 更新文档** ([#1629](https://github.com/adap/flower/pull/1629), "
"[#1628](https://github.com/adap/flower/pull/1628), "
"[#1620](https://github.com/adap/flower/pull/1620), "
"[#1618](https://github.com/adap/flower/pull/1618), "
"[#1617](https://github.com/adap/flower/pull/1617), "
"[#1613](https://github.com/adap/flower/pull/1613), "
"[#1614](https://github.com/adap/flower/pull/1614)))"

#: ../../source/ref-changelog.md:63
msgid ""
"**General improvements** "
"([#4239](https://github.com/adap/flower/pull/4239), "
"[4276](https://github.com/adap/flower/pull/4276), "
"[4204](https://github.com/adap/flower/pull/4204), "
"[4184](https://github.com/adap/flower/pull/4184), "
"[4227](https://github.com/adap/flower/pull/4227), "
"[4183](https://github.com/adap/flower/pull/4183), "
"[4202](https://github.com/adap/flower/pull/4202), "
"[4250](https://github.com/adap/flower/pull/4250), "
"[4267](https://github.com/adap/flower/pull/4267), "
"[4246](https://github.com/adap/flower/pull/4246), "
"[4240](https://github.com/adap/flower/pull/4240), "
"[4265](https://github.com/adap/flower/pull/4265), "
"[4238](https://github.com/adap/flower/pull/4238), "
"[4275](https://github.com/adap/flower/pull/4275), "
"[4318](https://github.com/adap/flower/pull/4318), "
"[#4178](https://github.com/adap/flower/pull/4178), "
"[#4315](https://github.com/adap/flower/pull/4315), "
"[#4241](https://github.com/adap/flower/pull/4241), "
"[#4289](https://github.com/adap/flower/pull/4289), "
"[#4290](https://github.com/adap/flower/pull/4290), "
"[#4181](https://github.com/adap/flower/pull/4181), "
"[#4208](https://github.com/adap/flower/pull/4208), "
"[#4225](https://github.com/adap/flower/pull/4225), "
"[#4314](https://github.com/adap/flower/pull/4314), "
"[#4174](https://github.com/adap/flower/pull/4174), "
"[#4203](https://github.com/adap/flower/pull/4203), "
"[#4274](https://github.com/adap/flower/pull/4274), "
"[#3154](https://github.com/adap/flower/pull/3154), "
"[#4201](https://github.com/adap/flower/pull/4201), "
"[#4268](https://github.com/adap/flower/pull/4268), "
"[#4254](https://github.com/adap/flower/pull/4254), "
"[#3990](https://github.com/adap/flower/pull/3990), "
"[#4212](https://github.com/adap/flower/pull/4212), "
"[#2938](https://github.com/adap/flower/pull/2938), "
"[#4205](https://github.com/adap/flower/pull/4205), "
"[#4222](https://github.com/adap/flower/pull/4222), "
"[#4313](https://github.com/adap/flower/pull/4313), "
"[#3936](https://github.com/adap/flower/pull/3936), "
"[#4278](https://github.com/adap/flower/pull/4278), "
"[#4319](https://github.com/adap/flower/pull/4319), "
"[#4332](https://github.com/adap/flower/pull/4332), "
"[#4333](https://github.com/adap/flower/pull/4333))"
msgstr ""

#: ../../source/ref-changelog.md:65 ../../source/ref-changelog.md:168
#: ../../source/ref-changelog.md:275
msgid ""
"As always, many parts of the Flower framework and quality infrastructure "
"were improved and updated."
msgstr ""

#: ../../source/ref-changelog.md:67 ../../source/ref-changelog.md:101
#: ../../source/ref-changelog.md:181 ../../source/ref-changelog.md:297
#: ../../source/ref-changelog.md:393 ../../source/ref-changelog.md:467
#: ../../source/ref-changelog.md:542 ../../source/ref-changelog.md:654
#: ../../source/ref-changelog.md:744 ../../source/ref-changelog.md:808
#: ../../source/ref-changelog.md:866 ../../source/ref-changelog.md:935
#: ../../source/ref-changelog.md:997 ../../source/ref-changelog.md:1016
#: ../../source/ref-changelog.md:1172 ../../source/ref-changelog.md:1243
#: ../../source/ref-changelog.md:1280 ../../source/ref-changelog.md:1323
msgid "Incompatible changes"
msgstr "不兼容的更改"

#: ../../source/ref-changelog.md:69
#, fuzzy
msgid ""
"**Drop Python 3.8 support and update minimum version to 3.9** "
"([#4180](https://github.com/adap/flower/pull/4180), "
"[#4213](https://github.com/adap/flower/pull/4213), "
"[#4193](https://github.com/adap/flower/pull/4193), "
"[#4199](https://github.com/adap/flower/pull/4199), "
"[#4196](https://github.com/adap/flower/pull/4196), "
"[#4195](https://github.com/adap/flower/pull/4195), "
"[#4198](https://github.com/adap/flower/pull/4198), "
"[#4194](https://github.com/adap/flower/pull/4194))"
msgstr ""
"** 更新文档** ([#1629](https://github.com/adap/flower/pull/1629), "
"[#1628](https://github.com/adap/flower/pull/1628), "
"[#1620](https://github.com/adap/flower/pull/1620), "
"[#1618](https://github.com/adap/flower/pull/1618), "
"[#1617](https://github.com/adap/flower/pull/1617), "
"[#1613](https://github.com/adap/flower/pull/1613), "
"[#1614](https://github.com/adap/flower/pull/1614)))"

#: ../../source/ref-changelog.md:71
msgid ""
"Python 3.8 support was deprecated in Flower 1.9, and this release removes"
" support. Flower now requires Python 3.9 or later (Python 3.11 is "
"recommended). CI and documentation were updated to use Python 3.9 as the "
"minimum supported version. Flower now supports Python 3.9 to 3.12."
msgstr ""

#: ../../source/ref-changelog.md:73
#, fuzzy
msgid "v1.11.1 (2024-09-11)"
msgstr "v1.3.0 (2023-02-06)"

#: ../../source/ref-changelog.md:79
#, fuzzy
msgid ""
"`Charles Beauville`, `Chong Shen Ng`, `Daniel J. Beutel`, `Heng Pan`, "
"`Javier`, `Robert Steiner`, `Yan Gao` <!---TOKEN_v1.11.1-->"
msgstr ""
"`Adam Narozniak`, `Anass Anhari`, `Charles Beauville`, `Dana-Farber`, "
"`Daniel J. Beutel`, `Daniel Nata Nugraha`, `Edoardo Gabrielli`, `Gustavo "
"Bertoli`, `Heng Pan`, `Javier`, `Mahdi`, `Steven Hé (Sīchàng)`, `Taner "
"Topal`, `achiverram28`, `danielnugraha`, `eunchung`, `ruthgal` <!---"
"TOKEN_v1.5.0-->"

#: ../../source/ref-changelog.md:81
#, fuzzy
msgid "Improvements"
msgstr "可选的改进措施"

#: ../../source/ref-changelog.md:83
#, fuzzy
msgid ""
"**Implement** `keys/values/items` **methods for** `TypedDict` "
"([#4146](https://github.com/adap/flower/pull/4146))"
msgstr ""
"**使** `get_parameters` **可配置** "
"([#1242](https://github.com/adap/flower/pull/1242))"

#: ../../source/ref-changelog.md:85
#, fuzzy
msgid ""
"**Fix parsing of** `--executor-config` **if present** "
"([#4125](https://github.com/adap/flower/pull/4125))"
msgstr "**引入 start_driver**（[#1697](https://github.com/adap/flower/pull/1697)）"

#: ../../source/ref-changelog.md:87
#, fuzzy
msgid ""
"**Adjust framework name in templates docstrings** "
"([#4127](https://github.com/adap/flower/pull/4127))"
msgstr "**新的 scikit-learn 代码示例** ([#748](https://github.com/adap/flower/pull/748))"

#: ../../source/ref-changelog.md:89
#, fuzzy
msgid ""
"**Update** `flwr new` **Hugging Face template** "
"([#4169](https://github.com/adap/flower/pull/4169))"
msgstr ""
"**新的Hugging Face Transformers代码示例** "
"([#863](https://github.com/adap/flower/pull/863))"

#: ../../source/ref-changelog.md:91
#, fuzzy
msgid ""
"**Fix** `flwr new` **FlowerTune template** "
"([#4123](https://github.com/adap/flower/pull/4123))"
msgstr "**新的 iOS CoreML 代码示例**（[#1289](https://github.com/adap/flower/pull/1289)）"

#: ../../source/ref-changelog.md:93
#, fuzzy
msgid ""
"**Add buffer time after** `ServerApp` **thread initialization** "
"([#4119](https://github.com/adap/flower/pull/4119))"
msgstr ""
"**在模拟过程中为***`历史`***对象添加训练指标*** "
"([#1696](https://github.com/adap/flower/pull/1696))"

#: ../../source/ref-changelog.md:95
#, fuzzy
msgid ""
"**Handle unsuitable resources for simulation** "
"([#4143](https://github.com/adap/flower/pull/4143))"
msgstr "** 添加新的模拟监控指南** ([#1649](https://github.com/adap/flower/pull/1649))"

#: ../../source/ref-changelog.md:97
#, fuzzy
msgid ""
"**Update example READMEs** "
"([#4117](https://github.com/adap/flower/pull/4117))"
msgstr ""
"**介绍Flower Android SDK** "
"([#2131](https://github.com/adap/flower/pull/2131))"

#: ../../source/ref-changelog.md:99
#, fuzzy
msgid ""
"**Update SuperNode authentication docs** "
"([#4160](https://github.com/adap/flower/pull/4160))"
msgstr "** 添加一个新的 gRPC 选项**（[#2197](https://github.com/adap/flower/pull/2197)）"

#: ../../source/ref-changelog.md:105
#, fuzzy
msgid "v1.11.0 (2024-08-30)"
msgstr "v1.3.0 (2023-02-06)"

#: ../../source/ref-changelog.md:111
#, fuzzy
msgid ""
"`Adam Narozniak`, `Charles Beauville`, `Chong Shen Ng`, `Daniel J. "
"Beutel`, `Daniel Nata Nugraha`, `Danny`, `Edoardo Gabrielli`, `Heng Pan`,"
" `Javier`, `Meng Yan`, `Michal Danilowski`, `Mohammad Naseri`, `Robert "
"Steiner`, `Steve Laskaridis`, `Taner Topal`, `Yan Gao` <!---"
"TOKEN_v1.11.0-->"
msgstr ""
"`Adam Narozniak`, `Anass Anhari`, `Charles Beauville`, `Dana-Farber`, "
"`Daniel J. Beutel`, `Daniel Nata Nugraha`, `Edoardo Gabrielli`, `Gustavo "
"Bertoli`, `Heng Pan`, `Javier`, `Mahdi`, `Steven Hé (Sīchàng)`, `Taner "
"Topal`, `achiverram28`, `danielnugraha`, `eunchung`, `ruthgal` <!---"
"TOKEN_v1.5.0-->"

#: ../../source/ref-changelog.md:115
msgid ""
"**Deliver Flower App Bundle (FAB) to SuperLink and SuperNodes** "
"([#4006](https://github.com/adap/flower/pull/4006), "
"[#3945](https://github.com/adap/flower/pull/3945), "
"[#3999](https://github.com/adap/flower/pull/3999), "
"[#4027](https://github.com/adap/flower/pull/4027), "
"[#3851](https://github.com/adap/flower/pull/3851), "
"[#3946](https://github.com/adap/flower/pull/3946), "
"[#4003](https://github.com/adap/flower/pull/4003), "
"[#4029](https://github.com/adap/flower/pull/4029), "
"[#3942](https://github.com/adap/flower/pull/3942), "
"[#3957](https://github.com/adap/flower/pull/3957), "
"[#4020](https://github.com/adap/flower/pull/4020), "
"[#4044](https://github.com/adap/flower/pull/4044), "
"[#3852](https://github.com/adap/flower/pull/3852), "
"[#4019](https://github.com/adap/flower/pull/4019), "
"[#4031](https://github.com/adap/flower/pull/4031), "
"[#4036](https://github.com/adap/flower/pull/4036), "
"[#4049](https://github.com/adap/flower/pull/4049), "
"[#4017](https://github.com/adap/flower/pull/4017), "
"[#3943](https://github.com/adap/flower/pull/3943), "
"[#3944](https://github.com/adap/flower/pull/3944), "
"[#4011](https://github.com/adap/flower/pull/4011), "
"[#3619](https://github.com/adap/flower/pull/3619))"
msgstr ""

#: ../../source/ref-changelog.md:117
msgid ""
"Dynamic code updates are here! `flwr run` can now ship and install the "
"latest version of your `ServerApp` and `ClientApp` to an already-running "
"federation (SuperLink and SuperNodes)."
msgstr ""

#: ../../source/ref-changelog.md:119
msgid ""
"How does it work? `flwr run` bundles your Flower app into a single FAB "
"(Flower App Bundle) file. It then ships this FAB file, via the SuperExec,"
" to both the SuperLink and those SuperNodes that need it. This allows you"
" to keep SuperExec, SuperLink and SuperNodes running as permanent "
"infrastructure, and then ship code updates (including completely new "
"projects!) dynamically."
msgstr ""

#: ../../source/ref-changelog.md:121
msgid "`flwr run` is all you need."
msgstr ""

#: ../../source/ref-changelog.md:123
#, fuzzy
msgid ""
"**Introduce isolated** `ClientApp` **execution** "
"([#3970](https://github.com/adap/flower/pull/3970), "
"[#3976](https://github.com/adap/flower/pull/3976), "
"[#4002](https://github.com/adap/flower/pull/4002), "
"[#4001](https://github.com/adap/flower/pull/4001), "
"[#4034](https://github.com/adap/flower/pull/4034), "
"[#4037](https://github.com/adap/flower/pull/4037), "
"[#3977](https://github.com/adap/flower/pull/3977), "
"[#4042](https://github.com/adap/flower/pull/4042), "
"[#3978](https://github.com/adap/flower/pull/3978), "
"[#4039](https://github.com/adap/flower/pull/4039), "
"[#4033](https://github.com/adap/flower/pull/4033), "
"[#3971](https://github.com/adap/flower/pull/3971), "
"[#4035](https://github.com/adap/flower/pull/4035), "
"[#3973](https://github.com/adap/flower/pull/3973), "
"[#4032](https://github.com/adap/flower/pull/4032))"
msgstr ""
"**普通改进** ([#1491](https://github.com/adap/flower/pull/1491), "
"[#1504](https://github.com/adap/flower/pull/1504), "
"[#1506](https://github.com/adap/flower/pull/1506), "
"[#1514](https://github.com/adap/flower/pull/1514), "
"[#1522](https://github.com/adap/flower/pull/1522), "
"[#1523](https://github.com/adap/flower/pull/1523), "
"[#1526](https://github. com/adap/flower/pull/1526), "
"[#1528](https://github.com/adap/flower/pull/1528), "
"[#1547](https://github.com/adap/flower/pull/1547), "
"[#1549](https://github.com/adap/flower/pull/1549), "
"[#1560](https://github.com/adap/flower/pull/1560), "
"[#1564](https://github.com/adap/flower/pull/1564), "
"[#1566](https://github.com/adap/flower/pull/1566))"

#: ../../source/ref-changelog.md:125
msgid ""
"The SuperNode can now run your `ClientApp` in a fully isolated way. In an"
" enterprise deployment, this allows you to set strict limits on what the "
"`ClientApp` can and cannot do."
msgstr ""

#: ../../source/ref-changelog.md:127
msgid "`flower-supernode` supports three `--isolation` modes:"
msgstr ""

#: ../../source/ref-changelog.md:129
msgid ""
"Unset: The SuperNode runs the `ClientApp` in the same process (as in "
"previous versions of Flower). This is the default mode."
msgstr ""

#: ../../source/ref-changelog.md:130
msgid ""
"`--isolation=subprocess`: The SuperNode starts a subprocess to run the "
"`ClientApp`."
msgstr ""

#: ../../source/ref-changelog.md:131
msgid ""
"`--isolation=process`: The SuperNode expects an externally-managed "
"process to run the `ClientApp`. This external process is not managed by "
"the SuperNode, so it has to be started beforehand and terminated "
"manually. The common way to use this isolation mode is via the new "
"`flwr/clientapp` Docker image."
msgstr ""

#: ../../source/ref-changelog.md:133
#, fuzzy
msgid ""
"**Improve Docker support for enterprise deployments** "
"([#4050](https://github.com/adap/flower/pull/4050), "
"[#4090](https://github.com/adap/flower/pull/4090), "
"[#3784](https://github.com/adap/flower/pull/3784), "
"[#3998](https://github.com/adap/flower/pull/3998), "
"[#4094](https://github.com/adap/flower/pull/4094), "
"[#3722](https://github.com/adap/flower/pull/3722))"
msgstr ""
"**移除对 Python 3.7 的支持** "
"([#2280](https://github.com/adap/flower/pull/2280), "
"[#2299](https://github.com/adap/flower/pull/2299), "
"[#2304](https://github.com/adap/flower/pull/2304), "
"[#2306](https://github.com/adap/flower/pull/2306), "
"[#2355](https://github.com/adap/flower/pull/2355), "
"[#2356](https://github.com/adap/flower/pull/2356))"

#: ../../source/ref-changelog.md:135
msgid ""
"Flower 1.11 ships many Docker improvements that are especially useful for"
" enterprise deployments:"
msgstr ""

#: ../../source/ref-changelog.md:137
msgid "`flwr/supernode` comes with a new Alpine Docker image."
msgstr ""

#: ../../source/ref-changelog.md:138
msgid ""
"`flwr/clientapp` is a new image to be used with the `--isolation=process`"
" option. In this mode, SuperNode and `ClientApp` run in two different "
"Docker containers. `flwr/supernode` (preferably the Alpine version) runs "
"the long-running SuperNode with `--isolation=process`. `flwr/clientapp` "
"runs the `ClientApp`. This is the recommended way to deploy Flower in "
"enterprise settings."
msgstr ""

#: ../../source/ref-changelog.md:139
msgid ""
"New all-in-one Docker Compose enables you to easily start a full Flower "
"Deployment Engine on a single machine."
msgstr ""

#: ../../source/ref-changelog.md:140
msgid ""
"Completely new Docker documentation: "
"https://flower.ai/docs/framework/docker/index.html"
msgstr ""

#: ../../source/ref-changelog.md:142
#, fuzzy
msgid ""
"**Improve SuperNode authentication** "
"([#4043](https://github.com/adap/flower/pull/4043), "
"[#4047](https://github.com/adap/flower/pull/4047), "
"[#4074](https://github.com/adap/flower/pull/4074))"
msgstr ""
"** 统一客户端应用程序接口** ([#2303](https://github.com/adap/flower/pull/2303), "
"[#2390](https://github.com/adap/flower/pull/2390), "
"[#2493](https://github.com/adap/flower/pull/2493))"

#: ../../source/ref-changelog.md:144
msgid ""
"SuperNode auth has been improved in several ways, including improved "
"logging, improved testing, and improved error handling."
msgstr ""

#: ../../source/ref-changelog.md:146
#, fuzzy
msgid ""
"**Update** `flwr new` **templates** "
"([#3933](https://github.com/adap/flower/pull/3933), "
"[#3894](https://github.com/adap/flower/pull/3894), "
"[#3930](https://github.com/adap/flower/pull/3930), "
"[#3931](https://github.com/adap/flower/pull/3931), "
"[#3997](https://github.com/adap/flower/pull/3997), "
"[#3979](https://github.com/adap/flower/pull/3979), "
"[#3965](https://github.com/adap/flower/pull/3965), "
"[#4013](https://github.com/adap/flower/pull/4013), "
"[#4064](https://github.com/adap/flower/pull/4064))"
msgstr ""
"**普通改进**（[#1872](https://github.com/adap/flower/pull/1872), "
"[#1866](https://github.com/adap/flower/pull/1866), "
"[#1884](https://github.com/adap/flower/pull/1884), "
"[#1837](https://github.com/adap/flower/pull/1837), "
"[#1477](https://github.com/adap/flower/pull/1477), "
"[#2171](https://github.com/adap/flower/pull/2171))"

#: ../../source/ref-changelog.md:148
msgid ""
"All `flwr new` templates have been updated to show the latest recommended"
" use of Flower APIs."
msgstr ""

#: ../../source/ref-changelog.md:150
#, fuzzy
msgid ""
"**Improve Simulation Engine** "
"([#4095](https://github.com/adap/flower/pull/4095), "
"[#3913](https://github.com/adap/flower/pull/3913), "
"[#4059](https://github.com/adap/flower/pull/4059), "
"[#3954](https://github.com/adap/flower/pull/3954), "
"[#4071](https://github.com/adap/flower/pull/4071), "
"[#3985](https://github.com/adap/flower/pull/3985), "
"[#3988](https://github.com/adap/flower/pull/3988))"
msgstr ""
"**移除对 Python 3.7 的支持** "
"([#2280](https://github.com/adap/flower/pull/2280), "
"[#2299](https://github.com/adap/flower/pull/2299), "
"[#2304](https://github.com/adap/flower/pull/2304), "
"[#2306](https://github.com/adap/flower/pull/2306), "
"[#2355](https://github.com/adap/flower/pull/2355), "
"[#2356](https://github.com/adap/flower/pull/2356))"

#: ../../source/ref-changelog.md:152
msgid ""
"The Flower Simulation Engine comes with several updates, including "
"improved run config support, verbose logging, simulation backend "
"configuration via `flwr run`, and more."
msgstr ""

#: ../../source/ref-changelog.md:154
#, fuzzy
msgid ""
"**Improve** `RecordSet` "
"([#4052](https://github.com/adap/flower/pull/4052), "
"[#3218](https://github.com/adap/flower/pull/3218), "
"[#4016](https://github.com/adap/flower/pull/4016))"
msgstr ""
"** 统一客户端应用程序接口** ([#2303](https://github.com/adap/flower/pull/2303), "
"[#2390](https://github.com/adap/flower/pull/2390), "
"[#2493](https://github.com/adap/flower/pull/2493))"

#: ../../source/ref-changelog.md:156
msgid ""
"`RecordSet` is the core object to exchange model parameters, "
"configuration values and metrics between `ClientApp` and `ServerApp`. "
"This release ships several smaller improvements to `RecordSet` and "
"related `*Record` types."
msgstr ""

#: ../../source/ref-changelog.md:158
#, fuzzy
msgid ""
"**Update documentation** "
"([#3972](https://github.com/adap/flower/pull/3972), "
"[#3925](https://github.com/adap/flower/pull/3925), "
"[#4061](https://github.com/adap/flower/pull/4061), "
"[#3984](https://github.com/adap/flower/pull/3984), "
"[#3917](https://github.com/adap/flower/pull/3917), "
"[#3900](https://github.com/adap/flower/pull/3900), "
"[#4066](https://github.com/adap/flower/pull/4066), "
"[#3765](https://github.com/adap/flower/pull/3765), "
"[#4021](https://github.com/adap/flower/pull/4021), "
"[#3906](https://github.com/adap/flower/pull/3906), "
"[#4063](https://github.com/adap/flower/pull/4063), "
"[#4076](https://github.com/adap/flower/pull/4076), "
"[#3920](https://github.com/adap/flower/pull/3920), "
"[#3916](https://github.com/adap/flower/pull/3916))"
msgstr ""
"**更新Example** ([#1772](https://github.com/adap/flower/pull/1772), "
"[#1873](https://github.com/adap/flower/pull/1873), "
"[#1981](https://github.com/adap/flower/pull/1981), "
"[#1988](https://github.com/adap/flower/pull/1988), "
"[#1984](https://github.com/adap/flower/pull/1984), "
"[#1982](https://github.com/adap/flower/pull/1982), "
"[#2112](https://github.com/adap/flower/pull/2112), "
"[#2144](https://github.com/adap/flower/pull/2144), "
"[#2174](https://github.com/adap/flower/pull/2174), "
"[#2225](https://github.com/adap/flower/pull/2225), "
"[#2183](https://github.com/adap/flower/pull/2183))"

#: ../../source/ref-changelog.md:160
msgid ""
"Many parts of the documentation, including the main tutorial, have been "
"migrated to show new Flower APIs and other new Flower features like the "
"improved Docker support."
msgstr ""

#: ../../source/ref-changelog.md:162
msgid ""
"**Migrate code example to use new Flower APIs** "
"([#3758](https://github.com/adap/flower/pull/3758), "
"[#3701](https://github.com/adap/flower/pull/3701), "
"[#3919](https://github.com/adap/flower/pull/3919), "
"[#3918](https://github.com/adap/flower/pull/3918), "
"[#3934](https://github.com/adap/flower/pull/3934), "
"[#3893](https://github.com/adap/flower/pull/3893), "
"[#3833](https://github.com/adap/flower/pull/3833), "
"[#3922](https://github.com/adap/flower/pull/3922), "
"[#3846](https://github.com/adap/flower/pull/3846), "
"[#3777](https://github.com/adap/flower/pull/3777), "
"[#3874](https://github.com/adap/flower/pull/3874), "
"[#3873](https://github.com/adap/flower/pull/3873), "
"[#3935](https://github.com/adap/flower/pull/3935), "
"[#3754](https://github.com/adap/flower/pull/3754), "
"[#3980](https://github.com/adap/flower/pull/3980), "
"[#4089](https://github.com/adap/flower/pull/4089), "
"[#4046](https://github.com/adap/flower/pull/4046), "
"[#3314](https://github.com/adap/flower/pull/3314), "
"[#3316](https://github.com/adap/flower/pull/3316), "
"[#3295](https://github.com/adap/flower/pull/3295), "
"[#3313](https://github.com/adap/flower/pull/3313))"
msgstr ""

#: ../../source/ref-changelog.md:164
msgid "Many code examples have been migrated to use new Flower APIs."
msgstr ""

#: ../../source/ref-changelog.md:166
msgid ""
"**Update Flower framework, framework internals and quality "
"infrastructure** ([#4018](https://github.com/adap/flower/pull/4018), "
"[#4053](https://github.com/adap/flower/pull/4053), "
"[#4098](https://github.com/adap/flower/pull/4098), "
"[#4067](https://github.com/adap/flower/pull/4067), "
"[#4105](https://github.com/adap/flower/pull/4105), "
"[#4048](https://github.com/adap/flower/pull/4048), "
"[#4107](https://github.com/adap/flower/pull/4107), "
"[#4069](https://github.com/adap/flower/pull/4069), "
"[#3915](https://github.com/adap/flower/pull/3915), "
"[#4101](https://github.com/adap/flower/pull/4101), "
"[#4108](https://github.com/adap/flower/pull/4108), "
"[#3914](https://github.com/adap/flower/pull/3914), "
"[#4068](https://github.com/adap/flower/pull/4068), "
"[#4041](https://github.com/adap/flower/pull/4041), "
"[#4040](https://github.com/adap/flower/pull/4040), "
"[#3986](https://github.com/adap/flower/pull/3986), "
"[#4026](https://github.com/adap/flower/pull/4026), "
"[#3961](https://github.com/adap/flower/pull/3961), "
"[#3975](https://github.com/adap/flower/pull/3975), "
"[#3983](https://github.com/adap/flower/pull/3983), "
"[#4091](https://github.com/adap/flower/pull/4091), "
"[#3982](https://github.com/adap/flower/pull/3982), "
"[#4079](https://github.com/adap/flower/pull/4079), "
"[#4073](https://github.com/adap/flower/pull/4073), "
"[#4060](https://github.com/adap/flower/pull/4060), "
"[#4106](https://github.com/adap/flower/pull/4106), "
"[#4080](https://github.com/adap/flower/pull/4080), "
"[#3974](https://github.com/adap/flower/pull/3974), "
"[#3996](https://github.com/adap/flower/pull/3996), "
"[#3991](https://github.com/adap/flower/pull/3991), "
"[#3981](https://github.com/adap/flower/pull/3981), "
"[#4093](https://github.com/adap/flower/pull/4093), "
"[#4100](https://github.com/adap/flower/pull/4100), "
"[#3939](https://github.com/adap/flower/pull/3939), "
"[#3955](https://github.com/adap/flower/pull/3955), "
"[#3940](https://github.com/adap/flower/pull/3940), "
"[#4038](https://github.com/adap/flower/pull/4038))"
msgstr ""

#: ../../source/ref-changelog.md:170 ../../source/ref-changelog.md:287
#: ../../source/ref-changelog.md:379 ../../source/ref-changelog.md:1362
msgid "Deprecations"
msgstr "停用"

#: ../../source/ref-changelog.md:172
#, fuzzy
msgid ""
"**Deprecate accessing `Context` via `Client.context`** "
"([#3797](https://github.com/adap/flower/pull/3797))"
msgstr "**移除过时的不操作额外安装** ([#973](https://github.com/adap/flower/pull/973))"

#: ../../source/ref-changelog.md:174
msgid ""
"Now that both `client_fn` and `server_fn` receive a `Context` object, "
"accessing `Context` via `Client.context` is deprecated. `Client.context` "
"will be removed in a future release. If you need to access `Context` in "
"your `Client` implementation, pass it manually when creating the `Client`"
" instance in `client_fn`:"
msgstr ""

#: ../../source/ref-changelog.md:183
#, fuzzy
msgid ""
"**Update CLIs to accept an app directory instead of** `ClientApp` **and**"
" `ServerApp` ([#3952](https://github.com/adap/flower/pull/3952), "
"[#4077](https://github.com/adap/flower/pull/4077), "
"[#3850](https://github.com/adap/flower/pull/3850))"
msgstr ""
"**引入新的模拟引擎** ([#1969](https://github.com/adap/flower/pull/1969), "
"[#2221](https://github.com/adap/flower/pull/2221), "
"[#2248](https://github.com/adap/flower/pull/2248))"

#: ../../source/ref-changelog.md:185
msgid ""
"The CLI commands `flower-supernode` and `flower-server-app` now accept an"
" app directory as argument (instead of references to a `ClientApp` or "
"`ServerApp`). An app directory is any directory containing a "
"`pyproject.toml` file (with the appropriate Flower config fields set). "
"The easiest way to generate a compatible project structure is to use "
"`flwr new`."
msgstr ""

#: ../../source/ref-changelog.md:187
#, fuzzy
msgid ""
"**Disable** `flower-client-app` **CLI command** "
"([#4022](https://github.com/adap/flower/pull/4022))"
msgstr ""
"**介绍Flower Android SDK** "
"([#2131](https://github.com/adap/flower/pull/2131))"

#: ../../source/ref-changelog.md:189
msgid "`flower-client-app` has been disabled. Use `flower-supernode` instead."
msgstr ""

#: ../../source/ref-changelog.md:191
#, fuzzy
msgid ""
"**Use spaces instead of commas for separating config args** "
"([#4000](https://github.com/adap/flower/pull/4000))"
msgstr "**服务器和策略的自定义指标** ([#717](https://github.com/adap/flower/pull/717))"

#: ../../source/ref-changelog.md:193
msgid ""
"When passing configs (run config, node config) to Flower, you now need to"
" separate key-value pairs using spaces instead of commas. For example:"
msgstr ""

#: ../../source/ref-changelog.md:199
msgid "Previously, you could pass configs using commas, like this:"
msgstr ""

#: ../../source/ref-changelog.md:205
#, fuzzy
msgid ""
"**Remove** `flwr example` **CLI command** "
"([#4084](https://github.com/adap/flower/pull/4084))"
msgstr "**移除过时的 KerasClient**（[#857](https://github.com/adap/flower/pull/857)）"

#: ../../source/ref-changelog.md:207
msgid ""
"The experimental `flwr example` CLI command has been removed. Use `flwr "
"new` to generate a project and then run it using `flwr run`."
msgstr ""

#: ../../source/ref-changelog.md:209
#, fuzzy
msgid "v1.10.0 (2024-07-24)"
msgstr "v1.0.0 (2022-07-28)"

#: ../../source/ref-changelog.md:215
#, fuzzy
msgid ""
"`Adam Narozniak`, `Charles Beauville`, `Chong Shen Ng`, `Daniel J. "
"Beutel`, `Daniel Nata Nugraha`, `Danny`, `Gustavo Bertoli`, `Heng Pan`, "
"`Ikko Eltociear Ashimine`, `Javier`, `Jiahao Tan`, `Mohammad Naseri`, "
"`Robert Steiner`, `Sebastian van der Voort`, `Taner Topal`, `Yan Gao` <!"
"---TOKEN_v1.10.0-->"
msgstr ""
"`Adam Narozniak`, `Anass Anhari`, `Charles Beauville`, `Dana-Farber`, "
"`Daniel J. Beutel`, `Daniel Nata Nugraha`, `Edoardo Gabrielli`, `Gustavo "
"Bertoli`, `Heng Pan`, `Javier`, `Mahdi`, `Steven Hé (Sīchàng)`, `Taner "
"Topal`, `achiverram28`, `danielnugraha`, `eunchung`, `ruthgal` <!---"
"TOKEN_v1.5.0-->"

#: ../../source/ref-changelog.md:219
#, fuzzy
msgid ""
"**Introduce** `flwr run` **(beta)** "
"([#3810](https://github.com/adap/flower/pull/3810), "
"[#3826](https://github.com/adap/flower/pull/3826), "
"[#3880](https://github.com/adap/flower/pull/3880), "
"[#3807](https://github.com/adap/flower/pull/3807), "
"[#3800](https://github.com/adap/flower/pull/3800), "
"[#3814](https://github.com/adap/flower/pull/3814), "
"[#3811](https://github.com/adap/flower/pull/3811), "
"[#3809](https://github.com/adap/flower/pull/3809), "
"[#3819](https://github.com/adap/flower/pull/3819))"
msgstr ""
"**改进教程** ([#1468](https://github.com/adap/flower/pull/1468), "
"[#1470](https://github.com/adap/flower/pull/1470), "
"[#1472](https://github.com/adap/flower/pull/1472), "
"[#1473](https://github.com/adap/flower/pull/1473), "
"[#1474](https://github.com/adap/flower/pull/1474), "
"[#1475](https://github.com/adap/flower/pull/1475)))"

#: ../../source/ref-changelog.md:221
msgid ""
"Flower 1.10 ships the first beta release of the new `flwr run` command. "
"`flwr run` can run different projects using `flwr run path/to/project`, "
"it enables you to easily switch between different federations using `flwr"
" run . federation` and it runs your Flower project using either local "
"simulation or the new (experimental) SuperExec service. This allows "
"Flower to scale federatated learning from fast local simulation to large-"
"scale production deployment, seamlessly. All projects generated with "
"`flwr new` are immediately runnable using `flwr run`. Give it a try: use "
"`flwr new` to generate a project and then run it using `flwr run`."
msgstr ""

#: ../../source/ref-changelog.md:223
#, fuzzy
msgid ""
"**Introduce run config** "
"([#3751](https://github.com/adap/flower/pull/3751), "
"[#3750](https://github.com/adap/flower/pull/3750), "
"[#3845](https://github.com/adap/flower/pull/3845), "
"[#3824](https://github.com/adap/flower/pull/3824), "
"[#3746](https://github.com/adap/flower/pull/3746), "
"[#3728](https://github.com/adap/flower/pull/3728), "
"[#3730](https://github.com/adap/flower/pull/3730), "
"[#3725](https://github.com/adap/flower/pull/3725), "
"[#3729](https://github.com/adap/flower/pull/3729), "
"[#3580](https://github.com/adap/flower/pull/3580), "
"[#3578](https://github.com/adap/flower/pull/3578), "
"[#3576](https://github.com/adap/flower/pull/3576), "
"[#3798](https://github.com/adap/flower/pull/3798), "
"[#3732](https://github.com/adap/flower/pull/3732), "
"[#3815](https://github.com/adap/flower/pull/3815))"
msgstr ""
"**引入（试验性）REST API** ([#1594](https://github.com/adap/flower/pull/1594), "
"[#1690](https://github.com/adap/flower/pull/1690), "
"[#1695](https://github.com/adap/flower/pull/1695), "
"[#1712](https://github.com/adap/flower/pull/1712), "
"[#1802](https://github.com/adap/flower/pull/1802), "
"[#1770](https://github.com/adap/flower/pull/1770), "
"[#1733](https://github.com/adap/flower/pull/1733))"

#: ../../source/ref-changelog.md:225
msgid ""
"The new run config feature allows you to run your Flower project in "
"different configurations without having to change a single line of code. "
"You can now build a configurable `ServerApp` and `ClientApp` that read "
"configuration values at runtime. This enables you to specify config "
"values like `learning-rate=0.01` in `pyproject.toml` (under the "
"`[tool.flwr.app.config]` key). These config values can then be easily "
"overridden via `flwr run --run-config learning-rate=0.02`, and read from "
"`Context` using `lr = context.run_config[\"learning-rate\"]`. Create a "
"new project using `flwr new` to see run config in action."
msgstr ""

#: ../../source/ref-changelog.md:227
#, fuzzy
msgid ""
"**Generalize** `client_fn` **signature to** `client_fn(context: Context) "
"-> Client` ([#3779](https://github.com/adap/flower/pull/3779), "
"[#3697](https://github.com/adap/flower/pull/3697), "
"[#3694](https://github.com/adap/flower/pull/3694), "
"[#3696](https://github.com/adap/flower/pull/3696))"
msgstr ""
"** 更新 C++ SDK** ([#2537](https://github/com/adap/flower/pull/2537), "
"[#2528](https://github/com/adap/flower/pull/2528), "
"[#2523](https://github.com/adap/flower/pull/2523), "
"[#2522](https://github.com/adap/flower/pull/2522))"

#: ../../source/ref-changelog.md:229
msgid ""
"The `client_fn` signature has been generalized to `client_fn(context: "
"Context) -> Client`. It now receives a `Context` object instead of the "
"(now depreacated) `cid: str`. `Context` allows accessing `node_id`, "
"`node_config` and `run_config`, among other things. This enables you to "
"build a configurable `ClientApp` that leverages the new run config "
"system."
msgstr ""

#: ../../source/ref-changelog.md:231
msgid ""
"The previous signature `client_fn(cid: str)` is now deprecated and "
"support for it will be removed in a future release. Use "
"`client_fn(context: Context) -> Client` everywhere."
msgstr ""

#: ../../source/ref-changelog.md:233
#, fuzzy
msgid ""
"**Introduce new** `server_fn(context)` "
"([#3773](https://github.com/adap/flower/pull/3773), "
"[#3796](https://github.com/adap/flower/pull/3796), "
"[#3771](https://github.com/adap/flower/pull/3771))"
msgstr ""
"**引入可选遥测**（[#1533](https://github.com/adap/flower/pull/1533), "
"[#1544](https://github.com/adap/flower/pull/1544), "
"[#1584](https://github.com/adap/flower/pull/1584)"

#: ../../source/ref-changelog.md:235
msgid ""
"In addition to the new `client_fn(context:Context)`, a new "
"`server_fn(context: Context) -> ServerAppComponents` can now be passed to"
" `ServerApp` (instead of passing, for example, `Strategy`, directly). "
"This enables you to leverage the full `Context` on the server-side to "
"build a configurable `ServerApp`."
msgstr ""

#: ../../source/ref-changelog.md:237
#, fuzzy
msgid ""
"**Relaunch all** `flwr new` **templates** "
"([#3877](https://github.com/adap/flower/pull/3877), "
"[#3821](https://github.com/adap/flower/pull/3821), "
"[#3587](https://github.com/adap/flower/pull/3587), "
"[#3795](https://github.com/adap/flower/pull/3795), "
"[#3875](https://github.com/adap/flower/pull/3875), "
"[#3859](https://github.com/adap/flower/pull/3859), "
"[#3760](https://github.com/adap/flower/pull/3760))"
msgstr ""
"** 更新文档** ([#1629](https://github.com/adap/flower/pull/1629), "
"[#1628](https://github.com/adap/flower/pull/1628), "
"[#1620](https://github.com/adap/flower/pull/1620), "
"[#1618](https://github.com/adap/flower/pull/1618), "
"[#1617](https://github.com/adap/flower/pull/1617), "
"[#1613](https://github.com/adap/flower/pull/1613), "
"[#1614](https://github.com/adap/flower/pull/1614)))"

#: ../../source/ref-changelog.md:239
msgid ""
"All `flwr new` templates have been significantly updated to showcase new "
"Flower features and best practices. This includes using `flwr run` and "
"the new run config feature. You can now easily create a new project using"
" `flwr new` and, after following the instructions to install it, `flwr "
"run` it."
msgstr ""

#: ../../source/ref-changelog.md:241
#, fuzzy
msgid ""
"**Introduce** `flower-supernode` **(preview)** "
"([#3353](https://github.com/adap/flower/pull/3353))"
msgstr ""
"**介绍Flower Android SDK** "
"([#2131](https://github.com/adap/flower/pull/2131))"

#: ../../source/ref-changelog.md:243
msgid ""
"The new `flower-supernode` CLI is here to replace `flower-client-app`. "
"`flower-supernode` brings full multi-app support to the Flower client-"
"side. It also allows to pass `--node-config` to the SuperNode, which is "
"accessible in your `ClientApp` via `Context` (using the new "
"`client_fn(context: Context)` signature)."
msgstr ""

#: ../../source/ref-changelog.md:245
#, fuzzy
msgid ""
"**Introduce node config** "
"([#3782](https://github.com/adap/flower/pull/3782), "
"[#3780](https://github.com/adap/flower/pull/3780), "
"[#3695](https://github.com/adap/flower/pull/3695), "
"[#3886](https://github.com/adap/flower/pull/3886))"
msgstr ""
"**引入新的 Flower Baseline： FedProx MNIST** "
"（[#1513](https://github.com/adap/flower/pull/1513), "
"[#1680](https://github.com/adap/flower/pull/1680), "
"[#1681](https://github.com/adap/flower/pull/1681), "
"[#1679](https://github.com/adap/flower/pull/1679)"

#: ../../source/ref-changelog.md:247
msgid ""
"A new node config feature allows you to pass a static configuration to "
"the SuperNode. This configuration is read-only and available to every "
"`ClientApp` running on that SuperNode. A `ClientApp` can access the node "
"config via `Context` (`context.node_config`)."
msgstr ""

#: ../../source/ref-changelog.md:249
msgid ""
"**Introduce SuperExec (experimental)** "
"([#3605](https://github.com/adap/flower/pull/3605), "
"[#3723](https://github.com/adap/flower/pull/3723), "
"[#3731](https://github.com/adap/flower/pull/3731), "
"[#3589](https://github.com/adap/flower/pull/3589), "
"[#3604](https://github.com/adap/flower/pull/3604), "
"[#3622](https://github.com/adap/flower/pull/3622), "
"[#3838](https://github.com/adap/flower/pull/3838), "
"[#3720](https://github.com/adap/flower/pull/3720), "
"[#3606](https://github.com/adap/flower/pull/3606), "
"[#3602](https://github.com/adap/flower/pull/3602), "
"[#3603](https://github.com/adap/flower/pull/3603), "
"[#3555](https://github.com/adap/flower/pull/3555), "
"[#3808](https://github.com/adap/flower/pull/3808), "
"[#3724](https://github.com/adap/flower/pull/3724), "
"[#3658](https://github.com/adap/flower/pull/3658), "
"[#3629](https://github.com/adap/flower/pull/3629))"
msgstr ""

#: ../../source/ref-changelog.md:251
msgid ""
"This is the first experimental release of Flower SuperExec, a new service"
" that executes your runs. It's not ready for production deployment just "
"yet, but don't hesitate to give it a try if you're interested."
msgstr ""

#: ../../source/ref-changelog.md:253
#, fuzzy
msgid ""
"**Add new federated learning with tabular data example** "
"([#3568](https://github.com/adap/flower/pull/3568))"
msgstr ""
"** 添加使用 fastai 和 Flower 进行联邦学习的新示例** "
"([#1598](https://github.com/adap/flower/pull/1598))"

#: ../../source/ref-changelog.md:255
msgid ""
"A new code example exemplifies a federated learning setup using the "
"Flower framework on the Adult Census Income tabular dataset."
msgstr ""

#: ../../source/ref-changelog.md:257
#, fuzzy
msgid ""
"**Create generic adapter layer (preview)** "
"([#3538](https://github.com/adap/flower/pull/3538), "
"[#3536](https://github.com/adap/flower/pull/3536), "
"[#3540](https://github.com/adap/flower/pull/3540))"
msgstr ""
"** 统一客户端应用程序接口** ([#2303](https://github.com/adap/flower/pull/2303), "
"[#2390](https://github.com/adap/flower/pull/2390), "
"[#2493](https://github.com/adap/flower/pull/2493))"

#: ../../source/ref-changelog.md:259
msgid ""
"A new generic gRPC adapter layer allows 3rd-party frameworks to integrate"
" with Flower in a transparent way. This makes Flower more modular and "
"allows for integration into other federated learning solutions and "
"platforms."
msgstr ""

#: ../../source/ref-changelog.md:261
#, fuzzy
msgid ""
"**Refactor Flower Simulation Engine** "
"([#3581](https://github.com/adap/flower/pull/3581), "
"[#3471](https://github.com/adap/flower/pull/3471), "
"[#3804](https://github.com/adap/flower/pull/3804), "
"[#3468](https://github.com/adap/flower/pull/3468), "
"[#3839](https://github.com/adap/flower/pull/3839), "
"[#3806](https://github.com/adap/flower/pull/3806), "
"[#3861](https://github.com/adap/flower/pull/3861), "
"[#3543](https://github.com/adap/flower/pull/3543), "
"[#3472](https://github.com/adap/flower/pull/3472), "
"[#3829](https://github.com/adap/flower/pull/3829), "
"[#3469](https://github.com/adap/flower/pull/3469))"
msgstr ""
"**改进教程** ([#1468](https://github.com/adap/flower/pull/1468), "
"[#1470](https://github.com/adap/flower/pull/1470), "
"[#1472](https://github.com/adap/flower/pull/1472), "
"[#1473](https://github.com/adap/flower/pull/1473), "
"[#1474](https://github.com/adap/flower/pull/1474), "
"[#1475](https://github.com/adap/flower/pull/1475)))"

#: ../../source/ref-changelog.md:263
msgid ""
"The Simulation Engine was significantly refactored. This results in "
"faster and more stable simulations. It is also the foundation for "
"upcoming changes that aim to provide the next level of performance and "
"configurability in federated learning simulations."
msgstr ""

#: ../../source/ref-changelog.md:265
#, fuzzy
msgid ""
"**Optimize Docker containers** "
"([#3591](https://github.com/adap/flower/pull/3591))"
msgstr "新文档主题 ([#551](https://github.com/adap/flower/pull/551))"

#: ../../source/ref-changelog.md:267
msgid ""
"Flower Docker containers were optimized and updated to use that latest "
"Flower framework features."
msgstr ""

#: ../../source/ref-changelog.md:269
#, fuzzy
msgid ""
"**Improve logging** ([#3776](https://github.com/adap/flower/pull/3776), "
"[#3789](https://github.com/adap/flower/pull/3789))"
msgstr ""
"** 更新代码示例** ([#1344](https://github.com/adap/flower/pull/1344), "
"[#1347](https://github.com/adap/flower/pull/1347))"

#: ../../source/ref-changelog.md:271
msgid ""
"Improved logging aims to be more concise and helpful to show you the "
"details you actually care about."
msgstr ""

#: ../../source/ref-changelog.md:273
#, fuzzy
msgid ""
"**Refactor framework internals** "
"([#3621](https://github.com/adap/flower/pull/3621), "
"[#3792](https://github.com/adap/flower/pull/3792), "
"[#3772](https://github.com/adap/flower/pull/3772), "
"[#3805](https://github.com/adap/flower/pull/3805), "
"[#3583](https://github.com/adap/flower/pull/3583), "
"[#3825](https://github.com/adap/flower/pull/3825), "
"[#3597](https://github.com/adap/flower/pull/3597), "
"[#3802](https://github.com/adap/flower/pull/3802), "
"[#3569](https://github.com/adap/flower/pull/3569))"
msgstr ""
"**改进教程** ([#1468](https://github.com/adap/flower/pull/1468), "
"[#1470](https://github.com/adap/flower/pull/1470), "
"[#1472](https://github.com/adap/flower/pull/1472), "
"[#1473](https://github.com/adap/flower/pull/1473), "
"[#1474](https://github.com/adap/flower/pull/1474), "
"[#1475](https://github.com/adap/flower/pull/1475)))"

#: ../../source/ref-changelog.md:277
#, fuzzy
msgid "Documentation improvements"
msgstr "可选的改进措施"

#: ../../source/ref-changelog.md:279
#, fuzzy
msgid ""
"**Add 🇰🇷 Korean translations** "
"([#3680](https://github.com/adap/flower/pull/3680))"
msgstr "**在 Colab 中打开按钮** ([#1389](https://github.com/adap/flower/pull/1389))"

#: ../../source/ref-changelog.md:281
#, fuzzy
msgid ""
"**Update translations** "
"([#3586](https://github.com/adap/flower/pull/3586), "
"[#3679](https://github.com/adap/flower/pull/3679), "
"[#3570](https://github.com/adap/flower/pull/3570), "
"[#3681](https://github.com/adap/flower/pull/3681), "
"[#3617](https://github.com/adap/flower/pull/3617), "
"[#3674](https://github.com/adap/flower/pull/3674), "
"[#3671](https://github.com/adap/flower/pull/3671), "
"[#3572](https://github.com/adap/flower/pull/3572), "
"[#3631](https://github.com/adap/flower/pull/3631))"
msgstr ""
"**改进教程** ([#1468](https://github.com/adap/flower/pull/1468), "
"[#1470](https://github.com/adap/flower/pull/1470), "
"[#1472](https://github.com/adap/flower/pull/1472), "
"[#1473](https://github.com/adap/flower/pull/1473), "
"[#1474](https://github.com/adap/flower/pull/1474), "
"[#1475](https://github.com/adap/flower/pull/1475)))"

#: ../../source/ref-changelog.md:283
#, fuzzy
msgid ""
"**Update documentation** "
"([#3864](https://github.com/adap/flower/pull/3864), "
"[#3688](https://github.com/adap/flower/pull/3688), "
"[#3562](https://github.com/adap/flower/pull/3562), "
"[#3641](https://github.com/adap/flower/pull/3641), "
"[#3384](https://github.com/adap/flower/pull/3384), "
"[#3634](https://github.com/adap/flower/pull/3634), "
"[#3823](https://github.com/adap/flower/pull/3823), "
"[#3793](https://github.com/adap/flower/pull/3793), "
"[#3707](https://github.com/adap/flower/pull/3707))"
msgstr ""
"**普通改进**（[#1872](https://github.com/adap/flower/pull/1872), "
"[#1866](https://github.com/adap/flower/pull/1866), "
"[#1884](https://github.com/adap/flower/pull/1884), "
"[#1837](https://github.com/adap/flower/pull/1837), "
"[#1477](https://github.com/adap/flower/pull/1477), "
"[#2171](https://github.com/adap/flower/pull/2171))"

#: ../../source/ref-changelog.md:285
msgid ""
"Updated documentation includes new install instructions for different "
"shells, a new Flower Code Examples documentation landing page, new `flwr`"
" CLI docs and an updated federated XGBoost code example."
msgstr ""

#: ../../source/ref-changelog.md:289
msgid "**Deprecate** `client_fn(cid: str)`"
msgstr ""

#: ../../source/ref-changelog.md:291
msgid ""
"`client_fn` used to have a signature `client_fn(cid: str) -> Client`. "
"This signature is now deprecated. Use the new signature "
"`client_fn(context: Context) -> Client` instead. The new argument "
"`context` allows accessing `node_id`, `node_config`, `run_config` and "
"other `Context` features. When running using the simulation engine (or "
"using `flower-supernode` with a custom `--node-config partition-id=...`),"
" `context.node_config[\"partition-id\"]` will return an `int` partition "
"ID that can be used with Flower Datasets to load a different partition of"
" the dataset on each simulated or deployed SuperNode."
msgstr ""

#: ../../source/ref-changelog.md:293
msgid ""
"**Deprecate passing** `Server/ServerConfig/Strategy/ClientManager` **to**"
" `ServerApp` **directly**"
msgstr ""

#: ../../source/ref-changelog.md:295
msgid ""
"Creating `ServerApp` using `ServerApp(config=config, strategy=strategy)` "
"is now deprecated. Instead of passing "
"`Server/ServerConfig/Strategy/ClientManager` to `ServerApp` directly, "
"pass them wrapped in a `server_fn(context: Context) -> "
"ServerAppComponents` function, like this: "
"`ServerApp(server_fn=server_fn)`. `ServerAppComponents` can hold "
"references to `Server/ServerConfig/Strategy/ClientManager`. In addition "
"to that, `server_fn` allows you to access `Context` (for example, to read"
" the `run_config`)."
msgstr ""

#: ../../source/ref-changelog.md:299
#, fuzzy
msgid ""
"**Remove support for `client_ids` in `start_simulation`** "
"([#3699](https://github.com/adap/flower/pull/3699))"
msgstr "**改进模拟中的 GPU 支持**（[#1555](https://github.com/adap/flower/pull/1555)）"

#: ../../source/ref-changelog.md:301
msgid ""
"The (rarely used) feature that allowed passing custom `client_ids` to the"
" `start_simulation` function was removed. This removal is part of a "
"bigger effort to refactor the simulation engine and unify how the Flower "
"internals work in simulation and deployment."
msgstr ""

#: ../../source/ref-changelog.md:303
#, fuzzy
msgid ""
"**Remove `flower-driver-api` and `flower-fleet-api`** "
"([#3418](https://github.com/adap/flower/pull/3418))"
msgstr "**移除过时的 KerasClient**（[#857](https://github.com/adap/flower/pull/857)）"

#: ../../source/ref-changelog.md:305
msgid ""
"The two deprecated CLI commands `flower-driver-api` and `flower-fleet-"
"api` were removed in an effort to streamline the SuperLink developer "
"experience. Use `flower-superlink` instead."
msgstr ""

#: ../../source/ref-changelog.md:307
#, fuzzy
msgid "v1.9.0 (2024-06-10)"
msgstr "v1.3.0 (2023-02-06)"

#: ../../source/ref-changelog.md:313
#, fuzzy
msgid ""
"`Adam Narozniak`, `Charles Beauville`, `Chong Shen Ng`, `Daniel J. "
"Beutel`, `Daniel Nata Nugraha`, `Heng Pan`, `Javier`, `Mahdi Beitollahi`,"
" `Robert Steiner`, `Taner Topal`, `Yan Gao`, `bapic`, `mohammadnaseri` <!"
"---TOKEN_v1.9.0-->"
msgstr ""
"`Adam Narozniak`, `Anass Anhari`, `Charles Beauville`, `Dana-Farber`, "
"`Daniel J. Beutel`, `Daniel Nata Nugraha`, `Edoardo Gabrielli`, `Gustavo "
"Bertoli`, `Heng Pan`, `Javier`, `Mahdi`, `Steven Hé (Sīchàng)`, `Taner "
"Topal`, `achiverram28`, `danielnugraha`, `eunchung`, `ruthgal` <!---"
"TOKEN_v1.5.0-->"

#: ../../source/ref-changelog.md:317
#, fuzzy
msgid ""
"**Introduce built-in authentication (preview)** "
"([#2946](https://github.com/adap/flower/pull/2946), "
"[#3388](https://github.com/adap/flower/pull/3388), "
"[#2948](https://github.com/adap/flower/pull/2948), "
"[#2917](https://github.com/adap/flower/pull/2917), "
"[#3386](https://github.com/adap/flower/pull/3386), "
"[#3308](https://github.com/adap/flower/pull/3308), "
"[#3001](https://github.com/adap/flower/pull/3001), "
"[#3409](https://github.com/adap/flower/pull/3409), "
"[#2999](https://github.com/adap/flower/pull/2999), "
"[#2979](https://github.com/adap/flower/pull/2979), "
"[#3389](https://github.com/adap/flower/pull/3389), "
"[#3503](https://github.com/adap/flower/pull/3503), "
"[#3366](https://github.com/adap/flower/pull/3366), "
"[#3357](https://github.com/adap/flower/pull/3357))"
msgstr ""
"** 更新文档** ([#1494](https://github.com/adap/flower/pull/1494), "
"[#1496](https://github.com/adap/flower/pull/1496), "
"[#1500](https://github.com/adap/flower/pull/1500), "
"[#1503](https://github.com/adap/flower/pull/1503), "
"[#1505](https://github.com/adap/flower/pull/1505), "
"[#1524](https://github.com/adap/flower/pull/1524), "
"[#1518](https://github.com/adap/flower/pull/1518), "
"[#1519](https://github.com/adap/flower/pull/1519), "
"[#1515](https://github.com/adap/flower/pull/1515))"

#: ../../source/ref-changelog.md:319
msgid ""
"Flower 1.9 introduces the first build-in version of client node "
"authentication. In previous releases, users often wrote glue code to "
"connect Flower to external authentication systems. With this release, the"
" SuperLink can authenticate SuperNodes using a built-in authentication "
"system. A new [how-to guide](https://flower.ai/docs/framework/how-to-"
"authenticate-supernodes.html) and a new [code "
"example](https://github.com/adap/flower/tree/main/examples/flower-"
"authentication) help you to get started."
msgstr ""

#: ../../source/ref-changelog.md:321
msgid ""
"This is the first preview release of the Flower-native authentication "
"system. Many additional features are on the roadmap for upcoming Flower "
"releases - stay tuned."
msgstr ""

#: ../../source/ref-changelog.md:323
#, fuzzy
msgid ""
"**Introduce end-to-end Docker support** "
"([#3483](https://github.com/adap/flower/pull/3483), "
"[#3266](https://github.com/adap/flower/pull/3266), "
"[#3390](https://github.com/adap/flower/pull/3390), "
"[#3283](https://github.com/adap/flower/pull/3283), "
"[#3285](https://github.com/adap/flower/pull/3285), "
"[#3391](https://github.com/adap/flower/pull/3391), "
"[#3403](https://github.com/adap/flower/pull/3403), "
"[#3458](https://github.com/adap/flower/pull/3458), "
"[#3533](https://github.com/adap/flower/pull/3533), "
"[#3453](https://github.com/adap/flower/pull/3453), "
"[#3486](https://github.com/adap/flower/pull/3486), "
"[#3290](https://github.com/adap/flower/pull/3290))"
msgstr ""
"**引入（试验性）REST API** ([#1594](https://github.com/adap/flower/pull/1594), "
"[#1690](https://github.com/adap/flower/pull/1690), "
"[#1695](https://github.com/adap/flower/pull/1695), "
"[#1712](https://github.com/adap/flower/pull/1712), "
"[#1802](https://github.com/adap/flower/pull/1802), "
"[#1770](https://github.com/adap/flower/pull/1770), "
"[#1733](https://github.com/adap/flower/pull/1733))"

#: ../../source/ref-changelog.md:325
msgid ""
"Full Flower Next Docker support is here! With the release of Flower 1.9, "
"Flower provides stable Docker images for the Flower SuperLink, the Flower"
" SuperNode, and the Flower `ServerApp`. This set of images enables you to"
" run all Flower components in Docker. Check out the new [how-to "
"guide](https://flower.ai/docs/framework/how-to-run-flower-using-"
"docker.html) to get stated."
msgstr ""

#: ../../source/ref-changelog.md:327
#, fuzzy
msgid ""
"**Re-architect Flower Next simulation engine** "
"([#3307](https://github.com/adap/flower/pull/3307), "
"[#3355](https://github.com/adap/flower/pull/3355), "
"[#3272](https://github.com/adap/flower/pull/3272), "
"[#3273](https://github.com/adap/flower/pull/3273), "
"[#3417](https://github.com/adap/flower/pull/3417), "
"[#3281](https://github.com/adap/flower/pull/3281), "
"[#3343](https://github.com/adap/flower/pull/3343), "
"[#3326](https://github.com/adap/flower/pull/3326))"
msgstr ""
"** 更新文档** ([#1629](https://github.com/adap/flower/pull/1629), "
"[#1628](https://github.com/adap/flower/pull/1628), "
"[#1620](https://github.com/adap/flower/pull/1620), "
"[#1618](https://github.com/adap/flower/pull/1618), "
"[#1617](https://github.com/adap/flower/pull/1617), "
"[#1613](https://github.com/adap/flower/pull/1613), "
"[#1614](https://github.com/adap/flower/pull/1614)))"

#: ../../source/ref-changelog.md:329
msgid ""
"Flower Next simulations now use a new in-memory `Driver` that improves "
"the reliability of simulations, especially in notebook environments. This"
" is a significant step towards a complete overhaul of the Flower Next "
"simulation architecture."
msgstr ""

#: ../../source/ref-changelog.md:331
#, fuzzy
msgid ""
"**Upgrade simulation engine** "
"([#3354](https://github.com/adap/flower/pull/3354), "
"[#3378](https://github.com/adap/flower/pull/3378), "
"[#3262](https://github.com/adap/flower/pull/3262), "
"[#3435](https://github.com/adap/flower/pull/3435), "
"[#3501](https://github.com/adap/flower/pull/3501), "
"[#3482](https://github.com/adap/flower/pull/3482), "
"[#3494](https://github.com/adap/flower/pull/3494))"
msgstr ""
"** 更新文档** ([#1629](https://github.com/adap/flower/pull/1629), "
"[#1628](https://github.com/adap/flower/pull/1628), "
"[#1620](https://github.com/adap/flower/pull/1620), "
"[#1618](https://github.com/adap/flower/pull/1618), "
"[#1617](https://github.com/adap/flower/pull/1617), "
"[#1613](https://github.com/adap/flower/pull/1613), "
"[#1614](https://github.com/adap/flower/pull/1614)))"

#: ../../source/ref-changelog.md:333
msgid ""
"The Flower Next simulation engine comes with improved and configurable "
"logging. The Ray-based simulation backend in Flower 1.9 was updated to "
"use Ray 2.10."
msgstr ""

#: ../../source/ref-changelog.md:335
#, fuzzy
msgid ""
"**Introduce FedPFT baseline** "
"([#3268](https://github.com/adap/flower/pull/3268))"
msgstr "**引入 start_driver**（[#1697](https://github.com/adap/flower/pull/1697)）"

#: ../../source/ref-changelog.md:337
msgid ""
"FedPFT allows you to perform one-shot Federated Learning by leveraging "
"widely available foundational models, dramatically reducing communication"
" costs while delivering high performing models. This is work led by Mahdi"
" Beitollahi from Huawei Noah's Ark Lab (Montreal, Canada). Read all the "
"details in their paper: \"Parametric Feature Transfer: One-shot Federated"
" Learning with Foundation Models\" "
"([arxiv](https://arxiv.org/abs/2402.01862))"
msgstr ""

#: ../../source/ref-changelog.md:339
#, fuzzy
msgid ""
"**Launch additional** `flwr new` **templates for Apple MLX, Hugging Face "
"Transformers, scikit-learn and TensorFlow** "
"([#3291](https://github.com/adap/flower/pull/3291), "
"[#3139](https://github.com/adap/flower/pull/3139), "
"[#3284](https://github.com/adap/flower/pull/3284), "
"[#3251](https://github.com/adap/flower/pull/3251), "
"[#3376](https://github.com/adap/flower/pull/3376), "
"[#3287](https://github.com/adap/flower/pull/3287))"
msgstr ""
"**移除对 Python 3.7 的支持** "
"([#2280](https://github.com/adap/flower/pull/2280), "
"[#2299](https://github.com/adap/flower/pull/2299), "
"[#2304](https://github.com/adap/flower/pull/2304), "
"[#2306](https://github.com/adap/flower/pull/2306), "
"[#2355](https://github.com/adap/flower/pull/2355), "
"[#2356](https://github.com/adap/flower/pull/2356))"

#: ../../source/ref-changelog.md:341
msgid ""
"The `flwr` CLI's `flwr new` command is starting to become everone's "
"favorite way of creating new Flower projects. This release introduces "
"additional `flwr new` templates for Apple MLX, Hugging Face Transformers,"
" scikit-learn and TensorFlow. In addition to that, existing templates "
"also received updates."
msgstr ""

#: ../../source/ref-changelog.md:343
#, fuzzy
msgid ""
"**Refine** `RecordSet` **API** "
"([#3209](https://github.com/adap/flower/pull/3209), "
"[#3331](https://github.com/adap/flower/pull/3331), "
"[#3334](https://github.com/adap/flower/pull/3334), "
"[#3335](https://github.com/adap/flower/pull/3335), "
"[#3375](https://github.com/adap/flower/pull/3375), "
"[#3368](https://github.com/adap/flower/pull/3368))"
msgstr ""
"**普通改进**（[#1872](https://github.com/adap/flower/pull/1872), "
"[#1866](https://github.com/adap/flower/pull/1866), "
"[#1884](https://github.com/adap/flower/pull/1884), "
"[#1837](https://github.com/adap/flower/pull/1837), "
"[#1477](https://github.com/adap/flower/pull/1477), "
"[#2171](https://github.com/adap/flower/pull/2171))"

#: ../../source/ref-changelog.md:345
msgid ""
"`RecordSet` is part of the Flower Next low-level API preview release. In "
"Flower 1.9, `RecordSet` received a number of usability improvements that "
"make it easier to build `RecordSet`-based `ServerApp`s and `ClientApp`s."
msgstr ""

#: ../../source/ref-changelog.md:347
#, fuzzy
msgid ""
"**Beautify logging** ([#3379](https://github.com/adap/flower/pull/3379), "
"[#3430](https://github.com/adap/flower/pull/3430), "
"[#3461](https://github.com/adap/flower/pull/3461), "
"[#3360](https://github.com/adap/flower/pull/3360), "
"[#3433](https://github.com/adap/flower/pull/3433))"
msgstr ""
"** 更新 C++ SDK** ([#2537](https://github/com/adap/flower/pull/2537), "
"[#2528](https://github/com/adap/flower/pull/2528), "
"[#2523](https://github.com/adap/flower/pull/2523), "
"[#2522](https://github.com/adap/flower/pull/2522))"

#: ../../source/ref-changelog.md:349
msgid ""
"Logs received a substantial update. Not only are logs now much nicer to "
"look at, but they are also more configurable."
msgstr ""

#: ../../source/ref-changelog.md:351
#, fuzzy
msgid ""
"**Improve reliability** "
"([#3564](https://github.com/adap/flower/pull/3564), "
"[#3561](https://github.com/adap/flower/pull/3561), "
"[#3566](https://github.com/adap/flower/pull/3566), "
"[#3462](https://github.com/adap/flower/pull/3462), "
"[#3225](https://github.com/adap/flower/pull/3225), "
"[#3514](https://github.com/adap/flower/pull/3514), "
"[#3535](https://github.com/adap/flower/pull/3535), "
"[#3372](https://github.com/adap/flower/pull/3372))"
msgstr ""
"**改进教程** ([#1468](https://github.com/adap/flower/pull/1468), "
"[#1470](https://github.com/adap/flower/pull/1470), "
"[#1472](https://github.com/adap/flower/pull/1472), "
"[#1473](https://github.com/adap/flower/pull/1473), "
"[#1474](https://github.com/adap/flower/pull/1474), "
"[#1475](https://github.com/adap/flower/pull/1475)))"

#: ../../source/ref-changelog.md:353
msgid ""
"Flower 1.9 includes reliability improvements across many parts of the "
"system. One example is a much improved SuperNode shutdown procedure."
msgstr ""

#: ../../source/ref-changelog.md:355
#, fuzzy
msgid ""
"**Update Swift and C++ SDKs** "
"([#3321](https://github.com/adap/flower/pull/3321), "
"[#2763](https://github.com/adap/flower/pull/2763))"
msgstr ""
"** 更新代码示例** ([#1344](https://github.com/adap/flower/pull/1344), "
"[#1347](https://github.com/adap/flower/pull/1347))"

#: ../../source/ref-changelog.md:357
msgid ""
"In the C++ SDK, communication-related code is now separate from main "
"client logic. A new abstract class `Communicator` has been introduced "
"alongside a gRPC implementation of it."
msgstr ""

#: ../../source/ref-changelog.md:359
msgid ""
"**Improve testing, tooling and CI/CD infrastructure** "
"([#3294](https://github.com/adap/flower/pull/3294), "
"[#3282](https://github.com/adap/flower/pull/3282), "
"[#3311](https://github.com/adap/flower/pull/3311), "
"[#2878](https://github.com/adap/flower/pull/2878), "
"[#3333](https://github.com/adap/flower/pull/3333), "
"[#3255](https://github.com/adap/flower/pull/3255), "
"[#3349](https://github.com/adap/flower/pull/3349), "
"[#3400](https://github.com/adap/flower/pull/3400), "
"[#3401](https://github.com/adap/flower/pull/3401), "
"[#3399](https://github.com/adap/flower/pull/3399), "
"[#3346](https://github.com/adap/flower/pull/3346), "
"[#3398](https://github.com/adap/flower/pull/3398), "
"[#3397](https://github.com/adap/flower/pull/3397), "
"[#3347](https://github.com/adap/flower/pull/3347), "
"[#3502](https://github.com/adap/flower/pull/3502), "
"[#3387](https://github.com/adap/flower/pull/3387), "
"[#3542](https://github.com/adap/flower/pull/3542), "
"[#3396](https://github.com/adap/flower/pull/3396), "
"[#3496](https://github.com/adap/flower/pull/3496), "
"[#3465](https://github.com/adap/flower/pull/3465), "
"[#3473](https://github.com/adap/flower/pull/3473), "
"[#3484](https://github.com/adap/flower/pull/3484), "
"[#3521](https://github.com/adap/flower/pull/3521), "
"[#3363](https://github.com/adap/flower/pull/3363), "
"[#3497](https://github.com/adap/flower/pull/3497), "
"[#3464](https://github.com/adap/flower/pull/3464), "
"[#3495](https://github.com/adap/flower/pull/3495), "
"[#3478](https://github.com/adap/flower/pull/3478), "
"[#3271](https://github.com/adap/flower/pull/3271))"
msgstr ""

#: ../../source/ref-changelog.md:361
msgid ""
"As always, the Flower tooling, testing, and CI/CD infrastructure has "
"received many updates."
msgstr ""

#: ../../source/ref-changelog.md:363
msgid ""
"**Improve documentation** "
"([#3530](https://github.com/adap/flower/pull/3530), "
"[#3539](https://github.com/adap/flower/pull/3539), "
"[#3425](https://github.com/adap/flower/pull/3425), "
"[#3520](https://github.com/adap/flower/pull/3520), "
"[#3286](https://github.com/adap/flower/pull/3286), "
"[#3516](https://github.com/adap/flower/pull/3516), "
"[#3523](https://github.com/adap/flower/pull/3523), "
"[#3545](https://github.com/adap/flower/pull/3545), "
"[#3498](https://github.com/adap/flower/pull/3498), "
"[#3439](https://github.com/adap/flower/pull/3439), "
"[#3440](https://github.com/adap/flower/pull/3440), "
"[#3382](https://github.com/adap/flower/pull/3382), "
"[#3559](https://github.com/adap/flower/pull/3559), "
"[#3432](https://github.com/adap/flower/pull/3432), "
"[#3278](https://github.com/adap/flower/pull/3278), "
"[#3371](https://github.com/adap/flower/pull/3371), "
"[#3519](https://github.com/adap/flower/pull/3519), "
"[#3267](https://github.com/adap/flower/pull/3267), "
"[#3204](https://github.com/adap/flower/pull/3204), "
"[#3274](https://github.com/adap/flower/pull/3274))"
msgstr ""

#: ../../source/ref-changelog.md:365
msgid ""
"As always, the Flower documentation has received many updates. Notable "
"new pages include:"
msgstr ""

#: ../../source/ref-changelog.md:367
msgid ""
"[How-to upgrate to Flower Next (Flower Next migration "
"guide)](https://flower.ai/docs/framework/how-to-upgrade-to-flower-"
"next.html)"
msgstr ""

#: ../../source/ref-changelog.md:369
#, fuzzy
msgid ""
"[How-to run Flower using Docker](https://flower.ai/docs/framework/how-to-"
"run-flower-using-docker.html)"
msgstr ""
"`TensorFlow快速入门 (教程) <https://flower.ai/docs/framework/tutorial-"
"quickstart-tensorflow.html>`_"

#: ../../source/ref-changelog.md:371
msgid ""
"[Flower Mods reference](https://flower.ai/docs/framework/ref-"
"api/flwr.client.mod.html#module-flwr.client.mod)"
msgstr ""

#: ../../source/ref-changelog.md:373
#, fuzzy
msgid ""
"**General updates to Flower Examples** "
"([#3205](https://github.com/adap/flower/pull/3205), "
"[#3226](https://github.com/adap/flower/pull/3226), "
"[#3211](https://github.com/adap/flower/pull/3211), "
"[#3252](https://github.com/adap/flower/pull/3252), "
"[#3427](https://github.com/adap/flower/pull/3427), "
"[#3410](https://github.com/adap/flower/pull/3410), "
"[#3426](https://github.com/adap/flower/pull/3426), "
"[#3228](https://github.com/adap/flower/pull/3228), "
"[#3342](https://github.com/adap/flower/pull/3342), "
"[#3200](https://github.com/adap/flower/pull/3200), "
"[#3202](https://github.com/adap/flower/pull/3202), "
"[#3394](https://github.com/adap/flower/pull/3394), "
"[#3488](https://github.com/adap/flower/pull/3488), "
"[#3329](https://github.com/adap/flower/pull/3329), "
"[#3526](https://github.com/adap/flower/pull/3526), "
"[#3392](https://github.com/adap/flower/pull/3392), "
"[#3474](https://github.com/adap/flower/pull/3474), "
"[#3269](https://github.com/adap/flower/pull/3269))"
msgstr ""
"**更新文档** ([#1223](https://github.com/adap/flower/pull/1223), "
"[#1209](https://github.com/adap/flower/pull/1209), "
"[#1251](https://github.com/adap/flower/pull/1251), "
"[#1257](https://github.com/adap/flower/pull/1257), "
"[#1267](https://github.com/adap/flower/pull/1267), "
"[#1268](https://github.com/adap/flower/pull/1268), "
"[#1300](https://github.com/adap/flower/pull/1300), "
"[#1304](https://github.com/adap/flower/pull/1304), "
"[#1305](https://github.com/adap/flower/pull/1305), "
"[#1307](https://github.com/adap/flower/pull/1307))"

#: ../../source/ref-changelog.md:375
#, fuzzy
msgid "As always, Flower code examples have received many updates."
msgstr "许多 \"Flower \"代码示例得到了大幅更新。"

#: ../../source/ref-changelog.md:377
msgid ""
"**General improvements** "
"([#3532](https://github.com/adap/flower/pull/3532), "
"[#3318](https://github.com/adap/flower/pull/3318), "
"[#3565](https://github.com/adap/flower/pull/3565), "
"[#3296](https://github.com/adap/flower/pull/3296), "
"[#3305](https://github.com/adap/flower/pull/3305), "
"[#3246](https://github.com/adap/flower/pull/3246), "
"[#3224](https://github.com/adap/flower/pull/3224), "
"[#3475](https://github.com/adap/flower/pull/3475), "
"[#3297](https://github.com/adap/flower/pull/3297), "
"[#3317](https://github.com/adap/flower/pull/3317), "
"[#3429](https://github.com/adap/flower/pull/3429), "
"[#3196](https://github.com/adap/flower/pull/3196), "
"[#3534](https://github.com/adap/flower/pull/3534), "
"[#3240](https://github.com/adap/flower/pull/3240), "
"[#3365](https://github.com/adap/flower/pull/3365), "
"[#3407](https://github.com/adap/flower/pull/3407), "
"[#3563](https://github.com/adap/flower/pull/3563), "
"[#3344](https://github.com/adap/flower/pull/3344), "
"[#3330](https://github.com/adap/flower/pull/3330), "
"[#3436](https://github.com/adap/flower/pull/3436), "
"[#3300](https://github.com/adap/flower/pull/3300), "
"[#3327](https://github.com/adap/flower/pull/3327), "
"[#3254](https://github.com/adap/flower/pull/3254), "
"[#3253](https://github.com/adap/flower/pull/3253), "
"[#3419](https://github.com/adap/flower/pull/3419), "
"[#3289](https://github.com/adap/flower/pull/3289), "
"[#3208](https://github.com/adap/flower/pull/3208), "
"[#3245](https://github.com/adap/flower/pull/3245), "
"[#3319](https://github.com/adap/flower/pull/3319), "
"[#3203](https://github.com/adap/flower/pull/3203), "
"[#3423](https://github.com/adap/flower/pull/3423), "
"[#3352](https://github.com/adap/flower/pull/3352), "
"[#3292](https://github.com/adap/flower/pull/3292), "
"[#3261](https://github.com/adap/flower/pull/3261))"
msgstr ""

#: ../../source/ref-changelog.md:381
#, fuzzy
msgid "**Deprecate Python 3.8 support**"
msgstr "** 过时的 Python 3.8**"

#: ../../source/ref-changelog.md:383
#, fuzzy
msgid ""
"Python 3.8 will stop receiving security fixes in [October "
"2024](https://devguide.python.org/versions/). Support for Python 3.8 is "
"now deprecated and will be removed in an upcoming release."
msgstr "由于 Python 3.8 已于 2024-10-01 弃用 (EOL)，对 Python 3.7 的支持现已废弃，并将在即将发布的版本中移除。"

#: ../../source/ref-changelog.md:385
#, fuzzy
msgid ""
"**Deprecate (experimental)** `flower-driver-api` **and** `flower-fleet-"
"api` ([#3416](https://github.com/adap/flower/pull/3416), "
"[#3420](https://github.com/adap/flower/pull/3420))"
msgstr ""
"FedBN ([#2608](https://github.com/adap/flower/pull/2608), "
"[#2615](https://github.com/adap/flower/pull/2615))"

#: ../../source/ref-changelog.md:387
msgid ""
"Flower 1.9 deprecates the two (experimental) commands `flower-driver-api`"
" and `flower-fleet-api`. Both commands will be removed in an upcoming "
"release. Use `flower-superlink` instead."
msgstr ""

#: ../../source/ref-changelog.md:389
#, fuzzy
msgid ""
"**Deprecate** `--server` **in favor of** `--superlink` "
"([#3518](https://github.com/adap/flower/pull/3518))"
msgstr ""
"**启用向** `start_simulation` 传递** `Server` 实例 "
"([#1281](https://github.com/adap/flower/pull/1281))"

#: ../../source/ref-changelog.md:391
msgid ""
"The commands `flower-server-app` and `flower-client-app` should use "
"`--superlink` instead of the now deprecated `--server`. Support for "
"`--server` will be removed in a future release."
msgstr ""

#: ../../source/ref-changelog.md:395
msgid ""
"**Replace** `flower-superlink` **CLI option** `--certificates` **with** "
"`--ssl-ca-certfile` **,** `--ssl-certfile` **and** `--ssl-keyfile` "
"([#3512](https://github.com/adap/flower/pull/3512), "
"[#3408](https://github.com/adap/flower/pull/3408))"
msgstr ""

#: ../../source/ref-changelog.md:397
msgid ""
"SSL-related `flower-superlink` CLI arguments were restructured in an "
"incompatible way. Instead of passing a single `--certificates` flag with "
"three values, you now need to pass three flags (`--ssl-ca-certfile`, "
"`--ssl-certfile` and `--ssl-keyfile`) with one value each. Check out the "
"[SSL connections](https://flower.ai/docs/framework/how-to-enable-ssl-"
"connections.html) documentation page for details."
msgstr ""

#: ../../source/ref-changelog.md:399
#, fuzzy
msgid ""
"**Remove SuperLink** `--vce` **option** "
"([#3513](https://github.com/adap/flower/pull/3513))"
msgstr "**重构文档**（[#1387](https://github.com/adap/flower/pull/1387)）"

#: ../../source/ref-changelog.md:401
msgid ""
"Instead of separately starting a SuperLink and a `ServerApp` for "
"simulation, simulations must now be started using the single `flower-"
"simulation` command."
msgstr ""

#: ../../source/ref-changelog.md:403
#, fuzzy
msgid ""
"**Merge** `--grpc-rere` **and** `--rest` **SuperLink options** "
"([#3527](https://github.com/adap/flower/pull/3527))"
msgstr ""
"**重新命名** `rnd` ** to** `server_round` "
"([#1321](https://github.com/adap/flower/pull/1321))"

#: ../../source/ref-changelog.md:405
msgid ""
"To simplify the usage of `flower-superlink`, previously separate sets of "
"CLI options for gRPC and REST were merged into one unified set of "
"options. Consult the [Flower CLI reference "
"documentation](https://flower.ai/docs/framework/ref-api-cli.html) for "
"details."
msgstr ""

#: ../../source/ref-changelog.md:407
#, fuzzy
msgid "v1.8.0 (2024-04-03)"
msgstr "v1.3.0 (2023-02-06)"

#: ../../source/ref-changelog.md:413
#, fuzzy
msgid ""
"`Adam Narozniak`, `Charles Beauville`, `Daniel J. Beutel`, `Daniel Nata "
"Nugraha`, `Danny`, `Gustavo Bertoli`, `Heng Pan`, `Ikko Eltociear "
"Ashimine`, `Jack Cook`, `Javier`, `Raj Parekh`, `Robert Steiner`, "
"`Sebastian van der Voort`, `Taner Topal`, `Yan Gao`, `mohammadnaseri`, "
"`tabdar-khan` <!---TOKEN_v1.8.0-->"
msgstr ""
"`Adam Narozniak`, `Anass Anhari`, `Charles Beauville`, `Dana-Farber`, "
"`Daniel J. Beutel`, `Daniel Nata Nugraha`, `Edoardo Gabrielli`, `Gustavo "
"Bertoli`, `Heng Pan`, `Javier`, `Mahdi`, `Steven Hé (Sīchàng)`, `Taner "
"Topal`, `achiverram28`, `danielnugraha`, `eunchung`, `ruthgal` <!---"
"TOKEN_v1.5.0-->"

#: ../../source/ref-changelog.md:417
#, fuzzy
msgid ""
"**Introduce Flower Next high-level API (stable)** "
"([#3002](https://github.com/adap/flower/pull/3002), "
"[#2934](https://github.com/adap/flower/pull/2934), "
"[#2958](https://github.com/adap/flower/pull/2958), "
"[#3173](https://github.com/adap/flower/pull/3173), "
"[#3174](https://github.com/adap/flower/pull/3174), "
"[#2923](https://github.com/adap/flower/pull/2923), "
"[#2691](https://github.com/adap/flower/pull/2691), "
"[#3079](https://github.com/adap/flower/pull/3079), "
"[#2961](https://github.com/adap/flower/pull/2961), "
"[#2924](https://github.com/adap/flower/pull/2924), "
"[#3166](https://github.com/adap/flower/pull/3166), "
"[#3031](https://github.com/adap/flower/pull/3031), "
"[#3057](https://github.com/adap/flower/pull/3057), "
"[#3000](https://github.com/adap/flower/pull/3000), "
"[#3113](https://github.com/adap/flower/pull/3113), "
"[#2957](https://github.com/adap/flower/pull/2957), "
"[#3183](https://github.com/adap/flower/pull/3183), "
"[#3180](https://github.com/adap/flower/pull/3180), "
"[#3035](https://github.com/adap/flower/pull/3035), "
"[#3189](https://github.com/adap/flower/pull/3189), "
"[#3185](https://github.com/adap/flower/pull/3185), "
"[#3190](https://github.com/adap/flower/pull/3190), "
"[#3191](https://github.com/adap/flower/pull/3191), "
"[#3195](https://github.com/adap/flower/pull/3195), "
"[#3197](https://github.com/adap/flower/pull/3197))"
msgstr ""
"**介绍 Flower Next 高级应用程序接口（稳定版）** "
"([#3002](https://github.com/adap/flower/pull/3002), "
"[#2934](https://github.com/adap/flower/pull/2934), "
"[#2958](https://github.com/adap/flower/pull/2958), "
"[#3173](https://github.com/adap/flower/pull/3173), "
"[#3174](https://github.com/adap/flower/pull/3174), "
"[#2923](https://github.com/adap/flower/pull/2923), "
"[#2691](https://github.com/adap/flower/pull/2691), "
"[#3079](https://github.com/adap/flower/pull/3079), "
"[#2961](https://github.com/adap/flower/pull/2961), "
"[#2924](https://github.com/adap/flower/pull/2924), "
"[#3166](https://github.com/adap/flower/pull/3166), "
"[#3031](https://github.com/adap/flower/pull/3031), "
"[#3057](https://github.com/adap/flower/pull/3057), "
"[#3000](https://github.com/adap/flower/pull/3000), "
"[#3113](https://github.com/adap/flower/pull/3113), "
"[#2957](https://github.com/adap/flower/pull/2957), "
"[#3183](https://github.com/adap/flower/pull/3183), "
"[#3180](https://github.com/adap/flower/pull/3180), "
"[#3035](https://github.com/adap/flower/pull/3035), "
"[#3189](https://github.com/adap/flower/pull/3189), "
"[#3185](https://github.com/adap/flower/pull/3185), "
"[#3190](https://github.com/adap/flower/pull/3190), "
"[#3191](https://github.com/adap/flower/pull/3191), "
"[#3195](https://github.com/adap/flower/pull/3195), "
"[#3197](https://github.com/adap/flower/pull/3197))"

#: ../../source/ref-changelog.md:419
#, fuzzy
msgid ""
"The Flower Next high-level API is stable! Flower Next is the future of "
"Flower - all new features (like Flower Mods) will be built on top of it. "
"You can start to migrate your existing projects to Flower Next by using "
"`ServerApp` and `ClientApp` (check out `quickstart-pytorch` or "
"`quickstart-tensorflow`, a detailed migration guide will follow shortly)."
" Flower Next allows you to run multiple projects concurrently (we call "
"this multi-run) and execute the same project in either simulation "
"environments or deployment environments without having to change a single"
" line of code. The best part? It's fully compatible with existing Flower "
"projects that use `Strategy`, `NumPyClient` & co."
msgstr ""
"Flower Next 高级应用程序接口已经稳定！Flower Next 是 Flower 的未来 - 所有新功能（如 Flower "
"Mods）都将构建在它之上。您可以使用 `ServerApp` 和 `ClientApp` 开始将现有项目迁移到 Flower Next（请查看 "
"`quickstart-pytorch` 或 `quickstart-tensorflow` ，详细的迁移指南将在不久后发布）。Flower "
"Next 允许您同时运行多个项目（我们称之为多重运行），并在模拟环境或部署环境中执行同一项目，而无需更改任何代码。最棒的是什么？它与使用 "
"`Strategy`、`NumPyClient` 等的现有 Flower 项目完全兼容。"

#: ../../source/ref-changelog.md:421
#, fuzzy
msgid ""
"**Introduce Flower Next low-level API (preview)** "
"([#3062](https://github.com/adap/flower/pull/3062), "
"[#3034](https://github.com/adap/flower/pull/3034), "
"[#3069](https://github.com/adap/flower/pull/3069))"
msgstr ""
"** 统一客户端应用程序接口** ([#2303](https://github.com/adap/flower/pull/2303), "
"[#2390](https://github.com/adap/flower/pull/2390), "
"[#2493](https://github.com/adap/flower/pull/2493))"

#: ../../source/ref-changelog.md:423
#, fuzzy
msgid ""
"In addition to the Flower Next *high-level* API that uses `Strategy`, "
"`NumPyClient` & co, Flower 1.8 also comes with a preview version of the "
"new Flower Next *low-level* API. The low-level API allows for granular "
"control of every aspect of the learning process by sending/receiving "
"individual messages to/from client nodes. The new `ServerApp` supports "
"registering a custom `main` function that allows writing custom training "
"loops for methods like async FL, cyclic training, or federated analytics."
" The new `ClientApp` supports registering `train`, `evaluate` and `query`"
" functions that can access the raw message received from the `ServerApp`."
" New abstractions like `RecordSet`, `Message` and `Context` further "
"enable sending multiple models, multiple sets of config values and "
"metrics, stateful computations on the client node and implementations of "
"custom SMPC protocols, to name just a few."
msgstr ""
"除了使用 \"Strategy\"、\"NumPyClient \"等的 Flower Next 高级应用程序接口外，Flower 1.8 "
"还提供了新的 Flower Next "
"低级应用程序接口的预览版。低级应用程序接口允许通过向/从客户端节点发送/接收单个消息，对学习过程的各个方面进行细粒度控制。新的 "
"\"ServerApp \"支持注册一个自定义的 \"main \"函数，允许为异步FL、循环训练或联合分析等方法编写自定义训练循环。新的 "
"\"ClientApp \"支持注册 \"训练\"、\"评估 \"和 \"查询 \"函数，这些函数可以访问从 \"ServerApp "
"\"接收到的原始信息。新的抽象（如 \"RecordSet\"、\"Message \"和 "
"\"Context\"）进一步支持发送多个模型、多套配置值和指标、客户端节点上的有状态计算以及自定义 SMPC 协议的实现等。"

#: ../../source/ref-changelog.md:425
#, fuzzy
msgid ""
"**Introduce Flower Mods (preview)** "
"([#3054](https://github.com/adap/flower/pull/3054), "
"[#2911](https://github.com/adap/flower/pull/2911), "
"[#3083](https://github.com/adap/flower/pull/3083))"
msgstr ""
"**引入新的模拟引擎** ([#1969](https://github.com/adap/flower/pull/1969), "
"[#2221](https://github.com/adap/flower/pull/2221), "
"[#2248](https://github.com/adap/flower/pull/2248))"

#: ../../source/ref-changelog.md:427
#, fuzzy
msgid ""
"Flower Modifiers (we call them Mods) can intercept messages and analyze, "
"edit or handle them directly. Mods can be used to develop pluggable "
"modules that work across different projects. Flower 1.8 already includes "
"mods to log the size of a message, the number of parameters sent over the"
" network, differential privacy with fixed clipping and adaptive clipping,"
" local differential privacy and secure aggregation protocols SecAgg and "
"SecAgg+. The Flower Mods API is released as a preview, but researchers "
"can already use it to experiment with arbirtrary SMPC protocols."
msgstr ""
"Flower Modifiers（我们称之为 "
"Mods）可以拦截信息，并直接对其进行分析、编辑或处理。修改器可用于开发可在不同项目中使用的可插拔模块。Flower 1.8 "
"已经包含了记录信息大小、通过网络发送的参数数量、固定剪切和自适应剪切的差分隐私、本地差分隐私以及安全聚合协议 SecAgg 和 SecAgg+ 的"
" Mods。Flower Mods API 作为预览版发布，但研究人员已经可以用它来试验任意的 SMPC 协议。"

#: ../../source/ref-changelog.md:429
#, fuzzy
msgid ""
"**Fine-tune LLMs with LLM FlowerTune** "
"([#3029](https://github.com/adap/flower/pull/3029), "
"[#3089](https://github.com/adap/flower/pull/3089), "
"[#3092](https://github.com/adap/flower/pull/3092), "
"[#3100](https://github.com/adap/flower/pull/3100), "
"[#3114](https://github.com/adap/flower/pull/3114), "
"[#3162](https://github.com/adap/flower/pull/3162), "
"[#3172](https://github.com/adap/flower/pull/3172))"
msgstr ""
"**改进教程** ([#1468](https://github.com/adap/flower/pull/1468), "
"[#1470](https://github.com/adap/flower/pull/1470), "
"[#1472](https://github.com/adap/flower/pull/1472), "
"[#1473](https://github.com/adap/flower/pull/1473), "
"[#1474](https://github.com/adap/flower/pull/1474), "
"[#1475](https://github.com/adap/flower/pull/1475)))"

#: ../../source/ref-changelog.md:431
#, fuzzy
msgid ""
"We are introducing LLM FlowerTune, an introductory example that "
"demonstrates federated LLM fine-tuning of pre-trained Llama2 models on "
"the Alpaca-GPT4 dataset. The example is built to be easily adapted to use"
" different models and/or datasets. Read our blog post [LLM FlowerTune: "
"Federated LLM Fine-tuning with Flower](https://flower.ai/blog/2024-03-14"
"-llm-flowertune-federated-llm-finetuning-with-flower/) for more details."
msgstr ""
"我们将介绍 LLM FlowerTune，这是一个介绍性示例，演示了在 Alpaca-GPT4 数据集上对预先训练好的 Llama2 模型进行联合"
" LLM 微调。该示例可轻松调整以使用不同的模型和/或数据集。请阅读我们的博文 [LLM FlowerTune: Federated LLM "
"Fine-tuning with Flower](https://flower.ai/blog/2024-03-14-llm-"
"flowertune-federated-llm-finetuning-with-flower/) 了解更多详情。"

#: ../../source/ref-changelog.md:433
#, fuzzy
msgid ""
"**Introduce built-in Differential Privacy (preview)** "
"([#2798](https://github.com/adap/flower/pull/2798), "
"[#2959](https://github.com/adap/flower/pull/2959), "
"[#3038](https://github.com/adap/flower/pull/3038), "
"[#3147](https://github.com/adap/flower/pull/3147), "
"[#2909](https://github.com/adap/flower/pull/2909), "
"[#2893](https://github.com/adap/flower/pull/2893), "
"[#2892](https://github.com/adap/flower/pull/2892), "
"[#3039](https://github.com/adap/flower/pull/3039), "
"[#3074](https://github.com/adap/flower/pull/3074))"
msgstr ""
"** 支持 SSL 的服务器和客户端** ([#842](https://github.com/adap/flower/pull/842), "
"[#844](https://github.com/adap/flower/pull/844), "
"[#845](https://github.com/adap/flower/pull/845), "
"[#847](https://github.com/adap/flower/pull/847), "
"[#993](https://github.com/adap/flower/pull/993), "
"[#994](https://github.com/adap/flower/pull/994))"

#: ../../source/ref-changelog.md:435
#, fuzzy
msgid ""
"Built-in Differential Privacy is here! Flower supports both central and "
"local differential privacy (DP). Central DP can be configured with either"
" fixed or adaptive clipping. The clipping can happen either on the "
"server-side or the client-side. Local DP does both clipping and noising "
"on the client-side. A new documentation page [explains Differential "
"Privacy approaches](https://flower.ai/docs/framework/explanation-"
"differential-privacy.html) and a new how-to guide describes [how to use "
"the new Differential Privacy components](https://flower.ai/docs/framework"
"/how-to-use-differential-privacy.html) in Flower."
msgstr ""
"内置差分保密功能！Flower 支持中央和本地差分保密 (DP)。中央差分隐私可配置为固定或自适应剪切。剪切可以发生在服务器端或客户端。本地 DP"
" 在客户端进行剪切和噪声处理。新的文档页面[解释差分隐私方法](https://flower.ai/docs/framework"
"/explanation-differential-privacy.html) "
"和新的操作指南[如何使用新的差分隐私组件](https://flower.ai/docs/framework/how-to-use-"
"differential-privacy.html) 介绍了 Flower 的使用方法。"

#: ../../source/ref-changelog.md:437
#, fuzzy
msgid ""
"**Introduce built-in Secure Aggregation (preview)** "
"([#3120](https://github.com/adap/flower/pull/3120), "
"[#3110](https://github.com/adap/flower/pull/3110), "
"[#3108](https://github.com/adap/flower/pull/3108))"
msgstr ""
"**引入新的模拟引擎** ([#1969](https://github.com/adap/flower/pull/1969), "
"[#2221](https://github.com/adap/flower/pull/2221), "
"[#2248](https://github.com/adap/flower/pull/2248))"

#: ../../source/ref-changelog.md:439
#, fuzzy
msgid ""
"Built-in Secure Aggregation is here! Flower now supports different secure"
" aggregation protocols out-of-the-box. The best part? You can add secure "
"aggregation to your Flower projects with only a few lines of code. In "
"this initial release, we inlcude support for SecAgg and SecAgg+, but more"
" protocols will be implemented shortly. We'll also add detailed docs that"
" explain secure aggregation and how to use it in Flower. You can already "
"check out the new code example that shows how to use Flower to easily "
"combine Federated Learning, Differential Privacy and Secure Aggregation "
"in the same project."
msgstr ""
"内置安全聚合功能！Flower 现在支持不同的安全聚合协议。最棒的是什么？只需几行代码，您就可以将安全聚合添加到 Flower "
"项目中。在这个初始版本中，我们包含了对 SecAgg 和 SecAgg+ "
"的支持，但更多协议将很快实现。我们还将添加详细的文档，解释安全聚合以及如何在 Flower 中使用它。您可以查看新的代码示例，了解如何使用 "
"Flower 在同一项目中轻松结合联合学习、差分隐私和安全聚合。"

#: ../../source/ref-changelog.md:441
#, fuzzy
msgid ""
"**Introduce** `flwr` **CLI (preview)** "
"([#2942](https://github.com/adap/flower/pull/2942), "
"[#3055](https://github.com/adap/flower/pull/3055), "
"[#3111](https://github.com/adap/flower/pull/3111), "
"[#3130](https://github.com/adap/flower/pull/3130), "
"[#3136](https://github.com/adap/flower/pull/3136), "
"[#3094](https://github.com/adap/flower/pull/3094), "
"[#3059](https://github.com/adap/flower/pull/3059), "
"[#3049](https://github.com/adap/flower/pull/3049), "
"[#3142](https://github.com/adap/flower/pull/3142))"
msgstr ""
"**普通改进**（[#1872](https://github.com/adap/flower/pull/1872), "
"[#1866](https://github.com/adap/flower/pull/1866), "
"[#1884](https://github.com/adap/flower/pull/1884), "
"[#1837](https://github.com/adap/flower/pull/1837), "
"[#1477](https://github.com/adap/flower/pull/1477), "
"[#2171](https://github.com/adap/flower/pull/2171))"

#: ../../source/ref-changelog.md:443
#, fuzzy
msgid ""
"A new `flwr` CLI command allows creating new Flower projects (`flwr new`)"
" and then running them using the Simulation Engine (`flwr run`)."
msgstr "新的 `flwr` CLI 命令允许创建新的 Flower 项目（`flwr new`），然后使用仿真引擎运行它们（`flwr run`）。"

#: ../../source/ref-changelog.md:445
#, fuzzy
msgid ""
"**Introduce Flower Next Simulation Engine** "
"([#3024](https://github.com/adap/flower/pull/3024), "
"[#3061](https://github.com/adap/flower/pull/3061), "
"[#2997](https://github.com/adap/flower/pull/2997), "
"[#2783](https://github.com/adap/flower/pull/2783), "
"[#3184](https://github.com/adap/flower/pull/3184), "
"[#3075](https://github.com/adap/flower/pull/3075), "
"[#3047](https://github.com/adap/flower/pull/3047), "
"[#2998](https://github.com/adap/flower/pull/2998), "
"[#3009](https://github.com/adap/flower/pull/3009), "
"[#3008](https://github.com/adap/flower/pull/3008))"
msgstr ""
"**引入（试验性）REST API** ([#1594](https://github.com/adap/flower/pull/1594), "
"[#1690](https://github.com/adap/flower/pull/1690), "
"[#1695](https://github.com/adap/flower/pull/1695), "
"[#1712](https://github.com/adap/flower/pull/1712), "
"[#1802](https://github.com/adap/flower/pull/1802), "
"[#1770](https://github.com/adap/flower/pull/1770), "
"[#1733](https://github.com/adap/flower/pull/1733))"

#: ../../source/ref-changelog.md:447
#, fuzzy
msgid ""
"The Flower Simulation Engine can now run Flower Next projects. For "
"notebook environments, there's also a new `run_simulation` function that "
"can run `ServerApp` and `ClientApp`."
msgstr ""
"Flower 模拟引擎现在可以运行 Flower Next 项目。对于笔记本环境，还有一个新的 `run_simulation` 函数，可以运行 "
"`ServerApp` 和 `ClientApp`。"

#: ../../source/ref-changelog.md:449
#, fuzzy
msgid ""
"**Handle SuperNode connection errors** "
"([#2969](https://github.com/adap/flower/pull/2969))"
msgstr "** 添加一个新的 gRPC 选项**（[#2197](https://github.com/adap/flower/pull/2197)）"

#: ../../source/ref-changelog.md:451
#, fuzzy
msgid ""
"A SuperNode will now try to reconnect indefinitely to the SuperLink in "
"case of connection errors. The arguments `--max-retries` and `--max-wait-"
"time` can now be passed to the `flower-client-app` command. `--max-"
"retries` will define the number of tentatives the client should make "
"before it gives up trying to reconnect to the SuperLink, and, `--max-"
"wait-time` defines the time before the SuperNode gives up trying to "
"reconnect to the SuperLink."
msgstr ""
"如果出现连接错误，超级节点现在会尝试无限期地重新连接超级链接。现在可以向 `flower-client-app` 命令传递参数 `-ax-"
"retries` 和 `-max-wait-time`。最大重试次数 \"将定义客户端在放弃重新连接超级链接之前的重试次数，而 \"最大等待时间 "
"\"则定义超级节点放弃重新连接超级链接之前的等待时间。"

#: ../../source/ref-changelog.md:453
#, fuzzy
msgid ""
"**General updates to Flower Baselines** "
"([#2904](https://github.com/adap/flower/pull/2904), "
"[#2482](https://github.com/adap/flower/pull/2482), "
"[#2985](https://github.com/adap/flower/pull/2985), "
"[#2968](https://github.com/adap/flower/pull/2968))"
msgstr ""
"**引入新的 Flower Baseline： FedProx MNIST** "
"（[#1513](https://github.com/adap/flower/pull/1513), "
"[#1680](https://github.com/adap/flower/pull/1680), "
"[#1681](https://github.com/adap/flower/pull/1681), "
"[#1679](https://github.com/adap/flower/pull/1679)"

#: ../../source/ref-changelog.md:455
#, fuzzy
msgid ""
"There's a new [FedStar](https://flower.ai/docs/baselines/fedstar.html) "
"baseline. Several other baselined have been updated as well."
msgstr ""
"有一条新的 [FedStar](https://flower.ai/docs/baselines/fedstar.html) "
"基准线。其他几条基准线也已更新。"

#: ../../source/ref-changelog.md:457
#, fuzzy
msgid ""
"**Improve documentation and translations** "
"([#3050](https://github.com/adap/flower/pull/3050), "
"[#3044](https://github.com/adap/flower/pull/3044), "
"[#3043](https://github.com/adap/flower/pull/3043), "
"[#2986](https://github.com/adap/flower/pull/2986), "
"[#3041](https://github.com/adap/flower/pull/3041), "
"[#3046](https://github.com/adap/flower/pull/3046), "
"[#3042](https://github.com/adap/flower/pull/3042), "
"[#2978](https://github.com/adap/flower/pull/2978), "
"[#2952](https://github.com/adap/flower/pull/2952), "
"[#3167](https://github.com/adap/flower/pull/3167), "
"[#2953](https://github.com/adap/flower/pull/2953), "
"[#3045](https://github.com/adap/flower/pull/3045), "
"[#2654](https://github.com/adap/flower/pull/2654), "
"[#3082](https://github.com/adap/flower/pull/3082), "
"[#2990](https://github.com/adap/flower/pull/2990), "
"[#2989](https://github.com/adap/flower/pull/2989))"
msgstr ""
"**改进文件和翻译** ([#3050](https://github.com/adap/flower/pull/3050), "
"[#3044](https://github.com/adap/flower/pull/3044), "
"[#3043](https://github.com/adap/flower/pull/3043), "
"[#2986](https://github.com/adap/flower/pull/2986), "
"[#3041](https://github.com/adap/flower/pull/3041), "
"[#3046](https://github.com/adap/flower/pull/3046), "
"[#3042](https://github.com/adap/flower/pull/3042), "
"[#2978](https://github.com/adap/flower/pull/2978), "
"[#2952](https://github.com/adap/flower/pull/2952), "
"[#3167](https://github.com/adap/flower/pull/3167), "
"[#2953](https://github.com/adap/flower/pull/2953), "
"[#3045](https://github.com/adap/flower/pull/3045), "
"[#2654](https://github.com/adap/flower/pull/2654), "
"[#3082](https://github.com/adap/flower/pull/3082), "
"[#2990](https://github.com/adap/flower/pull/2990), "
"[#2989](https://github.com/adap/flower/pull/2989))"

#: ../../source/ref-changelog.md:459
#, fuzzy
msgid ""
"As usual, we merged many smaller and larger improvements to the "
"documentation. A special thank you goes to [Sebastian van der "
"Voort](https://github.com/svdvoort) for landing a big documentation PR!"
msgstr ""
"像往常一样，我们合并了许多对文档的较大和较小的改进。特别要感谢 [Sebastian van der "
"Voort](https://github.com/svdvoort)，他为我们带来了一份重要的文档 PR！"

#: ../../source/ref-changelog.md:461
#, fuzzy
msgid ""
"**General updates to Flower Examples** "
"([3134](https://github.com/adap/flower/pull/3134), "
"[2996](https://github.com/adap/flower/pull/2996), "
"[2930](https://github.com/adap/flower/pull/2930), "
"[2967](https://github.com/adap/flower/pull/2967), "
"[2467](https://github.com/adap/flower/pull/2467), "
"[2910](https://github.com/adap/flower/pull/2910), "
"[#2918](https://github.com/adap/flower/pull/2918), "
"[#2773](https://github.com/adap/flower/pull/2773), "
"[#3063](https://github.com/adap/flower/pull/3063), "
"[#3116](https://github.com/adap/flower/pull/3116), "
"[#3117](https://github.com/adap/flower/pull/3117))"
msgstr ""
"** 更新文档** ([#1494](https://github.com/adap/flower/pull/1494), "
"[#1496](https://github.com/adap/flower/pull/1496), "
"[#1500](https://github.com/adap/flower/pull/1500), "
"[#1503](https://github.com/adap/flower/pull/1503), "
"[#1505](https://github.com/adap/flower/pull/1505), "
"[#1524](https://github.com/adap/flower/pull/1524), "
"[#1518](https://github.com/adap/flower/pull/1518), "
"[#1519](https://github.com/adap/flower/pull/1519), "
"[#1515](https://github.com/adap/flower/pull/1515))"

#: ../../source/ref-changelog.md:463
#, fuzzy
msgid ""
"Two new examples show federated training of a Vision Transformer (ViT) "
"and federated learning in a medical context using the popular MONAI "
"library. `quickstart-pytorch` and `quickstart-tensorflow` demonstrate the"
" new Flower Next `ServerApp` and `ClientApp`. Many other examples "
"received considerable updates as well."
msgstr ""
"两个新示例展示了视觉转换器（ViT）的联合训练，以及使用流行的 MONAI 库在医疗环境中进行的联合学习。quickstart-pytorch "
"\"和 \"quickstart-tensorflow \"展示了新的 Flower Next \"ServerApp \"和 "
"\"ClientApp\"。许多其他示例也得到了大量更新。"

#: ../../source/ref-changelog.md:465
#, fuzzy
msgid ""
"**General improvements** "
"([#3171](https://github.com/adap/flower/pull/3171), "
"[3099](https://github.com/adap/flower/pull/3099), "
"[3003](https://github.com/adap/flower/pull/3003), "
"[3145](https://github.com/adap/flower/pull/3145), "
"[3017](https://github.com/adap/flower/pull/3017), "
"[3085](https://github.com/adap/flower/pull/3085), "
"[3012](https://github.com/adap/flower/pull/3012), "
"[3119](https://github.com/adap/flower/pull/3119), "
"[2991](https://github.com/adap/flower/pull/2991), "
"[2970](https://github.com/adap/flower/pull/2970), "
"[2980](https://github.com/adap/flower/pull/2980), "
"[3086](https://github.com/adap/flower/pull/3086), "
"[2932](https://github.com/adap/flower/pull/2932), "
"[2928](https://github.com/adap/flower/pull/2928), "
"[2941](https://github.com/adap/flower/pull/2941), "
"[2933](https://github.com/adap/flower/pull/2933), "
"[3181](https://github.com/adap/flower/pull/3181), "
"[2973](https://github.com/adap/flower/pull/2973), "
"[2992](https://github.com/adap/flower/pull/2992), "
"[2915](https://github.com/adap/flower/pull/2915), "
"[3040](https://github.com/adap/flower/pull/3040), "
"[3022](https://github.com/adap/flower/pull/3022), "
"[3032](https://github.com/adap/flower/pull/3032), "
"[2902](https://github.com/adap/flower/pull/2902), "
"[2931](https://github.com/adap/flower/pull/2931), "
"[3005](https://github.com/adap/flower/pull/3005), "
"[3132](https://github.com/adap/flower/pull/3132), "
"[3115](https://github.com/adap/flower/pull/3115), "
"[2944](https://github.com/adap/flower/pull/2944), "
"[3064](https://github.com/adap/flower/pull/3064), "
"[3106](https://github.com/adap/flower/pull/3106), "
"[2974](https://github.com/adap/flower/pull/2974), "
"[3178](https://github.com/adap/flower/pull/3178), "
"[2993](https://github.com/adap/flower/pull/2993), "
"[3186](https://github.com/adap/flower/pull/3186), "
"[3091](https://github.com/adap/flower/pull/3091), "
"[3125](https://github.com/adap/flower/pull/3125), "
"[3093](https://github.com/adap/flower/pull/3093), "
"[3013](https://github.com/adap/flower/pull/3013), "
"[3033](https://github.com/adap/flower/pull/3033), "
"[3133](https://github.com/adap/flower/pull/3133), "
"[3068](https://github.com/adap/flower/pull/3068), "
"[2916](https://github.com/adap/flower/pull/2916), "
"[2975](https://github.com/adap/flower/pull/2975), "
"[2984](https://github.com/adap/flower/pull/2984), "
"[2846](https://github.com/adap/flower/pull/2846), "
"[3077](https://github.com/adap/flower/pull/3077), "
"[3143](https://github.com/adap/flower/pull/3143), "
"[2921](https://github.com/adap/flower/pull/2921), "
"[3101](https://github.com/adap/flower/pull/3101), "
"[2927](https://github.com/adap/flower/pull/2927), "
"[2995](https://github.com/adap/flower/pull/2995), "
"[2972](https://github.com/adap/flower/pull/2972), "
"[2912](https://github.com/adap/flower/pull/2912), "
"[3065](https://github.com/adap/flower/pull/3065), "
"[3028](https://github.com/adap/flower/pull/3028), "
"[2922](https://github.com/adap/flower/pull/2922), "
"[2982](https://github.com/adap/flower/pull/2982), "
"[2914](https://github.com/adap/flower/pull/2914), "
"[3179](https://github.com/adap/flower/pull/3179), "
"[3080](https://github.com/adap/flower/pull/3080), "
"[2994](https://github.com/adap/flower/pull/2994), "
"[3187](https://github.com/adap/flower/pull/3187), "
"[2926](https://github.com/adap/flower/pull/2926), "
"[3018](https://github.com/adap/flower/pull/3018), "
"[3144](https://github.com/adap/flower/pull/3144), "
"[3011](https://github.com/adap/flower/pull/3011), "
"[#3152](https://github.com/adap/flower/pull/3152), "
"[#2836](https://github.com/adap/flower/pull/2836), "
"[#2929](https://github.com/adap/flower/pull/2929), "
"[#2943](https://github.com/adap/flower/pull/2943), "
"[#2955](https://github.com/adap/flower/pull/2955), "
"[#2954](https://github.com/adap/flower/pull/2954))"
msgstr ""
"**一般改进**([#3171](https://github.com/adap/flower/pull/3171), "
"[3099](https://github.com/adap/flower/pull/3099), "
"[3003](https://github.com/adap/flower/pull/3003), "
"[3145](https://github.com/adap/flower/pull/3145), "
"[3017](https://github.com/adap/flower/pull/3017), "
"[3085](https://github.com/adap/flower/pull/3085), "
"[3012](https://github.com/adap/flower/pull/3012), "
"[3119](https://github.com/adap/flower/pull/3119), "
"[2991](https://github.com/adap/flower/pull/2991), "
"[2970](https://github.com/adap/flower/pull/2970), "
"[2980](https://github.com/adap/flower/pull/2980), "
"[3086](https://github.com/adap/flower/pull/3086), "
"[2932](https://github.com/adap/flower/pull/2932), "
"[2928](https://github.com/adap/flower/pull/2928), "
"[2941](https://github.com/adap/flower/pull/2941), "
"[2933](https://github.com/adap/flower/pull/2933), "
"[3181](https://github.com/adap/flower/pull/3181), "
"[2973](https://github.com/adap/flower/pull/2973), "
"[2992](https://github.com/adap/flower/pull/2992), "
"[2915](https://github.com/adap/flower/pull/2915), "
"[3040](https://github.com/adap/flower/pull/3040), "
"[3022](https://github.com/adap/flower/pull/3022), "
"[3032](https://github.com/adap/flower/pull/3032), "
"[2902](https://github.com/adap/flower/pull/2902), "
"[2931](https://github.com/adap/flower/pull/2931), "
"[3005](https://github.com/adap/flower/pull/3005), "
"[3132](https://github.com/adap/flower/pull/3132), "
"[3115](https://github.com/adap/flower/pull/3115), "
"[2944](https://github.com/adap/flower/pull/2944), "
"[3064](https://github.com/adap/flower/pull/3064), "
"[3106](https://github.com/adap/flower/pull/3106), "
"[2974](https://github.com/adap/flower/pull/2974), "
"[3178](https://github.com/adap/flower/pull/3178), "
"[2993](https://github.com/adap/flower/pull/2993), "
"[3186](https://github.com/adap/flower/pull/3186), "
"[3091](https://github.com/adap/flower/pull/3091), "
"[3125](https://github.com/adap/flower/pull/3125), "
"[3093](https://github.com/adap/flower/pull/3093), "
"[3013](https://github.com/adap/flower/pull/3013), "
"[3033](https://github.com/adap/flower/pull/3033), "
"[3133](https://github.com/adap/flower/pull/3133), "
"[3068](https://github.com/adap/flower/pull/3068), "
"[2916](https://github.com/adap/flower/pull/2916), "
"[2975](https://github.com/adap/flower/pull/2975), "
"[2984](https://github.com/adap/flower/pull/2984), "
"[2846](https://github.com/adap/flower/pull/2846), "
"[3077](https://github.com/adap/flower/pull/3077), "
"[3143](https://github.com/adap/flower/pull/3143), "
"[2921](https://github.com/adap/flower/pull/2921), "
"[3101](https://github.com/adap/flower/pull/3101), "
"[2927](https://github.com/adap/flower/pull/2927), "
"[2995](https://github.com/adap/flower/pull/2995), "
"[2972](https://github.com/adap/flower/pull/2972), "
"[2912](https://github.com/adap/flower/pull/2912), "
"[3065](https://github.com/adap/flower/pull/3065), "
"[3028](https://github.com/adap/flower/pull/3028), "
"[2922](https://github.com/adap/flower/pull/2922), "
"[2982](https://github.com/adap/flower/pull/2982), "
"[2914](https://github.com/adap/flower/pull/2914), "
"[3179](https://github.com/adap/flower/pull/3179), "
"[3080](https://github.com/adap/flower/pull/3080), "
"[2994](https://github.com/adap/flower/pull/2994), "
"[3187](https://github.com/adap/flower/pull/3187), "
"[2926](https://github.com/adap/flower/pull/2926), "
"[3018](https://github.com/adap/flower/pull/3018), "
"[3144](https://github.com/adap/flower/pull/3144), "
"[3011](https://github.com/adap/flower/pull/3011), "
"[#3152](https://github.com/adap/flower/pull/3152), "
"[#2836](https://github.com/adap/flower/pull/2836), "
"[#2929](https://github.com/adap/flower/pull/2929), "
"[#2943](https://github.com/adap/flower/pull/2943), "
"[#2955](https://github.com/adap/flower/pull/2955), "
"[#2954](https://github.com/adap/flower/pull/2954))"

#: ../../source/ref-changelog.md:471
#, fuzzy
msgid "v1.7.0 (2024-02-05)"
msgstr "v1.3.0 (2023-02-06)"

#: ../../source/ref-changelog.md:477
#, fuzzy
msgid ""
"`Aasheesh Singh`, `Adam Narozniak`, `Aml Hassan Esmil`, `Charles "
"Beauville`, `Daniel J. Beutel`, `Daniel Nata Nugraha`, `Edoardo "
"Gabrielli`, `Gustavo Bertoli`, `HelinLin`, `Heng Pan`, `Javier`, `M S "
"Chaitanya Kumar`, `Mohammad Naseri`, `Nikos Vlachakis`, `Pritam Neog`, "
"`Robert Kuska`, `Robert Steiner`, `Taner Topal`, `Yahia Salaheldin "
"Shaaban`, `Yan Gao`, `Yasar Abbas` <!---TOKEN_v1.7.0-->"
msgstr ""
"`Adam Narozniak`, `Anass Anhari`, `Charles Beauville`, `Dana-Farber`, "
"`Daniel J. Beutel`, `Daniel Nata Nugraha`, `Edoardo Gabrielli`, `Gustavo "
"Bertoli`, `Heng Pan`, `Javier`, `Mahdi`, `Steven Hé (Sīchàng)`, `Taner "
"Topal`, `achiverram28`, `danielnugraha`, `eunchung`, `ruthgal` <!---"
"TOKEN_v1.5.0-->"

#: ../../source/ref-changelog.md:481
#, fuzzy
msgid ""
"**Introduce stateful clients (experimental)** "
"([#2770](https://github.com/adap/flower/pull/2770), "
"[#2686](https://github.com/adap/flower/pull/2686), "
"[#2696](https://github.com/adap/flower/pull/2696), "
"[#2643](https://github.com/adap/flower/pull/2643), "
"[#2769](https://github.com/adap/flower/pull/2769))"
msgstr ""
"** baselines的普通更新** ([#2301](https://github.com/adap/flower/pull/2301), "
"[#2305](https://github.com/adap/flower/pull/2305), "
"[#2307](https://github.com/adap/flower/pull/2307), "
"[#2327](https://github.com/adap/flower/pull/2327), "
"[#2435](https://github.com/adap/flower/pull/2435))"

#: ../../source/ref-changelog.md:483
#, fuzzy
msgid ""
"Subclasses of `Client` and `NumPyClient` can now store local state that "
"remains on the client. Let's start with the highlight first: this new "
"feature is compatible with both simulated clients (via "
"`start_simulation`) and networked clients (via `start_client`). It's also"
" the first preview of new abstractions like `Context` and `RecordSet`. "
"Clients can access state of type `RecordSet` via `state: RecordSet = "
"self.context.state`. Changes to this `RecordSet` are preserved across "
"different rounds of execution to enable stateful computations in a "
"unified way across simulation and deployment."
msgstr ""
"客户端 \"和 \"NumPyClient \"的子类现在可以存储保留在客户端上的本地状态。让我们先从亮点开始：这一新功能与模拟客户端（通过 "
"`start_simulation`）和网络客户端（通过 `start_client`）兼容。这也是 `Context` 和 "
"`RecordSet` 等新抽象的首次预览。客户端可以通过 `state.RecordSet` 访问 `RecordSet` 类型的状态： "
"RecordSet = self.context.state`。对该 `RecordSet` "
"的更改会在不同轮执行中保留，以便在模拟和部署中以统一的方式进行有状态计算。"

#: ../../source/ref-changelog.md:485
#, fuzzy
msgid ""
"**Improve performance** "
"([#2293](https://github.com/adap/flower/pull/2293))"
msgstr "**改进示例笔记** ([#2005](https://github.com/adap/flower/pull/2005))"

#: ../../source/ref-changelog.md:487
#, fuzzy
msgid ""
"Flower is faster than ever. All `FedAvg`-derived strategies now use in-"
"place aggregation to reduce memory consumption. The Flower client "
"serialization/deserialization has been rewritten from the ground up, "
"which results in significant speedups, especially when the client-side "
"training time is short."
msgstr ""
"Flower 的速度比以往更快。所有源于 `FedAvg` 的策略现在都使用就地聚合，以减少内存消耗。Flower "
"客户端序列化/解序列化已从头开始重写，从而显著提高了速度，尤其是在客户端训练时间较短的情况下。"

#: ../../source/ref-changelog.md:489
#, fuzzy
msgid ""
"**Support Federated Learning with Apple MLX and Flower** "
"([#2693](https://github.com/adap/flower/pull/2693))"
msgstr ""
"** 添加使用 fastai 和 Flower 进行联邦学习的新示例** "
"([#1598](https://github.com/adap/flower/pull/1598))"

#: ../../source/ref-changelog.md:491
#, fuzzy
msgid ""
"Flower has official support for federated learning using [Apple "
"MLX](https://ml-explore.github.io/mlx) via the new `quickstart-mlx` code "
"example."
msgstr ""
"通过新的 `quickstart-mlx` 代码示例，Flower 正式支持使用 [Apple MLX](https://ml-"
"explore.github.io/mlx)的联合学习。"

#: ../../source/ref-changelog.md:493
#, fuzzy
msgid ""
"**Introduce new XGBoost cyclic strategy** "
"([#2666](https://github.com/adap/flower/pull/2666), "
"[#2668](https://github.com/adap/flower/pull/2668))"
msgstr ""
"**介绍 iOS SDK（预览版）** ([#1621](https://github.com/adap/flower/pull/1621), "
"[#1764](https://github.com/adap/flower/pull/1764))"

#: ../../source/ref-changelog.md:495
#, fuzzy
msgid ""
"A new strategy called `FedXgbCyclic` supports a client-by-client style of"
" training (often called cyclic). The `xgboost-comprehensive` code example"
" shows how to use it in a full project. In addition to that, `xgboost-"
"comprehensive` now also supports simulation mode. With this, Flower "
"offers best-in-class XGBoost support."
msgstr ""
"名为 `FedXgbCyclic` 的新策略支持逐个客户端的训练风格（通常称为循环）。xgboost-comprehensive "
"\"代码示例展示了如何在一个完整的项目中使用它。除此之外，`xgboost-comprehensive` 现在还支持模拟模式。由此，Flower "
"提供了同类最佳的 XGBoost 支持。"

#: ../../source/ref-changelog.md:497
#, fuzzy
msgid ""
"**Support Python 3.11** "
"([#2394](https://github.com/adap/flower/pull/2394))"
msgstr "** 支持 Python 3.10** ([#1320](https://github.com/adap/flower/pull/1320))"

#: ../../source/ref-changelog.md:499
#, fuzzy
msgid ""
"Framework tests now run on Python 3.8, 3.9, 3.10, and 3.11. This will "
"ensure better support for users using more recent Python versions."
msgstr "框架测试现在可在 Python 3.8、3.9、3.10 和 3.11 上运行。这将确保为使用最新 Python 版本的用户提供更好的支持。"

#: ../../source/ref-changelog.md:501
#, fuzzy
msgid ""
"**Update gRPC and ProtoBuf dependencies** "
"([#2814](https://github.com/adap/flower/pull/2814))"
msgstr ""
"**更新 REST API 以支持创建和删除节点** "
"([#2283](https://github.com/adap/flower/pull/2283))"

#: ../../source/ref-changelog.md:503
#, fuzzy
msgid ""
"The `grpcio` and `protobuf` dependencies were updated to their latest "
"versions for improved security and performance."
msgstr "为提高安全性和性能，\"grpcio \"和 \"protobuf \"依赖项已更新至最新版本。"

#: ../../source/ref-changelog.md:505
#, fuzzy
msgid ""
"**Introduce Docker image for Flower server** "
"([#2700](https://github.com/adap/flower/pull/2700), "
"[#2688](https://github.com/adap/flower/pull/2688), "
"[#2705](https://github.com/adap/flower/pull/2705), "
"[#2695](https://github.com/adap/flower/pull/2695), "
"[#2747](https://github.com/adap/flower/pull/2747), "
"[#2746](https://github.com/adap/flower/pull/2746), "
"[#2680](https://github.com/adap/flower/pull/2680), "
"[#2682](https://github.com/adap/flower/pull/2682), "
"[#2701](https://github.com/adap/flower/pull/2701))"
msgstr ""
"** 支持 SSL 的服务器和客户端** ([#842](https://github.com/adap/flower/pull/842), "
"[#844](https://github.com/adap/flower/pull/844), "
"[#845](https://github.com/adap/flower/pull/845), "
"[#847](https://github.com/adap/flower/pull/847), "
"[#993](https://github.com/adap/flower/pull/993), "
"[#994](https://github.com/adap/flower/pull/994))"

#: ../../source/ref-changelog.md:507
#, fuzzy
msgid ""
"The Flower server can now be run using an official Docker image. A new "
"how-to guide explains [how to run Flower using "
"Docker](https://flower.ai/docs/framework/how-to-run-flower-using-"
"docker.html). An official Flower client Docker image will follow."
msgstr ""
"现在可以使用官方 Docker 映像运行 Flower 服务器了。新的操作指南介绍了 [如何使用 Docker 运行 "
"Flower](https://flower.ai/docs/framework/how-to-run-flower-using-"
"docker.html)。Flower 客户端 Docker 官方镜像将随后发布。"

#: ../../source/ref-changelog.md:509
#, fuzzy
msgid ""
"**Introduce** `flower-via-docker-compose` **example** "
"([#2626](https://github.com/adap/flower/pull/2626))"
msgstr ""
"**介绍Flower Android SDK** "
"([#2131](https://github.com/adap/flower/pull/2131))"

#: ../../source/ref-changelog.md:511
#, fuzzy
msgid ""
"**Introduce** `quickstart-sklearn-tabular` **example** "
"([#2719](https://github.com/adap/flower/pull/2719))"
msgstr "**引入 start_driver**（[#1697](https://github.com/adap/flower/pull/1697)）"

#: ../../source/ref-changelog.md:513
#, fuzzy
msgid ""
"**Introduce** `custom-metrics` **example** "
"([#1958](https://github.com/adap/flower/pull/1958))"
msgstr "**引入 start_driver**（[#1697](https://github.com/adap/flower/pull/1697)）"

#: ../../source/ref-changelog.md:515
#, fuzzy
msgid ""
"**Update code examples to use Flower Datasets** "
"([#2450](https://github.com/adap/flower/pull/2450), "
"[#2456](https://github.com/adap/flower/pull/2456), "
"[#2318](https://github.com/adap/flower/pull/2318), "
"[#2712](https://github.com/adap/flower/pull/2712))"
msgstr ""
"更新开发人员工具（[#1231](https://github.com/adap/flower/pull/1231), "
"[#1276](https://github.com/adap/flower/pull/1276), "
"[#1301](https://github.com/adap/flower/pull/1301), "
"[#1310](https://github.com/adap/flower/pull/1310)"

#: ../../source/ref-changelog.md:517
#, fuzzy
msgid ""
"Several code examples were updated to use [Flower "
"Datasets](https://flower.ai/docs/datasets/)."
msgstr "更新了多个代码示例，以使用 [Flower Datasets](https://flower.ai/docs/datasets/) 。"

#: ../../source/ref-changelog.md:519
#, fuzzy
msgid ""
"**General updates to Flower Examples** "
"([#2381](https://github.com/adap/flower/pull/2381), "
"[#2805](https://github.com/adap/flower/pull/2805), "
"[#2782](https://github.com/adap/flower/pull/2782), "
"[#2806](https://github.com/adap/flower/pull/2806), "
"[#2829](https://github.com/adap/flower/pull/2829), "
"[#2825](https://github.com/adap/flower/pull/2825), "
"[#2816](https://github.com/adap/flower/pull/2816), "
"[#2726](https://github.com/adap/flower/pull/2726), "
"[#2659](https://github.com/adap/flower/pull/2659), "
"[#2655](https://github.com/adap/flower/pull/2655))"
msgstr ""
"**改进（试验性）驱动程序应用程序接口** ([#1663](https://github.com/adap/flower/pull/1663),"
" [#1666](https://github.com/adap/flower/pull/1666), "
"[#1667](https://github.com/adap/flower/pull/1667), "
"[#1664](https://github.com/adap/flower/pull/1664), "
"[#1675](https://github.com/adap/flower/pull/1675), "
"[#1676](https://github.com/adap/flower/pull/1676), "
"[#1693](https://github.com/adap/flower/pull/1693), "
"[#1662](https://github.com/adap/flower/pull/1662), "
"[#1794](https://github.com/adap/flower/pull/1794))"

#: ../../source/ref-changelog.md:521
#, fuzzy
msgid "Many Flower code examples received substantial updates."
msgstr "许多 \"Flower \"代码示例得到了大幅更新。"

#: ../../source/ref-changelog.md:523 ../../source/ref-changelog.md:616
msgid "**Update Flower Baselines**"
msgstr "**更新 Flower Baselines**"

#: ../../source/ref-changelog.md:525
#, fuzzy
msgid ""
"HFedXGBoost ([#2226](https://github.com/adap/flower/pull/2226), "
"[#2771](https://github.com/adap/flower/pull/2771))"
msgstr ""
"FedBN ([#2608](https://github.com/adap/flower/pull/2608), "
"[#2615](https://github.com/adap/flower/pull/2615))"

#: ../../source/ref-changelog.md:526
#, fuzzy
msgid "FedVSSL ([#2412](https://github.com/adap/flower/pull/2412))"
msgstr "FjORD [#2431](https://github.com/adap/flower/pull/2431)"

#: ../../source/ref-changelog.md:527
#, fuzzy
msgid "FedNova ([#2179](https://github.com/adap/flower/pull/2179))"
msgstr "FjORD [#2431](https://github.com/adap/flower/pull/2431)"

#: ../../source/ref-changelog.md:528
#, fuzzy
msgid "HeteroFL ([#2439](https://github.com/adap/flower/pull/2439))"
msgstr "FedMeta [#2438](https://github.com/adap/flower/pull/2438)"

#: ../../source/ref-changelog.md:529
#, fuzzy
msgid "FedAvgM ([#2246](https://github.com/adap/flower/pull/2246))"
msgstr "FedPer [#2266](https://github.com/adap/flower/pull/2266)"

#: ../../source/ref-changelog.md:530
#, fuzzy
msgid "FedPara ([#2722](https://github.com/adap/flower/pull/2722))"
msgstr "FedPer [#2266](https://github.com/adap/flower/pull/2266)"

#: ../../source/ref-changelog.md:532
#, fuzzy
msgid ""
"**Improve documentation** "
"([#2674](https://github.com/adap/flower/pull/2674), "
"[#2480](https://github.com/adap/flower/pull/2480), "
"[#2826](https://github.com/adap/flower/pull/2826), "
"[#2727](https://github.com/adap/flower/pull/2727), "
"[#2761](https://github.com/adap/flower/pull/2761), "
"[#2900](https://github.com/adap/flower/pull/2900))"
msgstr ""
"** 更新文档** ([#1629](https://github.com/adap/flower/pull/1629), "
"[#1628](https://github.com/adap/flower/pull/1628), "
"[#1620](https://github.com/adap/flower/pull/1620), "
"[#1618](https://github.com/adap/flower/pull/1618), "
"[#1617](https://github.com/adap/flower/pull/1617), "
"[#1613](https://github.com/adap/flower/pull/1613), "
"[#1614](https://github.com/adap/flower/pull/1614)))"

#: ../../source/ref-changelog.md:534
#, fuzzy
msgid ""
"**Improved testing and development infrastructure** "
"([#2797](https://github.com/adap/flower/pull/2797), "
"[#2676](https://github.com/adap/flower/pull/2676), "
"[#2644](https://github.com/adap/flower/pull/2644), "
"[#2656](https://github.com/adap/flower/pull/2656), "
"[#2848](https://github.com/adap/flower/pull/2848), "
"[#2675](https://github.com/adap/flower/pull/2675), "
"[#2735](https://github.com/adap/flower/pull/2735), "
"[#2767](https://github.com/adap/flower/pull/2767), "
"[#2732](https://github.com/adap/flower/pull/2732), "
"[#2744](https://github.com/adap/flower/pull/2744), "
"[#2681](https://github.com/adap/flower/pull/2681), "
"[#2699](https://github.com/adap/flower/pull/2699), "
"[#2745](https://github.com/adap/flower/pull/2745), "
"[#2734](https://github.com/adap/flower/pull/2734), "
"[#2731](https://github.com/adap/flower/pull/2731), "
"[#2652](https://github.com/adap/flower/pull/2652), "
"[#2720](https://github.com/adap/flower/pull/2720), "
"[#2721](https://github.com/adap/flower/pull/2721), "
"[#2717](https://github.com/adap/flower/pull/2717), "
"[#2864](https://github.com/adap/flower/pull/2864), "
"[#2694](https://github.com/adap/flower/pull/2694), "
"[#2709](https://github.com/adap/flower/pull/2709), "
"[#2658](https://github.com/adap/flower/pull/2658), "
"[#2796](https://github.com/adap/flower/pull/2796), "
"[#2692](https://github.com/adap/flower/pull/2692), "
"[#2657](https://github.com/adap/flower/pull/2657), "
"[#2813](https://github.com/adap/flower/pull/2813), "
"[#2661](https://github.com/adap/flower/pull/2661), "
"[#2398](https://github.com/adap/flower/pull/2398))"
msgstr ""
"**改进测试和开发基础设施** ([#2797](https://github.com/adap/flower/pull/2797), "
"[#2676](https://github.com/adap/flower/pull/2676), "
"[#2644](https://github.com/adap/flower/pull/2644), "
"[#2656](https://github.com/adap/flower/pull/2656), "
"[#2848](https://github.com/adap/flower/pull/2848), "
"[#2675](https://github.com/adap/flower/pull/2675), "
"[#2735](https://github.com/adap/flower/pull/2735), "
"[#2767](https://github.com/adap/flower/pull/2767), "
"[#2732](https://github.com/adap/flower/pull/2732), "
"[#2744](https://github.com/adap/flower/pull/2744), "
"[#2681](https://github.com/adap/flower/pull/2681), "
"[#2699](https://github.com/adap/flower/pull/2699), "
"[#2745](https://github.com/adap/flower/pull/2745), "
"[#2734](https://github.com/adap/flower/pull/2734), "
"[#2731](https://github.com/adap/flower/pull/2731), "
"[#2652](https://github.com/adap/flower/pull/2652), "
"[#2720](https://github.com/adap/flower/pull/2720), "
"[#2721](https://github.com/adap/flower/pull/2721), "
"[#2717](https://github.com/adap/flower/pull/2717), "
"[#2864](https://github.com/adap/flower/pull/2864), "
"[#2694](https://github.com/adap/flower/pull/2694), "
"[#2709](https://github.com/adap/flower/pull/2709), "
"[#2658](https://github.com/adap/flower/pull/2658), "
"[#2796](https://github.com/adap/flower/pull/2796), "
"[#2692](https://github.com/adap/flower/pull/2692), "
"[#2657](https://github.com/adap/flower/pull/2657), "
"[#2813](https://github.com/adap/flower/pull/2813), "
"[#2661](https://github.com/adap/flower/pull/2661), "
"[#2398](https://github.com/adap/flower/pull/2398))"

#: ../../source/ref-changelog.md:536
#, fuzzy
msgid ""
"The Flower testing and development infrastructure has received "
"substantial updates. This makes Flower 1.7 the most tested release ever."
msgstr "Flower 测试和开发基础架构已得到大幅更新。这使得 Flower 1.7 成为有史以来经过最多测试的版本。"

#: ../../source/ref-changelog.md:538
#, fuzzy
msgid ""
"**Update dependencies** "
"([#2753](https://github.com/adap/flower/pull/2753), "
"[#2651](https://github.com/adap/flower/pull/2651), "
"[#2739](https://github.com/adap/flower/pull/2739), "
"[#2837](https://github.com/adap/flower/pull/2837), "
"[#2788](https://github.com/adap/flower/pull/2788), "
"[#2811](https://github.com/adap/flower/pull/2811), "
"[#2774](https://github.com/adap/flower/pull/2774), "
"[#2790](https://github.com/adap/flower/pull/2790), "
"[#2751](https://github.com/adap/flower/pull/2751), "
"[#2850](https://github.com/adap/flower/pull/2850), "
"[#2812](https://github.com/adap/flower/pull/2812), "
"[#2872](https://github.com/adap/flower/pull/2872), "
"[#2736](https://github.com/adap/flower/pull/2736), "
"[#2756](https://github.com/adap/flower/pull/2756), "
"[#2857](https://github.com/adap/flower/pull/2857), "
"[#2757](https://github.com/adap/flower/pull/2757), "
"[#2810](https://github.com/adap/flower/pull/2810), "
"[#2740](https://github.com/adap/flower/pull/2740), "
"[#2789](https://github.com/adap/flower/pull/2789))"
msgstr ""
"**更新Example** ([#1772](https://github.com/adap/flower/pull/1772), "
"[#1873](https://github.com/adap/flower/pull/1873), "
"[#1981](https://github.com/adap/flower/pull/1981), "
"[#1988](https://github.com/adap/flower/pull/1988), "
"[#1984](https://github.com/adap/flower/pull/1984), "
"[#1982](https://github.com/adap/flower/pull/1982), "
"[#2112](https://github.com/adap/flower/pull/2112), "
"[#2144](https://github.com/adap/flower/pull/2144), "
"[#2174](https://github.com/adap/flower/pull/2174), "
"[#2225](https://github.com/adap/flower/pull/2225), "
"[#2183](https://github.com/adap/flower/pull/2183))"

#: ../../source/ref-changelog.md:540
#, fuzzy
msgid ""
"**General improvements** "
"([#2803](https://github.com/adap/flower/pull/2803), "
"[#2847](https://github.com/adap/flower/pull/2847), "
"[#2877](https://github.com/adap/flower/pull/2877), "
"[#2690](https://github.com/adap/flower/pull/2690), "
"[#2889](https://github.com/adap/flower/pull/2889), "
"[#2874](https://github.com/adap/flower/pull/2874), "
"[#2819](https://github.com/adap/flower/pull/2819), "
"[#2689](https://github.com/adap/flower/pull/2689), "
"[#2457](https://github.com/adap/flower/pull/2457), "
"[#2870](https://github.com/adap/flower/pull/2870), "
"[#2669](https://github.com/adap/flower/pull/2669), "
"[#2876](https://github.com/adap/flower/pull/2876), "
"[#2885](https://github.com/adap/flower/pull/2885), "
"[#2858](https://github.com/adap/flower/pull/2858), "
"[#2867](https://github.com/adap/flower/pull/2867), "
"[#2351](https://github.com/adap/flower/pull/2351), "
"[#2886](https://github.com/adap/flower/pull/2886), "
"[#2860](https://github.com/adap/flower/pull/2860), "
"[#2828](https://github.com/adap/flower/pull/2828), "
"[#2869](https://github.com/adap/flower/pull/2869), "
"[#2875](https://github.com/adap/flower/pull/2875), "
"[#2733](https://github.com/adap/flower/pull/2733), "
"[#2488](https://github.com/adap/flower/pull/2488), "
"[#2646](https://github.com/adap/flower/pull/2646), "
"[#2879](https://github.com/adap/flower/pull/2879), "
"[#2821](https://github.com/adap/flower/pull/2821), "
"[#2855](https://github.com/adap/flower/pull/2855), "
"[#2800](https://github.com/adap/flower/pull/2800), "
"[#2807](https://github.com/adap/flower/pull/2807), "
"[#2801](https://github.com/adap/flower/pull/2801), "
"[#2804](https://github.com/adap/flower/pull/2804), "
"[#2851](https://github.com/adap/flower/pull/2851), "
"[#2787](https://github.com/adap/flower/pull/2787), "
"[#2852](https://github.com/adap/flower/pull/2852), "
"[#2672](https://github.com/adap/flower/pull/2672), "
"[#2759](https://github.com/adap/flower/pull/2759))"
msgstr ""
"**一般改进** ([#2803](https://github.com/adap/flower/pull/2803), "
"[#2847](https://github.com/adap/flower/pull/2847), "
"[#2877](https://github.com/adap/flower/pull/2877), "
"[#2690](https://github.com/adap/flower/pull/2690), "
"[#2889](https://github.com/adap/flower/pull/2889), "
"[#2874](https://github.com/adap/flower/pull/2874), "
"[#2819](https://github.com/adap/flower/pull/2819), "
"[#2689](https://github.com/adap/flower/pull/2689), "
"[#2457](https://github.com/adap/flower/pull/2457), "
"[#2870](https://github.com/adap/flower/pull/2870), "
"[#2669](https://github.com/adap/flower/pull/2669), "
"[#2876](https://github.com/adap/flower/pull/2876), "
"[#2885](https://github.com/adap/flower/pull/2885), "
"[#2858](https://github.com/adap/flower/pull/2858), "
"[#2867](https://github.com/adap/flower/pull/2867), "
"[#2351](https://github.com/adap/flower/pull/2351), "
"[#2886](https://github.com/adap/flower/pull/2886), "
"[#2860](https://github.com/adap/flower/pull/2860), "
"[#2828](https://github.com/adap/flower/pull/2828), "
"[#2869](https://github.com/adap/flower/pull/2869), "
"[#2875](https://github.com/adap/flower/pull/2875), "
"[#2733](https://github.com/adap/flower/pull/2733), "
"[#2488](https://github.com/adap/flower/pull/2488), "
"[#2646](https://github.com/adap/flower/pull/2646), "
"[#2879](https://github.com/adap/flower/pull/2879), "
"[#2821](https://github.com/adap/flower/pull/2821), "
"[#2855](https://github.com/adap/flower/pull/2855), "
"[#2800](https://github.com/adap/flower/pull/2800), "
"[#2807](https://github.com/adap/flower/pull/2807), "
"[#2801](https://github.com/adap/flower/pull/2801), "
"[#2804](https://github.com/adap/flower/pull/2804), "
"[#2851](https://github.com/adap/flower/pull/2851), "
"[#2787](https://github.com/adap/flower/pull/2787), "
"[#2852](https://github.com/adap/flower/pull/2852), "
"[#2672](https://github.com/adap/flower/pull/2672), "
"[#2759](https://github.com/adap/flower/pull/2759))"

#: ../../source/ref-changelog.md:544
#, fuzzy
msgid ""
"**Deprecate** `start_numpy_client` "
"([#2563](https://github.com/adap/flower/pull/2563), "
"[#2718](https://github.com/adap/flower/pull/2718))"
msgstr ""
"TAMUNA ([#2254](https://github.com/adap/flower/pull/2254), "
"[#2508](https://github.com/adap/flower/pull/2508))"

#: ../../source/ref-changelog.md:546
#, fuzzy
msgid ""
"Until now, clients of type `NumPyClient` needed to be started via "
"`start_numpy_client`. In our efforts to consolidate framework APIs, we "
"have introduced changes, and now all client types should start via "
"`start_client`. To continue using `NumPyClient` clients, you simply need "
"to first call the `.to_client()` method and then pass returned `Client` "
"object to `start_client`. The examples and the documentation have been "
"updated accordingly."
msgstr ""
"到目前为止，\"NumPyClient \"类型的客户端需要通过 \"start_numpy_client \"启动。为了整合框架 "
"API，我们引入了一些变化，现在所有客户端类型都应通过 `start_client` 启动。要继续使用 `NumPyClient` "
"客户端，只需首先调用 `.to_client()` 方法，然后将返回的 `Client` 对象传递给 "
"`start_client`。示例和文档已相应更新。"

#: ../../source/ref-changelog.md:548
#, fuzzy
msgid ""
"**Deprecate legacy DP wrappers** "
"([#2749](https://github.com/adap/flower/pull/2749))"
msgstr "**移除过时的 KerasClient**（[#857](https://github.com/adap/flower/pull/857)）"

#: ../../source/ref-changelog.md:550
#, fuzzy
msgid ""
"Legacy DP wrapper classes are deprecated, but still functional. This is "
"in preparation for an all-new pluggable version of differential privacy "
"support in Flower."
msgstr "传统的 DP 封装类已废弃，但仍可正常使用。这是为 Flower 中的全新可插拔差分隐私支持版本做准备。"

#: ../../source/ref-changelog.md:552
#, fuzzy
msgid ""
"**Make optional arg** `--callable` **in** `flower-client` **a required "
"positional arg** ([#2673](https://github.com/adap/flower/pull/2673))"
msgstr ""
"**从** `start_client` 中移除** `rest` **实验参数 "
"([#2324](https://github.com/adap/flower/pull/2324))"

#: ../../source/ref-changelog.md:554
#, fuzzy
msgid ""
"**Rename** `certificates` **to** `root_certificates` **in** `Driver` "
"([#2890](https://github.com/adap/flower/pull/2890))"
msgstr ""
"**重新命名** `rnd` ** to** `server_round` "
"([#1321](https://github.com/adap/flower/pull/1321))"

#: ../../source/ref-changelog.md:556
#, fuzzy
msgid ""
"**Drop experimental** `Task` **fields** "
"([#2866](https://github.com/adap/flower/pull/2866), "
"[#2865](https://github.com/adap/flower/pull/2865))"
msgstr ""
"FedBN ([#2608](https://github.com/adap/flower/pull/2608), "
"[#2615](https://github.com/adap/flower/pull/2615))"

#: ../../source/ref-changelog.md:558
#, fuzzy
msgid ""
"Experimental fields `sa`, `legacy_server_message` and "
"`legacy_client_message` were removed from `Task` message. The removed "
"fields are superseded by the new `RecordSet` abstraction."
msgstr ""
"从 `Task` 消息中删除了试验性字段 `sa`、 `legacy_server_message` 和 "
"`legacy_client_message`。删除的字段已被新的 `RecordSet` 抽象所取代。"

#: ../../source/ref-changelog.md:560
#, fuzzy
msgid ""
"**Retire MXNet examples** "
"([#2724](https://github.com/adap/flower/pull/2724))"
msgstr "**新的 scikit-learn 代码示例** ([#748](https://github.com/adap/flower/pull/748))"

#: ../../source/ref-changelog.md:562
#, fuzzy
msgid ""
"The development of the MXNet fremework has ended and the project is now "
"[archived on GitHub](https://github.com/apache/mxnet). Existing MXNet "
"examples won't receive updates."
msgstr ""
"MXNet fremework 的开发工作已经结束，该项目现已[归档于 "
"GitHub](https://github.com/apache/mxnet)。现有的 MXNet 示例不会收到更新。"

#: ../../source/ref-changelog.md:564
#, fuzzy
msgid "v1.6.0 (2023-11-28)"
msgstr "v1.4.0 (2023-04-21)"

#: ../../source/ref-changelog.md:570
#, fuzzy
msgid ""
"`Aashish Kolluri`, `Adam Narozniak`, `Alessio Mora`, `Barathwaja S`, "
"`Charles Beauville`, `Daniel J. Beutel`, `Daniel Nata Nugraha`, `Gabriel "
"Mota`, `Heng Pan`, `Ivan Agarský`, `JS.KIM`, `Javier`, `Marius Schlegel`,"
" `Navin Chandra`, `Nic Lane`, `Peterpan828`, `Qinbin Li`, `Shaz-hash`, "
"`Steve Laskaridis`, `Taner Topal`, `William Lindskog`, `Yan Gao`, "
"`cnxdeveloper`, `k3nfalt` <!---TOKEN_v1.6.0-->"
msgstr ""
"`Aashish Kolluri`, `Adam Narozniak`, `Alessio Mora`, `Barathwaja S`, "
"`Charles Beauville`, `Daniel J. Beutel`, `Daniel Nata Nugraha`, `Gabriel "
"Mota`, `Heng Pan`, `Ivan Agarský`, `JS.KIM`, `Javier`, `Marius Schlegel`,"
" `Navin Chandra`, `Nic Lane`, `Peterpan828`, `Qinbin Li`, `Shaz-hash`, "
"`Steve Laskaridis`, `Taner Topal`, `William Lindskog`, `Yan Gao`, "
"`cnxdeveloper`, `k3nfalt` <!---TOKEN_v1.6.0-->"

#: ../../source/ref-changelog.md:574
msgid ""
"**Add experimental support for Python 3.12** "
"([#2565](https://github.com/adap/flower/pull/2565))"
msgstr ""
"** 增加对 Python 3.12 的实验支持** "
"([#2565](https://github.com/adap/flower/pull/2565))"

#: ../../source/ref-changelog.md:576
#, fuzzy
msgid ""
"**Add new XGBoost examples** "
"([#2612](https://github.com/adap/flower/pull/2612), "
"[#2554](https://github.com/adap/flower/pull/2554), "
"[#2617](https://github.com/adap/flower/pull/2617), "
"[#2618](https://github.com/adap/flower/pull/2618), "
"[#2619](https://github.com/adap/flower/pull/2619), "
"[#2567](https://github.com/adap/flower/pull/2567))"
msgstr ""
"**引入（试验性）Driver API** ([#1520](https://github.com/adap/flower/pull/1520),"
" [#1525](https://github.com/adap/flower/pull/1525), "
"[#1545](https://github.com/adap/flower/pull/1545), "
"[#1546](https://github.com/adap/flower/pull/1546), "
"[#1550](https://github.com/adap/flower/pull/1550), "
"[#1551](https://github.com/adap/flower/pull/1551), "
"[#1567](https://github.com/adap/flower/pull/1567))"

#: ../../source/ref-changelog.md:578
#, fuzzy
msgid ""
"We have added a new `xgboost-quickstart` example alongside a new "
"`xgboost-comprehensive` example that goes more in-depth."
msgstr ""
"我们添加了一个新的 \"xgboost-quickstart \"示例和一个新的 \"xgboost-comprehensive "
"\"示例，后者更加深入。"

#: ../../source/ref-changelog.md:580
#, fuzzy
msgid ""
"**Add Vertical FL example** "
"([#2598](https://github.com/adap/flower/pull/2598))"
msgstr "**新的 iOS CoreML 代码示例**（[#1289](https://github.com/adap/flower/pull/1289)）"

#: ../../source/ref-changelog.md:582
#, fuzzy
msgid ""
"We had many questions about Vertical Federated Learning using Flower, so "
"we decided to add an simple example for it on the [Titanic "
"dataset](https://www.kaggle.com/competitions/titanic/data) alongside a "
"tutorial (in the README)."
msgstr ""
"我们收到了许多关于使用 Flower 进行垂直联合学习的问题，因此我们决定在 [Titanic "
"数据集](https://www.kaggle.com/competitions/titanic/data) 上添加一个简单的示例，并附上教程（在"
" README 中）。"

#: ../../source/ref-changelog.md:584
msgid ""
"**Support custom** `ClientManager` **in** `start_driver()` "
"([#2292](https://github.com/adap/flower/pull/2292))"
msgstr "**在***`start_driver()`中支持自定义***`ClientManager([#2292](https://github.com/adap/flower/pull/2292))"

#: ../../source/ref-changelog.md:586
msgid ""
"**Update REST API to support create and delete nodes** "
"([#2283](https://github.com/adap/flower/pull/2283))"
msgstr ""
"**更新 REST API 以支持创建和删除节点** "
"([#2283](https://github.com/adap/flower/pull/2283))"

#: ../../source/ref-changelog.md:588
#, fuzzy
msgid ""
"**Update the Android SDK** "
"([#2187](https://github.com/adap/flower/pull/2187))"
msgstr ""
"**介绍Flower Android SDK** "
"([#2131](https://github.com/adap/flower/pull/2131))"

#: ../../source/ref-changelog.md:590
#, fuzzy
msgid "Add gRPC request-response capability to the Android SDK."
msgstr "为 C++ SDK 添加 gRPC 请求-响应功能。"

#: ../../source/ref-changelog.md:592
#, fuzzy
msgid ""
"**Update the C++ SDK** "
"([#2537](https://github.com/adap/flower/pull/2537), "
"[#2528](https://github.com/adap/flower/pull/2528), "
"[#2523](https://github.com/adap/flower/pull/2523), "
"[#2522](https://github.com/adap/flower/pull/2522))"
msgstr ""
"** 更新 C++ SDK** ([#2537](https://github/com/adap/flower/pull/2537), "
"[#2528](https://github/com/adap/flower/pull/2528), "
"[#2523](https://github.com/adap/flower/pull/2523), "
"[#2522](https://github.com/adap/flower/pull/2522))"

#: ../../source/ref-changelog.md:594
msgid "Add gRPC request-response capability to the C++ SDK."
msgstr "为 C++ SDK 添加 gRPC 请求-响应功能。"

#: ../../source/ref-changelog.md:596
#, fuzzy
msgid ""
"**Make HTTPS the new default** "
"([#2591](https://github.com/adap/flower/pull/2591), "
"[#2636](https://github.com/adap/flower/pull/2636))"
msgstr ""
"Baselines文档（[#2290](https://github.com/adap/flower/pull/2290), "
"[#2400](https://github.com/adap/flower/pull/2400)"

#: ../../source/ref-changelog.md:598
#, fuzzy
msgid ""
"Flower is moving to HTTPS by default. The new `flower-server` requires "
"passing `--certificates`, but users can enable `--insecure` to use HTTP "
"for prototyping. The same applies to `flower-client`, which can either "
"use user-provided credentials or gRPC-bundled certificates to connect to "
"an HTTPS-enabled server or requires opt-out via passing `--insecure` to "
"enable insecure HTTP connections."
msgstr ""
"Flower 默认使用 HTTPS。新的 \"flower-server \"需要通过\"--证书\"，但用户可以启用\"--不安全 \"来使用 "
"HTTP 进行原型开发。这同样适用于 `flower-client`，它可以使用用户提供的凭证或 gRPC 绑定证书连接到支持 HTTPS "
"的服务器，也可以通过传递 `--insecure`来启用不安全的 HTTP 连接。"

#: ../../source/ref-changelog.md:600
#, fuzzy
msgid ""
"For backward compatibility, `start_client()` and `start_numpy_client()` "
"will still start in insecure mode by default. In a future release, "
"insecure connections will require user opt-in by passing `insecure=True`."
msgstr ""
"为了向后兼容，`start_client()` 和 `start_numpy_client()` "
"默认仍以不安全模式启动。在未来的版本中，不安全连接将需要用户通过传递 `insecure=True` 进行选择。"

#: ../../source/ref-changelog.md:602
msgid ""
"**Unify client API** ([#2303](https://github.com/adap/flower/pull/2303), "
"[#2390](https://github.com/adap/flower/pull/2390), "
"[#2493](https://github.com/adap/flower/pull/2493))"
msgstr ""
"** 统一客户端应用程序接口** ([#2303](https://github.com/adap/flower/pull/2303), "
"[#2390](https://github.com/adap/flower/pull/2390), "
"[#2493](https://github.com/adap/flower/pull/2493))"

#: ../../source/ref-changelog.md:604
#, fuzzy
msgid ""
"Using the `client_fn`, Flower clients can interchangeably run as "
"standalone processes (i.e. via `start_client`) or in simulation (i.e. via"
" `start_simulation`) without requiring changes to how the client class is"
" defined and instantiated. The `to_client()` function is introduced to "
"convert a `NumPyClient` to a `Client`."
msgstr ""
"使用 `client_fn`，Flower 客户端可以作为独立进程（即通过 `start_client`）或在模拟中（即通过 "
"`start_simulation`）交替运行，而无需更改客户端类的定义和实例化方式。调用 `start_numpy_client` 现已过时。"

#: ../../source/ref-changelog.md:606
msgid ""
"**Add new** `Bulyan` **strategy** "
"([#1817](https://github.com/adap/flower/pull/1817), "
"[#1891](https://github.com/adap/flower/pull/1891))"
msgstr ""
"**添加新**\"Bulyan "
"\"**策略**（[#1817](https://github.com/adap/flower/pull/1817), "
"[#1891](https://github.com/adap/flower/pull/1891)"

#: ../../source/ref-changelog.md:608
msgid ""
"The new `Bulyan` strategy implements Bulyan by [El Mhamdi et al., "
"2018](https://arxiv.org/abs/1802.07927)"
msgstr "新的 \"Bulyan\"策略通过[El Mhamdi 等人，2018]（https://arxiv.org/abs/1802.07927）实现"

#: ../../source/ref-changelog.md:610
#, fuzzy
msgid ""
"**Add new** `XGB Bagging` **strategy** "
"([#2611](https://github.com/adap/flower/pull/2611))"
msgstr "**添加新的`FedProx`策略** （[#1619](https://github.com/adap/flower/pull/1619)）"

#: ../../source/ref-changelog.md:612 ../../source/ref-changelog.md:614
#, fuzzy
msgid ""
"**Introduce `WorkloadState`** "
"([#2564](https://github.com/adap/flower/pull/2564), "
"[#2632](https://github.com/adap/flower/pull/2632))"
msgstr ""
"**新的内置策略**（[#828](https://github.com/adap/flower/pull/828) "
"[#822](https://github.com/adap/flower/pull/822)"

#: ../../source/ref-changelog.md:618
msgid ""
"FedProx ([#2210](https://github.com/adap/flower/pull/2210), "
"[#2286](https://github.com/adap/flower/pull/2286), "
"[#2509](https://github.com/adap/flower/pull/2509))"
msgstr ""
"FedProx ([#2210](https://github.com/adap/flower/pull/2210), "
"[#2286](https://github.com/adap/flower/pull/2286), "
"[#2509](https://github.com/adap/flower/pull/2509))"

#: ../../source/ref-changelog.md:620
msgid ""
"Baselines Docs ([#2290](https://github.com/adap/flower/pull/2290), "
"[#2400](https://github.com/adap/flower/pull/2400))"
msgstr ""
"Baselines文档（[#2290](https://github.com/adap/flower/pull/2290), "
"[#2400](https://github.com/adap/flower/pull/2400)"

#: ../../source/ref-changelog.md:622
msgid ""
"FedMLB ([#2340](https://github.com/adap/flower/pull/2340), "
"[#2507](https://github.com/adap/flower/pull/2507))"
msgstr ""
"FedMLB ([#2340](https://github.com/adap/flower/pull/2340), "
"[#2507](https://github.com/adap/flower/pull/2507))"

#: ../../source/ref-changelog.md:624
msgid ""
"TAMUNA ([#2254](https://github.com/adap/flower/pull/2254), "
"[#2508](https://github.com/adap/flower/pull/2508))"
msgstr ""
"TAMUNA ([#2254](https://github.com/adap/flower/pull/2254), "
"[#2508](https://github.com/adap/flower/pull/2508))"

#: ../../source/ref-changelog.md:626
msgid "FedMeta [#2438](https://github.com/adap/flower/pull/2438)"
msgstr "FedMeta [#2438](https://github.com/adap/flower/pull/2438)"

#: ../../source/ref-changelog.md:628
msgid "FjORD [#2431](https://github.com/adap/flower/pull/2431)"
msgstr "FjORD [#2431](https://github.com/adap/flower/pull/2431)"

#: ../../source/ref-changelog.md:630
msgid "MOON [#2421](https://github.com/adap/flower/pull/2421)"
msgstr "MOON [#2421](https://github.com/adap/flower/pull/2421)"

#: ../../source/ref-changelog.md:632
msgid "DepthFL [#2295](https://github.com/adap/flower/pull/2295)"
msgstr "DepthFL [#2295](https://github.com/adap/flower/pull/2295)"

#: ../../source/ref-changelog.md:634
msgid "FedPer [#2266](https://github.com/adap/flower/pull/2266)"
msgstr "FedPer [#2266](https://github.com/adap/flower/pull/2266)"

#: ../../source/ref-changelog.md:636
msgid "FedWav2vec [#2551](https://github.com/adap/flower/pull/2551)"
msgstr "FedWav2vec [#2551](https://github.com/adap/flower/pull/2551)"

#: ../../source/ref-changelog.md:638
msgid "niid-Bench [#2428](https://github.com/adap/flower/pull/2428)"
msgstr "niid-Bench [#2428](https://github.com/adap/flower/pull/2428)"

#: ../../source/ref-changelog.md:640
msgid ""
"FedBN ([#2608](https://github.com/adap/flower/pull/2608), "
"[#2615](https://github.com/adap/flower/pull/2615))"
msgstr ""
"FedBN ([#2608](https://github.com/adap/flower/pull/2608), "
"[#2615](https://github.com/adap/flower/pull/2615))"

#: ../../source/ref-changelog.md:642
#, fuzzy
msgid ""
"**General updates to Flower Examples** "
"([#2384](https://github.com/adap/flower/pull/2384), "
"[#2425](https://github.com/adap/flower/pull/2425), "
"[#2526](https://github.com/adap/flower/pull/2526), "
"[#2302](https://github.com/adap/flower/pull/2302), "
"[#2545](https://github.com/adap/flower/pull/2545))"
msgstr ""
"** 更新 C++ SDK** ([#2537](https://github/com/adap/flower/pull/2537), "
"[#2528](https://github/com/adap/flower/pull/2528), "
"[#2523](https://github.com/adap/flower/pull/2523), "
"[#2522](https://github.com/adap/flower/pull/2522))"

#: ../../source/ref-changelog.md:644
#, fuzzy
msgid ""
"**General updates to Flower Baselines** "
"([#2301](https://github.com/adap/flower/pull/2301), "
"[#2305](https://github.com/adap/flower/pull/2305), "
"[#2307](https://github.com/adap/flower/pull/2307), "
"[#2327](https://github.com/adap/flower/pull/2327), "
"[#2435](https://github.com/adap/flower/pull/2435), "
"[#2462](https://github.com/adap/flower/pull/2462), "
"[#2463](https://github.com/adap/flower/pull/2463), "
"[#2461](https://github.com/adap/flower/pull/2461), "
"[#2469](https://github.com/adap/flower/pull/2469), "
"[#2466](https://github.com/adap/flower/pull/2466), "
"[#2471](https://github.com/adap/flower/pull/2471), "
"[#2472](https://github.com/adap/flower/pull/2472), "
"[#2470](https://github.com/adap/flower/pull/2470))"
msgstr ""
"**普通改进**（[#2309](https://github.com/adap/flower/pull/2309), "
"[#2310](https://github.com/adap/flower/pull/2310), "
"[2313](https://github.com/adap/flower/pull/2313), "
"[#2316](https://github.com/adap/flower/pull/2316), "
"[2317](https://github.com/adap/flower/pull/2317),[#2349](https://github.com/adap/flower/pull/2349),"
" [#2360](https://github.com/adap/flower/pull/2360), "
"[#2402](https://github.com/adap/flower/pull/2402), "
"[#2446](https://github.com/adap/flower/pull/2446) "
"[#2561](https://github.com/adap/flower/pull/2561))"

#: ../../source/ref-changelog.md:646
#, fuzzy
msgid ""
"**General updates to the simulation engine** "
"([#2331](https://github.com/adap/flower/pull/2331), "
"[#2447](https://github.com/adap/flower/pull/2447), "
"[#2448](https://github.com/adap/flower/pull/2448), "
"[#2294](https://github.com/adap/flower/pull/2294))"
msgstr ""
"**模拟引擎的普通更新** ([#2331](https://github.com/adap/flower/pull/2331), "
"[#2447](https://github.com/adap/flower/pull/2447), "
"[#2448](https://github.com/adap/flower/pull/2448))"

#: ../../source/ref-changelog.md:648
#, fuzzy
msgid ""
"**General updates to Flower SDKs** "
"([#2288](https://github.com/adap/flower/pull/2288), "
"[#2429](https://github.com/adap/flower/pull/2429), "
"[#2555](https://github.com/adap/flower/pull/2555), "
"[#2543](https://github.com/adap/flower/pull/2543), "
"[#2544](https://github.com/adap/flower/pull/2544), "
"[#2597](https://github.com/adap/flower/pull/2597), "
"[#2623](https://github.com/adap/flower/pull/2623))"
msgstr ""
"**改进教程** ([#1468](https://github.com/adap/flower/pull/1468), "
"[#1470](https://github.com/adap/flower/pull/1470), "
"[#1472](https://github.com/adap/flower/pull/1472), "
"[#1473](https://github.com/adap/flower/pull/1473), "
"[#1474](https://github.com/adap/flower/pull/1474), "
"[#1475](https://github.com/adap/flower/pull/1475)))"

#: ../../source/ref-changelog.md:650
#, fuzzy
msgid ""
"**General improvements** "
"([#2309](https://github.com/adap/flower/pull/2309), "
"[#2310](https://github.com/adap/flower/pull/2310), "
"[#2313](https://github.com/adap/flower/pull/2313), "
"[#2316](https://github.com/adap/flower/pull/2316), "
"[#2317](https://github.com/adap/flower/pull/2317), "
"[#2349](https://github.com/adap/flower/pull/2349), "
"[#2360](https://github.com/adap/flower/pull/2360), "
"[#2402](https://github.com/adap/flower/pull/2402), "
"[#2446](https://github.com/adap/flower/pull/2446), "
"[#2561](https://github.com/adap/flower/pull/2561), "
"[#2273](https://github.com/adap/flower/pull/2273), "
"[#2267](https://github.com/adap/flower/pull/2267), "
"[#2274](https://github.com/adap/flower/pull/2274), "
"[#2275](https://github.com/adap/flower/pull/2275), "
"[#2432](https://github.com/adap/flower/pull/2432), "
"[#2251](https://github.com/adap/flower/pull/2251), "
"[#2321](https://github.com/adap/flower/pull/2321), "
"[#1936](https://github.com/adap/flower/pull/1936), "
"[#2408](https://github.com/adap/flower/pull/2408), "
"[#2413](https://github.com/adap/flower/pull/2413), "
"[#2401](https://github.com/adap/flower/pull/2401), "
"[#2531](https://github.com/adap/flower/pull/2531), "
"[#2534](https://github.com/adap/flower/pull/2534), "
"[#2535](https://github.com/adap/flower/pull/2535), "
"[#2521](https://github.com/adap/flower/pull/2521), "
"[#2553](https://github.com/adap/flower/pull/2553), "
"[#2596](https://github.com/adap/flower/pull/2596))"
msgstr ""
"**一般改进** ([#2309](https://github.com/adap/flower/pull/2309), "
"[#2310](https://github.com/adap/flower/pull/2310), "
"[#2313](https://github.com/adap/flower/pull/2313), "
"[#2316](https://github.com/adap/flower/pull/2316), "
"[#2317](https://github.com/adap/flower/pull/2317), "
"[#2349](https://github.com/adap/flower/pull/2349), "
"[#2360](https://github.com/adap/flower/pull/2360), "
"[#2402](https://github.com/adap/flower/pull/2402), "
"[#2446](https://github.com/adap/flower/pull/2446), "
"[#2561](https://github.com/adap/flower/pull/2561), "
"[#2273](https://github.com/adap/flower/pull/2273), "
"[#2267](https://github.com/adap/flower/pull/2267), "
"[#2274](https://github.com/adap/flower/pull/2274), "
"[#2275](https://github.com/adap/flower/pull/2275), "
"[#2432](https://github.com/adap/flower/pull/2432), "
"[#2251](https://github.com/adap/flower/pull/2251), "
"[#2321](https://github.com/adap/flower/pull/2321), "
"[#1936](https://github.com/adap/flower/pull/1936), "
"[#2408](https://github.com/adap/flower/pull/2408), "
"[#2413](https://github.com/adap/flower/pull/2413), "
"[#2401](https://github.com/adap/flower/pull/2401), "
"[#2531](https://github.com/adap/flower/pull/2531), "
"[#2534](https://github.com/adap/flower/pull/2534), "
"[#2535](https://github.com/adap/flower/pull/2535), "
"[#2521](https://github.com/adap/flower/pull/2521), "
"[#2553](https://github.com/adap/flower/pull/2553), "
"[#2596](https://github.com/adap/flower/pull/2596))"

#: ../../source/ref-changelog.md:652 ../../source/ref-changelog.md:742
#: ../../source/ref-changelog.md:806 ../../source/ref-changelog.md:860
#: ../../source/ref-changelog.md:927
msgid "Flower received many improvements under the hood, too many to list here."
msgstr "Flower 进行了许多改进，这里就不一一列举了。"

#: ../../source/ref-changelog.md:656
msgid ""
"**Remove support for Python 3.7** "
"([#2280](https://github.com/adap/flower/pull/2280), "
"[#2299](https://github.com/adap/flower/pull/2299), "
"[#2304](https://github.com/adap/flower/pull/2304), "
"[#2306](https://github.com/adap/flower/pull/2306), "
"[#2355](https://github.com/adap/flower/pull/2355), "
"[#2356](https://github.com/adap/flower/pull/2356))"
msgstr ""
"**移除对 Python 3.7 的支持** "
"([#2280](https://github.com/adap/flower/pull/2280), "
"[#2299](https://github.com/adap/flower/pull/2299), "
"[#2304](https://github.com/adap/flower/pull/2304), "
"[#2306](https://github.com/adap/flower/pull/2306), "
"[#2355](https://github.com/adap/flower/pull/2355), "
"[#2356](https://github.com/adap/flower/pull/2356))"

#: ../../source/ref-changelog.md:658
msgid ""
"Python 3.7 support was deprecated in Flower 1.5, and this release removes"
" support. Flower now requires Python 3.8."
msgstr "在 Flower 1.5 中，Python 3.7 支持已被弃用，本版本将删除该支持。Flower 现在需要 Python 3.8。"

#: ../../source/ref-changelog.md:660
msgid ""
"**Remove experimental argument** `rest` **from** `start_client` "
"([#2324](https://github.com/adap/flower/pull/2324))"
msgstr ""
"**从** `start_client` 中移除** `rest` **实验参数 "
"([#2324](https://github.com/adap/flower/pull/2324))"

#: ../../source/ref-changelog.md:662
msgid ""
"The (still experimental) argument `rest` was removed from `start_client` "
"and `start_numpy_client`. Use `transport=\"rest\"` to opt into the "
"experimental REST API instead."
msgstr ""
"删除了 `start_client` 和 `start_numpy_client` 中的参数 `rest`（仍属试验性质）。请使用 "
"`transport=\"rest\"` 来选择使用试验性 REST API。"

#: ../../source/ref-changelog.md:664
msgid "v1.5.0 (2023-08-31)"
msgstr "v1.5.0 (2023-08-31)"

#: ../../source/ref-changelog.md:670
msgid ""
"`Adam Narozniak`, `Anass Anhari`, `Charles Beauville`, `Dana-Farber`, "
"`Daniel J. Beutel`, `Daniel Nata Nugraha`, `Edoardo Gabrielli`, `Gustavo "
"Bertoli`, `Heng Pan`, `Javier`, `Mahdi`, `Steven Hé (Sīchàng)`, `Taner "
"Topal`, `achiverram28`, `danielnugraha`, `eunchung`, `ruthgal` <!---"
"TOKEN_v1.5.0-->"
msgstr ""
"`Adam Narozniak`, `Anass Anhari`, `Charles Beauville`, `Dana-Farber`, "
"`Daniel J. Beutel`, `Daniel Nata Nugraha`, `Edoardo Gabrielli`, `Gustavo "
"Bertoli`, `Heng Pan`, `Javier`, `Mahdi`, `Steven Hé (Sīchàng)`, `Taner "
"Topal`, `achiverram28`, `danielnugraha`, `eunchung`, `ruthgal` <!---"
"TOKEN_v1.5.0-->"

#: ../../source/ref-changelog.md:674
msgid ""
"**Introduce new simulation engine** "
"([#1969](https://github.com/adap/flower/pull/1969), "
"[#2221](https://github.com/adap/flower/pull/2221), "
"[#2248](https://github.com/adap/flower/pull/2248))"
msgstr ""
"**引入新的模拟引擎** ([#1969](https://github.com/adap/flower/pull/1969), "
"[#2221](https://github.com/adap/flower/pull/2221), "
"[#2248](https://github.com/adap/flower/pull/2248))"

#: ../../source/ref-changelog.md:676
msgid ""
"The new simulation engine has been rewritten from the ground up, yet it "
"remains fully backwards compatible. It offers much improved stability and"
" memory handling, especially when working with GPUs. Simulations "
"transparently adapt to different settings to scale simulation in CPU-"
"only, CPU+GPU, multi-GPU, or multi-node multi-GPU environments."
msgstr ""
"新的模拟引擎从头开始重新编写，但仍完全向后兼容。它的稳定性和内存处理能力大大提高，尤其是在使用 GPU 时。仿真可透明地适应不同的设置，以在仅 "
"CPU、CPU+GPU、多 GPU 或多节点多 GPU 环境中扩展模拟。"

#: ../../source/ref-changelog.md:678
msgid ""
"Comprehensive documentation includes a new [how-to run "
"simulations](https://flower.ai/docs/framework/how-to-run-"
"simulations.html) guide, new [simulation-"
"pytorch](https://flower.ai/docs/examples/simulation-pytorch.html) and "
"[simulation-tensorflow](https://flower.ai/docs/examples/simulation-"
"tensorflow.html) notebooks, and a new [YouTube tutorial "
"series](https://www.youtube.com/watch?v=cRebUIGB5RU&list=PLNG4feLHqCWlnj8a_E1A_n5zr2-8pafTB)."
msgstr ""
"综合文档包括新的[how-to run simulations](https://flower.ai/docs/framework/how-to-"
"run-simulations.html) guide, new [simulation-"
"pytorch](https://flower.ai/docs/examples/simulation-pytorch.html) and "
"[simulation-tensorflow](https://flower.ai/docs/examples/simulation-"
"tensorflow.html) notebooks, and a new [YouTube tutorial "
"series](https://www.youtube.com/watch?v=cRebUIGB5RU&list=PLNG4feLHqCWlnj8a_E1A_n5zr2-8pafTB)。"

#: ../../source/ref-changelog.md:680
msgid ""
"**Restructure Flower Docs** "
"([#1824](https://github.com/adap/flower/pull/1824), "
"[#1865](https://github.com/adap/flower/pull/1865), "
"[#1884](https://github.com/adap/flower/pull/1884), "
"[#1887](https://github.com/adap/flower/pull/1887), "
"[#1919](https://github.com/adap/flower/pull/1919), "
"[#1922](https://github.com/adap/flower/pull/1922), "
"[#1920](https://github.com/adap/flower/pull/1920), "
"[#1923](https://github.com/adap/flower/pull/1923), "
"[#1924](https://github.com/adap/flower/pull/1924), "
"[#1962](https://github.com/adap/flower/pull/1962), "
"[#2006](https://github.com/adap/flower/pull/2006), "
"[#2133](https://github.com/adap/flower/pull/2133), "
"[#2203](https://github.com/adap/flower/pull/2203), "
"[#2215](https://github.com/adap/flower/pull/2215), "
"[#2122](https://github.com/adap/flower/pull/2122), "
"[#2223](https://github.com/adap/flower/pull/2223), "
"[#2219](https://github.com/adap/flower/pull/2219), "
"[#2232](https://github.com/adap/flower/pull/2232), "
"[#2233](https://github.com/adap/flower/pull/2233), "
"[#2234](https://github.com/adap/flower/pull/2234), "
"[#2235](https://github.com/adap/flower/pull/2235), "
"[#2237](https://github.com/adap/flower/pull/2237), "
"[#2238](https://github.com/adap/flower/pull/2238), "
"[#2242](https://github.com/adap/flower/pull/2242), "
"[#2231](https://github.com/adap/flower/pull/2231), "
"[#2243](https://github.com/adap/flower/pull/2243), "
"[#2227](https://github.com/adap/flower/pull/2227))"
msgstr ""
"**重构 Flower 文档** ([#1824](https://github.com/adap/flower/pull/1824), "
"[#1865](https://github.com/adap/flower/pull/1865), "
"[#1884](https://github.com/adap/flower/pull/1884), "
"[#1887](https://github.com/adap/flower/pull/1887), "
"[#1919](https://github.com/adap/flower/pull/1919), "
"[#1922](https://github.com/adap/flower/pull/1922), "
"[#1920](https://github.com/adap/flower/pull/1920), "
"[#1923](https://github.com/adap/flower/pull/1923), "
"[#1924](https://github.com/adap/flower/pull/1924), "
"[#1962](https://github.com/adap/flower/pull/1962), "
"[#2006](https://github.com/adap/flower/pull/2006), "
"[#2133](https://github.com/adap/flower/pull/2133), "
"[#2203](https://github.com/adap/flower/pull/2203), "
"[#2215](https://github.com/adap/flower/pull/2215), "
"[#2122](https://github.com/adap/flower/pull/2122), "
"[#2223](https://github.com/adap/flower/pull/2223), "
"[#2219](https://github.com/adap/flower/pull/2219), "
"[#2232](https://github.com/adap/flower/pull/2232), "
"[#2233](https://github.com/adap/flower/pull/2233), "
"[#2234](https://github.com/adap/flower/pull/2234), "
"[#2235](https://github.com/adap/flower/pull/2235), "
"[#2237](https://github.com/adap/flower/pull/2237), "
"[#2238](https://github.com/adap/flower/pull/2238), "
"[#2242](https://github.com/adap/flower/pull/2242), "
"[#2231](https://github.com/adap/flower/pull/2231), "
"[#2243](https://github.com/adap/flower/pull/2243), "
"[#2227](https://github.com/adap/flower/pull/2227))"

#: ../../source/ref-changelog.md:682
#, fuzzy
msgid ""
"Much effort went into a completely restructured Flower docs experience. "
"The documentation on [flower.ai/docs](https://flower.ai/docs) is now "
"divided into Flower Framework, Flower Baselines, Flower Android SDK, "
"Flower iOS SDK, and code example projects."
msgstr ""
"Flower 文档体验的全面重构耗费了大量精力。现在，[flower.ai/docs](flower.ai/docs)上的文档分为 Flower "
"Framework、Flower Baselines、Flower Android SDK、Flower iOS SDK 和代码示例项目。"

#: ../../source/ref-changelog.md:684
msgid ""
"**Introduce Flower Swift SDK** "
"([#1858](https://github.com/adap/flower/pull/1858), "
"[#1897](https://github.com/adap/flower/pull/1897))"
msgstr ""
"**介绍 Flower Swift SDK** "
"([#1858](https://github.com/adap/flower/pull/1858), "
"[#1897](https://github.com/adap/flower/pull/1897))"

#: ../../source/ref-changelog.md:686
msgid ""
"This is the first preview release of the Flower Swift SDK. Flower support"
" on iOS is improving, and alongside the Swift SDK and code example, there"
" is now also an iOS quickstart tutorial."
msgstr ""
"这是 Flower Swift SDK 的首个预览版。Flower 对 iOS 的支持正在不断改进，除了 Swift SDK "
"和代码示例外，现在还有 iOS 快速入门教程。"

#: ../../source/ref-changelog.md:688
msgid ""
"**Introduce Flower Android SDK** "
"([#2131](https://github.com/adap/flower/pull/2131))"
msgstr ""
"**介绍Flower Android SDK** "
"([#2131](https://github.com/adap/flower/pull/2131))"

#: ../../source/ref-changelog.md:690
msgid ""
"This is the first preview release of the Flower Kotlin SDK. Flower "
"support on Android is improving, and alongside the Kotlin SDK and code "
"example, there is now also an Android quickstart tutorial."
msgstr ""
"这是 Flower Kotlin SDK 的首个预览版。Flower 对 Android 的支持正在不断改进，除了 Kotlin SDK "
"和代码示例，现在还有 Android 快速入门教程。"

#: ../../source/ref-changelog.md:692
msgid ""
"**Introduce new end-to-end testing infrastructure** "
"([#1842](https://github.com/adap/flower/pull/1842), "
"[#2071](https://github.com/adap/flower/pull/2071), "
"[#2072](https://github.com/adap/flower/pull/2072), "
"[#2068](https://github.com/adap/flower/pull/2068), "
"[#2067](https://github.com/adap/flower/pull/2067), "
"[#2069](https://github.com/adap/flower/pull/2069), "
"[#2073](https://github.com/adap/flower/pull/2073), "
"[#2070](https://github.com/adap/flower/pull/2070), "
"[#2074](https://github.com/adap/flower/pull/2074), "
"[#2082](https://github.com/adap/flower/pull/2082), "
"[#2084](https://github.com/adap/flower/pull/2084), "
"[#2093](https://github.com/adap/flower/pull/2093), "
"[#2109](https://github.com/adap/flower/pull/2109), "
"[#2095](https://github.com/adap/flower/pull/2095), "
"[#2140](https://github.com/adap/flower/pull/2140), "
"[#2137](https://github.com/adap/flower/pull/2137), "
"[#2165](https://github.com/adap/flower/pull/2165))"
msgstr ""
"*介绍新的端到端测试** ([#1842](https://github.com/adap/flower/pull/1842), "
"[#2071](https://github.com/adap/flower/pull/2071), "
"[#2072](https://github.com/adap/flower/pull/2072), "
"[#2068](https://github.com/adap/flower/pull/2068), "
"[#2067](https://github.com/adap/flower/pull/2067), "
"[#2069](https://github.com/adap/flower/pull/2069), "
"[#2073](https://github.com/adap/flower/pull/2073), "
"[#2070](https://github.com/adap/flower/pull/2070), "
"[#2074](https://github.com/adap/flower/pull/2074), "
"[#2082](https://github.com/adap/flower/pull/2082), "
"[#2084](https://github.com/adap/flower/pull/2084), "
"[#2093](https://github.com/adap/flower/pull/2093), "
"[#2109](https://github.com/adap/flower/pull/2109), "
"[#2095](https://github.com/adap/flower/pull/2095), "
"[#2140](https://github.com/adap/flower/pull/2140), "
"[#2137](https://github.com/adap/flower/pull/2137), "
"[#2165](https://github.com/adap/flower/pull/2165))"

#: ../../source/ref-changelog.md:694
msgid ""
"A new testing infrastructure ensures that new changes stay compatible "
"with existing framework integrations or strategies."
msgstr "新的测试设施可确保新的变更与现有的框架集成或策略保持兼容。"

#: ../../source/ref-changelog.md:696
msgid "**Deprecate Python 3.7**"
msgstr "** 过时的 Python 3.7**"

#: ../../source/ref-changelog.md:698
msgid ""
"Since Python 3.7 reached its end of life (EOL) on 2023-06-27, support for"
" Python 3.7 is now deprecated and will be removed in an upcoming release."
msgstr "由于 Python 3.7 已于 2023-06-27 弃用 (EOL)，对 Python 3.7 的支持现已废弃，并将在即将发布的版本中移除。"

#: ../../source/ref-changelog.md:700
msgid ""
"**Add new** `FedTrimmedAvg` **strategy** "
"([#1769](https://github.com/adap/flower/pull/1769), "
"[#1853](https://github.com/adap/flower/pull/1853))"
msgstr ""
"**添加新的**`FedTrimmedAvg`**策略**（[#1769](https://github.com/adap/flower/pull/1769),"
" [#1853](https://github.com/adap/flower/pull/1853)"

#: ../../source/ref-changelog.md:702
msgid ""
"The new `FedTrimmedAvg` strategy implements Trimmed Mean by [Dong Yin, "
"2018](https://arxiv.org/abs/1803.01498)."
msgstr ""
"新的 \"FedTrimmedAvg \"策略实现了[Dong Yin, "
"2018]（https://arxiv.org/abs/1803.01498）的 \"Trimmed Mean\"。"

#: ../../source/ref-changelog.md:704
msgid ""
"**Introduce start_driver** "
"([#1697](https://github.com/adap/flower/pull/1697))"
msgstr "**引入 start_driver**（[#1697](https://github.com/adap/flower/pull/1697)）"

#: ../../source/ref-changelog.md:706
msgid ""
"In addition to `start_server` and using the raw Driver API, there is a "
"new `start_driver` function that allows for running `start_server` "
"scripts as a Flower driver with only a single-line code change. Check out"
" the `mt-pytorch` code example to see a working example using "
"`start_driver`."
msgstr ""
"除了 `start_server` 和使用原始驱动 API 之外，还有一个新的 `start_driver` 函数，只需修改一行代码，就能将 "
"`start_server` 脚本作为 Flower 驱动程序运行。请查看 `mt-pytorch` 代码示例，了解使用 "
"`start_driver` 的工作示例。"

#: ../../source/ref-changelog.md:708
msgid ""
"**Add parameter aggregation to** `mt-pytorch` **code example** "
"([#1785](https://github.com/adap/flower/pull/1785))"
msgstr ""
"为 `mt-pytorch` **代码示例**添加参数聚合 "
"([#1785](https://github.com/adap/flower/pull/1785))"

#: ../../source/ref-changelog.md:710
msgid ""
"The `mt-pytorch` example shows how to aggregate parameters when writing a"
" driver script. The included `driver.py` and `server.py` have been "
"aligned to demonstrate both the low-level way and the high-level way of "
"building server-side logic."
msgstr ""
"`mt-pytorch`示例展示了如何在编写驱动程序脚本时聚合参数。附带的 `driver.py` 和 `server.py` "
"已经进行了调整，以演示构建服务器端逻辑的低级方法和高级方法。"

#: ../../source/ref-changelog.md:712
msgid ""
"**Migrate experimental REST API to Starlette** "
"([2171](https://github.com/adap/flower/pull/2171))"
msgstr ""
"**将实验性 REST API 移植到 Starlette** "
"([2171](https://github.com/adap/flower/pull/2171))"

#: ../../source/ref-changelog.md:714
msgid ""
"The (experimental) REST API used to be implemented in "
"[FastAPI](https://fastapi.tiangolo.com/), but it has now been migrated to"
" use [Starlette](https://www.starlette.io/) directly."
msgstr ""
"REST API（试验性）曾在 [FastAPI](https://fastapi.tiangolo.com/) 中实现，但现在已迁移到直接使用 "
"[Starlette](https://www.starlette.io/) 。"

#: ../../source/ref-changelog.md:716
msgid ""
"Please note: The REST request-response API is still experimental and will"
" likely change significantly over time."
msgstr "请注意：REST 请求-响应 API 仍处于试验阶段，随着时间的推移可能会发生重大变化。"

#: ../../source/ref-changelog.md:718
msgid ""
"**Introduce experimental gRPC request-response API** "
"([#1867](https://github.com/adap/flower/pull/1867), "
"[#1901](https://github.com/adap/flower/pull/1901))"
msgstr ""
"**引入实验性 gRPC 请求-响应 API** "
"（[#1867](https://github.com/adap/flower/pull/1867), "
"[#1901](https://github.com/adap/flower/pull/1901)"

#: ../../source/ref-changelog.md:720
msgid ""
"In addition to the existing gRPC API (based on bidirectional streaming) "
"and the experimental REST API, there is now a new gRPC API that uses a "
"request-response model to communicate with client nodes."
msgstr ""
"除了现有的 gRPC 应用程序接口（基于双向流）和试验性 REST 应用程序接口外，现在还有一个新的 gRPC "
"应用程序接口，它使用请求-响应模型与客户端节点通信。"

#: ../../source/ref-changelog.md:722
msgid ""
"Please note: The gRPC request-response API is still experimental and will"
" likely change significantly over time."
msgstr "请注意：gRPC 请求-响应 API 仍处于试验阶段，随着时间的推移可能会发生重大变化。"

#: ../../source/ref-changelog.md:724
msgid ""
"**Replace the experimental** `start_client(rest=True)` **with the new** "
"`start_client(transport=\"rest\")` "
"([#1880](https://github.com/adap/flower/pull/1880))"
msgstr ""
"**用新的** `start_client(transport=\"rest\")` 替换实验性** "
"`start_client(rest=True)` "
"([#1880](https://github.com/adap/flower/pull/1880))"

#: ../../source/ref-changelog.md:726
msgid ""
"The (experimental) `start_client` argument `rest` was deprecated in "
"favour of a new argument `transport`. `start_client(transport=\"rest\")` "
"will yield the same behaviour as `start_client(rest=True)` did before. "
"All code should migrate to the new argument `transport`. The deprecated "
"argument `rest` will be removed in a future release."
msgstr ""
"已废弃（试验性的）`start_client`参数`rest`，改用新参数`transport`。`start_client(transport=\"rest\")`将产生与以前的`start_client(rest=True)`相同的行为。所有代码都应迁移到新参数"
" `transport`。过时的参数 `rest` 将在今后的版本中删除。"

#: ../../source/ref-changelog.md:728
msgid ""
"**Add a new gRPC option** "
"([#2197](https://github.com/adap/flower/pull/2197))"
msgstr "** 添加一个新的 gRPC 选项**（[#2197](https://github.com/adap/flower/pull/2197)）"

#: ../../source/ref-changelog.md:730
msgid ""
"We now start a gRPC server with the `grpc.keepalive_permit_without_calls`"
" option set to 0 by default. This prevents the clients from sending "
"keepalive pings when there is no outstanding stream."
msgstr ""
"现在我们启动一个 gRPC 服务器，并将 `grpc.keepalive_permit_without_calls` 选项默认设置为 "
"0。这将防止客户端在没有未处理数据流时发送 keepalive pings。"

#: ../../source/ref-changelog.md:732
msgid ""
"**Improve example notebooks** "
"([#2005](https://github.com/adap/flower/pull/2005))"
msgstr "**改进示例笔记** ([#2005](https://github.com/adap/flower/pull/2005))"

#: ../../source/ref-changelog.md:734
msgid "There's a new 30min Federated Learning PyTorch tutorial!"
msgstr "有一个新的 30 分钟的联邦学习 PyTorch 教程！"

#: ../../source/ref-changelog.md:736
msgid ""
"**Example updates** ([#1772](https://github.com/adap/flower/pull/1772), "
"[#1873](https://github.com/adap/flower/pull/1873), "
"[#1981](https://github.com/adap/flower/pull/1981), "
"[#1988](https://github.com/adap/flower/pull/1988), "
"[#1984](https://github.com/adap/flower/pull/1984), "
"[#1982](https://github.com/adap/flower/pull/1982), "
"[#2112](https://github.com/adap/flower/pull/2112), "
"[#2144](https://github.com/adap/flower/pull/2144), "
"[#2174](https://github.com/adap/flower/pull/2174), "
"[#2225](https://github.com/adap/flower/pull/2225), "
"[#2183](https://github.com/adap/flower/pull/2183))"
msgstr ""
"**更新Example** ([#1772](https://github.com/adap/flower/pull/1772), "
"[#1873](https://github.com/adap/flower/pull/1873), "
"[#1981](https://github.com/adap/flower/pull/1981), "
"[#1988](https://github.com/adap/flower/pull/1988), "
"[#1984](https://github.com/adap/flower/pull/1984), "
"[#1982](https://github.com/adap/flower/pull/1982), "
"[#2112](https://github.com/adap/flower/pull/2112), "
"[#2144](https://github.com/adap/flower/pull/2144), "
"[#2174](https://github.com/adap/flower/pull/2174), "
"[#2225](https://github.com/adap/flower/pull/2225), "
"[#2183](https://github.com/adap/flower/pull/2183))"

#: ../../source/ref-changelog.md:738
msgid ""
"Many examples have received significant updates, including simplified "
"advanced-tensorflow and advanced-pytorch examples, improved macOS "
"compatibility of TensorFlow examples, and code examples for simulation. A"
" major upgrade is that all code examples now have a `requirements.txt` "
"(in addition to `pyproject.toml`)."
msgstr ""
"许多示例都进行了重大更新，包括简化了 advanced-tensorflow 和 advanced-pytorch 示例，改进了 "
"TensorFlow 示例的 macOS 兼容性，以及模拟代码示例。一项重大升级是所有代码示例现在都有了 "
"\"requirements.txt\"（除 \"pyproject.toml \"外）。"

#: ../../source/ref-changelog.md:740
msgid ""
"**General improvements** "
"([#1872](https://github.com/adap/flower/pull/1872), "
"[#1866](https://github.com/adap/flower/pull/1866), "
"[#1884](https://github.com/adap/flower/pull/1884), "
"[#1837](https://github.com/adap/flower/pull/1837), "
"[#1477](https://github.com/adap/flower/pull/1477), "
"[#2171](https://github.com/adap/flower/pull/2171))"
msgstr ""
"**普通改进**（[#1872](https://github.com/adap/flower/pull/1872), "
"[#1866](https://github.com/adap/flower/pull/1866), "
"[#1884](https://github.com/adap/flower/pull/1884), "
"[#1837](https://github.com/adap/flower/pull/1837), "
"[#1477](https://github.com/adap/flower/pull/1477), "
"[#2171](https://github.com/adap/flower/pull/2171))"

#: ../../source/ref-changelog.md:748
msgid "v1.4.0 (2023-04-21)"
msgstr "v1.4.0 (2023-04-21)"

#: ../../source/ref-changelog.md:754
msgid ""
"`Adam Narozniak`, `Alexander Viala Bellander`, `Charles Beauville`, "
"`Chenyang Ma (Danny)`, `Daniel J. Beutel`, `Edoardo`, `Gautam Jajoo`, "
"`Iacob-Alexandru-Andrei`, `JDRanpariya`, `Jean Charle Yaacoub`, `Kunal "
"Sarkhel`, `L. Jiang`, `Lennart Behme`, `Max Kapsecker`, `Michał`, `Nic "
"Lane`, `Nikolaos Episkopos`, `Ragy`, `Saurav Maheshkar`, `Semo Yang`, "
"`Steve Laskaridis`, `Steven Hé (Sīchàng)`, `Taner Topal`"
msgstr ""
"`Adam Narozniak`, `Alexander Viala Bellander`, `Charles Beauville`, "
"`Chenyang Ma (Danny)`, `Daniel J. Beutel`, `Edoardo`, `Gautam Jajoo`, "
"`Iacob-Alexandru-Andrei`, `JDRanpariya`, `Jean Charle Yaacoub`, `Kunal "
"Sarkhel`, `L. Jiang`, `Lennart Behme`, `Max Kapsecker`, `Michał`, `Nic "
"Lane`, `Nikolaos Episkopos`, `Ragy`, `Saurav Maheshkar`, `Semo Yang`, "
"`Steve Laskaridis`, `Steven Hé (Sīchàng)`, `Taner Topal`"

#: ../../source/ref-changelog.md:758
msgid ""
"**Introduce support for XGBoost (**`FedXgbNnAvg` **strategy and "
"example)** ([#1694](https://github.com/adap/flower/pull/1694), "
"[#1709](https://github.com/adap/flower/pull/1709), "
"[#1715](https://github.com/adap/flower/pull/1715), "
"[#1717](https://github.com/adap/flower/pull/1717), "
"[#1763](https://github.com/adap/flower/pull/1763), "
"[#1795](https://github.com/adap/flower/pull/1795))"
msgstr ""
"**引入对XGBoost的支持（**`FedXgbNnAvg` **策略和示例）** "
"([#1694](https://github.com/adap/flower/pull/1694), "
"[#1709](https://github.com/adap/flower/pull/1709), "
"[#1715](https://github.com/adap/flower/pull/1715), "
"[#1717](https://github.com/adap/flower/pull/1717), "
"[#1763](https://github.com/adap/flower/pull/1763), "
"[#1795](https://github.com/adap/flower/pull/1795))"

#: ../../source/ref-changelog.md:760
msgid ""
"XGBoost is a tree-based ensemble machine learning algorithm that uses "
"gradient boosting to improve model accuracy. We added a new `FedXgbNnAvg`"
" "
"[strategy](https://github.com/adap/flower/tree/main/src/py/flwr/server/strategy/fedxgb_nn_avg.py),"
" and a [code example](https://github.com/adap/flower/tree/main/examples"
"/xgboost-quickstart) that demonstrates the usage of this new strategy in "
"an XGBoost project."
msgstr ""
"XGBoost 是一种基于树的集合机器学习算法，它使用梯度提升来提高模型的准确性。我们添加了一个新的 "
"\"FedXgbNnAvg\"[策略](https://github.com/adap/flower/tree/main/src/py/flwr/server/strategy/fedxgb_nn_avg.py)和一个[代码示例](https://github.com/adap/flower/tree/main/examples"
"/xgboost-quickstart)，演示如何在 XGBoost 项目中使用这个新策略。"

#: ../../source/ref-changelog.md:762
msgid ""
"**Introduce iOS SDK (preview)** "
"([#1621](https://github.com/adap/flower/pull/1621), "
"[#1764](https://github.com/adap/flower/pull/1764))"
msgstr ""
"**介绍 iOS SDK（预览版）** ([#1621](https://github.com/adap/flower/pull/1621), "
"[#1764](https://github.com/adap/flower/pull/1764))"

#: ../../source/ref-changelog.md:764
msgid ""
"This is a major update for anyone wanting to implement Federated Learning"
" on iOS mobile devices. We now have a swift iOS SDK present under "
"[src/swift/flwr](https://github.com/adap/flower/tree/main/src/swift/flwr)"
" that will facilitate greatly the app creating process. To showcase its "
"use, the [iOS "
"example](https://github.com/adap/flower/tree/main/examples/ios) has also "
"been updated!"
msgstr ""
"对于想要在 iOS 移动设备上实施联邦学习的人来说，这是一次重大更新。现在，我们在 "
"[src/swift/flwr](https://github.com/adap/flower/tree/main/src/swift/flwr)"
" 下提供了一个迅捷的 iOS SDK，这将大大方便应用程序的创建过程。为了展示其使用情况，我们还更新了 [iOS "
"示例](https://github.com/adap/flower/tree/main/examples/ios)！"

#: ../../source/ref-changelog.md:766
msgid ""
"**Introduce new \"What is Federated Learning?\" tutorial** "
"([#1657](https://github.com/adap/flower/pull/1657), "
"[#1721](https://github.com/adap/flower/pull/1721))"
msgstr ""
"**引入新的 "
"\"什么是联邦学习？\"教程**（[#1657](https://github.com/adap/flower/pull/1657), "
"[#1721](https://github.com/adap/flower/pull/1721)"

#: ../../source/ref-changelog.md:768
msgid ""
"A new [entry-level tutorial](https://flower.ai/docs/framework/tutorial-"
"what-is-federated-learning.html) in our documentation explains the basics"
" of Fedetated Learning. It enables anyone who's unfamiliar with Federated"
" Learning to start their journey with Flower. Forward it to anyone who's "
"interested in Federated Learning!"
msgstr ""
"我们的文档中新增了一个[入门级教程](https://flower.ai/docs/framework/tutorial-what-is-"
"federated-learning.html)，解释了联邦学习的基础知识。它让任何不熟悉联邦学习的人都能开始 Flower "
"之旅。请转发给对联邦学习感兴趣的人！"

#: ../../source/ref-changelog.md:770
msgid ""
"**Introduce new Flower Baseline: FedProx MNIST** "
"([#1513](https://github.com/adap/flower/pull/1513), "
"[#1680](https://github.com/adap/flower/pull/1680), "
"[#1681](https://github.com/adap/flower/pull/1681), "
"[#1679](https://github.com/adap/flower/pull/1679))"
msgstr ""
"**引入新的 Flower Baseline： FedProx MNIST** "
"（[#1513](https://github.com/adap/flower/pull/1513), "
"[#1680](https://github.com/adap/flower/pull/1680), "
"[#1681](https://github.com/adap/flower/pull/1681), "
"[#1679](https://github.com/adap/flower/pull/1679)"

#: ../../source/ref-changelog.md:772
msgid ""
"This new baseline replicates the MNIST+CNN task from the paper [Federated"
" Optimization in Heterogeneous Networks (Li et al., "
"2018)](https://arxiv.org/abs/1812.06127). It uses the `FedProx` strategy,"
" which aims at making convergence more robust in heterogeneous settings."
msgstr ""
"这条新Baseline复现了论文[Federated Optimization in Heterogeneous Networks (Li et "
"al., 2018)](https://arxiv.org/abs/1812.06127)中的 MNIST+CNN 任务。它使用 "
"\"FedProx \"策略，旨在使收敛在异构环境中更加稳健。"

#: ../../source/ref-changelog.md:774
msgid ""
"**Introduce new Flower Baseline: FedAvg FEMNIST** "
"([#1655](https://github.com/adap/flower/pull/1655))"
msgstr ""
"**引入新的 Flower Baseline： FedAvg FEMNIST** "
"([#1655](https://github.com/adap/flower/pull/1655))"

#: ../../source/ref-changelog.md:776
msgid ""
"This new baseline replicates an experiment evaluating the performance of "
"the FedAvg algorithm on the FEMNIST dataset from the paper [LEAF: A "
"Benchmark for Federated Settings (Caldas et al., "
"2018)](https://arxiv.org/abs/1812.01097)."
msgstr ""
"这一新Baseline复现了论文[LEAF: A Benchmark for Federated Settings（Caldas 等人，2018 "
"年）](https://arxiv.org/abs/1812.01097)中评估 FedAvg 算法在 FEMNIST 数据集上性能的实验。"

#: ../../source/ref-changelog.md:778
msgid ""
"**Introduce (experimental) REST API** "
"([#1594](https://github.com/adap/flower/pull/1594), "
"[#1690](https://github.com/adap/flower/pull/1690), "
"[#1695](https://github.com/adap/flower/pull/1695), "
"[#1712](https://github.com/adap/flower/pull/1712), "
"[#1802](https://github.com/adap/flower/pull/1802), "
"[#1770](https://github.com/adap/flower/pull/1770), "
"[#1733](https://github.com/adap/flower/pull/1733))"
msgstr ""
"**引入（试验性）REST API** ([#1594](https://github.com/adap/flower/pull/1594), "
"[#1690](https://github.com/adap/flower/pull/1690), "
"[#1695](https://github.com/adap/flower/pull/1695), "
"[#1712](https://github.com/adap/flower/pull/1712), "
"[#1802](https://github.com/adap/flower/pull/1802), "
"[#1770](https://github.com/adap/flower/pull/1770), "
"[#1733](https://github.com/adap/flower/pull/1733))"

#: ../../source/ref-changelog.md:780
msgid ""
"A new REST API has been introduced as an alternative to the gRPC-based "
"communication stack. In this initial version, the REST API only supports "
"anonymous clients."
msgstr "作为基于 gRPC 的通信栈的替代方案，我们引入了新的 REST API。在初始版本中，REST API 仅支持匿名客户端。"

#: ../../source/ref-changelog.md:782
msgid ""
"Please note: The REST API is still experimental and will likely change "
"significantly over time."
msgstr "请注意：REST API 仍处于试验阶段，随着时间的推移可能会发生重大变化。"

#: ../../source/ref-changelog.md:784
msgid ""
"**Improve the (experimental) Driver API** "
"([#1663](https://github.com/adap/flower/pull/1663), "
"[#1666](https://github.com/adap/flower/pull/1666), "
"[#1667](https://github.com/adap/flower/pull/1667), "
"[#1664](https://github.com/adap/flower/pull/1664), "
"[#1675](https://github.com/adap/flower/pull/1675), "
"[#1676](https://github.com/adap/flower/pull/1676), "
"[#1693](https://github.com/adap/flower/pull/1693), "
"[#1662](https://github.com/adap/flower/pull/1662), "
"[#1794](https://github.com/adap/flower/pull/1794))"
msgstr ""
"**改进（试验性）驱动程序应用程序接口** ([#1663](https://github.com/adap/flower/pull/1663),"
" [#1666](https://github.com/adap/flower/pull/1666), "
"[#1667](https://github.com/adap/flower/pull/1667), "
"[#1664](https://github.com/adap/flower/pull/1664), "
"[#1675](https://github.com/adap/flower/pull/1675), "
"[#1676](https://github.com/adap/flower/pull/1676), "
"[#1693](https://github.com/adap/flower/pull/1693), "
"[#1662](https://github.com/adap/flower/pull/1662), "
"[#1794](https://github.com/adap/flower/pull/1794))"

#: ../../source/ref-changelog.md:786
msgid ""
"The Driver API is still an experimental feature, but this release "
"introduces some major upgrades. One of the main improvements is the "
"introduction of an SQLite database to store server state on disk (instead"
" of in-memory). Another improvement is that tasks (instructions or "
"results) that have been delivered will now be deleted. This greatly "
"improves the memory efficiency of a long-running Flower server."
msgstr ""
"驱动程序应用程序接口（Driver API）仍是一项试验性功能，但这一版本引入了一些重大升级。主要改进之一是引入了 SQLite "
"数据库，将服务器状态存储在磁盘上（而不是内存中）。另一项改进是，已交付的任务（指令或结果）现在将被删除。这大大提高了长期运行的 Flower "
"服务器的内存效率。"

#: ../../source/ref-changelog.md:788
msgid ""
"**Fix spilling issues related to Ray during simulations** "
"([#1698](https://github.com/adap/flower/pull/1698))"
msgstr "**修复模拟过程中与Ray有关的溢出问题** ([#1698](https://github.com/adap/flower/pull/1698))"

#: ../../source/ref-changelog.md:790
msgid ""
"While running long simulations, `ray` was sometimes spilling huge amounts"
" of data that would make the training unable to continue. This is now "
"fixed! 🎉"
msgstr "在运行长时间模拟时，`ray` 有时会溢出大量数据，导致训练无法继续。现在这个问题已经解决！🎉"

#: ../../source/ref-changelog.md:792
msgid ""
"**Add new example using** `TabNet` **and Flower** "
"([#1725](https://github.com/adap/flower/pull/1725))"
msgstr ""
"** 添加使用** `TabNet` ** 的新示例** "
"([#1725](https://github.com/adap/flower/pull/1725))"

#: ../../source/ref-changelog.md:794
msgid ""
"TabNet is a powerful and flexible framework for training machine learning"
" models on tabular data. We now have a federated example using Flower: "
"[quickstart-tabnet](https://github.com/adap/flower/tree/main/examples"
"/quickstart-tabnet)."
msgstr ""
"TabNet 是一个强大而灵活的框架，用于在表格数据上训练机器学习模型。我们现在有一个使用 Flower 的联邦示例：[quickstart-"
"tabnet](https://github.com/adap/flower/tree/main/examples/quickstart-"
"tabnet)。"

#: ../../source/ref-changelog.md:796
msgid ""
"**Add new how-to guide for monitoring simulations** "
"([#1649](https://github.com/adap/flower/pull/1649))"
msgstr "** 添加新的模拟监控指南** ([#1649](https://github.com/adap/flower/pull/1649))"

#: ../../source/ref-changelog.md:798
msgid ""
"We now have a documentation guide to help users monitor their performance"
" during simulations."
msgstr "我们现在有一份文档指南，可帮助用户在模拟过程中监控其性能。"

#: ../../source/ref-changelog.md:800
msgid ""
"**Add training metrics to** `History` **object during simulations** "
"([#1696](https://github.com/adap/flower/pull/1696))"
msgstr ""
"**在模拟过程中为***`历史`***对象添加训练指标*** "
"([#1696](https://github.com/adap/flower/pull/1696))"

#: ../../source/ref-changelog.md:802
msgid ""
"The `fit_metrics_aggregation_fn` can be used to aggregate training "
"metrics, but previous releases did not save the results in the `History` "
"object. This is now the case!"
msgstr ""
"`fit_metrics_aggregation_fn`可用于汇总训练指标，但以前的版本不会将结果保存在 \"History "
"\"对象中。现在可以了！"

#: ../../source/ref-changelog.md:804
msgid ""
"**General improvements** "
"([#1659](https://github.com/adap/flower/pull/1659), "
"[#1646](https://github.com/adap/flower/pull/1646), "
"[#1647](https://github.com/adap/flower/pull/1647), "
"[#1471](https://github.com/adap/flower/pull/1471), "
"[#1648](https://github.com/adap/flower/pull/1648), "
"[#1651](https://github.com/adap/flower/pull/1651), "
"[#1652](https://github.com/adap/flower/pull/1652), "
"[#1653](https://github.com/adap/flower/pull/1653), "
"[#1659](https://github.com/adap/flower/pull/1659), "
"[#1665](https://github.com/adap/flower/pull/1665), "
"[#1670](https://github.com/adap/flower/pull/1670), "
"[#1672](https://github.com/adap/flower/pull/1672), "
"[#1677](https://github.com/adap/flower/pull/1677), "
"[#1684](https://github.com/adap/flower/pull/1684), "
"[#1683](https://github.com/adap/flower/pull/1683), "
"[#1686](https://github.com/adap/flower/pull/1686), "
"[#1682](https://github.com/adap/flower/pull/1682), "
"[#1685](https://github.com/adap/flower/pull/1685), "
"[#1692](https://github.com/adap/flower/pull/1692), "
"[#1705](https://github.com/adap/flower/pull/1705), "
"[#1708](https://github.com/adap/flower/pull/1708), "
"[#1711](https://github.com/adap/flower/pull/1711), "
"[#1713](https://github.com/adap/flower/pull/1713), "
"[#1714](https://github.com/adap/flower/pull/1714), "
"[#1718](https://github.com/adap/flower/pull/1718), "
"[#1716](https://github.com/adap/flower/pull/1716), "
"[#1723](https://github.com/adap/flower/pull/1723), "
"[#1735](https://github.com/adap/flower/pull/1735), "
"[#1678](https://github.com/adap/flower/pull/1678), "
"[#1750](https://github.com/adap/flower/pull/1750), "
"[#1753](https://github.com/adap/flower/pull/1753), "
"[#1736](https://github.com/adap/flower/pull/1736), "
"[#1766](https://github.com/adap/flower/pull/1766), "
"[#1760](https://github.com/adap/flower/pull/1760), "
"[#1775](https://github.com/adap/flower/pull/1775), "
"[#1776](https://github.com/adap/flower/pull/1776), "
"[#1777](https://github.com/adap/flower/pull/1777), "
"[#1779](https://github.com/adap/flower/pull/1779), "
"[#1784](https://github.com/adap/flower/pull/1784), "
"[#1773](https://github.com/adap/flower/pull/1773), "
"[#1755](https://github.com/adap/flower/pull/1755), "
"[#1789](https://github.com/adap/flower/pull/1789), "
"[#1788](https://github.com/adap/flower/pull/1788), "
"[#1798](https://github.com/adap/flower/pull/1798), "
"[#1799](https://github.com/adap/flower/pull/1799), "
"[#1739](https://github.com/adap/flower/pull/1739), "
"[#1800](https://github.com/adap/flower/pull/1800), "
"[#1804](https://github.com/adap/flower/pull/1804), "
"[#1805](https://github.com/adap/flower/pull/1805))"
msgstr ""
"**普通改进** ([#1659](https://github.com/adap/flower/pull/1659), "
"[#1646](https://github.com/adap/flower/pull/1646), "
"[#1647](https://github.com/adap/flower/pull/1647), "
"[#1471](https://github.com/adap/flower/pull/1471), "
"[#1648](https://github.com/adap/flower/pull/1648), "
"[#1651](https://github.com/adap/flower/pull/1651), "
"[#1652](https://github.com/adap/flower/pull/1652), "
"[#1653](https://github.com/adap/flower/pull/1653), "
"[#1659](https://github.com/adap/flower/pull/1659), "
"[#1665](https://github.com/adap/flower/pull/1665), "
"[#1670](https://github.com/adap/flower/pull/1670), "
"[#1672](https://github.com/adap/flower/pull/1672), "
"[#1677](https://github.com/adap/flower/pull/1677), "
"[#1684](https://github.com/adap/flower/pull/1684), "
"[#1683](https://github.com/adap/flower/pull/1683), "
"[#1686](https://github.com/adap/flower/pull/1686), "
"[#1682](https://github.com/adap/flower/pull/1682), "
"[#1685](https://github.com/adap/flower/pull/1685), "
"[#1692](https://github.com/adap/flower/pull/1692), "
"[#1705](https://github.com/adap/flower/pull/1705), "
"[#1708](https://github.com/adap/flower/pull/1708), "
"[#1711](https://github.com/adap/flower/pull/1711), "
"[#1713](https://github.com/adap/flower/pull/1713), "
"[#1714](https://github.com/adap/flower/pull/1714), "
"[#1718](https://github.com/adap/flower/pull/1718), "
"[#1716](https://github.com/adap/flower/pull/1716), "
"[#1723](https://github.com/adap/flower/pull/1723), "
"[#1735](https://github.com/adap/flower/pull/1735), "
"[#1678](https://github.com/adap/flower/pull/1678), "
"[#1750](https://github.com/adap/flower/pull/1750), "
"[#1753](https://github.com/adap/flower/pull/1753), "
"[#1736](https://github.com/adap/flower/pull/1736), "
"[#1766](https://github.com/adap/flower/pull/1766), "
"[#1760](https://github.com/adap/flower/pull/1760), "
"[#1775](https://github.com/adap/flower/pull/1775), "
"[#1776](https://github.com/adap/flower/pull/1776), "
"[#1777](https://github.com/adap/flower/pull/1777), "
"[#1779](https://github.com/adap/flower/pull/1779), "
"[#1784](https://github.com/adap/flower/pull/1784), "
"[#1773](https://github.com/adap/flower/pull/1773), "
"[#1755](https://github.com/adap/flower/pull/1755), "
"[#1789](https://github.com/adap/flower/pull/1789), "
"[#1788](https://github.com/adap/flower/pull/1788), "
"[#1798](https://github.com/adap/flower/pull/1798), "
"[#1799](https://github.com/adap/flower/pull/1799), "
"[#1739](https://github.com/adap/flower/pull/1739), "
"[#1800](https://github.com/adap/flower/pull/1800), "
"[#1804](https://github.com/adap/flower/pull/1804), "
"[#1805](https://github.com/adap/flower/pull/1805))"

#: ../../source/ref-changelog.md:812
msgid "v1.3.0 (2023-02-06)"
msgstr "v1.3.0 (2023-02-06)"

#: ../../source/ref-changelog.md:818
msgid ""
"`Adam Narozniak`, `Alexander Viala Bellander`, `Charles Beauville`, "
"`Daniel J. Beutel`, `JDRanpariya`, `Lennart Behme`, `Taner Topal`"
msgstr ""
"`Adam Narozniak`, `Alexander Viala Bellander`, `Charles Beauville`, "
"`Daniel J. Beutel`, `JDRanpariya`, `Lennart Behme`, `Taner Topal`"

#: ../../source/ref-changelog.md:822
msgid ""
"**Add support for** `workload_id` **and** `group_id` **in Driver API** "
"([#1595](https://github.com/adap/flower/pull/1595))"
msgstr ""
"**在驱动程序应用程序接口中添加对** `workload_id` **和** `group_id` **的支持** "
"([#1595](https://github.com/adap/flower/pull/1595))"

#: ../../source/ref-changelog.md:824
msgid ""
"The (experimental) Driver API now supports a `workload_id` that can be "
"used to identify which workload a task belongs to. It also supports a new"
" `group_id` that can be used, for example, to indicate the current "
"training round. Both the `workload_id` and `group_id` enable client nodes"
" to decide whether they want to handle a task or not."
msgstr ""
"驱动程序 API（试验性）现在支持 `workload_id`，可用于识别任务所属的工作量。它还支持新的 "
"`group_id`，例如，可用于指示当前的训练轮次。通过 `workload_id` 和 `group_id` "
"客户端节点可以决定是否要处理某个任务。"

#: ../../source/ref-changelog.md:826
msgid ""
"**Make Driver API and Fleet API address configurable** "
"([#1637](https://github.com/adap/flower/pull/1637))"
msgstr ""
"**使Driver API 和Fleet "
"API地址可配置**（[#1637](https://github.com/adap/flower/pull/1637)）"

#: ../../source/ref-changelog.md:828
msgid ""
"The (experimental) long-running Flower server (Driver API and Fleet API) "
"can now configure the server address of both Driver API (via `--driver-"
"api-address`) and Fleet API (via `--fleet-api-address`) when starting:"
msgstr ""
"长期运行的 Flower 服务器（Driver API 和 Fleet API）现在可以在启动时配置 Driver API（通过 "
"`--driver-api-address`）和 Fleet API（通过 `-fleet-api-address`）的服务器地址："

#: ../../source/ref-changelog.md:830
#, fuzzy
msgid ""
"`flower-server --driver-api-address \"0.0.0.0:8081\" --fleet-api-address "
"\"0.0.0.0:8086\"`"
msgstr ""
"`flower-server --driver-api-address \"0.0.0.0:8081\" --fleet-api-address "
"\"0.0.0.0:8086\"`"

#: ../../source/ref-changelog.md:832
msgid "Both IPv4 and IPv6 addresses are supported."
msgstr "支持 IPv4 和 IPv6 地址。"

#: ../../source/ref-changelog.md:834
msgid ""
"**Add new example of Federated Learning using fastai and Flower** "
"([#1598](https://github.com/adap/flower/pull/1598))"
msgstr ""
"** 添加使用 fastai 和 Flower 进行联邦学习的新示例** "
"([#1598](https://github.com/adap/flower/pull/1598))"

#: ../../source/ref-changelog.md:836
msgid ""
"A new code example (`quickstart-fastai`) demonstrates federated learning "
"with [fastai](https://www.fast.ai/) and Flower. You can find it here: "
"[quickstart-fastai](https://github.com/adap/flower/tree/main/examples"
"/quickstart-fastai)."
msgstr ""
"一个新的代码示例（`quickstart-fastai`）演示了使用 [fastai](https://www.fast.ai/) 和 "
"Flower 的联邦学习。您可以在这里找到它： [quickstart-"
"fastai](https://github.com/adap/flower/tree/main/examples/quickstart-"
"fastai)。"

#: ../../source/ref-changelog.md:838
msgid ""
"**Make Android example compatible with** `flwr >= 1.0.0` **and the latest"
" versions of Android** "
"([#1603](https://github.com/adap/flower/pull/1603))"
msgstr ""
"**使安卓示例兼容** `flwr >= 1.0.0` **和最新版本的安卓** "
"([#1603](https://github.com/adap/flower/pull/1603))"

#: ../../source/ref-changelog.md:840
msgid ""
"The Android code example has received a substantial update: the project "
"is compatible with Flower 1.0 (and later), the UI received a full "
"refresh, and the project is updated to be compatible with newer Android "
"tooling."
msgstr ""
"Android 代码示例已进行了大幅更新：项目兼容 Flower 1.0（及更高版本），用户界面已全面刷新，项目已更新为兼容较新的 Android"
" 工具。"

#: ../../source/ref-changelog.md:842
msgid ""
"**Add new `FedProx` strategy** "
"([#1619](https://github.com/adap/flower/pull/1619))"
msgstr "**添加新的`FedProx`策略** （[#1619](https://github.com/adap/flower/pull/1619)）"

#: ../../source/ref-changelog.md:844
msgid ""
"This "
"[strategy](https://github.com/adap/flower/blob/main/src/py/flwr/server/strategy/fedprox.py)"
" is almost identical to "
"[`FedAvg`](https://github.com/adap/flower/blob/main/src/py/flwr/server/strategy/fedavg.py),"
" but helps users replicate what is described in this "
"[paper](https://arxiv.org/abs/1812.06127). It essentially adds a "
"parameter called `proximal_mu` to regularize the local models with "
"respect to the global models."
msgstr ""
"该[策略](https://github.com/adap/flower/blob/main/src/py/flwr/server/strategy/fedprox.py)与[`FedAvg`](https://github.com/adap/flower/blob/main/src/py/flwr/server/strategy/fedavg.py)几乎相同，但可以帮助用户复现本[论文](https://arxiv.org/abs/1812.06127)中的描述。它的本质是添加一个名为"
" `proximal_mu`的参数，使局部模型与全局模型正则化。"

#: ../../source/ref-changelog.md:846
msgid ""
"**Add new metrics to telemetry events** "
"([#1640](https://github.com/adap/flower/pull/1640))"
msgstr "**为遥测事件添加新指标**（[#1640](https://github.com/adap/flower/pull/1640)）"

#: ../../source/ref-changelog.md:848
msgid ""
"An updated event structure allows, for example, the clustering of events "
"within the same workload."
msgstr "例如，更新后的事件结构可以将同一工作负载中的事件集中在一起。"

#: ../../source/ref-changelog.md:850
msgid ""
"**Add new custom strategy tutorial section** "
"[#1623](https://github.com/adap/flower/pull/1623)"
msgstr "**添加新的自定义策略教程部分** [#1623](https://github.com/adap/flower/pull/1623)"

#: ../../source/ref-changelog.md:852
msgid ""
"The Flower tutorial now has a new section that covers implementing a "
"custom strategy from scratch: [Open in "
"Colab](https://colab.research.google.com/github/adap/flower/blob/main/doc/source"
"/tutorial-build-a-strategy-from-scratch-pytorch.ipynb)"
msgstr ""
"Flower 教程新增了一个章节，介绍如何从零开始实施自定义策略： [在 Colab "
"中打开](https://colab.research.google.com/github/adap/flower/blob/main/doc/source"
"/tutorial-build-a-strategy-from-scratch-pytorch.ipynb)"

#: ../../source/ref-changelog.md:854
msgid ""
"**Add new custom serialization tutorial section** "
"([#1622](https://github.com/adap/flower/pull/1622))"
msgstr "** 添加新的自定义序列化教程部分** ([#1622](https://github.com/adap/flower/pull/1622))"

#: ../../source/ref-changelog.md:856
msgid ""
"The Flower tutorial now has a new section that covers custom "
"serialization: [Open in "
"Colab](https://colab.research.google.com/github/adap/flower/blob/main/doc/source"
"/tutorial-customize-the-client-pytorch.ipynb)"
msgstr ""
"Flower 教程现在新增了一个章节，介绍自定义序列化： [在 Colab "
"中打开](https://colab.research.google.com/github/adap/flower/blob/main/doc/source"
"/tutorial-customize-the-client-pytorch.ipynb)"

#: ../../source/ref-changelog.md:858
msgid ""
"**General improvements** "
"([#1638](https://github.com/adap/flower/pull/1638), "
"[#1634](https://github.com/adap/flower/pull/1634), "
"[#1636](https://github.com/adap/flower/pull/1636), "
"[#1635](https://github.com/adap/flower/pull/1635), "
"[#1633](https://github.com/adap/flower/pull/1633), "
"[#1632](https://github.com/adap/flower/pull/1632), "
"[#1631](https://github.com/adap/flower/pull/1631), "
"[#1630](https://github.com/adap/flower/pull/1630), "
"[#1627](https://github.com/adap/flower/pull/1627), "
"[#1593](https://github.com/adap/flower/pull/1593), "
"[#1616](https://github.com/adap/flower/pull/1616), "
"[#1615](https://github.com/adap/flower/pull/1615), "
"[#1607](https://github.com/adap/flower/pull/1607), "
"[#1609](https://github.com/adap/flower/pull/1609), "
"[#1608](https://github.com/adap/flower/pull/1608), "
"[#1603](https://github.com/adap/flower/pull/1603), "
"[#1590](https://github.com/adap/flower/pull/1590), "
"[#1580](https://github.com/adap/flower/pull/1580), "
"[#1599](https://github.com/adap/flower/pull/1599), "
"[#1600](https://github.com/adap/flower/pull/1600), "
"[#1601](https://github.com/adap/flower/pull/1601), "
"[#1597](https://github.com/adap/flower/pull/1597), "
"[#1595](https://github.com/adap/flower/pull/1595), "
"[#1591](https://github.com/adap/flower/pull/1591), "
"[#1588](https://github.com/adap/flower/pull/1588), "
"[#1589](https://github.com/adap/flower/pull/1589), "
"[#1587](https://github.com/adap/flower/pull/1587), "
"[#1573](https://github.com/adap/flower/pull/1573), "
"[#1581](https://github.com/adap/flower/pull/1581), "
"[#1578](https://github.com/adap/flower/pull/1578), "
"[#1574](https://github.com/adap/flower/pull/1574), "
"[#1572](https://github.com/adap/flower/pull/1572), "
"[#1586](https://github.com/adap/flower/pull/1586))"
msgstr ""
"**普通改进** ([#1638](https://github.com/adap/flower/pull/1638), "
"[#1634](https://github.com/adap/flower/pull/1634), "
"[#1636](https://github.com/adap/flower/pull/1636), "
"[#1635](https://github.com/adap/flower/pull/1635), "
"[#1633](https://github.com/adap/flower/pull/1633), "
"[#1632](https://github.com/adap/flower/pull/1632), "
"[#1631](https://github.com/adap/flower/pull/1631), "
"[#1630](https://github.com/adap/flower/pull/1630), "
"[#1627](https://github. com/adap/flower/pull/1627), "
"[#1593](https://github.com/adap/flower/pull/1593), "
"[#1616](https://github.com/adap/flower/pull/1616), "
"[#1615](https://github.com/adap/flower/pull/1615), "
"[#1607](https://github.com/adap/flower/pull/1607), "
"[#1609](https://github.com/adap/flower/pull/1609), "
"[#1608](https://github.com/adap/flower/pull/1608), "
"[#1603](https://github.com/adap/flower/pull/1603), "
"[#1590](https://github. com/adap/flower/pull/1590), "
"[#1580](https://github.com/adap/flower/pull/1580), "
"[#1599](https://github.com/adap/flower/pull/1599), "
"[#1600](https://github.com/adap/flower/pull/1600), "
"[#1601](https://github.com/adap/flower/pull/1601), "
"[#1597](https://github.com/adap/flower/pull/1597), "
"[#1595](https://github.com/adap/flower/pull/1595), "
"[#1591](https://github.com/adap/flower/pull/1591), "
"[#1588](https://github. com/adap/flower/pull/1588), "
"[#1589](https://github.com/adap/flower/pull/1589), "
"[#1587](https://github.com/adap/flower/pull/1587), "
"[#1573](https://github.com/adap/flower/pull/1573), "
"[#1581](https://github.com/adap/flower/pull/1581), "
"[#1578](https://github.com/adap/flower/pull/1578), "
"[#1574](https://github.com/adap/flower/pull/1574), "
"[#1572](https://github.com/adap/flower/pull/1572), "
"[#1586](https://github.com/adap/flower/pull/1586))"

#: ../../source/ref-changelog.md:862
msgid ""
"**Updated documentation** "
"([#1629](https://github.com/adap/flower/pull/1629), "
"[#1628](https://github.com/adap/flower/pull/1628), "
"[#1620](https://github.com/adap/flower/pull/1620), "
"[#1618](https://github.com/adap/flower/pull/1618), "
"[#1617](https://github.com/adap/flower/pull/1617), "
"[#1613](https://github.com/adap/flower/pull/1613), "
"[#1614](https://github.com/adap/flower/pull/1614))"
msgstr ""
"** 更新文档** ([#1629](https://github.com/adap/flower/pull/1629), "
"[#1628](https://github.com/adap/flower/pull/1628), "
"[#1620](https://github.com/adap/flower/pull/1620), "
"[#1618](https://github.com/adap/flower/pull/1618), "
"[#1617](https://github.com/adap/flower/pull/1617), "
"[#1613](https://github.com/adap/flower/pull/1613), "
"[#1614](https://github.com/adap/flower/pull/1614)))"

#: ../../source/ref-changelog.md:864 ../../source/ref-changelog.md:931
msgid ""
"As usual, the documentation has improved quite a bit. It is another step "
"in our effort to make the Flower documentation the best documentation of "
"any project. Stay tuned and as always, feel free to provide feedback!"
msgstr "和往常一样，我们的文档有了很大的改进。这是我们努力使 Flower 文档成为所有项目中最好文档的又一步骤。请继续关注，并随时提供反馈意见！"

#: ../../source/ref-changelog.md:870
msgid "v1.2.0 (2023-01-13)"
msgstr "v1.2.0 (2023-01-13)"

#: ../../source/ref-changelog.md:876
msgid ""
"`Adam Narozniak`, `Charles Beauville`, `Daniel J. Beutel`, `Edoardo`, `L."
" Jiang`, `Ragy`, `Taner Topal`, `dannymcy`"
msgstr ""
"`Adam Narozniak`, `Charles Beauville`, `Daniel J. Beutel`, `Edoardo`, `L."
" Jiang`, `Ragy`, `Taner Topal`, `dannymcy`"

#: ../../source/ref-changelog.md:880
msgid ""
"**Introduce new Flower Baseline: FedAvg MNIST** "
"([#1497](https://github.com/adap/flower/pull/1497), "
"[#1552](https://github.com/adap/flower/pull/1552))"
msgstr ""
"**引入新的 Flower Baseline： FedAvg MNIST** "
"([#1497](https://github.com/adap/flower/pull/1497), "
"[#1552](https://github.com/adap/flower/pull/1552))"

#: ../../source/ref-changelog.md:882
msgid ""
"Over the coming weeks, we will be releasing a number of new reference "
"implementations useful especially to FL newcomers. They will typically "
"revisit well known papers from the literature, and be suitable for "
"integration in your own application or for experimentation, in order to "
"deepen your knowledge of FL in general. Today's release is the first in "
"this series. [Read more.](https://flower.ai/blog/2023-01-12-fl-starter-"
"pack-fedavg-mnist-cnn/)"
msgstr ""
"在未来几周内，我们将发布一些新的参考，特别是对 FL "
"新手有用的方法。它们通常会重温文献中的知名论文，适合集成到您自己的应用程序中或用于实验，以加深您对 FL "
"的总体了解。今天发布的是该系列中的第一篇。[阅读全文](https://flower.ai/blog/2023-01-12-fl-starter-"
"pack-fedavg-mnist-cnn/)"

#: ../../source/ref-changelog.md:884
msgid ""
"**Improve GPU support in simulations** "
"([#1555](https://github.com/adap/flower/pull/1555))"
msgstr "**改进模拟中的 GPU 支持**（[#1555](https://github.com/adap/flower/pull/1555)）"

#: ../../source/ref-changelog.md:886
msgid ""
"The Ray-based Virtual Client Engine (`start_simulation`) has been updated"
" to improve GPU support. The update includes some of the hard-earned "
"lessons from scaling simulations in GPU cluster environments. New "
"defaults make running GPU-based simulations substantially more robust."
msgstr ""
"基于 Ray 的虚拟客户端引擎 (`start_simulation`)已更新，以改进对 GPU 的支持。此次更新包含了在 GPU "
"集群环境中扩展模拟的一些经验教训。新的默认设置使基于 GPU 的模拟运行更加稳健。"

#: ../../source/ref-changelog.md:888
msgid ""
"**Improve GPU support in Jupyter Notebook tutorials** "
"([#1527](https://github.com/adap/flower/pull/1527), "
"[#1558](https://github.com/adap/flower/pull/1558))"
msgstr ""
"**改进 Jupyter Notebook 教程中的 GPU 支持** "
"([#1527](https://github.com/adap/flower/pull/1527), "
"[#1558](https://github.com/adap/flower/pull/1558))"

#: ../../source/ref-changelog.md:890
msgid ""
"Some users reported that Jupyter Notebooks have not always been easy to "
"use on GPU instances. We listened and made improvements to all of our "
"Jupyter notebooks! Check out the updated notebooks here:"
msgstr ""
"一些用户报告说，在 GPU 实例上使用 Jupyter 笔记本并不是很方便。我们听取了他们的意见，并对所有 Jupyter "
"笔记本进行了改进！点击这里查看更新后的笔记本："

#: ../../source/ref-changelog.md:892
msgid ""
"[An Introduction to Federated Learning](https://flower.ai/docs/framework"
"/tutorial-get-started-with-flower-pytorch.html)"
msgstr ""
"[联邦学习简介](https://flower.ai/docs/framework/tutorial-get-started-with-"
"flower-pytorch.html)"

#: ../../source/ref-changelog.md:893
msgid ""
"[Strategies in Federated Learning](https://flower.ai/docs/framework"
"/tutorial-use-a-federated-learning-strategy-pytorch.html)"
msgstr ""
"[联邦学习策略](https://flower.ai/docs/framework/tutorial-use-a-federated-"
"learning-strategy-pytorch.html)"

#: ../../source/ref-changelog.md:894
msgid ""
"[Building a Strategy](https://flower.ai/docs/framework/tutorial-build-a"
"-strategy-from-scratch-pytorch.html)"
msgstr ""
"[制定策略](https://flower.ai/docs/framework/tutorial-build-a-strategy-from-"
"scratch-pytorch.html)"

#: ../../source/ref-changelog.md:895
msgid ""
"[Client and NumPyClient](https://flower.ai/docs/framework/tutorial-"
"customize-the-client-pytorch.html)"
msgstr ""
"[客户端和 NumPyClient](https://flower.ai/docs/framework/tutorial-customize-"
"the-client-pytorch.html)"

#: ../../source/ref-changelog.md:897
msgid ""
"**Introduce optional telemetry** "
"([#1533](https://github.com/adap/flower/pull/1533), "
"[#1544](https://github.com/adap/flower/pull/1544), "
"[#1584](https://github.com/adap/flower/pull/1584))"
msgstr ""
"**引入可选遥测**（[#1533](https://github.com/adap/flower/pull/1533), "
"[#1544](https://github.com/adap/flower/pull/1544), "
"[#1584](https://github.com/adap/flower/pull/1584)"

#: ../../source/ref-changelog.md:899
msgid ""
"After a [request for "
"feedback](https://github.com/adap/flower/issues/1534) from the community,"
" the Flower open-source project introduces optional collection of "
"*anonymous* usage metrics to make well-informed decisions to improve "
"Flower. Doing this enables the Flower team to understand how Flower is "
"used and what challenges users might face."
msgstr ""
"在社区发出[反馈请求](https://github.com/adap/flower/issues/1534)之后，Flower "
"开放源码项目引入了可选的*匿名*使用指标收集，以便在充分知情的情况下做出改进 Flower 的决定。这样做能让 Flower 团队了解 "
"Flower 的使用情况以及用户可能面临的挑战。"

#: ../../source/ref-changelog.md:901
msgid ""
"**Flower is a friendly framework for collaborative AI and data science.**"
" Staying true to this statement, Flower makes it easy to disable "
"telemetry for users who do not want to share anonymous usage metrics. "
"[Read more.](https://flower.ai/docs/telemetry.html)."
msgstr ""
"**Flower 是一个用于协作式人工智能和数据科学的友好框架。** Flower "
"遵循这一声明，让不想分享匿名使用指标的用户可以轻松禁用遥测技术。[阅读全文](https://flower.ai/docs/telemetry.html)。"

#: ../../source/ref-changelog.md:903
msgid ""
"**Introduce (experimental) Driver API** "
"([#1520](https://github.com/adap/flower/pull/1520), "
"[#1525](https://github.com/adap/flower/pull/1525), "
"[#1545](https://github.com/adap/flower/pull/1545), "
"[#1546](https://github.com/adap/flower/pull/1546), "
"[#1550](https://github.com/adap/flower/pull/1550), "
"[#1551](https://github.com/adap/flower/pull/1551), "
"[#1567](https://github.com/adap/flower/pull/1567))"
msgstr ""
"**引入（试验性）Driver API** ([#1520](https://github.com/adap/flower/pull/1520),"
" [#1525](https://github.com/adap/flower/pull/1525), "
"[#1545](https://github.com/adap/flower/pull/1545), "
"[#1546](https://github.com/adap/flower/pull/1546), "
"[#1550](https://github.com/adap/flower/pull/1550), "
"[#1551](https://github.com/adap/flower/pull/1551), "
"[#1567](https://github.com/adap/flower/pull/1567))"

#: ../../source/ref-changelog.md:905
msgid ""
"Flower now has a new (experimental) Driver API which will enable fully "
"programmable, async, and multi-tenant Federated Learning and Federated "
"Analytics applications. Phew, that's a lot! Going forward, the Driver API"
" will be the abstraction that many upcoming features will be built on - "
"and you can start building those things now, too."
msgstr ""
"Flower 现在有了一个新的（试验性的）驱动程序应用程序接口（Driver "
"API），它将支持完全可编程、异步和多租户的联邦学习（Federated Learning）和联邦分析（Federated "
"Analytics）应用程序。展望未来，Driver API 将成为许多即将推出的功能的抽象基础，您现在就可以开始构建这些功能。"

#: ../../source/ref-changelog.md:907
msgid ""
"The Driver API also enables a new execution mode in which the server runs"
" indefinitely. Multiple individual workloads can run concurrently and "
"start and stop their execution independent of the server. This is "
"especially useful for users who want to deploy Flower in production."
msgstr ""
"驱动程序应用程序接口还支持一种新的执行模式，在这种模式下，服务器可无限期运行。多个单独的工作负载可以同时运行，并独立于服务器启动和停止执行。这对于希望在生产中部署"
" Flower 的用户来说尤其有用。"

#: ../../source/ref-changelog.md:909
msgid ""
"To learn more, check out the `mt-pytorch` code example. We look forward "
"to you feedback!"
msgstr "要了解更多信息，请查看 `mt-pytorch` 代码示例。我们期待您的反馈！"

#: ../../source/ref-changelog.md:911
msgid ""
"Please note: *The Driver API is still experimental and will likely change"
" significantly over time.*"
msgstr "请注意：Driver API仍处于试验阶段，随着时间的推移可能会发生重大变化。*"

#: ../../source/ref-changelog.md:913
msgid ""
"**Add new Federated Analytics with Pandas example** "
"([#1469](https://github.com/adap/flower/pull/1469), "
"[#1535](https://github.com/adap/flower/pull/1535))"
msgstr ""
"** 添加新的使用 Pandas "
"的联邦分析示例**（[#1469](https://github.com/adap/flower/pull/1469), "
"[#1535](https://github.com/adap/flower/pull/1535)"

#: ../../source/ref-changelog.md:915
msgid ""
"A new code example (`quickstart-pandas`) demonstrates federated analytics"
" with Pandas and Flower. You can find it here: [quickstart-"
"pandas](https://github.com/adap/flower/tree/main/examples/quickstart-"
"pandas)."
msgstr ""
"新代码示例（`quickstart-pandas`）演示了使用 Pandas 和 Flower 进行联邦分析。您可以在此处找到它： "
"[quickstart-pandas](https://github.com/adap/flower/tree/main/examples"
"/quickstart-pandas)。"

#: ../../source/ref-changelog.md:917
msgid ""
"**Add new strategies: Krum and MultiKrum** "
"([#1481](https://github.com/adap/flower/pull/1481))"
msgstr ""
"**添加新策略： Krum 和 MultiKrum** "
"([#1481](https://github.com/adap/flower/pull/1481))"

#: ../../source/ref-changelog.md:919
msgid ""
"Edoardo, a computer science student at the Sapienza University of Rome, "
"contributed a new `Krum` strategy that enables users to easily use Krum "
"and MultiKrum in their workloads."
msgstr ""
"罗马萨皮恩扎大学（Sapienza University）计算机科学专业的学生埃多尔多（Edoardo）提出了一种新的 \"Krum "
"\"策略，使用户能够在其工作负载中轻松使用 Krum 和 MultiKrum。"

#: ../../source/ref-changelog.md:921
msgid ""
"**Update C++ example to be compatible with Flower v1.2.0** "
"([#1495](https://github.com/adap/flower/pull/1495))"
msgstr ""
"** 更新 C++ 示例，与 Flower v1.2.0 兼容** "
"([#1495](https://github.com/adap/flower/pull/1495))"

#: ../../source/ref-changelog.md:923
msgid ""
"The C++ code example has received a substantial update to make it "
"compatible with the latest version of Flower."
msgstr "为了与最新版本的 Flower 兼容，C++ 示例代码进行了大幅更新。"

#: ../../source/ref-changelog.md:925
msgid ""
"**General improvements** "
"([#1491](https://github.com/adap/flower/pull/1491), "
"[#1504](https://github.com/adap/flower/pull/1504), "
"[#1506](https://github.com/adap/flower/pull/1506), "
"[#1514](https://github.com/adap/flower/pull/1514), "
"[#1522](https://github.com/adap/flower/pull/1522), "
"[#1523](https://github.com/adap/flower/pull/1523), "
"[#1526](https://github.com/adap/flower/pull/1526), "
"[#1528](https://github.com/adap/flower/pull/1528), "
"[#1547](https://github.com/adap/flower/pull/1547), "
"[#1549](https://github.com/adap/flower/pull/1549), "
"[#1560](https://github.com/adap/flower/pull/1560), "
"[#1564](https://github.com/adap/flower/pull/1564), "
"[#1566](https://github.com/adap/flower/pull/1566))"
msgstr ""
"**普通改进** ([#1491](https://github.com/adap/flower/pull/1491), "
"[#1504](https://github.com/adap/flower/pull/1504), "
"[#1506](https://github.com/adap/flower/pull/1506), "
"[#1514](https://github.com/adap/flower/pull/1514), "
"[#1522](https://github.com/adap/flower/pull/1522), "
"[#1523](https://github.com/adap/flower/pull/1523), "
"[#1526](https://github. com/adap/flower/pull/1526), "
"[#1528](https://github.com/adap/flower/pull/1528), "
"[#1547](https://github.com/adap/flower/pull/1547), "
"[#1549](https://github.com/adap/flower/pull/1549), "
"[#1560](https://github.com/adap/flower/pull/1560), "
"[#1564](https://github.com/adap/flower/pull/1564), "
"[#1566](https://github.com/adap/flower/pull/1566))"

#: ../../source/ref-changelog.md:929
msgid ""
"**Updated documentation** "
"([#1494](https://github.com/adap/flower/pull/1494), "
"[#1496](https://github.com/adap/flower/pull/1496), "
"[#1500](https://github.com/adap/flower/pull/1500), "
"[#1503](https://github.com/adap/flower/pull/1503), "
"[#1505](https://github.com/adap/flower/pull/1505), "
"[#1524](https://github.com/adap/flower/pull/1524), "
"[#1518](https://github.com/adap/flower/pull/1518), "
"[#1519](https://github.com/adap/flower/pull/1519), "
"[#1515](https://github.com/adap/flower/pull/1515))"
msgstr ""
"** 更新文档** ([#1494](https://github.com/adap/flower/pull/1494), "
"[#1496](https://github.com/adap/flower/pull/1496), "
"[#1500](https://github.com/adap/flower/pull/1500), "
"[#1503](https://github.com/adap/flower/pull/1503), "
"[#1505](https://github.com/adap/flower/pull/1505), "
"[#1524](https://github.com/adap/flower/pull/1524), "
"[#1518](https://github.com/adap/flower/pull/1518), "
"[#1519](https://github.com/adap/flower/pull/1519), "
"[#1515](https://github.com/adap/flower/pull/1515))"

#: ../../source/ref-changelog.md:933
msgid ""
"One highlight is the new [first time contributor "
"guide](https://flower.ai/docs/first-time-contributors.html): if you've "
"never contributed on GitHub before, this is the perfect place to start!"
msgstr ""
"其中一个亮点是新的[首次贡献者指南](https://flower.ai/docs/first-time-"
"contributors.html)：如果你以前从未在 GitHub 上做过贡献，这将是一个完美的开始！"

#: ../../source/ref-changelog.md:939
msgid "v1.1.0 (2022-10-31)"
msgstr "v1.1.0 (2022-10-31)"

#: ../../source/ref-changelog.md:943
msgid ""
"We would like to give our **special thanks** to all the contributors who "
"made the new version of Flower possible (in `git shortlog` order):"
msgstr "在此，我们向所有促成 Flower 新版本的贡献者致以**特别的谢意（按 \"git shortlog \"顺序排列）："

#: ../../source/ref-changelog.md:945
msgid ""
"`Akis Linardos`, `Christopher S`, `Daniel J. Beutel`, `George`, `Jan "
"Schlicht`, `Mohammad Fares`, `Pedro Porto Buarque de Gusmão`, `Philipp "
"Wiesner`, `Rob Luke`, `Taner Topal`, `VasundharaAgarwal`, "
"`danielnugraha`, `edogab33`"
msgstr ""
"`Akis Linardos`, `Christopher S`, `Daniel J. Beutel`, `George`, `Jan "
"Schlicht`, `Mohammad Fares`, `Pedro Porto Buarque de Gusmão`, `Philipp "
"Wiesner`, `Rob Luke`, `Taner Topal`, `VasundharaAgarwal`, "
"`danielnugraha`, `edogab33`"

#: ../../source/ref-changelog.md:949
msgid ""
"**Introduce Differential Privacy wrappers (preview)** "
"([#1357](https://github.com/adap/flower/pull/1357), "
"[#1460](https://github.com/adap/flower/pull/1460))"
msgstr ""
"**引入差分隐私包装器（预览）** ([#1357](https://github.com/adap/flower/pull/1357), "
"[#1460](https://github.com/adap/flower/pull/1460))"

#: ../../source/ref-changelog.md:951
msgid ""
"The first (experimental) preview of pluggable Differential Privacy "
"wrappers enables easy configuration and usage of differential privacy "
"(DP). The pluggable DP wrappers enable framework-agnostic **and** "
"strategy-agnostic usage of both client-side DP and server-side DP. Head "
"over to the Flower docs, a new explainer goes into more detail."
msgstr ""
"可插拔差分隐私封装器的首个（实验性）预览版可轻松配置和使用差分隐私（DP）。可插拔的差分隐私封装器可实现客户端差分隐私和服务器端差分隐私的框架无关**以及**策略无关的使用。请访问"
" Flower 文档，新的解释器会提供更多细节。"

#: ../../source/ref-changelog.md:953
msgid ""
"**New iOS CoreML code example** "
"([#1289](https://github.com/adap/flower/pull/1289))"
msgstr "**新的 iOS CoreML 代码示例**（[#1289](https://github.com/adap/flower/pull/1289)）"

#: ../../source/ref-changelog.md:955
msgid ""
"Flower goes iOS! A massive new code example shows how Flower clients can "
"be built for iOS. The code example contains both Flower iOS SDK "
"components that can be used for many tasks, and one task example running "
"on CoreML."
msgstr ""
"Flower 进入 iOS！大量新代码示例展示了如何为 iOS 构建 Flower 客户端。该代码示例包含可用于多种任务的 Flower iOS "
"SDK 组件，以及在 CoreML 上运行的一个任务示例。"

#: ../../source/ref-changelog.md:957
msgid ""
"**New FedMedian strategy** "
"([#1461](https://github.com/adap/flower/pull/1461))"
msgstr "**新的联邦医疗策略** ([#1461](https://github.com/adap/flower/pull/1461))"

#: ../../source/ref-changelog.md:959
msgid ""
"The new `FedMedian` strategy implements Federated Median (FedMedian) by "
"[Yin et al., 2018](https://arxiv.org/pdf/1803.01498v1.pdf)."
msgstr ""
"新的 \"FedMedian \"战略实现了[Yin "
"等人，2018]的联邦中值（FedMedian）(https://arxiv.org/pdf/1803.01498v1.pdf)。"

#: ../../source/ref-changelog.md:961
msgid ""
"**Log** `Client` **exceptions in Virtual Client Engine** "
"([#1493](https://github.com/adap/flower/pull/1493))"
msgstr "**虚拟客户端引擎中的**日志**`客户端`**异常（[#1493](https://github.com/adap/flower/pull/1493)）"

#: ../../source/ref-changelog.md:963
msgid ""
"All `Client` exceptions happening in the VCE are now logged by default "
"and not just exposed to the configured `Strategy` (via the `failures` "
"argument)."
msgstr "VCE 中发生的所有 \"客户端 \"异常现在都会被默认记录下来，而不只是暴露给配置的 `Strategy`（通过 `failures`参数）。"

#: ../../source/ref-changelog.md:965
msgid ""
"**Improve Virtual Client Engine internals** "
"([#1401](https://github.com/adap/flower/pull/1401), "
"[#1453](https://github.com/adap/flower/pull/1453))"
msgstr "**改进虚拟客户端引擎内部**（[#1401](https://github.com/adap/flower/pull/1401)、[#1453](https://github.com/adap/flower/pull/1453)）"

#: ../../source/ref-changelog.md:967
msgid ""
"Some internals of the Virtual Client Engine have been revamped. The VCE "
"now uses Ray 2.0 under the hood, the value type of the `client_resources`"
" dictionary changed to `float` to allow fractions of resources to be "
"allocated."
msgstr ""
"虚拟客户端引擎的部分内部结构已进行了修改。VCE 现在使用 Ray 2.0，\"client_resources \"字典的值类型改为 "
"\"float\"，以允许分配分数资源。"

#: ../../source/ref-changelog.md:969
msgid ""
"**Support optional** `Client`**/**`NumPyClient` **methods in Virtual "
"Client Engine**"
msgstr "**支持虚拟客户端引擎中的可选** `Client`**/**`NumPyClient` **方法**"

#: ../../source/ref-changelog.md:971
msgid ""
"The Virtual Client Engine now has full support for optional `Client` (and"
" `NumPyClient`) methods."
msgstr "虚拟客户端引擎现在完全支持可选的 `Client`（和 `NumPyClient`）方法。"

#: ../../source/ref-changelog.md:973
msgid ""
"**Provide type information to packages using** `flwr` "
"([#1377](https://github.com/adap/flower/pull/1377))"
msgstr ""
"**使用** `flwr`向软件包提供类型信息 "
"([#1377](https://github.com/adap/flower/pull/1377))"

#: ../../source/ref-changelog.md:975
msgid ""
"The package `flwr` is now bundled with a `py.typed` file indicating that "
"the package is typed. This enables typing support for projects or "
"packages that use `flwr` by enabling them to improve their code using "
"static type checkers like `mypy`."
msgstr ""
"软件包 `flwr` 现在捆绑了一个 `py.typed` 文件，表明该软件包是类型化的。这样，使用 `flwr` 的项目或软件包就可以使用 "
"`mypy` 等静态类型检查器改进代码，从而获得类型支持。"

#: ../../source/ref-changelog.md:977
msgid ""
"**Updated code example** "
"([#1344](https://github.com/adap/flower/pull/1344), "
"[#1347](https://github.com/adap/flower/pull/1347))"
msgstr ""
"** 更新代码示例** ([#1344](https://github.com/adap/flower/pull/1344), "
"[#1347](https://github.com/adap/flower/pull/1347))"

#: ../../source/ref-changelog.md:979
msgid ""
"The code examples covering scikit-learn and PyTorch Lightning have been "
"updated to work with the latest version of Flower."
msgstr "涵盖 scikit-learn 和 PyTorch Lightning 的代码示例已更新，以便与最新版本的 Flower 配合使用。"

#: ../../source/ref-changelog.md:981
msgid ""
"**Updated documentation** "
"([#1355](https://github.com/adap/flower/pull/1355), "
"[#1558](https://github.com/adap/flower/pull/1558), "
"[#1379](https://github.com/adap/flower/pull/1379), "
"[#1380](https://github.com/adap/flower/pull/1380), "
"[#1381](https://github.com/adap/flower/pull/1381), "
"[#1332](https://github.com/adap/flower/pull/1332), "
"[#1391](https://github.com/adap/flower/pull/1391), "
"[#1403](https://github.com/adap/flower/pull/1403), "
"[#1364](https://github.com/adap/flower/pull/1364), "
"[#1409](https://github.com/adap/flower/pull/1409), "
"[#1419](https://github.com/adap/flower/pull/1419), "
"[#1444](https://github.com/adap/flower/pull/1444), "
"[#1448](https://github.com/adap/flower/pull/1448), "
"[#1417](https://github.com/adap/flower/pull/1417), "
"[#1449](https://github.com/adap/flower/pull/1449), "
"[#1465](https://github.com/adap/flower/pull/1465), "
"[#1467](https://github.com/adap/flower/pull/1467))"
msgstr ""
"**更新文档** ([#1355](https://github.com/adap/flower/pull/1355), "
"[#1558](https://github.com/adap/flower/pull/1558), "
"[#1379](https://github.com/adap/flower/pull/1379), "
"[#1380](https://github.com/adap/flower/pull/1380), "
"[#1381](https://github.com/adap/flower/pull/1381), "
"[#1332](https://github.com/adap/flower/pull/1332), "
"[#1391](https://github.com/adap/flower/pull/1391), "
"[#1403](https://github.com/adap/flower/pull/1403), "
"[#1364](https://github. com/adap/flower/pull/1364), "
"[#1409](https://github.com/adap/flower/pull/1409), "
"[#1419](https://github.com/adap/flower/pull/1419), "
"[#1444](https://github.com/adap/flower/pull/1444), "
"[#1448](https://github.com/adap/flower/pull/1448), "
"[#1417](https://github.com/adap/flower/pull/1417), "
"[#1449](https://github.com/adap/flower/pull/1449), "
"[#1465](https://github.com/adap/flower/pull/1465), "
"[#1467](https://github.com/adap/flower/pull/1467))"

#: ../../source/ref-changelog.md:983
msgid ""
"There have been so many documentation updates that it doesn't even make "
"sense to list them individually."
msgstr "文档更新的数量之多，甚至没有必要逐一列出。"

#: ../../source/ref-changelog.md:985
msgid ""
"**Restructured documentation** "
"([#1387](https://github.com/adap/flower/pull/1387))"
msgstr "**重构文档**（[#1387](https://github.com/adap/flower/pull/1387)）"

#: ../../source/ref-changelog.md:987
msgid ""
"The documentation has been restructured to make it easier to navigate. "
"This is just the first step in a larger effort to make the Flower "
"documentation the best documentation of any project ever. Stay tuned!"
msgstr "我们对文档进行了重组，使其更易于浏览。这只是让 Flower 文档成为所有项目中最好文档的第一步。敬请期待！"

#: ../../source/ref-changelog.md:989
msgid ""
"**Open in Colab button** "
"([#1389](https://github.com/adap/flower/pull/1389))"
msgstr "**在 Colab 中打开按钮** ([#1389](https://github.com/adap/flower/pull/1389))"

#: ../../source/ref-changelog.md:991
msgid ""
"The four parts of the Flower Federated Learning Tutorial now come with a "
"new `Open in Colab` button. No need to install anything on your local "
"machine, you can now use and learn about Flower in your browser, it's "
"only a single click away."
msgstr ""
"Flower 联邦学习教程的四个部分现在都带有一个新的 \"在 Colab 中打开 "
"\"按钮。现在，您无需在本地计算机上安装任何软件，只需点击一下，就可以在浏览器中使用和学习 Flower。"

#: ../../source/ref-changelog.md:993
msgid ""
"**Improved tutorial** ([#1468](https://github.com/adap/flower/pull/1468),"
" [#1470](https://github.com/adap/flower/pull/1470), "
"[#1472](https://github.com/adap/flower/pull/1472), "
"[#1473](https://github.com/adap/flower/pull/1473), "
"[#1474](https://github.com/adap/flower/pull/1474), "
"[#1475](https://github.com/adap/flower/pull/1475))"
msgstr ""
"**改进教程** ([#1468](https://github.com/adap/flower/pull/1468), "
"[#1470](https://github.com/adap/flower/pull/1470), "
"[#1472](https://github.com/adap/flower/pull/1472), "
"[#1473](https://github.com/adap/flower/pull/1473), "
"[#1474](https://github.com/adap/flower/pull/1474), "
"[#1475](https://github.com/adap/flower/pull/1475)))"

#: ../../source/ref-changelog.md:995
msgid ""
"The Flower Federated Learning Tutorial has two brand-new parts covering "
"custom strategies (still WIP) and the distinction between `Client` and "
"`NumPyClient`. The existing parts one and two have also been improved "
"(many small changes and fixes)."
msgstr ""
"Flower 联邦学习教程有两个全新的部分，涉及自定义策略（仍处于 WIP 阶段）和 `Client` 与 `NumPyClient` "
"之间的区别。现有的第一和第二部分也得到了改进（许多小改动和修正）。"

#: ../../source/ref-changelog.md:1001
msgid "v1.0.0 (2022-07-28)"
msgstr "v1.0.0 (2022-07-28)"

#: ../../source/ref-changelog.md:1003
msgid "Highlights"
msgstr "亮点"

#: ../../source/ref-changelog.md:1005
msgid "Stable **Virtual Client Engine** (accessible via `start_simulation`)"
msgstr "稳定的**虚拟客户端引擎**（可通过`start_simulation`访问）"

#: ../../source/ref-changelog.md:1006
msgid "All `Client`/`NumPyClient` methods are now optional"
msgstr "所有 `Client`/`NumPyClient` 方法现在都是可选的了"

#: ../../source/ref-changelog.md:1007
msgid "Configurable `get_parameters`"
msgstr "可配置的`get_parameters`"

#: ../../source/ref-changelog.md:1008
msgid ""
"Tons of small API cleanups resulting in a more coherent developer "
"experience"
msgstr "对大量小型应用程序接口进行了清理，使开发人员的体验更加一致"

#: ../../source/ref-changelog.md:1012
msgid ""
"We would like to give our **special thanks** to all the contributors who "
"made Flower 1.0 possible (in reverse [GitHub "
"Contributors](https://github.com/adap/flower/graphs/contributors) order):"
msgstr ""
"在此，我们谨向所有促成 Flower 1.0 的贡献者致以**特别的谢意（按[GitHub "
"贡献者](https://github.com/adap/flower/graphs/contributors) 倒序排列）："

#: ../../source/ref-changelog.md:1014
msgid ""
"[@rtaiello](https://github.com/rtaiello), "
"[@g-pichler](https://github.com/g-pichler), [@rob-"
"luke](https://github.com/rob-luke), [@andreea-zaharia](https://github.com"
"/andreea-zaharia), [@kinshukdua](https://github.com/kinshukdua), "
"[@nfnt](https://github.com/nfnt), "
"[@tatiana-s](https://github.com/tatiana-s), "
"[@TParcollet](https://github.com/TParcollet), "
"[@vballoli](https://github.com/vballoli), "
"[@negedng](https://github.com/negedng), "
"[@RISHIKESHAVAN](https://github.com/RISHIKESHAVAN), "
"[@hei411](https://github.com/hei411), "
"[@SebastianSpeitel](https://github.com/SebastianSpeitel), "
"[@AmitChaulwar](https://github.com/AmitChaulwar), "
"[@Rubiel1](https://github.com/Rubiel1), [@FANTOME-PAN](https://github.com"
"/FANTOME-PAN), [@Rono-BC](https://github.com/Rono-BC), "
"[@lbhm](https://github.com/lbhm), "
"[@sishtiaq](https://github.com/sishtiaq), "
"[@remde](https://github.com/remde), [@Jueun-Park](https://github.com"
"/Jueun-Park), [@architjen](https://github.com/architjen), "
"[@PratikGarai](https://github.com/PratikGarai), "
"[@mrinaald](https://github.com/mrinaald), "
"[@zliel](https://github.com/zliel), "
"[@MeiruiJiang](https://github.com/MeiruiJiang), "
"[@sancarlim](https://github.com/sancarlim), "
"[@gubertoli](https://github.com/gubertoli), "
"[@Vingt100](https://github.com/Vingt100), "
"[@MakGulati](https://github.com/MakGulati), "
"[@cozek](https://github.com/cozek), "
"[@jafermarq](https://github.com/jafermarq), "
"[@sisco0](https://github.com/sisco0), "
"[@akhilmathurs](https://github.com/akhilmathurs), "
"[@CanTuerk](https://github.com/CanTuerk), "
"[@mariaboerner1987](https://github.com/mariaboerner1987), "
"[@pedropgusmao](https://github.com/pedropgusmao), "
"[@tanertopal](https://github.com/tanertopal), "
"[@danieljanes](https://github.com/danieljanes)."
msgstr ""
"[@rtaiello](https://github.com/rtaiello), "
"[@g-pichler](https://github.com/g-pichler), [@rob-"
"luke](https://github.com/rob-luke), [@andreea-zaharia](https://github.com"
"/andreea-zaharia), [@kinshukdua](https://github.com/kinshukdua), "
"[@nfnt](https://github.com/nfnt), "
"[@tatiana-s](https://github.com/tatiana-s), "
"[@TParcollet](https://github.com/TParcollet), "
"[@vballoli](https://github.com/vballoli), "
"[@negedng](https://github.com/negedng), "
"[@RISHIKESHAVAN](https://github.com/RISHIKESHAVAN), "
"[@hei411](https://github.com/hei411), "
"[@SebastianSpeitel](https://github.com/SebastianSpeitel), "
"[@AmitChaulwar](https://github.com/AmitChaulwar), "
"[@Rubiel1](https://github.com/Rubiel1), [@FANTOME-PAN](https://github.com"
"/FANTOME-PAN), [@Rono-BC](https://github.com/Rono-BC), "
"[@lbhm](https://github.com/lbhm), "
"[@sishtiaq](https://github.com/sishtiaq), "
"[@remde](https://github.com/remde), [@Jueun-Park](https://github.com"
"/Jueun-Park), [@architjen](https://github.com/architjen), "
"[@PratikGarai](https://github.com/PratikGarai), "
"[@mrinaald](https://github.com/mrinaald), "
"[@zliel](https://github.com/zliel), "
"[@MeiruiJiang](https://github.com/MeiruiJiang), "
"[@sancarlim](https://github.com/sancarlim), "
"[@gubertoli](https://github.com/gubertoli), "
"[@Vingt100](https://github.com/Vingt100), "
"[@MakGulati](https://github.com/MakGulati), "
"[@cozek](https://github.com/cozek), "
"[@jafermarq](https://github.com/jafermarq), "
"[@sisco0](https://github.com/sisco0), "
"[@akhilmathurs](https://github.com/akhilmathurs), "
"[@CanTuerk](https://github.com/CanTuerk), "
"[@mariaboerner1987](https://github.com/mariaboerner1987), "
"[@pedropgusmao](https://github.com/pedropgusmao), "
"[@tanertopal](https://github.com/tanertopal), "
"[@danieljanes](https://github.com/danieljanes)."

#: ../../source/ref-changelog.md:1018
msgid ""
"**All arguments must be passed as keyword arguments** "
"([#1338](https://github.com/adap/flower/pull/1338))"
msgstr "** 所有参数必须作为关键字参数传递** ([#1338](https://github.com/adap/flower/pull/1338))"

#: ../../source/ref-changelog.md:1020
msgid ""
"Pass all arguments as keyword arguments, positional arguments are not "
"longer supported. Code that uses positional arguments (e.g., "
"`start_client(\"127.0.0.1:8080\", FlowerClient())`) must add the keyword "
"for each positional argument (e.g., "
"`start_client(server_address=\"127.0.0.1:8080\", "
"client=FlowerClient())`)."
msgstr ""
"以关键字参数传递所有参数，不再支持位置参数。使用位置参数的代码（例如，`start_client(\"127.0.0.1:8080\", "
"FlowerClient())`）必须为每个位置参数添加关键字（例如，`start_client(server_address=\"127.0.0.1:8080\","
" client=FlowerClient())`）。"

#: ../../source/ref-changelog.md:1022
msgid ""
"**Introduce configuration object** `ServerConfig` **in** `start_server` "
"**and** `start_simulation` "
"([#1317](https://github.com/adap/flower/pull/1317))"
msgstr ""
"**在*** `start_server` ***和*** `start_simulation` 中引入配置对象*** "
"`ServerConfig` ([#1317](https://github.com/adap/flower/pull/1317))"

#: ../../source/ref-changelog.md:1024
msgid ""
"Instead of a config dictionary `{\"num_rounds\": 3, \"round_timeout\": "
"600.0}`, `start_server` and `start_simulation` now expect a configuration"
" object of type `flwr.server.ServerConfig`. `ServerConfig` takes the same"
" arguments that as the previous config dict, but it makes writing type-"
"safe code easier and the default parameters values more transparent."
msgstr ""
"并非配置字典`{\"num_rounds\"： 3, \"round_timeout\"： 600.0}`, `start_server`和 "
"`start_simulation`现在用一个类型为 "
"`flwr.server.ServerConfig`的配置对象。`ServerConfig`接收的参数与之前的 config dict "
"相同，但它使编写类型安全代码变得更容易，默认参数值也更加透明。"

#: ../../source/ref-changelog.md:1026
msgid ""
"**Rename built-in strategy parameters for clarity** "
"([#1334](https://github.com/adap/flower/pull/1334))"
msgstr "**重新命名内置策略参数，使其更加清晰** ([#1334](https://github.com/adap/flower/pull/1334))"

#: ../../source/ref-changelog.md:1028
msgid ""
"The following built-in strategy parameters were renamed to improve "
"readability and consistency with other API's:"
msgstr "以下内置策略参数已重新命名，以提高可读性并与其他 API 保持一致："

#: ../../source/ref-changelog.md:1030
msgid "`fraction_eval` --> `fraction_evaluate`"
msgstr "`fraction_eval` --> `fraction_evaluate`"

#: ../../source/ref-changelog.md:1031
msgid "`min_eval_clients` --> `min_evaluate_clients`"
msgstr "`min_eval_clients` --> `min_evaluate_clients`"

#: ../../source/ref-changelog.md:1032
msgid "`eval_fn` --> `evaluate_fn`"
msgstr "`eval_fn` --> `evaluate_fn`"

#: ../../source/ref-changelog.md:1034
msgid ""
"**Update default arguments of built-in strategies** "
"([#1278](https://github.com/adap/flower/pull/1278))"
msgstr "**更新内置策略的默认参数** ([#1278](https://github.com/adap/flower/pull/1278))"

#: ../../source/ref-changelog.md:1036
msgid ""
"All built-in strategies now use `fraction_fit=1.0` and "
"`fraction_evaluate=1.0`, which means they select *all* currently "
"available clients for training and evaluation. Projects that relied on "
"the previous default values can get the previous behaviour by "
"initializing the strategy in the following way:"
msgstr ""
"所有内置策略现在都使用 \"fraction_fit=1.0 \"和 "
"\"fraction_evaluate=1.0\"，这意味着它们会选择*所有*当前可用的客户端进行训练和评估。依赖以前默认值的项目可以通过以下方式初始化策略，获得以前的行为："

#: ../../source/ref-changelog.md:1038
msgid "`strategy = FedAvg(fraction_fit=0.1, fraction_evaluate=0.1)`"
msgstr "`strategy = FedAvg(fraction_fit=0.1, fraction_evaluate=0.1)`"

#: ../../source/ref-changelog.md:1040
msgid ""
"**Add** `server_round` **to** `Strategy.evaluate` "
"([#1334](https://github.com/adap/flower/pull/1334))"
msgstr ""
"**添加*** `server_round` ***到*** `Strategy.evaluate` "
"([#1334](https://github.com/adap/flower/pull/1334))"

#: ../../source/ref-changelog.md:1042
msgid ""
"The `Strategy` method `evaluate` now receives the current round of "
"federated learning/evaluation as the first parameter."
msgstr "`Strategy`的`evaluate` 方法现在会接收当前一轮联邦学习/评估作为第一个参数。"

#: ../../source/ref-changelog.md:1044
msgid ""
"**Add** `server_round` **and** `config` **parameters to** `evaluate_fn` "
"([#1334](https://github.com/adap/flower/pull/1334))"
msgstr ""
"**将*** `server_round` **和*** `config` **参数添加到*** `evaluate_fn` "
"([#1334](https://github.com/adap/flower/pull/1334))"

#: ../../source/ref-changelog.md:1046
msgid ""
"The `evaluate_fn` passed to built-in strategies like `FedAvg` now takes "
"three parameters: (1) The current round of federated learning/evaluation "
"(`server_round`), (2) the model parameters to evaluate (`parameters`), "
"and (3) a config dictionary (`config`)."
msgstr ""
"传递给内置策略（如 `FedAvg`）的 `evaluate_fn` 现在需要三个参数：(1) 当前一轮联邦学习/评估 "
"(`server_round`)，(2) 要评估的模型参数 (`parameters`)，(3) 配置字典 (`config`)。"

#: ../../source/ref-changelog.md:1048
msgid ""
"**Rename** `rnd` **to** `server_round` "
"([#1321](https://github.com/adap/flower/pull/1321))"
msgstr ""
"**重新命名** `rnd` ** to** `server_round` "
"([#1321](https://github.com/adap/flower/pull/1321))"

#: ../../source/ref-changelog.md:1050
msgid ""
"Several Flower methods and functions (`evaluate_fn`, `configure_fit`, "
"`aggregate_fit`, `configure_evaluate`, `aggregate_evaluate`) receive the "
"current round of federated learning/evaluation as their first parameter. "
"To improve reaability and avoid confusion with *random*, this parameter "
"has been renamed from `rnd` to `server_round`."
msgstr ""
"几个 Flower "
"方法和函数（`evaluate_fn`、`configure_fit`、`aggregate_fit`、`configure_evaluate`、`aggregate_evaluate`）的第一个参数是当前一轮的联邦学习/评估。为提高可重复性并避免与"
" *random* 混淆，该参数已从 `rnd` 更名为 `server_round`。"

#: ../../source/ref-changelog.md:1052
msgid ""
"**Move** `flwr.dataset` **to** `flwr_baselines` "
"([#1273](https://github.com/adap/flower/pull/1273))"
msgstr ""
"**移动*** `flwr.dataset` **到*** `flwr_baselines` "
"([#1273](https://github.com/adap/flower/pull/1273))"

#: ../../source/ref-changelog.md:1054
msgid "The experimental package `flwr.dataset` was migrated to Flower Baselines."
msgstr "实验软件包 `flwr.dataset` 已迁移至 Flower Baselines。"

#: ../../source/ref-changelog.md:1056
msgid ""
"**Remove experimental strategies** "
"([#1280](https://github.com/adap/flower/pull/1280))"
msgstr "**删除实验策略** ([#1280](https://github.com/adap/flower/pull/1280))"

#: ../../source/ref-changelog.md:1058
msgid ""
"Remove unmaintained experimental strategies (`FastAndSlow`, `FedFSv0`, "
"`FedFSv1`)."
msgstr "移除未维护的试验性策略（`FastAndSlow`、`FedFSv0`、`FedFSv1`）。"

#: ../../source/ref-changelog.md:1060
msgid ""
"**Rename** `Weights` **to** `NDArrays` "
"([#1258](https://github.com/adap/flower/pull/1258), "
"[#1259](https://github.com/adap/flower/pull/1259))"
msgstr ""
"**重新命名** `Weights` **到** `NDArrays` "
"([#1258](https://github.com/adap/flower/pull/1258), "
"[#1259](https://github.com/adap/flower/pull/1259))"

#: ../../source/ref-changelog.md:1062
msgid ""
"`flwr.common.Weights` was renamed to `flwr.common.NDArrays` to better "
"capture what this type is all about."
msgstr "flwr.common.Weights \"更名为 \"flwr.common.NDArrays\"，以更好地反映该类型的含义。"

#: ../../source/ref-changelog.md:1064
msgid ""
"**Remove antiquated** `force_final_distributed_eval` **from** "
"`start_server` ([#1258](https://github.com/adap/flower/pull/1258), "
"[#1259](https://github.com/adap/flower/pull/1259))"
msgstr ""
"**从** `start_server` 中移除过时的** `force_final_distributed_eval` "
"([#1258](https://github.com/adap/flower/pull/1258), "
"[#1259](https://github.com/adap/flower/pull/1259))"

#: ../../source/ref-changelog.md:1066
msgid ""
"The `start_server` parameter `force_final_distributed_eval` has long been"
" a historic artefact, in this release it is finally gone for good."
msgstr ""
"start_server \"参数 \"force_final_distributed_eval "
"\"长期以来一直是个历史遗留问题，在此版本中终于永远消失了。"

#: ../../source/ref-changelog.md:1068
msgid ""
"**Make** `get_parameters` **configurable** "
"([#1242](https://github.com/adap/flower/pull/1242))"
msgstr ""
"**使** `get_parameters` **可配置** "
"([#1242](https://github.com/adap/flower/pull/1242))"

#: ../../source/ref-changelog.md:1070
msgid ""
"The `get_parameters` method now accepts a configuration dictionary, just "
"like `get_properties`, `fit`, and `evaluate`."
msgstr ""
"现在，\"get_parameters \"方法与 \"get_properties\"、\"fit \"和 \"evaluate "
"\"一样，都接受配置字典。"

#: ../../source/ref-changelog.md:1072
msgid ""
"**Replace** `num_rounds` **in** `start_simulation` **with new** `config` "
"**parameter** ([#1281](https://github.com/adap/flower/pull/1281))"
msgstr ""
"**用新的** `config` 参数** 替换** `num_rounds` ** in** `start_simulation` ** "
"([#1281](https://github.com/adap/flower/pull/1281))"

#: ../../source/ref-changelog.md:1074
msgid ""
"The `start_simulation` function now accepts a configuration dictionary "
"`config` instead of the `num_rounds` integer. This improves the "
"consistency between `start_simulation` and `start_server` and makes "
"transitioning between the two easier."
msgstr ""
"现在，`start_simulation`（开始模拟）` 函数接受配置字典 `config` 而不是 `num_rounds` 整数。这改进了 "
"`start_simulation` 和 `start_server` 之间的一致性，并使两者之间的转换更容易。"

#: ../../source/ref-changelog.md:1078
msgid ""
"**Support Python 3.10** "
"([#1320](https://github.com/adap/flower/pull/1320))"
msgstr "** 支持 Python 3.10** ([#1320](https://github.com/adap/flower/pull/1320))"

#: ../../source/ref-changelog.md:1080
msgid ""
"The previous Flower release introduced experimental support for Python "
"3.10, this release declares Python 3.10 support as stable."
msgstr "上一个 Flower 版本引入了对 Python 3.10 的实验支持，而本版本则宣布对 Python 3.10 的支持为稳定支持。"

#: ../../source/ref-changelog.md:1082
msgid ""
"**Make all** `Client` **and** `NumPyClient` **methods optional** "
"([#1260](https://github.com/adap/flower/pull/1260), "
"[#1277](https://github.com/adap/flower/pull/1277))"
msgstr ""
"**使所有** `Client` **和** `NumPyClient` **方法成为可选** "
"([#1260](https://github.com/adap/flower/pull/1260), "
"[#1277](https://github.com/adap/flower/pull/1277))"

#: ../../source/ref-changelog.md:1084
msgid ""
"The `Client`/`NumPyClient` methods `get_properties`, `get_parameters`, "
"`fit`, and `evaluate` are all optional. This enables writing clients that"
" implement, for example, only `fit`, but no other method. No need to "
"implement `evaluate` when using centralized evaluation!"
msgstr ""
"`Client`/`NumPyClient`的 \"get_properties\"、\"get_parameters\"、\"fit \"和 "
"\"evaluate \"方法都是可选的。这样就可以编写只实现 `fit` 而不实现其他方法的客户端。使用集中评估时，无需实现 "
"`evaluate`！"

#: ../../source/ref-changelog.md:1086
msgid ""
"**Enable passing a** `Server` **instance to** `start_simulation` "
"([#1281](https://github.com/adap/flower/pull/1281))"
msgstr ""
"**启用向** `start_simulation` 传递** `Server` 实例 "
"([#1281](https://github.com/adap/flower/pull/1281))"

#: ../../source/ref-changelog.md:1088
msgid ""
"Similar to `start_server`, `start_simulation` now accepts a full `Server`"
" instance. This enables users to heavily customize the execution of "
"eperiments and opens the door to running, for example, async FL using the"
" Virtual Client Engine."
msgstr ""
"与 `start_server` 类似，`start_simulation` 现在也接受一个完整的 `Server` "
"实例。这使得用户可以对实验的执行进行大量自定义，并为使用虚拟客户端引擎运行异步 FL 等打开了大门。"

#: ../../source/ref-changelog.md:1090
msgid ""
"**Update code examples** "
"([#1291](https://github.com/adap/flower/pull/1291), "
"[#1286](https://github.com/adap/flower/pull/1286), "
"[#1282](https://github.com/adap/flower/pull/1282))"
msgstr ""
"**更新代码示例** ([#1291](https://github.com/adap/flower/pull/1291), "
"[#1286](https://github.com/adap/flower/pull/1286), "
"[#1282](https://github.com/adap/flower/pull/1282))"

#: ../../source/ref-changelog.md:1092
msgid ""
"Many code examples received small or even large maintenance updates, "
"among them are"
msgstr "许多代码示例都进行了小规模甚至大规模的维护更新，其中包括"

#: ../../source/ref-changelog.md:1094
msgid "`scikit-learn`"
msgstr "`scikit-learn`"

#: ../../source/ref-changelog.md:1095
msgid "`simulation_pytorch`"
msgstr "`simulation_pytorch`"

#: ../../source/ref-changelog.md:1096
msgid "`quickstart_pytorch`"
msgstr "`quickstart_pytorch`"

#: ../../source/ref-changelog.md:1097
msgid "`quickstart_simulation`"
msgstr "`quickstart_simulation`"

#: ../../source/ref-changelog.md:1098
msgid "`quickstart_tensorflow`"
msgstr "`quickstart_tensorflow`"

#: ../../source/ref-changelog.md:1099
msgid "`advanced_tensorflow`"
msgstr "`advanced_tensorflow`"

#: ../../source/ref-changelog.md:1101
msgid ""
"**Remove the obsolete simulation example** "
"([#1328](https://github.com/adap/flower/pull/1328))"
msgstr "**删除过时的模拟示例** ([#1328](https://github.com/adap/flower/pull/1328))"

#: ../../source/ref-changelog.md:1103
msgid ""
"Removes the obsolete `simulation` example and renames "
"`quickstart_simulation` to `simulation_tensorflow` so it fits withs the "
"naming of `simulation_pytorch`"
msgstr ""
"删除过时的 \"simulation \"示例，并将 \"quickstart_simulation \"重命名为 "
"\"simulation_tensorflow\"，使其与 \"simulation_pytorch \"的命名一致"

#: ../../source/ref-changelog.md:1105
msgid ""
"**Update documentation** "
"([#1223](https://github.com/adap/flower/pull/1223), "
"[#1209](https://github.com/adap/flower/pull/1209), "
"[#1251](https://github.com/adap/flower/pull/1251), "
"[#1257](https://github.com/adap/flower/pull/1257), "
"[#1267](https://github.com/adap/flower/pull/1267), "
"[#1268](https://github.com/adap/flower/pull/1268), "
"[#1300](https://github.com/adap/flower/pull/1300), "
"[#1304](https://github.com/adap/flower/pull/1304), "
"[#1305](https://github.com/adap/flower/pull/1305), "
"[#1307](https://github.com/adap/flower/pull/1307))"
msgstr ""
"**更新文档** ([#1223](https://github.com/adap/flower/pull/1223), "
"[#1209](https://github.com/adap/flower/pull/1209), "
"[#1251](https://github.com/adap/flower/pull/1251), "
"[#1257](https://github.com/adap/flower/pull/1257), "
"[#1267](https://github.com/adap/flower/pull/1267), "
"[#1268](https://github.com/adap/flower/pull/1268), "
"[#1300](https://github.com/adap/flower/pull/1300), "
"[#1304](https://github.com/adap/flower/pull/1304), "
"[#1305](https://github.com/adap/flower/pull/1305), "
"[#1307](https://github.com/adap/flower/pull/1307))"

#: ../../source/ref-changelog.md:1107
msgid ""
"One substantial documentation update fixes multiple smaller rendering "
"issues, makes titles more succinct to improve navigation, removes a "
"deprecated library, updates documentation dependencies, includes the "
"`flwr.common` module in the API reference, includes support for markdown-"
"based documentation, migrates the changelog from `.rst` to `.md`, and "
"fixes a number of smaller details!"
msgstr ""
"其中一个实质性的文档更新修复了多个较小的渲染问题，使标题更加简洁以改善导航，删除了一个已废弃的库，更新了文档依赖关系，在 API 参考中包含了 "
"`flwr.common` 模块，包含了对基于 markdown 的文档的支持，将更新日志从 `.rst` 移植到了 "
"`.md`，并修复了一些较小的细节！"

#: ../../source/ref-changelog.md:1109 ../../source/ref-changelog.md:1164
#: ../../source/ref-changelog.md:1233 ../../source/ref-changelog.md:1272
msgid "**Minor updates**"
msgstr "**小规模更新**"

#: ../../source/ref-changelog.md:1111
msgid ""
"Add round number to fit and evaluate log messages "
"([#1266](https://github.com/adap/flower/pull/1266))"
msgstr "添加四舍五入数字，以适应和评估日志信息（[#1266](https://github.com/adap/flower/pull/1266)）"

#: ../../source/ref-changelog.md:1112
msgid ""
"Add secure gRPC connection to the `advanced_tensorflow` code example "
"([#847](https://github.com/adap/flower/pull/847))"
msgstr ""
"为 `advanced_tensorflow` 代码示例添加安全 gRPC 连接 "
"([#847](https://github.com/adap/flower/pull/847))"

#: ../../source/ref-changelog.md:1113
msgid ""
"Update developer tooling "
"([#1231](https://github.com/adap/flower/pull/1231), "
"[#1276](https://github.com/adap/flower/pull/1276), "
"[#1301](https://github.com/adap/flower/pull/1301), "
"[#1310](https://github.com/adap/flower/pull/1310))"
msgstr ""
"更新开发人员工具（[#1231](https://github.com/adap/flower/pull/1231), "
"[#1276](https://github.com/adap/flower/pull/1276), "
"[#1301](https://github.com/adap/flower/pull/1301), "
"[#1310](https://github.com/adap/flower/pull/1310)"

#: ../../source/ref-changelog.md:1114
msgid ""
"Rename ProtoBuf messages to improve consistency "
"([#1214](https://github.com/adap/flower/pull/1214), "
"[#1258](https://github.com/adap/flower/pull/1258), "
"[#1259](https://github.com/adap/flower/pull/1259))"
msgstr ""
"重命名 ProtoBuf 消息以提高一致性（[#1214](https://github.com/adap/flower/pull/1214), "
"[#1258](https://github.com/adap/flower/pull/1258), "
"[#1259](https://github.com/adap/flower/pull/1259)"

#: ../../source/ref-changelog.md:1116
msgid "v0.19.0 (2022-05-18)"
msgstr "v0.19.0 (2022-05-18)"

#: ../../source/ref-changelog.md:1120
msgid ""
"**Flower Baselines (preview): FedOpt, FedBN, FedAvgM** "
"([#919](https://github.com/adap/flower/pull/919), "
"[#1127](https://github.com/adap/flower/pull/1127), "
"[#914](https://github.com/adap/flower/pull/914))"
msgstr ""
"**Flower Baselines（预览）： FedOpt、FedBN、FedAvgM** "
"([#919](https://github.com/adap/flower/pull/919), "
"[#1127](https://github.com/adap/flower/pull/1127), "
"[#914](https://github.com/adap/flower/pull/914))"

#: ../../source/ref-changelog.md:1122
#, fuzzy
msgid ""
"The first preview release of Flower Baselines has arrived! We're "
"kickstarting Flower Baselines with implementations of FedOpt (FedYogi, "
"FedAdam, FedAdagrad), FedBN, and FedAvgM. Check the documentation on how "
"to use [Flower Baselines](https://flower.ai/docs/using-baselines.html). "
"With this first preview release we're also inviting the community to "
"[contribute their own baselines](https://flower.ai/docs/baselines/how-to-"
"contribute-baselines.html)."
msgstr ""
"Flower Baselines 的第一个预览版已经发布！我们通过实现 "
"FedOpt（FedYogi、FedAdam、FedAdagrad）、FedBN 和 FedAvgM 来启动 Flower "
"Baselines。请查阅文档了解如何使用 [Flower Baselines](https://flower.ai/docs/using-"
"baselines.html)。在首次发布预览版时，我们还邀请社区成员[贡献自己的Baselines](https://flower.ai/docs"
"/contributing-baselines.html)。"

#: ../../source/ref-changelog.md:1124
msgid ""
"**C++ client SDK (preview) and code example** "
"([#1111](https://github.com/adap/flower/pull/1111))"
msgstr "**C++客户端SDK（预览版）和代码示例**（[#1111](https://github.com/adap/flower/pull/1111)）"

#: ../../source/ref-changelog.md:1126
msgid ""
"Preview support for Flower clients written in C++. The C++ preview "
"includes a Flower client SDK and a quickstart code example that "
"demonstrates a simple C++ client using the SDK."
msgstr ""
"预览版支持用 C++ 编写的 Flower 客户端。C++ 预览版包括一个 Flower 客户端 SDK 和一个快速入门代码示例，使用 SDK "
"演示了一个简单的 C++ 客户端。"

#: ../../source/ref-changelog.md:1128
msgid ""
"**Add experimental support for Python 3.10 and Python 3.11** "
"([#1135](https://github.com/adap/flower/pull/1135))"
msgstr ""
"** 增加对 Python 3.10 和 Python 3.11 的实验支持** "
"([#1135](https://github.com/adap/flower/pull/1135))"

#: ../../source/ref-changelog.md:1130
msgid ""
"Python 3.10 is the latest stable release of Python and Python 3.11 is due"
" to be released in October. This Flower release adds experimental support"
" for both Python versions."
msgstr ""
"Python 3.10 是 Python 的最新稳定版本，Python 3.11 将于 10 月份发布。Flower 版本增加了对这两个 "
"Python 版本的实验支持。"

#: ../../source/ref-changelog.md:1132
msgid ""
"**Aggregate custom metrics through user-provided functions** "
"([#1144](https://github.com/adap/flower/pull/1144))"
msgstr "**通过用户提供的函数聚合自定义指标**（[#1144](https://github.com/adap/flower/pull/1144)）"

#: ../../source/ref-changelog.md:1134
msgid ""
"Custom metrics (e.g., `accuracy`) can now be aggregated without having to"
" customize the strategy. Built-in strategies support two new arguments, "
"`fit_metrics_aggregation_fn` and `evaluate_metrics_aggregation_fn`, that "
"allow passing custom metric aggregation functions."
msgstr ""
"现在无需定制策略即可聚合自定义度量（如`准确度`）。内置策略支持两个新参数：`fit_metrics_aggregation_fn` "
"和`evaluate_metrics_aggregation_fn`，允许传递自定义度量聚合函数。"

#: ../../source/ref-changelog.md:1136
msgid ""
"**User-configurable round timeout** "
"([#1162](https://github.com/adap/flower/pull/1162))"
msgstr "**用户可配置的回合超时**（[#1162](https://github.com/adap/flower/pull/1162)）"

#: ../../source/ref-changelog.md:1138
msgid ""
"A new configuration value allows the round timeout to be set for "
"`start_server` and `start_simulation`. If the `config` dictionary "
"contains a `round_timeout` key (with a `float` value in seconds), the "
"server will wait *at least* `round_timeout` seconds before it closes the "
"connection."
msgstr ""
"新的配置值允许为 `start_server` 和 `start_simulation` 设置回合超时。如果 `config` 字典中包含一个 "
"`round_timeout` 键（以秒为单位的 `float`值），服务器将至少等待 ** `round_timeout` 秒后才关闭连接。"

#: ../../source/ref-changelog.md:1140
msgid ""
"**Enable both federated evaluation and centralized evaluation to be used "
"at the same time in all built-in strategies** "
"([#1091](https://github.com/adap/flower/pull/1091))"
msgstr ""
"**允许在所有内置策略中同时使用联邦评价和集中评估** "
"([#1091](https://github.com/adap/flower/pull/1091))"

#: ../../source/ref-changelog.md:1142
msgid ""
"Built-in strategies can now perform both federated evaluation (i.e., "
"client-side) and centralized evaluation (i.e., server-side) in the same "
"round. Federated evaluation can be disabled by setting `fraction_eval` to"
" `0.0`."
msgstr ""
"内置策略现在可以在同一轮中同时执行联邦评估（即客户端）和集中评估（即服务器端）。可以通过将 `fraction_eval` 设置为 "
"`0.0`来禁用联邦评估。"

#: ../../source/ref-changelog.md:1144
msgid ""
"**Two new Jupyter Notebook tutorials** "
"([#1141](https://github.com/adap/flower/pull/1141))"
msgstr ""
"**两本新的 Jupyter Notebook 教程** "
"([#1141](https://github.com/adap/flower/pull/1141))"

#: ../../source/ref-changelog.md:1146
msgid ""
"Two Jupyter Notebook tutorials (compatible with Google Colab) explain "
"basic and intermediate Flower features:"
msgstr "两本 Jupyter Notebook 教程（与 Google Colab 兼容）介绍了 Flower 的基本和中级功能："

#: ../../source/ref-changelog.md:1148
msgid ""
"*An Introduction to Federated Learning*: [Open in "
"Colab](https://colab.research.google.com/github/adap/flower/blob/main/tutorials/Flower-1"
"-Intro-to-FL-PyTorch.ipynb)"
msgstr ""
"*联邦学习简介*： [在 Colab "
"中打开](https://colab.research.google.com/github/adap/flower/blob/main/tutorials/Flower-1"
"-Intro-to-FL-PyTorch.ipynb)"

#: ../../source/ref-changelog.md:1150
msgid ""
"*Using Strategies in Federated Learning*: [Open in "
"Colab](https://colab.research.google.com/github/adap/flower/blob/main/tutorials/Flower-2"
"-Strategies-in-FL-PyTorch.ipynb)"
msgstr ""
"*在联邦学习中使用策略*： [在 Colab "
"中打开](https://colab.research.google.com/github/adap/flower/blob/main/tutorials/Flower-2"
"-Strategies-in-FL-PyTorch.ipynb)"

#: ../../source/ref-changelog.md:1152
msgid ""
"**New FedAvgM strategy (Federated Averaging with Server Momentum)** "
"([#1076](https://github.com/adap/flower/pull/1076))"
msgstr ""
"**新的 FedAvgM 策略（带服务器动量的联邦平均）** "
"([#1076](https://github.com/adap/flower/pull/1076))"

#: ../../source/ref-changelog.md:1154
msgid ""
"The new `FedAvgM` strategy implements Federated Averaging with Server "
"Momentum \\[Hsu et al., 2019\\]."
msgstr "新的 \"FedAvgM \"策略实现了带服务器动量的联邦平均[Hsu et al., 2019\\]."

#: ../../source/ref-changelog.md:1156
msgid ""
"**New advanced PyTorch code example** "
"([#1007](https://github.com/adap/flower/pull/1007))"
msgstr "**新的 PyTorch 高级代码示例** ([#1007](https://github.com/adap/flower/pull/1007))"

#: ../../source/ref-changelog.md:1158
msgid ""
"A new code example (`advanced_pytorch`) demonstrates advanced Flower "
"concepts with PyTorch."
msgstr "新代码示例 (`advanced_pytorch`) 演示了 PyTorch 的高级 Flower 概念。"

#: ../../source/ref-changelog.md:1160
msgid ""
"**New JAX code example** "
"([#906](https://github.com/adap/flower/pull/906), "
"[#1143](https://github.com/adap/flower/pull/1143))"
msgstr ""
"**新的 JAX 代码示例**（[#906](https://github.com/adap/flower/pull/906), "
"[#1143](https://github.com/adap/flower/pull/1143)"

#: ../../source/ref-changelog.md:1162
msgid ""
"A new code example (`jax_from_centralized_to_federated`) shows federated "
"learning with JAX and Flower."
msgstr "新代码示例（`jax_from_centralized_to_federated`）展示了使用 JAX 和 Flower 的联邦学习。"

#: ../../source/ref-changelog.md:1166
msgid ""
"New option to keep Ray running if Ray was already initialized in "
"`start_simulation` ([#1177](https://github.com/adap/flower/pull/1177))"
msgstr ""
"新增选项，用于在 \"start_simulation\"（开始模拟）中已初始化 Ray 的情况下保持 Ray "
"运行（[#1177](https://github.com/adap/flower/pull/1177)）"

#: ../../source/ref-changelog.md:1167
msgid ""
"Add support for custom `ClientManager` as a `start_simulation` parameter "
"([#1171](https://github.com/adap/flower/pull/1171))"
msgstr ""
"添加对自定义 \"客户端管理器 \"作为 \"start_simulation "
"\"参数的支持（[#1171](https://github.com/adap/flower/pull/1171)）"

#: ../../source/ref-changelog.md:1168
msgid ""
"New documentation for [implementing "
"strategies](https://flower.ai/docs/framework/how-to-implement-"
"strategies.html) ([#1097](https://github.com/adap/flower/pull/1097), "
"[#1175](https://github.com/adap/flower/pull/1175))"
msgstr ""
"[实施战略](https://flower.ai/docs/framework/how-to-implement-strategies.html)"
" 的新文件（[#1097](https://github.com/adap/flower/pull/1097), "
"[#1175](https://github.com/adap/flower/pull/1175)"

#: ../../source/ref-changelog.md:1169
msgid ""
"New mobile-friendly documentation theme "
"([#1174](https://github.com/adap/flower/pull/1174))"
msgstr "新的移动友好型文档主题 ([#1174](https://github.com/adap/flower/pull/1174))"

#: ../../source/ref-changelog.md:1170
msgid ""
"Limit version range for (optional) `ray` dependency to include only "
"compatible releases (`>=1.9.2,<1.12.0`) "
"([#1205](https://github.com/adap/flower/pull/1205))"
msgstr ""
"限制（可选）`ray`依赖的版本范围，使其仅包含兼容版本（`>=1.9.2,<1.12.0`） "
"([#1205](https://github.com/adap/flower/pull/1205))"

#: ../../source/ref-changelog.md:1174
msgid ""
"**Remove deprecated support for Python 3.6** "
"([#871](https://github.com/adap/flower/pull/871))"
msgstr "**删除对 Python 3.6 的过时支持** ([#871](https://github.com/adap/flower/pull/871))"

#: ../../source/ref-changelog.md:1175
msgid ""
"**Remove deprecated KerasClient** "
"([#857](https://github.com/adap/flower/pull/857))"
msgstr "**移除过时的 KerasClient**（[#857](https://github.com/adap/flower/pull/857)）"

#: ../../source/ref-changelog.md:1176
msgid ""
"**Remove deprecated no-op extra installs** "
"([#973](https://github.com/adap/flower/pull/973))"
msgstr "**移除过时的不操作额外安装** ([#973](https://github.com/adap/flower/pull/973))"

#: ../../source/ref-changelog.md:1177
msgid ""
"**Remove deprecated proto fields from** `FitRes` **and** `EvaluateRes` "
"([#869](https://github.com/adap/flower/pull/869))"
msgstr ""
"**从** `FitRes` **和** `EvaluateRes` 中移除已废弃的 proto 字段 "
"([#869](https://github.com/adap/flower/pull/869))"

#: ../../source/ref-changelog.md:1178
msgid ""
"**Remove deprecated QffedAvg strategy (replaced by QFedAvg)** "
"([#1107](https://github.com/adap/flower/pull/1107))"
msgstr ""
"**移除过时的 QffedAvg 策略（由 QFedAvg 取代）** "
"([#1107](https://github.com/adap/flower/pull/1107))"

#: ../../source/ref-changelog.md:1179
msgid ""
"**Remove deprecated DefaultStrategy strategy** "
"([#1142](https://github.com/adap/flower/pull/1142))"
msgstr ""
"**删除过时的 DefaultStrategy 策略** "
"([#1142](https://github.com/adap/flower/pull/1142))"

#: ../../source/ref-changelog.md:1180
msgid ""
"**Remove deprecated support for eval_fn accuracy return value** "
"([#1142](https://github.com/adap/flower/pull/1142))"
msgstr ""
"**删除已过时的对 eval_fn 返回值准确性的支持** "
"([#1142](https://github.com/adap/flower/pull/1142))"

#: ../../source/ref-changelog.md:1181
msgid ""
"**Remove deprecated support for passing initial parameters as NumPy "
"ndarrays** ([#1142](https://github.com/adap/flower/pull/1142))"
msgstr ""
"**移除对以 NumPy ndarrays 传递初始参数的过时支持** "
"([#1142](https://github.com/adap/flower/pull/1142))"

#: ../../source/ref-changelog.md:1183
msgid "v0.18.0 (2022-02-28)"
msgstr "v0.18.0 (2022-02-28)"

#: ../../source/ref-changelog.md:1187
msgid ""
"**Improved Virtual Client Engine compatibility with Jupyter Notebook / "
"Google Colab** ([#866](https://github.com/adap/flower/pull/866), "
"[#872](https://github.com/adap/flower/pull/872), "
"[#833](https://github.com/adap/flower/pull/833), "
"[#1036](https://github.com/adap/flower/pull/1036))"
msgstr ""
"**改进了虚拟客户端引擎与 Jupyter Notebook / Google Colab 的兼容性** "
"([#866](https://github.com/adap/flower/pull/866), "
"[#872](https://github.com/adap/flower/pull/872), "
"[#833](https://github.com/adap/flower/pull/833), "
"[#1036](https://github.com/adap/flower/pull/1036))"

#: ../../source/ref-changelog.md:1189
msgid ""
"Simulations (using the Virtual Client Engine through `start_simulation`) "
"now work more smoothly on Jupyter Notebooks (incl. Google Colab) after "
"installing Flower with the `simulation` extra (`pip install "
"'flwr[simulation]'`)."
msgstr ""
"通过 `start_simulation` 在 Jupyter 笔记本（包括 Google Colab）上安装 Flower 并附加 "
"`simulation` (`pip install 'flwr[simulation]'`)后，模拟（通过 `start_simulation`"
" 使用虚拟客户端引擎）现在可以更流畅地运行。"

#: ../../source/ref-changelog.md:1191
msgid ""
"**New Jupyter Notebook code example** "
"([#833](https://github.com/adap/flower/pull/833))"
msgstr ""
"**新的 Jupyter Notebook 代码示例** "
"([#833](https://github.com/adap/flower/pull/833))"

#: ../../source/ref-changelog.md:1193
msgid ""
"A new code example (`quickstart_simulation`) demonstrates Flower "
"simulations using the Virtual Client Engine through Jupyter Notebook "
"(incl. Google Colab)."
msgstr ""
"新代码示例（`quickstart_simulation`）通过 Jupyter Notebook（包括 Google "
"Colab）演示了使用虚拟客户端引擎进行 Flower 模拟。"

#: ../../source/ref-changelog.md:1195
msgid ""
"**Client properties (feature preview)** "
"([#795](https://github.com/adap/flower/pull/795))"
msgstr "**客户端属性（功能预览）** ([#795](https://github.com/adap/flower/pull/795))"

#: ../../source/ref-changelog.md:1197
msgid ""
"Clients can implement a new method `get_properties` to enable server-side"
" strategies to query client properties."
msgstr "客户端可以实现一个新方法 `get_properties`，以启用服务器端策略来查询客户端属性。"

#: ../../source/ref-changelog.md:1199
msgid ""
"**Experimental Android support with TFLite** "
"([#865](https://github.com/adap/flower/pull/865))"
msgstr "** 使用 TFLite 实验性支持安卓系统** ([#865](https://github.com/adap/flower/pull/865))"

#: ../../source/ref-changelog.md:1201
msgid ""
"Android support has finally arrived in `main`! Flower is both client-"
"agnostic and framework-agnostic by design. One can integrate arbitrary "
"client platforms and with this release, using Flower on Android has "
"become a lot easier."
msgstr ""
"`main`终于支持 Android 了！Flower 的设计与客户端和框架无关。我们可以集成任意客户端平台，有了这个版本，在安卓系统上使用 "
"Flower 就变得更容易了。"

#: ../../source/ref-changelog.md:1203
msgid ""
"The example uses TFLite on the client side, along with a new "
"`FedAvgAndroid` strategy. The Android client and `FedAvgAndroid` are "
"still experimental, but they are a first step towards a fully-fledged "
"Android SDK and a unified `FedAvg` implementation that integrated the new"
" functionality from `FedAvgAndroid`."
msgstr ""
"该示例在客户端使用了 TFLite 以及新的 `FedAvgAndroid`策略。Android 客户端和 "
"`FedAvgAndroid`仍处于试验阶段，但这是向成熟的 Android SDK 和集成了 `FedAvgAndroid`新功能的统一 "
"`FedAvg`实现迈出的第一步。"

#: ../../source/ref-changelog.md:1205
msgid ""
"**Make gRPC keepalive time user-configurable and decrease default "
"keepalive time** ([#1069](https://github.com/adap/flower/pull/1069))"
msgstr ""
"**使 gRPC 保持连接时间可由用户配置，并缩短默认保持连接时间** "
"([#1069](https://github.com/adap/flower/pull/1069))"

#: ../../source/ref-changelog.md:1207
msgid ""
"The default gRPC keepalive time has been reduced to increase the "
"compatibility of Flower with more cloud environments (for example, "
"Microsoft Azure). Users can configure the keepalive time to customize the"
" gRPC stack based on specific requirements."
msgstr ""
"为提高 Flower 与更多云环境（如 Microsoft Azure）的兼容性，缩短了默认 gRPC 保持时间。用户可以根据具体要求配置 "
"keepalive 时间，自定义 gRPC 堆栈。"

#: ../../source/ref-changelog.md:1209
msgid ""
"**New differential privacy example using Opacus and PyTorch** "
"([#805](https://github.com/adap/flower/pull/805))"
msgstr ""
"**使用 Opacus 和 PyTorch 的新差分隐私示例** "
"([#805](https://github.com/adap/flower/pull/805))"

#: ../../source/ref-changelog.md:1211
msgid ""
"A new code example (`opacus`) demonstrates differentially-private "
"federated learning with Opacus, PyTorch, and Flower."
msgstr "一个新的代码示例（\"opacus\"）演示了使用 Opacus、PyTorch 和 Flower 进行差分隐私的联邦学习。"

#: ../../source/ref-changelog.md:1213
msgid ""
"**New Hugging Face Transformers code example** "
"([#863](https://github.com/adap/flower/pull/863))"
msgstr ""
"**新的Hugging Face Transformers代码示例** "
"([#863](https://github.com/adap/flower/pull/863))"

#: ../../source/ref-changelog.md:1215
msgid ""
"A new code example (`quickstart_huggingface`) demonstrates usage of "
"Hugging Face Transformers with Flower."
msgstr "新的代码示例(`quickstart_huggingface`)证明了结合Flower和Hugging Face Transformers的实用性。"

#: ../../source/ref-changelog.md:1217
msgid ""
"**New MLCube code example** "
"([#779](https://github.com/adap/flower/pull/779), "
"[#1034](https://github.com/adap/flower/pull/1034), "
"[#1065](https://github.com/adap/flower/pull/1065), "
"[#1090](https://github.com/adap/flower/pull/1090))"
msgstr ""
"**新的 MLCube 代码示例** ([#779](https://github.com/adap/flower/pull/779), "
"[#1034](https://github.com/adap/flower/pull/1034), "
"[#1065](https://github.com/adap/flower/pull/1065), "
"[#1090](https://github.com/adap/flower/pull/1090))"

#: ../../source/ref-changelog.md:1219
msgid ""
"A new code example (`quickstart_mlcube`) demonstrates usage of MLCube "
"with Flower."
msgstr "新代码示例（\"quickstart_mlcube\"）演示了 MLCube 与 Flower 的用法。"

#: ../../source/ref-changelog.md:1221
msgid ""
"**SSL-enabled server and client** "
"([#842](https://github.com/adap/flower/pull/842),  "
"[#844](https://github.com/adap/flower/pull/844),  "
"[#845](https://github.com/adap/flower/pull/845), "
"[#847](https://github.com/adap/flower/pull/847), "
"[#993](https://github.com/adap/flower/pull/993), "
"[#994](https://github.com/adap/flower/pull/994))"
msgstr ""
"** 支持 SSL 的服务器和客户端** ([#842](https://github.com/adap/flower/pull/842), "
"[#844](https://github.com/adap/flower/pull/844), "
"[#845](https://github.com/adap/flower/pull/845), "
"[#847](https://github.com/adap/flower/pull/847), "
"[#993](https://github.com/adap/flower/pull/993), "
"[#994](https://github.com/adap/flower/pull/994))"

#: ../../source/ref-changelog.md:1223
msgid ""
"SSL enables secure encrypted connections between clients and servers. "
"This release open-sources the Flower secure gRPC implementation to make "
"encrypted communication channels accessible to all Flower users."
msgstr "SSL 可实现客户端与服务器之间的安全加密连接。该版本开源了 Flower 安全 gRPC 实现，使所有 Flower 用户都能访问加密通信通道。"

#: ../../source/ref-changelog.md:1225
msgid ""
"**Updated** `FedAdam` **and** `FedYogi` **strategies** "
"([#885](https://github.com/adap/flower/pull/885), "
"[#895](https://github.com/adap/flower/pull/895))"
msgstr ""
"**更新**`FedAdam`**和**`FedYogi`**战略** "
"([#885](https://github.com/adap/flower/pull/885), "
"[#895](https://github.com/adap/flower/pull/895))"

#: ../../source/ref-changelog.md:1227
msgid ""
"`FedAdam` and `FedAdam` match the latest version of the Adaptive "
"Federated Optimization paper."
msgstr "FedAdam \"和 \"FedAdam \"与最新版本的 \"自适应联邦优化 \"论文相匹配。"

#: ../../source/ref-changelog.md:1229
msgid ""
"**Initialize** `start_simulation` **with a list of client IDs** "
"([#860](https://github.com/adap/flower/pull/860))"
msgstr ""
"**初始化** `start_simulation` **使用客户端 ID 列表** "
"([#860](https://github.com/adap/flower/pull/860))"

#: ../../source/ref-changelog.md:1231
msgid ""
"`start_simulation` can now be called with a list of client IDs "
"(`clients_ids`, type: `List[str]`). Those IDs will be passed to the "
"`client_fn` whenever a client needs to be initialized, which can make it "
"easier to load data partitions that are not accessible through `int` "
"identifiers."
msgstr ""
"现在可以使用客户端 ID 列表（`clients_ids`，类型：`List[str]`）调用 "
"`start_simulation`。每当需要初始化客户端时，这些 ID 就会被传递到 `client_fn` 中，这样就能更轻松地加载无法通过 "
"`int` 标识符访问的数据分区。"

#: ../../source/ref-changelog.md:1235
msgid ""
"Update `num_examples` calculation in PyTorch code examples in "
"([#909](https://github.com/adap/flower/pull/909))"
msgstr ""
"更新 PyTorch 代码示例中的 \"num_examples \"计算 "
"([#909](https://github.com/adap/flower/pull/909))"

#: ../../source/ref-changelog.md:1236
msgid ""
"Expose Flower version through `flwr.__version__` "
"([#952](https://github.com/adap/flower/pull/952))"
msgstr ""
"通过 `flwr.__version__` 公开 Flower 版本 "
"([#952](https://github.com/adap/flower/pull/952))"

#: ../../source/ref-changelog.md:1237
msgid ""
"`start_server` in `app.py` now returns a `History` object containing "
"metrics from training ([#974](https://github.com/adap/flower/pull/974))"
msgstr ""
"`app.py`中的 `start_server`现在会返回一个 `History` "
"对象，其中包含训练中的指标（[#974](https://github.com/adap/flower/pull/974)）"

#: ../../source/ref-changelog.md:1238
msgid ""
"Make `max_workers` (used by `ThreadPoolExecutor`) configurable "
"([#978](https://github.com/adap/flower/pull/978))"
msgstr ""
"使 `max_workers`（由 "
"`ThreadPoolExecutor`使用）可配置（[#978](https://github.com/adap/flower/pull/978)）"

#: ../../source/ref-changelog.md:1239
msgid ""
"Increase sleep time after server start to three seconds in all code "
"examples ([#1086](https://github.com/adap/flower/pull/1086))"
msgstr "在所有代码示例中，将服务器启动后的休眠时间延长至三秒（[#1086](https://github.com/adap/flower/pull/1086)）"

#: ../../source/ref-changelog.md:1240
msgid ""
"Added a new FAQ section to the documentation "
"([#948](https://github.com/adap/flower/pull/948))"
msgstr "在文档中添加了新的常见问题部分 ([#948](https://github.com/adap/flower/pull/948))"

#: ../../source/ref-changelog.md:1241
msgid ""
"And many more under-the-hood changes, library updates, documentation "
"changes, and tooling improvements!"
msgstr "还有更多底层更改、库更新、文档更改和工具改进！"

#: ../../source/ref-changelog.md:1245
msgid ""
"**Removed** `flwr_example` **and** `flwr_experimental` **from release "
"build** ([#869](https://github.com/adap/flower/pull/869))"
msgstr ""
"**从发布版中删除**`flwr_example`**和**`flwr_experimental`** "
"([#869](https://github.com/adap/flower/pull/869))"

#: ../../source/ref-changelog.md:1247
msgid ""
"The packages `flwr_example` and `flwr_experimental` have been deprecated "
"since Flower 0.12.0 and they are not longer included in Flower release "
"builds. The associated extras (`baseline`, `examples-pytorch`, `examples-"
"tensorflow`, `http-logger`, `ops`) are now no-op and will be removed in "
"an upcoming release."
msgstr ""
"自 Flower 0.12.0 起，软件包 `flwr_example` 和 `flwr_experimental` 已被弃用，它们不再包含在 "
"Flower 的发布版本中。相关的额外包（`baseline`, `examples-pytorch`, `examples-"
"tensorflow`, `http-logger`, `ops`）现在已不再使用，并将在即将发布的版本中移除。"

#: ../../source/ref-changelog.md:1249
msgid "v0.17.0 (2021-09-24)"
msgstr "v0.17.0 (2021-09-24)"

#: ../../source/ref-changelog.md:1253
msgid ""
"**Experimental virtual client engine** "
"([#781](https://github.com/adap/flower/pull/781) "
"[#790](https://github.com/adap/flower/pull/790) "
"[#791](https://github.com/adap/flower/pull/791))"
msgstr ""
"**实验性虚拟客户端引擎** ([#781](https://github.com/adap/flower/pull/781) "
"[#790](https://github.com/adap/flower/pull/790) "
"[#791](https://github.com/adap/flower/pull/791))"

#: ../../source/ref-changelog.md:1255
msgid ""
"One of Flower's goals is to enable research at scale. This release "
"enables a first (experimental) peek at a major new feature, codenamed the"
" virtual client engine. Virtual clients enable simulations that scale to "
"a (very) large number of clients on a single machine or compute cluster. "
"The easiest way to test the new functionality is to look at the two new "
"code examples called `quickstart_simulation` and `simulation_pytorch`."
msgstr ""
"Flower 的目标之一是实现大规模研究。这一版本首次（试验性地）展示了代号为 \"虚拟客户端引擎 "
"\"的重要新功能。虚拟客户端可以在单台机器或计算集群上对大量客户端进行模拟。测试新功能的最简单方法是查看名为 "
"\"quickstart_simulation \"和 \"simulation_pytorch \"的两个新代码示例。"

#: ../../source/ref-changelog.md:1257
msgid ""
"The feature is still experimental, so there's no stability guarantee for "
"the API. It's also not quite ready for prime time and comes with a few "
"known caveats. However, those who are curious are encouraged to try it "
"out and share their thoughts."
msgstr ""
"该功能仍处于试验阶段，因此无法保证 API "
"的稳定性。此外，它还没有完全准备好进入黄金时间，并有一些已知的注意事项。不过，我们鼓励好奇的用户尝试使用并分享他们的想法。"

#: ../../source/ref-changelog.md:1259
msgid ""
"**New built-in strategies** "
"([#828](https://github.com/adap/flower/pull/828) "
"[#822](https://github.com/adap/flower/pull/822))"
msgstr ""
"**新的内置策略**（[#828](https://github.com/adap/flower/pull/828) "
"[#822](https://github.com/adap/flower/pull/822)"

#: ../../source/ref-changelog.md:1261
msgid ""
"FedYogi - Federated learning strategy using Yogi on server-side. "
"Implementation based on https://arxiv.org/abs/2003.00295"
msgstr "FedYogi - 在服务器端使用 Yogi 的联邦学习策略。基于 https://arxiv.org/abs/2003.00295 实现"

#: ../../source/ref-changelog.md:1262
msgid ""
"FedAdam - Federated learning strategy using Adam on server-side. "
"Implementation based on https://arxiv.org/abs/2003.00295"
msgstr "FedAdam - 在服务器端使用 Adam 的联邦学习策略。基于 https://arxiv.org/abs/2003.00295 实现"

#: ../../source/ref-changelog.md:1264
msgid ""
"**New PyTorch Lightning code example** "
"([#617](https://github.com/adap/flower/pull/617))"
msgstr ""
"**新的 PyTorch Lightning 代码示例** "
"([#617](https://github.com/adap/flower/pull/617))"

#: ../../source/ref-changelog.md:1266
msgid ""
"**New Variational Auto-Encoder code example** "
"([#752](https://github.com/adap/flower/pull/752))"
msgstr "**新的变分自动编码器代码示例** ([#752](https://github.com/adap/flower/pull/752))"

#: ../../source/ref-changelog.md:1268
msgid ""
"**New scikit-learn code example** "
"([#748](https://github.com/adap/flower/pull/748))"
msgstr "**新的 scikit-learn 代码示例** ([#748](https://github.com/adap/flower/pull/748))"

#: ../../source/ref-changelog.md:1270
msgid ""
"**New experimental TensorBoard strategy** "
"([#789](https://github.com/adap/flower/pull/789))"
msgstr "**新的实验性 TensorBoard 策略**（[#789](https://github.com/adap/flower/pull/789)）"

#: ../../source/ref-changelog.md:1274
msgid ""
"Improved advanced TensorFlow code example "
"([#769](https://github.com/adap/flower/pull/769))"
msgstr "改进的高级 TensorFlow 代码示例（[#769](https://github.com/adap/flower/pull/769)"

#: ../../source/ref-changelog.md:1275
msgid ""
"Warning when `min_available_clients` is misconfigured "
"([#830](https://github.com/adap/flower/pull/830))"
msgstr ""
"当 `min_available_clients` 配置错误时发出警告 "
"([#830](https://github.com/adap/flower/pull/830))"

#: ../../source/ref-changelog.md:1276
msgid ""
"Improved gRPC server docs "
"([#841](https://github.com/adap/flower/pull/841))"
msgstr "改进了 gRPC 服务器文档（[#841](https://github.com/adap/flower/pull/841)）"

#: ../../source/ref-changelog.md:1277
msgid ""
"Improved error message in `NumPyClient` "
"([#851](https://github.com/adap/flower/pull/851))"
msgstr "改进了 `NumPyClient` 中的错误信息 ([#851](https://github.com/adap/flower/pull/851))"

#: ../../source/ref-changelog.md:1278
msgid ""
"Improved PyTorch quickstart code example "
"([#852](https://github.com/adap/flower/pull/852))"
msgstr "改进的 PyTorch 快速启动代码示例 ([#852](https://github.com/adap/flower/pull/852))"

#: ../../source/ref-changelog.md:1282
msgid ""
"**Disabled final distributed evaluation** "
"([#800](https://github.com/adap/flower/pull/800))"
msgstr "**禁用最终分布式评价** ([#800](https://github.com/adap/flower/pull/800))"

#: ../../source/ref-changelog.md:1284
msgid ""
"Prior behaviour was to perform a final round of distributed evaluation on"
" all connected clients, which is often not required (e.g., when using "
"server-side evaluation). The prior behaviour can be enabled by passing "
"`force_final_distributed_eval=True` to `start_server`."
msgstr ""
"之前的行为是在所有连接的客户端上执行最后一轮分布式评估，而这通常是不需要的（例如，在使用服务器端评估时）。可以通过向 `start_server`"
" 传递 `force_final_distributed_eval=True` 来启用之前的行为。"

#: ../../source/ref-changelog.md:1286
msgid ""
"**Renamed q-FedAvg strategy** "
"([#802](https://github.com/adap/flower/pull/802))"
msgstr "**更名为 q-FedAvg 策略** ([#802](https://github.com/adap/flower/pull/802))"

#: ../../source/ref-changelog.md:1288
msgid ""
"The strategy named `QffedAvg` was renamed to `QFedAvg` to better reflect "
"the notation given in the original paper (q-FFL is the optimization "
"objective, q-FedAvg is the proposed solver). Note the original (now "
"deprecated) `QffedAvg` class is still available for compatibility reasons"
" (it will be removed in a future release)."
msgstr ""
"名为 `QffedAvg` 的策略已更名为 `QFedAvg`，以更好地反映原始论文中给出的符号（q-FFL 是优化目标，q-FedAvg "
"是建议的求解器）。请注意，出于兼容性原因，原始（现已废弃）的 `QffedAvg` 类仍然可用（它将在未来的版本中移除）。"

#: ../../source/ref-changelog.md:1290
msgid ""
"**Deprecated and renamed code example** `simulation_pytorch` **to** "
"`simulation_pytorch_legacy` "
"([#791](https://github.com/adap/flower/pull/791))"
msgstr ""
"**删除并重命名代码示例**`simulation_pytorch`**为**`simulation_pytorch_legacy` "
"([#791](https://github.com/adap/flower/pull/791))"

#: ../../source/ref-changelog.md:1292
msgid ""
"This example has been replaced by a new example. The new example is based"
" on the experimental virtual client engine, which will become the new "
"default way of doing most types of large-scale simulations in Flower. The"
" existing example was kept for reference purposes, but it might be "
"removed in the future."
msgstr ""
"该示例已被新示例取代。新示例基于试验性虚拟客户端引擎，它将成为在 Flower "
"中进行大多数类型大规模模拟的新的默认方式。现有示例将作为参考保留，但将来可能会删除。"

#: ../../source/ref-changelog.md:1294
msgid "v0.16.0 (2021-05-11)"
msgstr "v0.16.0 (2021-05-11)"

#: ../../source/ref-changelog.md:1298
msgid ""
"**New built-in strategies** "
"([#549](https://github.com/adap/flower/pull/549))"
msgstr "**新的内置策略** ([#549](https://github.com/adap/flower/pull/549))"

#: ../../source/ref-changelog.md:1300
msgid "(abstract) FedOpt"
msgstr "（摘要） FedOpt"

#: ../../source/ref-changelog.md:1303
msgid ""
"**Custom metrics for server and strategies** "
"([#717](https://github.com/adap/flower/pull/717))"
msgstr "**服务器和策略的自定义指标** ([#717](https://github.com/adap/flower/pull/717))"

#: ../../source/ref-changelog.md:1305
msgid ""
"The Flower server is now fully task-agnostic, all remaining instances of "
"task-specific metrics (such as `accuracy`) have been replaced by custom "
"metrics dictionaries. Flower 0.15 introduced the capability to pass a "
"dictionary containing custom metrics from client to server. As of this "
"release, custom metrics replace task-specific metrics on the server."
msgstr ""
"Flower 服务器现在完全与任务无关，所有剩余的任务特定度量（如 \"准确度\"）都已被自定义度量字典取代。Flower 0.15 "
"引入了从客户端向服务器传递包含自定义指标的字典的功能。从本版本开始，自定义指标将取代服务器上的特定任务指标。"

#: ../../source/ref-changelog.md:1307
msgid ""
"Custom metric dictionaries are now used in two user-facing APIs: they are"
" returned from Strategy methods `aggregate_fit`/`aggregate_evaluate` and "
"they enable evaluation functions passed to built-in strategies (via "
"`eval_fn`) to return more than two evaluation metrics. Strategies can "
"even return *aggregated* metrics dictionaries for the server to keep "
"track of."
msgstr ""
"自定义度量字典现在可在两个面向用户的 API 中使用：它们可从策略方法 `aggregate_fit`/`aggregate_evaluate` "
"返回，还可使传递给内置策略（通过 `eval_fn`）的评估函数返回两个以上的评估度量。策略甚至可以返回 *aggregated* "
"指标字典，以便服务器跟踪。"

#: ../../source/ref-changelog.md:1309
msgid ""
"Strategy implementations should migrate their `aggregate_fit` and "
"`aggregate_evaluate` methods to the new return type (e.g., by simply "
"returning an empty `{}`), server-side evaluation functions should migrate"
" from `return loss, accuracy` to `return loss, {\"accuracy\": accuracy}`."
msgstr ""
"Strategy 实现应将其 `aggregate_fit` 和 `aggregate_evaluate` "
"方法迁移到新的返回类型（例如，只需返回空的 `{}`），服务器端评估函数应从 `return loss, accuracy` 迁移到 "
"`return loss, {\"accuracy\": accuracy}`。"

#: ../../source/ref-changelog.md:1311
msgid ""
"Flower 0.15-style return types are deprecated (but still supported), "
"compatibility will be removed in a future release."
msgstr "Flower 0.15 风格的返回类型已被弃用（但仍受支持），兼容性将在未来的版本中移除。"

#: ../../source/ref-changelog.md:1313
msgid ""
"**Migration warnings for deprecated functionality** "
"([#690](https://github.com/adap/flower/pull/690))"
msgstr "** 过时功能的迁移警告** ([#690](https://github.com/adap/flower/pull/690))"

#: ../../source/ref-changelog.md:1315
msgid ""
"Earlier versions of Flower were often migrated to new APIs, while "
"maintaining compatibility with legacy APIs. This release introduces "
"detailed warning messages if usage of deprecated APIs is detected. The "
"new warning messages often provide details on how to migrate to more "
"recent APIs, thus easing the transition from one release to another."
msgstr ""
"Flower 早期版本通常会迁移到新的应用程序接口，同时保持与旧版应用程序接口的兼容。如果检测到使用了过时的 "
"API，本版本将引入详细的警告信息。新的警告信息通常会详细说明如何迁移到更新的 API，从而简化从一个版本到另一个版本的过渡。"

#: ../../source/ref-changelog.md:1317
msgid ""
"Improved docs and docstrings "
"([#691](https://github.com/adap/flower/pull/691) "
"[#692](https://github.com/adap/flower/pull/692) "
"[#713](https://github.com/adap/flower/pull/713))"
msgstr ""
"改进了文档和文档说明 ([#691](https://github.com/adap/flower/pull/691) "
"[#692](https://github.com/adap/flower/pull/692) "
"[#713](https://github.com/adap/flower/pull/713))"

#: ../../source/ref-changelog.md:1319
msgid "MXNet example and documentation"
msgstr "MXNet 示例和文档"

#: ../../source/ref-changelog.md:1321
msgid ""
"FedBN implementation in example PyTorch: From Centralized To Federated "
"([#696](https://github.com/adap/flower/pull/696) "
"[#702](https://github.com/adap/flower/pull/702) "
"[#705](https://github.com/adap/flower/pull/705))"
msgstr ""
"PyTorch 示例中的 FedBN 实现： 从集中到联邦 "
"([#696](https://github.com/adap/flower/pull/696) "
"[#702](https://github.com/adap/flower/pull/702) "
"[#705](https://github.com/adap/flower/pull/705))"

#: ../../source/ref-changelog.md:1325
msgid ""
"**Serialization-agnostic server** "
"([#721](https://github.com/adap/flower/pull/721))"
msgstr "**序列化无关服务器** ([#721](https://github.com/adap/flower/pull/721))"

#: ../../source/ref-changelog.md:1327
msgid ""
"The Flower server is now fully serialization-agnostic. Prior usage of "
"class `Weights` (which represents parameters as deserialized NumPy "
"ndarrays) was replaced by class `Parameters` (e.g., in `Strategy`). "
"`Parameters` objects are fully serialization-agnostic and represents "
"parameters as byte arrays, the `tensor_type` attributes indicates how "
"these byte arrays should be interpreted (e.g., for "
"serialization/deserialization)."
msgstr ""
"Flower 服务器现在完全不依赖序列化。之前使用的 `Weights` 类（以反序列化的 NumPy ndarrays 表示参数）已被 "
"`Parameters` 类取代（例如在 `Strategy`中）。参数 "
"\"对象与序列化完全无关，它以字节数组的形式表示参数，\"tensor_type \"属性表示如何解释这些字节数组（例如，用于序列化/反序列化）。"

#: ../../source/ref-changelog.md:1329
msgid ""
"Built-in strategies implement this approach by handling serialization and"
" deserialization to/from `Weights` internally. Custom/3rd-party Strategy "
"implementations should update to the slightly changed Strategy method "
"definitions. Strategy authors can consult PR "
"[#721](https://github.com/adap/flower/pull/721) to see how strategies can"
" easily migrate to the new format."
msgstr ""
"内置策略通过在内部处理序列化和反序列化到/从`Weights`来实现这种方法。自定义/第三方策略实现应更新为稍有改动的策略方法定义。策略作者可查阅"
" PR [#721](https://github.com/adap/flower/pull/721) 以了解如何将策略轻松迁移到新格式。"

#: ../../source/ref-changelog.md:1331
msgid ""
"Deprecated `flwr.server.Server.evaluate`, use "
"`flwr.server.Server.evaluate_round` instead "
"([#717](https://github.com/adap/flower/pull/717))"
msgstr ""
"已弃用 `flwr.server.Server.evaluate`，改用 "
"`flwr.server.Server.evaluate_round`（[#717](https://github.com/adap/flower/pull/717)"

#: ../../source/ref-changelog.md:1333
msgid "v0.15.0 (2021-03-12)"
msgstr "v0.15.0 (2021-03-12)"

#: ../../source/ref-changelog.md:1337
msgid ""
"**Server-side parameter initialization** "
"([#658](https://github.com/adap/flower/pull/658))"
msgstr "**服务器端参数初始化** ([#658](https://github.com/adap/flower/pull/658))"

#: ../../source/ref-changelog.md:1339
msgid ""
"Model parameters can now be initialized on the server-side. Server-side "
"parameter initialization works via a new `Strategy` method called "
"`initialize_parameters`."
msgstr ""
"现在可以在服务器端初始化模型参数。服务器端参数初始化通过名为 \"initialize_parameters \"的新 \"Strategy "
"\"方法进行。"

#: ../../source/ref-changelog.md:1341
msgid ""
"Built-in strategies support a new constructor argument called "
"`initial_parameters` to set the initial parameters. Built-in strategies "
"will provide these initial parameters to the server on startup and then "
"delete them to free the memory afterwards."
msgstr ""
"内置策略支持名为 \"initial_parameters "
"\"的新构造函数参数，用于设置初始参数。内置策略会在启动时向服务器提供这些初始参数，然后删除它们以释放内存。"

#: ../../source/ref-changelog.md:1360
msgid ""
"If no initial parameters are provided to the strategy, the server will "
"continue to use the current behaviour (namely, it will ask one of the "
"connected clients for its parameters and use these as the initial global "
"parameters)."
msgstr "如果没有向策略提供初始参数，服务器将继续使用当前行为（即向其中一个已连接的客户端询问参数，并将这些参数用作初始全局参数）。"

#: ../../source/ref-changelog.md:1364
msgid ""
"Deprecate `flwr.server.strategy.DefaultStrategy` (migrate to "
"`flwr.server.strategy.FedAvg`, which is equivalent)"
msgstr ""
"停用 `flwr.server.strategy.DefaultStrategy`（迁移到等价的 "
"`flwr.server.strategy.FedAvg`）"

#: ../../source/ref-changelog.md:1366
msgid "v0.14.0 (2021-02-18)"
msgstr "v0.14.0 (2021-02-18)"

#: ../../source/ref-changelog.md:1370
msgid ""
"**Generalized** `Client.fit` **and** `Client.evaluate` **return values** "
"([#610](https://github.com/adap/flower/pull/610) "
"[#572](https://github.com/adap/flower/pull/572) "
"[#633](https://github.com/adap/flower/pull/633))"
msgstr ""
"**通用** `Client.fit` **和** `Client.evaluate` **返回值** "
"([#610](https://github.com/adap/flower/pull/610) "
"[#572](https://github.com/adap/flower/pull/572) "
"[#633](https://github.com/adap/flower/pull/633))"

#: ../../source/ref-changelog.md:1372
msgid ""
"Clients can now return an additional dictionary mapping `str` keys to "
"values of the following types: `bool`, `bytes`, `float`, `int`, `str`. "
"This means one can return almost arbitrary values from `fit`/`evaluate` "
"and make use of them on the server side!"
msgstr ""
"客户端现在可以返回一个额外的字典，将 `str` 键映射为以下类型的值： "
"bool`、`bytes`、`float`、`int`、`str`。这意味着我们可以从 `fit`/`evaluate` "
"返回几乎任意的值，并在服务器端使用它们！"

#: ../../source/ref-changelog.md:1374
msgid ""
"This improvement also allowed for more consistent return types between "
"`fit` and `evaluate`: `evaluate` should now return a tuple `(float, int, "
"dict)` representing the loss, number of examples, and a dictionary "
"holding arbitrary problem-specific values like accuracy."
msgstr ""
"这一改进还使 `fit` 和 `evaluate` 之间的返回类型更加一致：`evaluate` 现在应返回一个元组`(float, int, "
"dict)`，代表损失、示例数和一个包含特定问题任意值（如准确度）的字典。"

#: ../../source/ref-changelog.md:1376
msgid ""
"In case you wondered: this feature is compatible with existing projects, "
"the additional dictionary return value is optional. New code should "
"however migrate to the new return types to be compatible with upcoming "
"Flower releases (`fit`: `List[np.ndarray], int, Dict[str, Scalar]`, "
"`evaluate`: `float, int, Dict[str, Scalar]`). See the example below for "
"details."
msgstr ""
"如果你想知道：此功能与现有项目兼容，额外的字典返回值是可选的。不过，新代码应迁移到新的返回类型，以便与即将发布的 Flower "
"版本兼容（`fit`: `List[np.ndarray], int, Dict[str, Scalar]`，`evaluate`: "
"`float, int, Dict[str, Scalar]`）。详见下面的示例。"

#: ../../source/ref-changelog.md:1378
msgid ""
"*Code example:* note the additional dictionary return values in both "
"`FlwrClient.fit` and `FlwrClient.evaluate`:"
msgstr "*代码示例：* 注意 `FlwrClient.fit` 和 `FlwrClient.evaluate` 中的附加字典返回值："

#: ../../source/ref-changelog.md:1393
msgid ""
"**Generalized** `config` **argument in** `Client.fit` **and** "
"`Client.evaluate` ([#595](https://github.com/adap/flower/pull/595))"
msgstr ""
"**在**`Client.fit` "
"**和**`Client.evaluate`中泛化**`config`参数（[#595](https://github.com/adap/flower/pull/595)）"

#: ../../source/ref-changelog.md:1395
msgid ""
"The `config` argument used to be of type `Dict[str, str]`, which means "
"that dictionary values were expected to be strings. The new release "
"generalizes this to enable values of the following types: `bool`, "
"`bytes`, `float`, `int`, `str`."
msgstr ""
"`config`参数曾是 \"字典[str, str]\"类型，这意味着字典值应是字符串。新版本将其扩展为以下类型的值： "
"bool`、`bytes`、`float`、`int`、`str`。"

#: ../../source/ref-changelog.md:1397
msgid ""
"This means one can now pass almost arbitrary values to `fit`/`evaluate` "
"using the `config` dictionary. Yay, no more `str(epochs)` on the server-"
"side and `int(config[\"epochs\"])` on the client side!"
msgstr ""
"这意味着现在可以使用 `config` 字典向 `fit`/`evaluate` 传递几乎任意的值。耶，服务器端不再需要 "
"`str(epochs)`，客户端不再需要 `int(config[\"epochs\"])`！"

#: ../../source/ref-changelog.md:1399
msgid ""
"*Code example:* note that the `config` dictionary now contains non-`str` "
"values in both `Client.fit` and `Client.evaluate`:"
msgstr "*代码示例：* 注意 `config` 字典现在在 `Client.fit` 和 `Client.evaluate` 中都包含非 `str` 值："

#: ../../source/ref-changelog.md:1416
msgid "v0.13.0 (2021-01-08)"
msgstr "v0.13.0 (2021-01-08)"

#: ../../source/ref-changelog.md:1420
msgid ""
"New example: PyTorch From Centralized To Federated "
"([#549](https://github.com/adap/flower/pull/549))"
msgstr "新示例： PyTorch 从集中到联邦 ([#549](https://github.com/adap/flower/pull/549))"

#: ../../source/ref-changelog.md:1421
msgid "Improved documentation"
msgstr "改进文档"

#: ../../source/ref-changelog.md:1422
msgid "New documentation theme ([#551](https://github.com/adap/flower/pull/551))"
msgstr "新文档主题 ([#551](https://github.com/adap/flower/pull/551))"

#: ../../source/ref-changelog.md:1423
msgid "New API reference ([#554](https://github.com/adap/flower/pull/554))"
msgstr "新的 API 参考 ([#554](https://github.com/adap/flower/pull/554))"

#: ../../source/ref-changelog.md:1424
msgid ""
"Updated examples documentation "
"([#549](https://github.com/adap/flower/pull/549))"
msgstr "更新了示例文档 ([#549](https://github.com/adap/flower/pull/549))"

#: ../../source/ref-changelog.md:1425
msgid ""
"Removed obsolete documentation "
"([#548](https://github.com/adap/flower/pull/548))"
msgstr "删除了过时的文档 ([#548](https://github.com/adap/flower/pull/548))"

#: ../../source/ref-changelog.md:1427
msgid "Bugfix:"
msgstr "错误修正："

#: ../../source/ref-changelog.md:1429
msgid ""
"`Server.fit` does not disconnect clients when finished, disconnecting the"
" clients is now handled in `flwr.server.start_server` "
"([#553](https://github.com/adap/flower/pull/553) "
"[#540](https://github.com/adap/flower/issues/540))."
msgstr ""
"Server.fit \"完成后不会断开客户端连接，现在断开客户端连接是在 \"flwr.server.start_server "
"\"中处理的（[#553](https://github.com/adap/flower/pull/553) "
"[#540](https://github.com/adap/flower/issues/540)）。"

#: ../../source/ref-changelog.md:1431
msgid "v0.12.0 (2020-12-07)"
msgstr "v0.12.0 (2020-12-07)"

#: ../../source/ref-changelog.md:1433 ../../source/ref-changelog.md:1449
msgid "Important changes:"
msgstr "重要变更："

#: ../../source/ref-changelog.md:1435
msgid ""
"Added an example for embedded devices "
"([#507](https://github.com/adap/flower/pull/507))"
msgstr "添加了嵌入式设备示例 ([#507](https://github.com/adap/flower/pull/507))"

#: ../../source/ref-changelog.md:1436
msgid ""
"Added a new NumPyClient (in addition to the existing KerasClient) "
"([#504](https://github.com/adap/flower/pull/504) "
"[#508](https://github.com/adap/flower/pull/508))"
msgstr ""
"添加了一个新的 NumPyClient（除现有的 KerasClient "
"之外）（[#504](https://github.com/adap/flower/pull/504) "
"[#508](https://github.com/adap/flower/pull/508)"

#: ../../source/ref-changelog.md:1437
msgid ""
"Deprecated `flwr_example` package and started to migrate examples into "
"the top-level `examples` directory "
"([#494](https://github.com/adap/flower/pull/494) "
"[#512](https://github.com/adap/flower/pull/512))"
msgstr ""
"弃用 `flwr_example` 软件包，并开始将示例迁移到顶层的 `examples` 目录 "
"([#494](https://github.com/adap/flower/pull/494) "
"[#512](https://github.com/adap/flower/pull/512))"

#: ../../source/ref-changelog.md:1439
msgid "v0.11.0 (2020-11-30)"
msgstr "v0.11.0 (2020-11-30)"

#: ../../source/ref-changelog.md:1441
msgid "Incompatible changes:"
msgstr "不兼容的更改："

#: ../../source/ref-changelog.md:1443
msgid ""
"Renamed strategy methods "
"([#486](https://github.com/adap/flower/pull/486)) to unify the naming of "
"Flower's public APIs. Other public methods/functions (e.g., every method "
"in `Client`, but also `Strategy.evaluate`) do not use the `on_` prefix, "
"which is why we're removing it from the four methods in Strategy. To "
"migrate rename the following `Strategy` methods accordingly:"
msgstr ""
"重命名了策略方法（[#486](https://github.com/adap/flower/pull/486)），以统一 Flower公共 "
"API 的命名。其他公共方法/函数（例如 `Client` 中的每个方法，以及 `Strategy.evaluate`）不使用 `on_` "
"前缀，这就是我们从 Strategy 中的四个方法中移除它的原因。迁移时，请相应地重命名以下 `Strategy` 方法："

#: ../../source/ref-changelog.md:1444
msgid "`on_configure_evaluate` => `configure_evaluate`"
msgstr "`on_configure_evaluate` => `configure_evaluate`"

#: ../../source/ref-changelog.md:1445
msgid "`on_aggregate_evaluate` => `aggregate_evaluate`"
msgstr "`on_aggregate_evaluate` => `aggregate_evaluate`"

#: ../../source/ref-changelog.md:1446
msgid "`on_configure_fit` => `configure_fit`"
msgstr "`on_configure_fit` => `configure_fit`"

#: ../../source/ref-changelog.md:1447
msgid "`on_aggregate_fit` => `aggregate_fit`"
msgstr "`on_aggregate_fit` => `aggregate_fit`"

#: ../../source/ref-changelog.md:1451
msgid ""
"Deprecated `DefaultStrategy` "
"([#479](https://github.com/adap/flower/pull/479)). To migrate use "
"`FedAvg` instead."
msgstr ""
"已废弃的 `DefaultStrategy` ([#479](https://github.com/adap/flower/pull/479)) "
"。迁移时请使用 `FedAvg`。"

#: ../../source/ref-changelog.md:1452
msgid ""
"Simplified examples and baselines "
"([#484](https://github.com/adap/flower/pull/484))."
msgstr "简化示例和baselines（[#484](https://github.com/adap/flower/pull/484)）。"

#: ../../source/ref-changelog.md:1453
msgid ""
"Removed presently unused `on_conclude_round` from strategy interface "
"([#483](https://github.com/adap/flower/pull/483))."
msgstr ""
"删除了策略界面中目前未使用的 "
"\"on_conclude_round\"（[#483](https://github.com/adap/flower/pull/483)）。"

#: ../../source/ref-changelog.md:1454
msgid ""
"Set minimal Python version to 3.6.1 instead of 3.6.9 "
"([#471](https://github.com/adap/flower/pull/471))."
msgstr ""
"将最小 Python 版本设为 3.6.1，而不是 3.6.9 "
"([#471](https://github.com/adap/flower/pull/471))."

#: ../../source/ref-changelog.md:1455
msgid ""
"Improved `Strategy` docstrings "
"([#470](https://github.com/adap/flower/pull/470))."
msgstr ""
"改进了 `Strategy` "
"docstrings（[#470](https://github.com/adap/flower/pull/470)）。"

#: ../../source/ref-example-projects.rst:2
msgid "Example projects"
msgstr "项目实例"

#: ../../source/ref-example-projects.rst:4
msgid ""
"Flower comes with a number of usage examples. The examples demonstrate "
"how Flower can be used to federate different kinds of existing machine "
"learning pipelines, usually leveraging popular machine learning "
"frameworks such as `PyTorch <https://pytorch.org/>`_ or `TensorFlow "
"<https://www.tensorflow.org/>`_."
msgstr ""
"Flower 附带了许多使用示例。这些示例演示了如何使用 Flower 联邦不同类型的现有机器学习形式，通常是利用流行的机器学习框架，如 "
"`PyTorch <https://pytorch.org/>`_ 或 `TensorFlow "
"<https://www.tensorflow.org/>`_。"

#: ../../source/ref-example-projects.rst:9
#, fuzzy
msgid "The following examples are available as standalone projects."
msgstr "以下示例可作为独立项目使用。"

#: ../../source/ref-example-projects.rst:12
#, fuzzy
msgid "Quickstart TensorFlow/Keras"
msgstr "快速入门 TensorFlow"

#: ../../source/ref-example-projects.rst:14
msgid ""
"The TensorFlow/Keras quickstart example shows CIFAR-10 image "
"classification with MobileNetV2:"
msgstr "TensorFlow/Keras 快速入门示例展示了使用 MobileNetV2 进行的 CIFAR-10 图像分类："

#: ../../source/ref-example-projects.rst:17
msgid ""
"`Quickstart TensorFlow (Code) "
"<https://github.com/adap/flower/tree/main/examples/quickstart-"
"tensorflow>`_"
msgstr ""
"`TensorFlow快速入门 (代码) <https://github.com/adap/flower/tree/main/examples"
"/quickstart-tensorflow>`_"

#: ../../source/ref-example-projects.rst:19
#, fuzzy
msgid ":doc:`Quickstart TensorFlow (Tutorial) <tutorial-quickstart-tensorflow>`"
msgstr ""
"`TensorFlow快速入门 (教程) <https://flower.ai/docs/framework/tutorial-"
"quickstart-tensorflow.html>`_"

#: ../../source/ref-example-projects.rst:20
msgid ""
"`Quickstart TensorFlow (Blog Post) <https://flower.ai/blog/2020-12-11"
"-federated-learning-in-less-than-20-lines-of-code>`_"
msgstr ""
"`TensorFlow快速入门 (博客) <https://flower.ai/blog/2020-12-11-federated-"
"learning-in-less-than-20-lines-of-code>`_"

#: ../../source/ref-example-projects.rst:24
#: ../../source/tutorial-quickstart-pytorch.rst:4
msgid "Quickstart PyTorch"
msgstr "PyTorch快速入门"

#: ../../source/ref-example-projects.rst:26
msgid ""
"The PyTorch quickstart example shows CIFAR-10 image classification with a"
" simple Convolutional Neural Network:"
msgstr "PyTorch 快速入门范例展示了使用简单卷积神经网络进行 CIFAR-10 图像分类的情况："

#: ../../source/ref-example-projects.rst:29
msgid ""
"`Quickstart PyTorch (Code) "
"<https://github.com/adap/flower/tree/main/examples/quickstart-pytorch>`_"
msgstr ""
"`PyTorch快速入门 (代码) <https://github.com/adap/flower/tree/main/examples"
"/quickstart-pytorch>`_"

#: ../../source/ref-example-projects.rst:31
#, fuzzy
msgid ":doc:`Quickstart PyTorch (Tutorial) <tutorial-quickstart-pytorch>`"
msgstr ""
"`PyTorch快速入门 (教程) <https://flower.ai/docs/framework/tutorial-quickstart-"
"pytorch.html>`_"

#: ../../source/ref-example-projects.rst:34
msgid "PyTorch: From Centralized To Federated"
msgstr "PyTorch： 从集中式到联邦式"

#: ../../source/ref-example-projects.rst:36
msgid ""
"This example shows how a regular PyTorch project can be federated using "
"Flower:"
msgstr "本例展示了如何使用 Flower 联邦化一个普通的 PyTorch 项目："

#: ../../source/ref-example-projects.rst:38
msgid ""
"`PyTorch: From Centralized To Federated (Code) "
"<https://github.com/adap/flower/tree/main/examples/pytorch-from-"
"centralized-to-federated>`_"
msgstr ""
"PyTorch： 从集中式到联邦式（代码） <https://github.com/adap/flower/tree/main/examples"
"/pytorch-from-centralized-to-federated>`_"

#: ../../source/ref-example-projects.rst:40
#, fuzzy
msgid ""
":doc:`PyTorch: From Centralized To Federated (Tutorial) <example-pytorch-"
"from-centralized-to-federated>`"
msgstr ""
"PyTorch： 从集中式到联邦式（教程） <https://flower.ai/docs/framework/example-pytorch-"
"from-centralized-to-federated.html>`_"

#: ../../source/ref-example-projects.rst:44
msgid "Federated Learning on Raspberry Pi and Nvidia Jetson"
msgstr "树莓派和 Nvidia Jetson 上的联邦学习"

#: ../../source/ref-example-projects.rst:46
msgid ""
"This example shows how Flower can be used to build a federated learning "
"system that run across Raspberry Pi and Nvidia Jetson:"
msgstr "本示例展示了如何利用 Flower 建立一个跨 Raspberry Pi 和 Nvidia Jetson 运行的联邦学习系统："

#: ../../source/ref-example-projects.rst:49
msgid ""
"`Federated Learning on Raspberry Pi and Nvidia Jetson (Code) "
"<https://github.com/adap/flower/tree/main/examples/embedded-devices>`_"
msgstr ""
"Raspberry Pi 和 Nvidia Jetson 上的联邦学习（代码） "
"<https://github.com/adap/flower/tree/main/examples/embedded-devices>`_"

#: ../../source/ref-example-projects.rst:51
msgid ""
"`Federated Learning on Raspberry Pi and Nvidia Jetson (Blog Post) "
"<https://flower.ai/blog/2020-12-16-running_federated_learning_applications_on_embedded_devices_with_flower>`_"
msgstr ""
"Raspberry Pi和 Nvidia Jetson 上的联邦学习（博客） "
"<https://flower.ai/blog/2020-12-16-running_federated_learning_applications_on_embedded_devices_with_flower>`_"

#: ../../source/ref-faq.rst:2
msgid "FAQ"
msgstr "常见问题"

#: ../../source/ref-faq.rst:4
msgid ""
"This page collects answers to commonly asked questions about Federated "
"Learning with Flower."
msgstr "本页收集了有关 \"Flower 联邦学习 \"常见问题的答案。"

#: ../../source/ref-faq.rst
#, fuzzy
msgid ":fa:`eye,mr-1` Can Flower run on Jupyter Notebooks / Google Colab?"
msgstr ":fa:`eye,mr-1` Flower 可以在 Juptyter Notebooks / Google Colab 上运行吗？"

#: ../../source/ref-faq.rst:9
msgid ""
"Yes, it can! Flower even comes with a few under-the-hood optimizations to"
" make it work even better on Colab. Here's a quickstart example:"
msgstr "是的，它可以！Flower 甚至还进行了一些底层优化，使其在 Colab 上运行得更好。下面是一个快速启动示例："

#: ../../source/ref-faq.rst:11
msgid ""
"`Flower simulation PyTorch "
"<https://colab.research.google.com/github/adap/flower/blob/main/examples"
"/simulation-pytorch/sim.ipynb>`_"
msgstr ""
"`Flower 模拟 PyTorch "
"<https://colab.research.google.com/github/adap/flower/blob/main/examples"
"/simulation-pytorch/sim.ipynb>`_"

#: ../../source/ref-faq.rst:12
msgid ""
"`Flower simulation TensorFlow/Keras "
"<https://colab.research.google.com/github/adap/flower/blob/main/examples"
"/simulation-tensorflow/sim.ipynb>`_"
msgstr ""
"`Flower模拟TensorFlow/Keras "
"<https://colab.research.google.com/github/adap/flower/blob/main/examples"
"/simulation-tensorflow/sim.ipynb>`_"

#: ../../source/ref-faq.rst
msgid ":fa:`eye,mr-1` How can I run Federated Learning on a Raspberry Pi?"
msgstr ":fa:`eye,mr-1` 如何在 Raspberry Pi 上运行联邦学习？"

#: ../../source/ref-faq.rst:16
msgid ""
"Find the `blog post about federated learning on embedded device here "
"<https://flower.ai/blog/2020-12-16-running_federated_learning_applications_on_embedded_devices_with_flower>`_"
" and the corresponding `GitHub code example "
"<https://github.com/adap/flower/tree/main/examples/embedded-devices>`_."
msgstr ""
"请点击此处查看有关嵌入式设备联邦学习的 "
"\"博文\"<https://flower.ai/blog/2020-12-16-running_federated_learning_applications_on_embedded_devices_with_flower>`_和相应的"
" \"GitHub 代码示例\"<https://github.com/adap/flower/tree/main/examples"
"/embedded-devices>`_。"

#: ../../source/ref-faq.rst
msgid ":fa:`eye,mr-1` Does Flower support federated learning on Android devices?"
msgstr ":fa:`eye,mr-1` Flower 是否支持安卓设备上的联邦学习？"

#: ../../source/ref-faq.rst:20
msgid ""
"Yes, it does. Please take a look at our `blog post "
"<https://flower.ai/blog/2021-12-15-federated-learning-on-android-devices-"
"with-flower>`_ or check out the code examples:"
msgstr ""
"是的，确实如此。请查看我们的 \"博客文章 <https://flower.ai/blog/2021-12-15-federated-"
"learning-on-android-devices-with-flower>`_\" 或查看代码示例："

#: ../../source/ref-faq.rst:22
msgid ""
"`Android Kotlin example <https://flower.ai/docs/examples/android-"
"kotlin.html>`_"
msgstr "`Android Kotlin 示例 <https://flower.ai/docs/examples/android-kotlin.html>`_"

#: ../../source/ref-faq.rst:23
msgid "`Android Java example <https://flower.ai/docs/examples/android.html>`_"
msgstr "Android Java 示例 <https://flower.ai/docs/examples/android.html>`_"

#: ../../source/ref-faq.rst
msgid ":fa:`eye,mr-1` Can I combine federated learning with blockchain?"
msgstr ":fa:`eye,mr-1` 我可以将联邦学习与区块链结合起来吗？"

#: ../../source/ref-faq.rst:27
msgid ""
"Yes, of course. A list of available examples using Flower within a "
"blockchain environment is available here:"
msgstr "当然可以。有关在区块链环境中使用 Flower 的可用示例列表，请点击此处："

#: ../../source/ref-faq.rst:30
msgid "`FLock: A Decentralised AI Training Platform <https://www.flock.io/#/>`_."
msgstr ""

#: ../../source/ref-faq.rst:30
msgid "Contribute to on-chain training the model and earn rewards."
msgstr ""

#: ../../source/ref-faq.rst:31
#, fuzzy
msgid "Local blockchain with federated learning simulation."
msgstr "扩大联邦学习的规模"

#: ../../source/ref-faq.rst:32
msgid ""
"`Flower meets Nevermined GitHub Repository <https://github.com"
"/nevermined-io/fl-demo/tree/master/image-classification-flower>`_."
msgstr ""
"`Flower meets Nevermined GitHub Repository <https://github.com"
"/nevermined-io/fl-demo/tree/master/image-classification-flower>`_."

#: ../../source/ref-faq.rst:33
msgid ""
"`Flower meets Nevermined YouTube video "
"<https://www.youtube.com/watch?v=A0A9hSlPhKI>`_."
msgstr ""
"`Flower meets Nevermined YouTube 视频 "
"<https://www.youtube.com/watch?v=A0A9hSlPhKI>`_."

#: ../../source/ref-faq.rst:34
#, fuzzy
msgid ""
"`Flower meets KOSMoS <https://www.isw-sites.de/kosmos/wp-"
"content/uploads/sites/13/2021/05/Talk-Flower-Summit-2021.pdf>`_."
msgstr ""
"`Flower meets KOSMoS <https://www.kosmos-bmbf.de/wp-"
"content/uploads/sites/13/2021/05/Talk-Flower-Summit-2021.pdf>`_."

#: ../../source/ref-faq.rst:35
msgid ""
"`Flower meets Talan blog post <https://www.linkedin.com/pulse/federated-"
"learning-same-mask-different-faces-imen-"
"ayari/?trackingId=971oIlxLQ9%2BA9RB0IQ73XQ%3D%3D>`_ ."
msgstr ""
"`Flower meets Talan博文 <https://www.linkedin.com/pulse/federated-learning-"
"same-mask-different-faces-imen-"
"ayari/?trackingId=971oIlxLQ9%2BA9RB0IQ73XQ%3D%3D>`_ 。"

#: ../../source/ref-faq.rst:36
msgid ""
"`Flower meets Talan GitHub Repository "
"<https://gitlab.com/Talan_Innovation_Factory/food-waste-prevention>`_ ."
msgstr ""
"`Flower meets Talan GitHub Repository "
"<https://gitlab.com/Talan_Innovation_Factory/food-waste-prevention>`_ ."

#: ../../source/ref-telemetry.md:1
msgid "Telemetry"
msgstr "遥测功能"

#: ../../source/ref-telemetry.md:3
msgid ""
"The Flower open-source project collects **anonymous** usage metrics to "
"make well-informed decisions to improve Flower. Doing this enables the "
"Flower team to understand how Flower is used and what challenges users "
"might face."
msgstr ""
"Flower 开源项目收集**匿名**使用指标，以便在充分知情的情况下做出改进 Flower 的决定。这样做能让 Flower 团队了解 "
"Flower 的使用情况以及用户可能面临的挑战。"

#: ../../source/ref-telemetry.md:5
msgid ""
"**Flower is a friendly framework for collaborative AI and data science.**"
" Staying true to this statement, Flower makes it easy to disable "
"telemetry for users that do not want to share anonymous usage metrics."
msgstr "**Flower 是一个用于协作式人工智能和数据科学的友好框架。** Flower 遵循这一声明，让不想分享匿名使用指标的用户可以轻松禁用遥测技术。"

#: ../../source/ref-telemetry.md:7
msgid "Principles"
msgstr "原则"

#: ../../source/ref-telemetry.md:9
msgid "We follow strong principles guarding anonymous usage metrics collection:"
msgstr "我们遵循严格的匿名使用指标收集原则："

#: ../../source/ref-telemetry.md:11
msgid ""
"**Optional:** You will always be able to disable telemetry; read on to "
"learn “[How to opt-out](#how-to-opt-out)”."
msgstr "**可选：** 您始终可以禁用遥测功能；请继续阅读\"[如何退出](#how-to-opt-out)\"。"

#: ../../source/ref-telemetry.md:12
msgid ""
"**Anonymous:** The reported usage metrics are anonymous and do not "
"contain any personally identifiable information (PII). See “[Collected "
"metrics](#collected-metrics)” to understand what metrics are being "
"reported."
msgstr ""
"**匿名：** 报告的使用指标是匿名的，不包含任何个人身份信息 (PII)。请参阅\"[收集的指标](#collected-metrics) "
"\"了解报告的指标。"

#: ../../source/ref-telemetry.md:13
msgid ""
"**Transparent:** You can easily inspect what anonymous metrics are being "
"reported; see the section “[How to inspect what is being reported](#how-"
"to-inspect-what-is-being-reported)”"
msgstr ""
"**透明：** 您可以轻松查看正在报告的匿名指标；请参阅\"[如何查看正在报告的指标]（#how-to-inspect-what-is-"
"being-reported）\"部分"

#: ../../source/ref-telemetry.md:14
msgid ""
"**Open for feedback:** You can always reach out to us if you have "
"feedback; see the section “[How to contact us](#how-to-contact-us)” for "
"details."
msgstr "**欢迎反馈：** 如果您有反馈意见，可以随时联系我们；详情请参见\"[如何联系我们](#how-to-contact-us) \"部分。"

#: ../../source/ref-telemetry.md:16
msgid "How to opt-out"
msgstr "如何退出"

#: ../../source/ref-telemetry.md:18
msgid ""
"When Flower starts, it will check for an environment variable called "
"`FLWR_TELEMETRY_ENABLED`. Telemetry can easily be disabled by setting "
"`FLWR_TELEMETRY_ENABLED=0`. Assuming you are starting a Flower server or "
"client, simply do so by prepending your command as in:"
msgstr ""
"Flower 启动时，会检查环境变量 `FLWR_TELEMETRY_ENABLED` 是否存在。通过设置 "
"`FLWR_TELEMETRY_ENABLED=0` 可以轻松禁用遥测功能。假设你启动的是 Flower "
"服务器或客户端，只需在命令前添加以下内容即可："

#: ../../source/ref-telemetry.md:24
msgid ""
"Alternatively, you can export `FLWR_TELEMETRY_ENABLED=0` in, for example,"
" `.bashrc` (or whatever configuration file applies to your environment) "
"to disable Flower telemetry permanently."
msgstr ""
"或者，你也可以在 `.bashrc`（或任何适用于你的环境的配置文件）中导出 `FLWR_TELEMETRY_ENABLED=0` 来永久禁用 "
"Flower telemetry。"

#: ../../source/ref-telemetry.md:26
msgid "Collected metrics"
msgstr "收集的指标"

#: ../../source/ref-telemetry.md:28
msgid "Flower telemetry collects the following metrics:"
msgstr "Flower 遥测技术收集以下指标："

#: ../../source/ref-telemetry.md:30
msgid ""
"**Flower version.** Understand which versions of Flower are currently "
"being used. This helps us to decide whether we should invest effort into "
"releasing a patch version for an older version of Flower or instead use "
"the bandwidth to build new features."
msgstr "**了解目前使用的 Flower 版本。这有助于我们决定是否应该投入精力为旧版本的 Flower 发布补丁版本，还是利用带宽来构建新功能。"

#: ../../source/ref-telemetry.md:32
msgid ""
"**Operating system.** Enables us to answer questions such as: *Should we "
"create more guides for Linux, macOS, or Windows?*"
msgstr "**操作系统**使我们能够回答以下问题： *我们应该为 Linux、macOS 还是 Windows 创建更多指南？*"

#: ../../source/ref-telemetry.md:34
msgid ""
"**Python version.** Knowing the Python version helps us, for example, to "
"decide whether we should invest effort into supporting old versions of "
"Python or stop supporting them and start taking advantage of new Python "
"features."
msgstr "**例如，了解 Python 版本有助于我们决定是否应该投入精力支持旧版本的 Python，还是停止支持这些版本并开始利用新的 Python 功能。"

#: ../../source/ref-telemetry.md:36
msgid ""
"**Hardware properties.** Understanding the hardware environment that "
"Flower is being used in helps to decide whether we should, for example, "
"put more effort into supporting low-resource environments."
msgstr "**硬件属性** 了解 Flower 的硬件使用环境，有助于决定我们是否应在支持低资源环境等方面投入更多精力。"

#: ../../source/ref-telemetry.md:38
msgid ""
"**Execution mode.** Knowing what execution mode Flower starts in enables "
"us to understand how heavily certain features are being used and better "
"prioritize based on that."
msgstr "** 执行模式** 了解 Flower 的启动执行模式，能让我们了解某些功能的使用率，并据此更好地确定优先级。"

#: ../../source/ref-telemetry.md:40
msgid ""
"**Cluster.** Flower telemetry assigns a random in-memory cluster ID each "
"time a Flower workload starts. This allows us to understand which device "
"types not only start Flower workloads but also successfully complete "
"them."
msgstr ""
"**每次 Flower 工作负载启动时，Flower 遥测都会随机分配一个内存集群 ID。这样，我们就能了解哪些设备类型不仅启动了 Flower "
"工作负载，而且还成功完成了它们。"

#: ../../source/ref-telemetry.md:42
msgid ""
"**Source.** Flower telemetry tries to store a random source ID in "
"`~/.flwr/source` the first time a telemetry event is generated. The "
"source ID is important to identify whether an issue is recurring or "
"whether an issue is triggered by multiple clusters running concurrently "
"(which often happens in simulation). For example, if a device runs "
"multiple workloads at the same time, and this results in an issue, then, "
"in order to reproduce the issue, multiple workloads must be started at "
"the same time."
msgstr ""
"**Source.** Flower 遥测会在第一次生成遥测事件时，尝试在 `~/.flwr/source` 中存储一个随机源 ID。源 ID "
"对于识别问题是否反复出现或问题是否由多个集群同时运行触发（这在模拟中经常发生）非常重要。例如，如果设备同时运行多个工作负载并导致问题，那么为了重现问题，必须同时启动多个工作负载。"

#: ../../source/ref-telemetry.md:44
msgid ""
"You may delete the source ID at any time. If you wish for all events "
"logged under a specific source ID to be deleted, you can send a deletion "
"request mentioning the source ID to `telemetry@flower.ai`. All events "
"related to that source ID will then be permanently deleted."
msgstr ""
"您可以随时删除源 ID。如果您希望删除特定源 ID 下记录的所有事件，可以向 `telemetry@flower.ai` 发送删除请求，并提及该源"
" ID。届时，与该源 ID 相关的所有事件都将被永久删除。"

#: ../../source/ref-telemetry.md:46
msgid ""
"We will not collect any personally identifiable information. If you think"
" any of the metrics collected could be misused in any way, please [get in"
" touch with us](#how-to-contact-us). We will update this page to reflect "
"any changes to the metrics collected and publish changes in the "
"changelog."
msgstr ""
"我们不会收集任何个人身份信息。如果您认为所收集的任何指标可能以任何方式被滥用，请[与我们联系]（#how-to-contact-"
"us）。我们将更新本页面，以反映对所收集指标的任何更改，并在更新日志中公布更改内容。"

#: ../../source/ref-telemetry.md:48
msgid ""
"If you think other metrics would be helpful for us to better guide our "
"decisions, please let us know! We will carefully review them; if we are "
"confident that they do not compromise user privacy, we may add them."
msgstr "如果您认为其他指标有助于我们更好地指导决策，请告诉我们！我们将仔细审查这些指标；如果我们确信它们不会损害用户隐私，我们可能会添加这些指标。"

#: ../../source/ref-telemetry.md:50
msgid "How to inspect what is being reported"
msgstr "如何检查报告中的内容"

#: ../../source/ref-telemetry.md:52
msgid ""
"We wanted to make it very easy for you to inspect what anonymous usage "
"metrics are reported. You can view all the reported telemetry information"
" by setting the environment variable `FLWR_TELEMETRY_LOGGING=1`. Logging "
"is disabled by default. You may use logging independently from "
"`FLWR_TELEMETRY_ENABLED` so that you can inspect the telemetry feature "
"without sending any metrics."
msgstr ""
"我们希望能让您轻松查看所报告的匿名使用指标。通过设置环境变量 `FLWR_TELEMETRY_LOGGING=1` "
"可以查看所有报告的遥测信息。日志记录默认为禁用。您可以不使用 `FLWR_TELEMETRY_ENABLED` "
"而单独使用日志记录，这样就可以在不发送任何指标的情况下检查遥测功能。"

#: ../../source/ref-telemetry.md:58
msgid ""
"The inspect Flower telemetry without sending any anonymous usage metrics,"
" use both environment variables:"
msgstr "在不发送任何匿名使用指标的情况下检查 Flower 遥测，可使用这两个环境变量："

#: ../../source/ref-telemetry.md:64
msgid "How to contact us"
msgstr "如何联系我们"

#: ../../source/ref-telemetry.md:66
msgid ""
"We want to hear from you. If you have any feedback or ideas on how to "
"improve the way we handle anonymous usage metrics, reach out to us via "
"[Slack](https://flower.ai/join-slack/) (channel `#telemetry`) or email "
"(`telemetry@flower.ai`)."
msgstr ""
"我们希望听到您的意见。如果您对如何改进我们处理匿名使用指标的方式有任何反馈或想法，请通过 [Slack](https://flower.ai"
"/join-slack/) （频道 `#telemetry`）或电子邮件 (`telemetry@flower.ai`)与我们联系。"

#: ../../source/tutorial-quickstart-android.rst:-1
msgid ""
"Read this Federated Learning quickstart tutorial for creating an Android "
"app using Flower."
msgstr "阅读本联邦学习快速入门教程，了解如何使用 Flower 创建 Android 应用程序。"

#: ../../source/tutorial-quickstart-android.rst:4
msgid "Quickstart Android"
msgstr "快速入门 Android"

#: ../../source/tutorial-quickstart-android.rst:11
msgid ""
"The experimental Flower Android SDK is not compatible with the latest "
"version of Flower. Android support is currently being reworked and will "
"be released in 2025."
msgstr ""

#: ../../source/tutorial-quickstart-android.rst:14
msgid ""
"This quickstart tutorial is kept for historical purposes and will be "
"updated once the new Android SDK is released."
msgstr ""

#: ../../source/tutorial-quickstart-android.rst:17
msgid ""
"Let's build a federated learning system using TFLite and Flower on "
"Android!"
msgstr "让我们在 Android 上使用 TFLite 和 Flower 构建一个联邦学习系统！"

#: ../../source/tutorial-quickstart-android.rst:19
msgid ""
"Please refer to the `full code example "
"<https://github.com/adap/flower/tree/main/examples/android>`_ to learn "
"more."
msgstr ""
"请参阅`完整代码示例 "
"<https://github.com/adap/flower/tree/main/examples/android>`_了解更多信息。"

#: ../../source/tutorial-quickstart-fastai.rst:4
msgid "Quickstart fastai"
msgstr "快速入门 fastai"

#: ../../source/tutorial-quickstart-fastai.rst:6
#, fuzzy
msgid ""
"In this federated learning tutorial we will learn how to train a "
"SqueezeNet model on MNIST using Flower and fastai. It is recommended to "
"create a virtual environment and run everything within a :doc:`virtualenv"
" <contributor-how-to-set-up-a-virtual-env>`."
msgstr ""
"首先，建议创建一个虚拟环境，并在 `virtualenv <https://flower.ai/docs/recommended-env-"
"setup.html>`_ 中运行一切。"

#: ../../source/tutorial-quickstart-fastai.rst:10
#: ../../source/tutorial-quickstart-pytorch-lightning.rst:11
msgid "Then, clone the code example directly from GitHub:"
msgstr ""

#: ../../source/tutorial-quickstart-fastai.rst:18
msgid ""
"This will create a new directory called `quickstart-fastai` containing "
"the following files:"
msgstr ""

#: ../../source/tutorial-quickstart-fastai.rst:31
#: ../../source/tutorial-quickstart-pytorch-lightning.rst:32
#, fuzzy
msgid "Next, activate your environment, then run:"
msgstr "并激活虚拟环境："

#: ../../source/tutorial-quickstart-fastai.rst:41
msgid ""
"This example by default runs the Flower Simulation Engine, creating a "
"federation of 10 nodes using `FedAvg <https://flower.ai/docs/framework"
"/ref-api/flwr.server.strategy.FedAvg.html#flwr.server.strategy.FedAvg>`_ "
"as the aggregation strategy. The dataset will be partitioned using Flower"
" Dataset's `IidPartitioner <https://flower.ai/docs/datasets/ref-"
"api/flwr_datasets.partitioner.IidPartitioner.html#flwr_datasets.partitioner.IidPartitioner>`_."
" Let's run the project:"
msgstr ""

#: ../../source/tutorial-quickstart-fastai.rst:54
#: ../../source/tutorial-quickstart-huggingface.rst:61
#: ../../source/tutorial-quickstart-jax.rst:60
#: ../../source/tutorial-quickstart-mlx.rst:60
#: ../../source/tutorial-quickstart-pytorch-lightning.rst:55
#: ../../source/tutorial-quickstart-pytorch.rst:62
#: ../../source/tutorial-quickstart-scikitlearn.rst:59
#: ../../source/tutorial-quickstart-tensorflow.rst:62
#: ../../source/tutorial-quickstart-xgboost.rst:492
msgid "With default arguments you will see an output like this one:"
msgstr ""

#: ../../source/tutorial-quickstart-fastai.rst:98
#: ../../source/tutorial-quickstart-huggingface.rst:112
#: ../../source/tutorial-quickstart-jax.rst:102
#: ../../source/tutorial-quickstart-pytorch-lightning.rst:105
#: ../../source/tutorial-quickstart-pytorch.rst:103
#: ../../source/tutorial-quickstart-scikitlearn.rst:101
#: ../../source/tutorial-quickstart-tensorflow.rst:103
#: ../../source/tutorial-quickstart-xgboost.rst:537
msgid ""
"You can also override the parameters defined in the "
"``[tool.flwr.app.config]`` section in ``pyproject.toml`` like this:"
msgstr ""

#: ../../source/tutorial-quickstart-fastai.rst:108
#, fuzzy
msgid ""
"Check the `source code <https://github.com/adap/flower/tree/main/examples"
"/quickstart-fastai>`_ of this tutorial in ``examples/quickstart-fasai`` "
"in the Flower GitHub repository."
msgstr ""
"此示例的`完整源代码 <https://github.com/adap/flower/blob/main/examples/xgboost-"
"quickstart/>`_ 可在 :code:`examples/xgboost-quickstart` 中找到。"

#: ../../source/tutorial-quickstart-huggingface.rst:-1
#, fuzzy
msgid ""
"Check out this Federating Learning quickstart tutorial for using Flower "
"with 🤗 HuggingFace Transformers in order to fine-tune an LLM."
msgstr "查看此联邦学习 快速入门教程，了解如何使用 Flower 和 HuggingFace Transformers 来微调 LLM。"

#: ../../source/tutorial-quickstart-huggingface.rst:4
msgid "Quickstart 🤗 Transformers"
msgstr "🤗 Transformers快速入门"

#: ../../source/tutorial-quickstart-huggingface.rst:6
#, fuzzy
msgid ""
"In this federated learning tutorial we will learn how to train a large "
"language model (LLM) on the `IMDB "
"<https://huggingface.co/datasets/stanfordnlp/imdb>`_ dataset using Flower"
" and the 🤗 Hugging Face Transformers library. It is recommended to create"
" a virtual environment and run everything within a :doc:`virtualenv "
"<contributor-how-to-set-up-a-virtual-env>`."
msgstr ""
"首先，建议创建一个虚拟环境，并在 `virtualenv <https://flower.ai/docs/recommended-env-"
"setup.html>`_ 中运行一切。"

#: ../../source/tutorial-quickstart-huggingface.rst:12
msgid ""
"Let's use ``flwr new`` to create a complete Flower+🤗 Hugging Face "
"project. It will generate all the files needed to run, by default with "
"the Flower Simulation Engine, a federation of 10 nodes using |fedavg|_ "
"The dataset will be partitioned using |flowerdatasets|_'s "
"|iidpartitioner|_."
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:17
#: ../../source/tutorial-quickstart-jax.rst:16
#: ../../source/tutorial-quickstart-mlx.rst:17
#: ../../source/tutorial-quickstart-pytorch.rst:18
#: ../../source/tutorial-quickstart-scikitlearn.rst:15
#: ../../source/tutorial-quickstart-tensorflow.rst:18
#, fuzzy
msgid ""
"Now that we have a rough idea of what this example is about, let's get "
"started. First, install Flower in your new environment:"
msgstr "现在，我们已经有了一个大致的概念，让我们开始吧。首先，我们需要安装 Flower。运行："

#: ../../source/tutorial-quickstart-huggingface.rst:25
msgid ""
"Then, run the command below. You will be prompted to select one of the "
"available templates (choose ``HuggingFace``), give a name to your "
"project, and type in your developer name:"
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:33
#: ../../source/tutorial-quickstart-jax.rst:32
#: ../../source/tutorial-quickstart-mlx.rst:32
#: ../../source/tutorial-quickstart-pytorch.rst:34
#: ../../source/tutorial-quickstart-scikitlearn.rst:31
#: ../../source/tutorial-quickstart-tensorflow.rst:34
msgid ""
"After running it you'll notice a new directory with your project name has"
" been created. It should have the following structure:"
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:47
#: ../../source/tutorial-quickstart-jax.rst:46
#: ../../source/tutorial-quickstart-mlx.rst:46
#: ../../source/tutorial-quickstart-pytorch.rst:48
#: ../../source/tutorial-quickstart-scikitlearn.rst:45
#: ../../source/tutorial-quickstart-tensorflow.rst:48
msgid ""
"If you haven't yet installed the project and its dependencies, you can do"
" so by:"
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:54
#: ../../source/tutorial-quickstart-jax.rst:53
#: ../../source/tutorial-quickstart-pytorch.rst:55
#: ../../source/tutorial-quickstart-scikitlearn.rst:52
#: ../../source/tutorial-quickstart-tensorflow.rst:55
#: ../../source/tutorial-quickstart-xgboost.rst:485
msgid "To run the project, do:"
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:102
msgid "You can also run the project with GPU as follows:"
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:109
msgid ""
"This will use the default arguments where each ``ClientApp`` will use 2 "
"CPUs and at most 4 ``ClientApp``\\s will run in a given GPU."
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:120
#: ../../source/tutorial-quickstart-jax.rst:110
#: ../../source/tutorial-quickstart-mlx.rst:110
#: ../../source/tutorial-quickstart-pytorch.rst:111
#: ../../source/tutorial-quickstart-scikitlearn.rst:109
msgid ""
"What follows is an explanation of each component in the project you just "
"created: dataset partition, the model, defining the ``ClientApp`` and "
"defining the ``ServerApp``."
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:124
#: ../../source/tutorial-quickstart-jax.rst:114
#: ../../source/tutorial-quickstart-mlx.rst:114
#: ../../source/tutorial-quickstart-pytorch.rst:115
#: ../../source/tutorial-quickstart-scikitlearn.rst:113
#: ../../source/tutorial-quickstart-tensorflow.rst:112
#: ../../source/tutorial-quickstart-xgboost.rst:89
#, fuzzy
msgid "The Data"
msgstr "加载数据"

#: ../../source/tutorial-quickstart-huggingface.rst:126
msgid ""
"This tutorial uses |flowerdatasets|_ to easily download and partition the"
" `IMDB <https://huggingface.co/datasets/stanfordnlp/imdb>`_ dataset. In "
"this example you'll make use of the |iidpartitioner|_ to generate "
"``num_partitions`` partitions. You can choose |otherpartitioners|_ "
"available in Flower Datasets. To tokenize the text, we will also load the"
" tokenizer from the pre-trained Transformer model that we'll use during "
"training - more on that in the next section. Each ``ClientApp`` will call"
" this function to create dataloaders with the data that correspond to "
"their data partition."
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:171
#: ../../source/tutorial-quickstart-jax.rst:128
#: ../../source/tutorial-quickstart-mlx.rst:155
#: ../../source/tutorial-quickstart-pytorch.rst:150
#: ../../source/tutorial-quickstart-scikitlearn.rst:138
#: ../../source/tutorial-quickstart-tensorflow.rst:139
#, fuzzy
msgid "The Model"
msgstr "训练模型"

#: ../../source/tutorial-quickstart-huggingface.rst:173
#, fuzzy
msgid ""
"We will leverage 🤗 Hugging Face to federate the training of language "
"models over multiple clients using Flower. More specifically, we will "
"fine-tune a pre-trained Transformer model (|berttiny|_) for sequence "
"classification over the dataset of IMDB ratings. The end goal is to "
"detect if a movie rating is positive or negative. If you have access to "
"larger GPUs, feel free to use larger models!"
msgstr ""
"我们将利用Hugging Face技术，使用 Flower 在多个客户端上联邦训练语言模型。更具体地说，我们将对预先训练好的 "
"Transformer 模型（distilBERT）进行微调，以便在 IMDB 评分数据集上进行序列分类。最终目标是检测电影评分是正面还是负面。"

#: ../../source/tutorial-quickstart-huggingface.rst:185
msgid ""
"Note that here, ``model_name`` is a string that will be loaded from the "
"``Context`` in the ClientApp and ServerApp."
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:188
msgid ""
"In addition to loading the pretrained model weights and architecture, we "
"also include two utility functions to perform both training (i.e. "
"``train()``) and evaluation (i.e. ``test()``) using the above model. "
"These functions should look fairly familiar if you have some prior "
"experience with PyTorch. Note these functions do not have anything "
"specific to Flower. That being said, the training function will normally "
"be called, as we'll see later, from a Flower client passing its own data."
" In summary, your clients can use standard training/testing functions to "
"perform local training or evaluation:"
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:228
#: ../../source/tutorial-quickstart-jax.rst:170
#: ../../source/tutorial-quickstart-mlx.rst:199
#: ../../source/tutorial-quickstart-pytorch.rst:224
#: ../../source/tutorial-quickstart-scikitlearn.rst:157
#: ../../source/tutorial-quickstart-tensorflow.rst:168
#: ../../source/tutorial-quickstart-xgboost.rst:149
#, fuzzy
msgid "The ClientApp"
msgstr "客户端"

#: ../../source/tutorial-quickstart-huggingface.rst:230
msgid ""
"The main changes we have to make to use 🤗 Hugging Face with Flower will "
"be found in the ``get_weights()`` and ``set_weights()`` functions. Under "
"the hood, the ``transformers`` library uses PyTorch, which means we can "
"reuse the ``get_weights()`` and ``set_weights()`` code that we defined in"
" the :doc:`Quickstart PyTorch <tutorial-quickstart-pytorch>` tutorial. As"
" a reminder, in ``get_weights()``, PyTorch model parameters are extracted"
" and represented as a list of NumPy arrays. The ``set_weights()`` "
"function that's the opposite: given a list of NumPy arrays it applies "
"them to an existing PyTorch model. Doing this in fairly easy in PyTorch."
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:241
#: ../../source/tutorial-quickstart-pytorch.rst:234
msgid ""
"The specific implementation of ``get_weights()`` and ``set_weights()`` "
"depends on the type of models you use. The ones shown below work for a "
"wide range of PyTorch models but you might need to adjust them if you "
"have more exotic model architectures."
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:257
#: ../../source/tutorial-quickstart-jax.rst:197
#: ../../source/tutorial-quickstart-pytorch.rst:250
msgid ""
"The rest of the functionality is directly inspired by the centralized "
"case. The ``fit()`` method in the client trains the model using the local"
" dataset. Similarly, the ``evaluate()`` method is used to evaluate the "
"model received on a held-out validation set that the client might have:"
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:283
msgid ""
"Finally, we can construct a ``ClientApp`` using the ``FlowerClient`` "
"defined above by means of a ``client_fn()`` callback. Note that the "
"`context` enables you to get access to hyperparemeters defined in your "
"``pyproject.toml`` to configure the run. In this tutorial we access the "
"``local-epochs`` setting to control the number of epochs a ``ClientApp`` "
"will perform when running the ``fit()`` method. You could define "
"additional hyperparameters in ``pyproject.toml`` and access them here."
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:316
#: ../../source/tutorial-quickstart-jax.rst:246
#: ../../source/tutorial-quickstart-mlx.rst:361
#: ../../source/tutorial-quickstart-pytorch.rst:307
#: ../../source/tutorial-quickstart-scikitlearn.rst:255
#: ../../source/tutorial-quickstart-tensorflow.rst:232
#: ../../source/tutorial-quickstart-xgboost.rst:269
#, fuzzy
msgid "The ServerApp"
msgstr "服务器"

#: ../../source/tutorial-quickstart-huggingface.rst:318
msgid ""
"To construct a ``ServerApp`` we define a ``server_fn()`` callback with an"
" identical signature to that of ``client_fn()`` but the return type is "
"|serverappcomponents|_ as opposed to a |client|_ In this example we use "
"the `FedAvg` strategy. To it we pass a randomly initialized model that "
"will server as the global model to federated. Note that the value of "
"``fraction_fit`` is read from the run config. You can find the default "
"value defined in the ``pyproject.toml``."
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:356
msgid ""
"Congratulations! You've successfully built and run your first federated "
"learning system for an LLM."
msgstr ""

#: ../../source/tutorial-quickstart-huggingface.rst:361
msgid ""
"Check the source code of the extended version of this tutorial in "
"|quickstart_hf_link|_ in the Flower GitHub repository. For a "
"comprehensive example of a federated fine-tuning of an LLM with Flower, "
"refer to the |flowertune|_ example in the Flower GitHub repository."
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:-1
msgid ""
"Read this Federated Learning quickstart tutorial for creating an iOS app "
"using Flower to train a neural network on MNIST."
msgstr "阅读本联邦学习快速入门教程，了解如何使用 Flower 创建 iOS 应用程序，并在 MNIST 上训练神经网络。"

#: ../../source/tutorial-quickstart-ios.rst:4
msgid "Quickstart iOS"
msgstr "快速入门 iOS"

#: ../../source/tutorial-quickstart-ios.rst:11
msgid ""
"The experimental Flower iOS SDK is not compatible with the latest version"
" of Flower. iOS support is currently being reworked and will be released "
"in 2025."
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:14
msgid ""
"This quickstart tutorial is kept for historical purposes and will be "
"updated once the new iOS SDK is released."
msgstr ""

#: ../../source/tutorial-quickstart-ios.rst:17
msgid ""
"In this tutorial we will learn how to train a Neural Network on MNIST "
"using Flower and CoreML on iOS devices."
msgstr "在本教程中，我们将学习如何在 iOS 设备上使用 Flower 和 CoreML 在 MNIST 上训练神经网络。"

#: ../../source/tutorial-quickstart-ios.rst:20
#, fuzzy
msgid ""
"First of all, for running the Flower Python server, it is recommended to "
"create a virtual environment and run everything within a :doc:`virtualenv"
" <contributor-how-to-set-up-a-virtual-env>`. For the Flower client "
"implementation in iOS, it is recommended to use Xcode as our IDE."
msgstr ""
"首先，为了运行 Flower Python 服务器，建议创建一个虚拟环境，并在 `virtualenv "
"<https://flower.ai/docs/recommended-env-setup.html>`_ 中运行一切。对于在 iOS 中实现 "
"Flower 客户端，建议使用 Xcode 作为我们的集成开发环境。"

#: ../../source/tutorial-quickstart-ios.rst:25
msgid ""
"Our example consists of one Python *server* and two iPhone *clients* that"
" all have the same model."
msgstr "我们的示例包括一个 Python *服务器*和两个 iPhone *客户端*，它们都具有相同的模型。"

#: ../../source/tutorial-quickstart-ios.rst:28
msgid ""
"*Clients* are responsible for generating individual weight updates for "
"the model based on their local datasets. These updates are then sent to "
"the *server* which will aggregate them to produce a better model. "
"Finally, the *server* sends this improved version of the model back to "
"each *client*. A complete cycle of weight updates is called a *round*."
msgstr "*客户端*负责根据其本地数据集为模型生成独立的模型参数。然后，这些参数更新会被发送到*服务器*，由*服务器*汇总后生成一个更好的模型。最后，*服务器*将改进后的模型发送回每个*客户端*。一个完整的参数更新周期称为一*轮*。"

#: ../../source/tutorial-quickstart-ios.rst:34
msgid ""
"Now that we have a rough idea of what is going on, let's get started to "
"setup our Flower server environment. We first need to install Flower. You"
" can do this by using pip:"
msgstr "现在我们已经有了一个大致的概念，让我们开始设置 Flower 服务器环境吧。首先，我们需要安装 Flower。你可以使用 pip 来安装："

#: ../../source/tutorial-quickstart-ios.rst:41
msgid "Or Poetry:"
msgstr "或者Poetry："

#: ../../source/tutorial-quickstart-ios.rst:48
msgid "Flower Client"
msgstr "Flower 客户端"

#: ../../source/tutorial-quickstart-ios.rst:50
msgid ""
"Now that we have all our dependencies installed, let's run a simple "
"distributed training using CoreML as our local training pipeline and "
"MNIST as our dataset. For simplicity reasons we will use the complete "
"Flower client with CoreML, that has been implemented and stored inside "
"the Swift SDK. The client implementation can be seen below:"
msgstr ""
"现在我们已经安装了所有依赖项，让我们使用 CoreML 作为本地训练框架和 MNIST "
"作为数据集，运行一个简单的分布式训练。为了简单起见，我们将使用 CoreML 的完整 Flower 客户端，该客户端已在 Swift SDK "
"中实现并存储。客户端实现如下："

#: ../../source/tutorial-quickstart-ios.rst:88
#, fuzzy
msgid ""
"Let's create a new application project in Xcode and add ``flwr`` as a "
"dependency in your project. For our application, we will store the logic "
"of our app in ``FLiOSModel.swift`` and the UI elements in "
"``ContentView.swift``. We will focus more on ``FLiOSModel.swift`` in this"
" quickstart. Please refer to the `full code example "
"<https://github.com/adap/flower/tree/main/examples/ios>`_ to learn more "
"about the app."
msgstr ""
"让我们在 Xcode 中创建一个新的应用程序项目，并在项目中添加 :code:`flwr` 作为依赖关系。对于我们的应用程序，我们将在 "
":code:`FLiOSModel.swift` 中存储应用程序的逻辑，在 :code:`ContentView.swift` 中存储 UI "
"元素。在本快速入门中，我们将更多地关注 :code:`FLiOSModel.swift`。请参阅 `完整代码示例 "
"<https://github.com/adap/flower/tree/main/examples/ios>`_ 以了解更多有关应用程序的信息。"

#: ../../source/tutorial-quickstart-ios.rst:94
#, fuzzy
msgid "Import Flower and CoreML related packages in ``FLiOSModel.swift``:"
msgstr "在 :code:`FLiOSModel.swift` 中导入 Flower 和 CoreML 相关软件包："

#: ../../source/tutorial-quickstart-ios.rst:102
#, fuzzy
msgid ""
"Then add the mlmodel to the project simply by drag-and-drop, the mlmodel "
"will be bundled inside the application during deployment to your iOS "
"device. We need to pass the url to access mlmodel and run CoreML machine "
"learning processes, it can be retrieved by calling the function "
"``Bundle.main.url``. For the MNIST dataset, we need to preprocess it into"
" ``MLBatchProvider`` object. The preprocessing is done inside "
"``DataLoader.swift``."
msgstr ""
"然后通过拖放将 mlmodel 添加到项目中，在部署到 iOS 设备时，mlmodel 将被捆绑到应用程序中。我们需要传递 url 以访问 "
"mlmodel 并运行 CoreML 机器学习进程，可通过调用函数 :code:`Bundle.main.url` 获取。对于 MNIST "
"数据集，我们需要将其预处理为 :code:`MLBatchProvider` 对象。预处理在 :code:`DataLoader.swift` "
"中完成。"

#: ../../source/tutorial-quickstart-ios.rst:120
#, fuzzy
msgid ""
"Since CoreML does not allow the model parameters to be seen before "
"training, and accessing the model parameters during or after the training"
" can only be done by specifying the layer name, we need to know this "
"information beforehand, through looking at the model specification, which"
" are written as proto files. The implementation can be seen in "
"``MLModelInspect``."
msgstr ""
"由于 CoreML 不允许在训练前查看模型参数，而在训练过程中或训练后访问模型参数只能通过指定层名来完成，因此我们需要事先通过查看模型规范（写成 "
"proto 文件）来了解这些信息。具体实现可参见 :code:`MLModelInspect`。"

#: ../../source/tutorial-quickstart-ios.rst:126
#, fuzzy
msgid ""
"After we have all of the necessary information, let's create our Flower "
"client."
msgstr "获得所有必要信息后，让我们创建 Flower 客户端。"

#: ../../source/tutorial-quickstart-ios.rst:141
#, fuzzy
msgid ""
"Then start the Flower gRPC client and start communicating to the server "
"by passing our Flower client to the function ``startFlwrGRPC``."
msgstr "然后启动 Flower gRPC 客户端，并通过将 Flower 客户端传递给函数 :code:`startFlwrGRPC` 来开始与服务器通信。"

#: ../../source/tutorial-quickstart-ios.rst:149
#, fuzzy
msgid ""
"That's it for the client. We only have to implement ``Client`` or call "
"the provided ``MLFlwrClient`` and call ``startFlwrGRPC()``. The attribute"
" ``hostname`` and ``port`` tells the client which server to connect to. "
"This can be done by entering the hostname and port in the application "
"before clicking the start button to start the federated learning process."
msgstr ""
"这就是客户端。我们只需实现 :code:`Client` 或调用提供的 :code:`MLFlwrClient` 并调用 "
":code:`startFlwrGRPC()`。属性 :code:`hostname` 和 :code:`port` "
"会告诉客户端要连接到哪个服务器。这可以通过在应用程序中输入主机名和端口来实现，然后再点击开始按钮启动联邦学习进程。"

#: ../../source/tutorial-quickstart-ios.rst:156
msgid "Flower Server"
msgstr "Flower 服务器"

#: ../../source/tutorial-quickstart-ios.rst:158
#, fuzzy
msgid ""
"For simple workloads we can start a Flower server and leave all the "
"configuration possibilities at their default values. In a file named "
"``server.py``, import Flower and start the server:"
msgstr ""
"对于简单的工作负载，我们可以启动 Flower 服务器，并将所有配置选项保留为默认值。在名为 :code:`server.py` 的文件中，导入 "
"Flower 并启动服务器："

#: ../../source/tutorial-quickstart-ios.rst:169
msgid "Train the model, federated!"
msgstr "联邦训练模型！"

#: ../../source/tutorial-quickstart-ios.rst:171
msgid ""
"With both client and server ready, we can now run everything and see "
"federated learning in action. FL systems usually have a server and "
"multiple clients. We therefore have to start the server first:"
msgstr "客户端和服务器都已准备就绪，我们现在可以运行一切，看看联邦学习的实际效果。FL 系统通常有一个服务器和多个客户端。因此，我们必须先启动服务器："

#: ../../source/tutorial-quickstart-ios.rst:179
msgid ""
"Once the server is running we can start the clients in different "
"terminals. Build and run the client through your Xcode, one through Xcode"
" Simulator and the other by deploying it to your iPhone. To see more "
"about how to deploy your app to iPhone or Simulator visit `here "
"<https://developer.apple.com/documentation/xcode/running-your-app-in-"
"simulator-or-on-a-device>`_."
msgstr ""
"服务器运行后，我们就可以在不同的终端启动客户端。通过 Xcode 构建并运行客户端，一个通过 Xcode 模拟器，另一个通过部署到 "
"iPhone。要了解更多有关如何将应用程序部署到 iPhone 或模拟器的信息，请访问 `此处 "
"<https://developer.apple.com/documentation/xcode/running-your-app-in-"
"simulator-or-on-a-device>`_。"

#: ../../source/tutorial-quickstart-ios.rst:185
#, fuzzy
msgid ""
"Congratulations! You've successfully built and run your first federated "
"learning system in your ios device. The full `source code "
"<https://github.com/adap/flower/blob/main/examples/ios>`_ for this "
"example can be found in ``examples/ios``."
msgstr ""
"恭喜您！ 您已经成功地在 ios 设备中构建并运行了第一个联邦学习系统。本示例的`完整源代码 "
"<https://github.com/adap/flower/blob/main/examples/ios>`_ 可在 "
":code:`examples/ios` 中找到。"

#: ../../source/tutorial-quickstart-jax.rst:-1
msgid ""
"Check out this Federated Learning quickstart tutorial for using Flower "
"with Jax to train a linear regression model on a scikit-learn dataset."
msgstr "查看此联邦学习快速入门教程，了解如何使用 Flower 和 Jax 在 scikit-learn 数据集上训练线性回归模型。"

#: ../../source/tutorial-quickstart-jax.rst:4
msgid "Quickstart JAX"
msgstr "快速入门 JAX"

#: ../../source/tutorial-quickstart-jax.rst:6
#, fuzzy
msgid ""
"In this federated learning tutorial we will learn how to train a linear "
"regression model using Flower and `JAX "
"<https://jax.readthedocs.io/en/latest/>`_. It is recommended to create a "
"virtual environment and run everything within a :doc:`virtualenv "
"<contributor-how-to-set-up-a-virtual-env>`."
msgstr ""
"首先，建议创建一个虚拟环境，并在 `virtualenv <https://flower.ai/docs/recommended-env-"
"setup.html>`_ 中运行一切。"

#: ../../source/tutorial-quickstart-jax.rst:11
msgid ""
"Let's use ``flwr new`` to create a complete Flower+JAX project. It will "
"generate all the files needed to run, by default with the Flower "
"Simulation Engine, a federation of 10 nodes using |fedavg|_. A random "
"regression dataset will be loaded from scikit-learn's |makeregression|_ "
"function."
msgstr ""

#: ../../source/tutorial-quickstart-jax.rst:24
msgid ""
"Then, run the command below. You will be prompted to select one of the "
"available templates (choose ``JAX``), give a name to your project, and "
"type in your developer name:"
msgstr ""

#: ../../source/tutorial-quickstart-jax.rst:116
msgid ""
"This tutorial uses scikit-learn's |makeregression|_ function to generate "
"a random regression problem."
msgstr ""

#: ../../source/tutorial-quickstart-jax.rst:130
msgid ""
"We defined a simple linear regression model to demonstrate how to create "
"a JAX model, but feel free to replace it with a more sophisticated JAX "
"model if you'd like, (such as with NN-based `Flax "
"<https://flax.readthedocs.io/en/latest/index.html>`_):"
msgstr ""

#: ../../source/tutorial-quickstart-jax.rst:141
msgid ""
"In addition to defining the model architecture, we also include two "
"utility functions to perform both training (i.e. ``train()``) and "
"evaluation (i.e. ``evaluation()``) using the above model."
msgstr ""

#: ../../source/tutorial-quickstart-jax.rst:172
msgid ""
"The main changes we have to make to use JAX with Flower will be found in "
"the ``get_params()`` and ``set_params()`` functions. In ``get_params()``,"
" JAX model parameters are extracted and represented as a list of NumPy "
"arrays. The ``set_params()`` function is the opposite: given a list of "
"NumPy arrays it applies them to an existing JAX model."
msgstr ""

#: ../../source/tutorial-quickstart-jax.rst:180
msgid ""
"The ``get_params()`` and ``set_params()`` functions here are conceptually"
" similar to the ``get_weights()`` and ``set_weights()`` functions that we"
" defined in the :doc:`QuickStart PyTorch <tutorial-quickstart-pytorch>` "
"tutorial."
msgstr ""

#: ../../source/tutorial-quickstart-jax.rst:227
msgid ""
"Finally, we can construct a ``ClientApp`` using the ``FlowerClient`` "
"defined above by means of a ``client_fn()`` callback. Note that the "
"`context` enables you to get access to hyperparemeters defined in your "
"``pyproject.toml`` to configure the run. In this tutorial we access the "
"``local-epochs`` setting to control the number of epochs a ``ClientApp`` "
"will perform when running the ``fit()`` method. You could define "
"additioinal hyperparameters in ``pyproject.toml`` and access them here."
msgstr ""

#: ../../source/tutorial-quickstart-jax.rst:248
msgid ""
"To construct a ``ServerApp`` we define a ``server_fn()`` callback with an"
" identical signature to that of ``client_fn()`` but the return type is "
"|serverappcomponents|_ as opposed to a |client|_ In this example we use "
"the ``FedAvg`` strategy. To it we pass a randomly initialized model that "
"will server as the global model to federated. Note that the value of "
"``input_dim`` is read from the run config. You can find the default value"
" defined in the ``pyproject.toml``."
msgstr ""

#: ../../source/tutorial-quickstart-jax.rst:276
msgid ""
"Congratulations! You've successfully built and run your first federated "
"learning system for JAX with Flower!"
msgstr ""

#: ../../source/tutorial-quickstart-jax.rst:281
#, fuzzy
msgid ""
"Check the source code of the extended version of this tutorial in "
"|quickstart_jax_link|_ in the Flower GitHub repository."
msgstr ""
"此示例的`完整源代码 <https://github.com/adap/flower/blob/main/examples/xgboost-"
"quickstart/>`_ 可在 :code:`examples/xgboost-quickstart` 中找到。"

#: ../../source/tutorial-quickstart-mlx.rst:4
#, fuzzy
msgid "Quickstart MLX"
msgstr "快速入门 JAX"

#: ../../source/tutorial-quickstart-mlx.rst:6
#, fuzzy
msgid ""
"In this federated learning tutorial we will learn how to train simple MLP"
" on MNIST using Flower and MLX. It is recommended to create a virtual "
"environment and run everything within a :doc:`virtualenv <contributor-"
"how-to-set-up-a-virtual-env>`."
msgstr ""
"首先，建议创建一个虚拟环境，并在 `virtualenv <https://flower.ai/docs/recommended-env-"
"setup.html>`_ 中运行一切。"

#: ../../source/tutorial-quickstart-mlx.rst:10
msgid ""
"Let's use `flwr new` to create a complete Flower+MLX project. It will "
"generate all the files needed to run, by default with the Simulation "
"Engine, a federation of 10 nodes using `FedAvg "
"<https://flower.ai/docs/framework/ref-"
"api/flwr.server.strategy.FedAvg.html#flwr.server.strategy.FedAvg>`_. The "
"dataset will be partitioned using Flower Dataset's `IidPartitioner "
"<https://flower.ai/docs/datasets/ref-"
"api/flwr_datasets.partitioner.IidPartitioner.html#flwr_datasets.partitioner.IidPartitioner>`_."
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:25
msgid ""
"Then, run the command below. You will be prompted to select of the "
"available templates (choose ``MLX``), give a name to your project, and "
"type in your developer name:"
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:53
msgid "To run the project do:"
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:102
msgid ""
"You can also override the parameters defined in "
"``[tool.flwr.app.config]`` section in the ``pyproject.toml`` like this:"
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:116
msgid ""
"We will use `Flower Datasets <https://flower.ai/docs/datasets/>`_ to "
"easily download and partition the `MNIST` dataset. In this example you'll"
" make use of the `IidPartitioner <https://flower.ai/docs/datasets/ref-"
"api/flwr_datasets.partitioner.IidPartitioner.html#flwr_datasets.partitioner.IidPartitioner>`_"
" to generate `num_partitions` partitions. You can choose `other "
"partitioners <https://flower.ai/docs/datasets/ref-"
"api/flwr_datasets.partitioner.html>`_ available in Flower Datasets:"
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:157
msgid ""
"We define the model as in the `centralized MLX example "
"<https://github.com/ml-explore/mlx-examples/tree/main/mnist>`_, it's a "
"simple MLP:"
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:180
msgid ""
"We also define some utility functions to test our model and to iterate "
"over batches."
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:201
msgid ""
"The main changes we have to make to use `MLX` with `Flower` will be found"
" in the ``get_params()`` and ``set_params()`` functions. Indeed, MLX "
"doesn't provide an easy way to convert the model parameters into a list "
"of ``np.array`` objects (the format we need for the serialization of the "
"messages to work)."
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:206
msgid "The way MLX stores its parameters is as follows:"
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:219
msgid ""
"Therefore, to get our list of ``np.array`` objects, we need to extract "
"each array and convert them into a NumPy array:"
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:228
msgid ""
"For the ``set_params()`` function, we perform the reverse operation. We "
"receive a list of NumPy arrays and want to convert them into MLX "
"parameters. Therefore, we iterate through pairs of parameters and assign "
"them to the `weight` and `bias` keys of each layer dict:"
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:243
msgid ""
"The rest of the functionality is directly inspired by the centralized "
"case. The ``fit()`` method in the client trains the model using the local"
" dataset:"
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:259
msgid ""
"Here, after updating the parameters, we perform the training as in the "
"centralized case, and return the new parameters."
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:262
msgid "And for the ``evaluate()`` method of the client:"
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:272
msgid ""
"We also begin by updating the parameters with the ones sent by the "
"server, and then we compute the loss and accuracy using the functions "
"defined above. In the constructor of the ``FlowerClient`` we instantiate "
"the `MLP` model as well as other components such as the optimizer."
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:277
#, fuzzy
msgid "Putting everything together we have:"
msgstr "把所有东西放在一起"

#: ../../source/tutorial-quickstart-mlx.rst:331
msgid ""
"Finally, we can construct a ``ClientApp`` using the ``FlowerClient`` "
"defined above by means of a ``client_fn()`` callback. Note that "
"``context`` enables you to get access to hyperparemeters defined in "
"``pyproject.toml`` to configure the run. In this tutorial we access, "
"among other hyperparameters, the ``local-epochs`` setting to control the "
"number of epochs a ``ClientApp`` will perform when running the ``fit()`` "
"method."
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:363
msgid ""
"To construct a ``ServerApp``, we define a ``server_fn()`` callback with "
"an identical signature to that of ``client_fn()``, but the return type is"
" `ServerAppComponents <https://flower.ai/docs/framework/ref-"
"api/flwr.server.ServerAppComponents.html#serverappcomponents>`_ as "
"opposed to `Client <https://flower.ai/docs/framework/ref-"
"api/flwr.client.Client.html#client>`_. In this example we use the "
"``FedAvg`` strategy."
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:386
#: ../../source/tutorial-quickstart-pytorch.rst:344
#: ../../source/tutorial-quickstart-tensorflow.rst:266
msgid ""
"Congratulations! You've successfully built and run your first federated "
"learning system."
msgstr ""

#: ../../source/tutorial-quickstart-mlx.rst:390
#, fuzzy
msgid ""
"Check the `source code <https://github.com/adap/flower/blob/main/examples"
"/quickstart-mlx>`_ of the extended version of this tutorial in ``examples"
"/quickstart-mlx`` in the Flower GitHub repository."
msgstr ""
"此示例的`完整源代码 <https://github.com/adap/flower/blob/main/examples/xgboost-"
"quickstart/>`_ 可在 :code:`examples/xgboost-quickstart` 中找到。"

#: ../../source/tutorial-quickstart-pandas.rst:-1
msgid ""
"Check out this Federated Learning quickstart tutorial for using Flower "
"with Pandas to perform Federated Analytics."
msgstr "查看此联邦学习快速入门教程，了解如何使用 Flower 和 Pandas 执行联邦分析。"

#: ../../source/tutorial-quickstart-pandas.rst:4
msgid "Quickstart Pandas"
msgstr "快速入门Pandas"

#: ../../source/tutorial-quickstart-pandas.rst:9
msgid "Let's build a federated analytics system using Pandas and Flower!"
msgstr "让我们使用 Pandas 和 Flower 建立一个联邦分析系统！"

#: ../../source/tutorial-quickstart-pandas.rst:11
msgid ""
"Please refer to the `full code example "
"<https://github.com/adap/flower/tree/main/examples/quickstart-pandas>`_ "
"to learn more."
msgstr ""
"请参阅 `完整代码示例 <https://github.com/adap/flower/tree/main/examples"
"/quickstart-pandas>`_\" 了解更多信息。"

#: ../../source/tutorial-quickstart-pytorch.rst:-1
msgid ""
"Check out this Federated Learning quickstart tutorial for using Flower "
"with PyTorch to train a CNN model on MNIST."
msgstr "查看此联邦学习快速入门教程，了解如何使用 Flower 和 PyTorch 在 MNIST 上训练 CNN 模型。"

#: ../../source/tutorial-quickstart-pytorch.rst:6
#, fuzzy
msgid ""
"In this federated learning tutorial we will learn how to train a "
"Convolutional Neural Network on CIFAR-10 using Flower and PyTorch. It is "
"recommended to create a virtual environment and run everything within a "
":doc:`virtualenv <contributor-how-to-set-up-a-virtual-env>`."
msgstr ""
"首先，建议创建一个虚拟环境，并在 `virtualenv <https://flower.ai/docs/recommended-env-"
"setup.html>`_ 中运行一切。"

#: ../../source/tutorial-quickstart-pytorch.rst:11
msgid ""
"Let's use `flwr new` to create a complete Flower+PyTorch project. It will"
" generate all the files needed to run, by default with the Flower "
"Simulation Engine, a federation of 10 nodes using `FedAvg "
"<https://flower.ai/docs/framework/ref-"
"api/flwr.server.strategy.FedAvg.html#flwr.server.strategy.FedAvg>`_. The "
"dataset will be partitioned using Flower Dataset's `IidPartitioner "
"<https://flower.ai/docs/datasets/ref-"
"api/flwr_datasets.partitioner.IidPartitioner.html#flwr_datasets.partitioner.IidPartitioner>`_."
msgstr ""

#: ../../source/tutorial-quickstart-pytorch.rst:26
msgid ""
"Then, run the command below. You will be prompted to select one of the "
"available templates (choose ``PyTorch``), give a name to your project, "
"and type in your developer name:"
msgstr ""

#: ../../source/tutorial-quickstart-pytorch.rst:117
msgid ""
"This tutorial uses `Flower Datasets <https://flower.ai/docs/datasets/>`_ "
"to easily download and partition the `CIFAR-10` dataset. In this example "
"you'll make use of the `IidPartitioner <https://flower.ai/docs/datasets"
"/ref-"
"api/flwr_datasets.partitioner.IidPartitioner.html#flwr_datasets.partitioner.IidPartitioner>`_"
" to generate `num_partitions` partitions. You can choose `other "
"partitioners <https://flower.ai/docs/datasets/ref-"
"api/flwr_datasets.partitioner.html>`_ available in Flower Datasets. Each "
"``ClientApp`` will call this function to create dataloaders with the data"
" that correspond to their data partition."
msgstr ""

#: ../../source/tutorial-quickstart-pytorch.rst:152
msgid ""
"We defined a simple Convolutional Neural Network (CNN), but feel free to "
"replace it with a more sophisticated model if you'd like:"
msgstr ""

#: ../../source/tutorial-quickstart-pytorch.rst:177
msgid ""
"In addition to defining the model architecture, we also include two "
"utility functions to perform both training (i.e. ``train()``) and "
"evaluation (i.e. ``test()``) using the above model. These functions "
"should look fairly familiar if you have some prior experience with "
"PyTorch. Note these functions do not have anything specific to Flower. "
"That being said, the training function will normally be called, as we'll "
"see later, from a Flower client passing its own data. In summary, your "
"clients can use standard training/testing functions to perform local "
"training or evaluation:"
msgstr ""

#: ../../source/tutorial-quickstart-pytorch.rst:226
msgid ""
"The main changes we have to make to use `PyTorch` with `Flower` will be "
"found in the ``get_weights()`` and ``set_weights()`` functions. In "
"``get_weights()`` PyTorch model parameters are extracted and represented "
"as a list of NumPy arrays. The ``set_weights()`` function that's the "
"oposite: given a list of NumPy arrays it applies them to an existing "
"PyTorch model. Doing this in fairly easy in PyTorch."
msgstr ""

#: ../../source/tutorial-quickstart-pytorch.rst:282
msgid ""
"Finally, we can construct a ``ClientApp`` using the ``FlowerClient`` "
"defined above by means of a ``client_fn()`` callback. Note that the "
"`context` enables you to get access to hyperparemeters defined in your "
"``pyproject.toml`` to configure the run. In this tutorial we access the "
"`local-epochs` setting to control the number of epochs a ``ClientApp`` "
"will perform when running the ``fit()`` method. You could define "
"additioinal hyperparameters in ``pyproject.toml`` and access them here."
msgstr ""

#: ../../source/tutorial-quickstart-pytorch.rst:309
msgid ""
"To construct a ``ServerApp`` we define a ``server_fn()`` callback with an"
" identical signature to that of ``client_fn()`` but the return type is "
"`ServerAppComponents <https://flower.ai/docs/framework/ref-"
"api/flwr.server.ServerAppComponents.html#serverappcomponents>`_ as "
"opposed to a `Client <https://flower.ai/docs/framework/ref-"
"api/flwr.client.Client.html#client>`_. In this example we use the "
"`FedAvg`. To it we pass a randomly initialized model that will server as "
"the global model to federated. Note that the value of ``fraction_fit`` is"
" read from the run config. You can find the default value defined in the "
"``pyproject.toml``."
msgstr ""

#: ../../source/tutorial-quickstart-pytorch.rst:348
#, fuzzy
msgid ""
"Check the `source code <https://github.com/adap/flower/blob/main/examples"
"/quickstart-pytorch>`_ of the extended version of this tutorial in "
"``examples/quickstart-pytorch`` in the Flower GitHub repository."
msgstr ""
"此示例的`完整源代码 <https://github.com/adap/flower/blob/main/examples/xgboost-"
"quickstart/>`_ 可在 :code:`examples/xgboost-quickstart` 中找到。"

#: ../../source/tutorial-quickstart-pytorch.rst:354
#: ../../source/tutorial-quickstart-tensorflow.rst:278
#, fuzzy
msgid "Video tutorial"
msgstr "教程"

#: ../../source/tutorial-quickstart-pytorch.rst:358
msgid ""
"The video shown below shows how to setup a PyTorch + Flower project using"
" our previously recommended APIs. A new video tutorial will be released "
"that shows the new APIs (as the content above does)"
msgstr ""

#: ../../source/tutorial-quickstart-pytorch-lightning.rst:4
msgid "Quickstart PyTorch Lightning"
msgstr "快速入门 PyTorch Lightning"

#: ../../source/tutorial-quickstart-pytorch-lightning.rst:6
#, fuzzy
msgid ""
"In this federated learning tutorial we will learn how to train an "
"AutoEncoder model on MNIST using Flower and PyTorch Lightning. It is "
"recommended to create a virtual environment and run everything within a "
":doc:`virtualenv <contributor-how-to-set-up-a-virtual-env>`."
msgstr ""
"首先，建议创建一个虚拟环境，并在 `virtualenv <https://flower.ai/docs/recommended-env-"
"setup.html>`_ 中运行一切。"

#: ../../source/tutorial-quickstart-pytorch-lightning.rst:19
msgid ""
"This will create a new directory called `quickstart-pytorch-lightning` "
"containing the following files:"
msgstr ""

#: ../../source/tutorial-quickstart-pytorch-lightning.rst:42
msgid ""
"By default, Flower Simulation Engine will be started and it will create a"
" federation of 4 nodes using `FedAvg <https://flower.ai/docs/framework"
"/ref-api/flwr.server.strategy.FedAvg.html#flwr.server.strategy.FedAvg>`_ "
"as the aggregation strategy. The dataset will be partitioned using Flower"
" Dataset's `IidPartitioner <https://flower.ai/docs/datasets/ref-"
"api/flwr_datasets.partitioner.IidPartitioner.html#flwr_datasets.partitioner.IidPartitioner>`_."
" To run the project, do:"
msgstr ""

#: ../../source/tutorial-quickstart-pytorch-lightning.rst:93
msgid ""
"Each simulated `ClientApp` (two per round) will also log a summary of "
"their local training process. Expect this output to be similar to:"
msgstr ""

#: ../../source/tutorial-quickstart-pytorch-lightning.rst:115
#, fuzzy
msgid ""
"Check the `source code <https://github.com/adap/flower/tree/main/examples"
"/quickstart-pytorch-lightning>`_ of this tutorial in ``examples"
"/quickstart-pytorch-lightning`` in the Flower GitHub repository."
msgstr ""
"此示例的`完整源代码 <https://github.com/adap/flower/blob/main/examples/xgboost-"
"quickstart/>`_ 可在 :code:`examples/xgboost-quickstart` 中找到。"

#: ../../source/tutorial-quickstart-scikitlearn.rst:-1
msgid ""
"Check out this Federated Learning quickstart tutorial for using Flower "
"with scikit-learn to train a linear regression model."
msgstr "查看此联邦学习快速入门教程，了解如何使用 Flower 和 scikit-learn 训练线性回归模型。"

#: ../../source/tutorial-quickstart-scikitlearn.rst:4
msgid "Quickstart scikit-learn"
msgstr "scikit-learn快速入门"

#: ../../source/tutorial-quickstart-scikitlearn.rst:6
#, fuzzy
msgid ""
"In this federated learning tutorial we will learn how to train a Logistic"
" Regression on MNIST using Flower and scikit-learn. It is recommended to "
"create a virtual environment and run everything within a :doc:`virtualenv"
" <contributor-how-to-set-up-a-virtual-env>`."
msgstr ""
"首先，建议创建一个虚拟环境，并在 `virtualenv <https://flower.ai/docs/recommended-env-"
"setup.html>`_ 中运行一切。"

#: ../../source/tutorial-quickstart-scikitlearn.rst:10
msgid ""
"Let's use ``flwr new`` to create a complete Flower+scikit-learn project. "
"It will generate all the files needed to run, by default with the Flower "
"Simulation Engine, a federation of 10 nodes using |fedavg|_ The dataset "
"will be partitioned using |flowerdatasets|_'s |iidpartitioner|_"
msgstr ""

#: ../../source/tutorial-quickstart-scikitlearn.rst:23
msgid ""
"Then, run the command below. You will be prompted to select one of the "
"available templates (choose ``sklearn``), give a name to your project, "
"and type in your developer name:"
msgstr ""

#: ../../source/tutorial-quickstart-scikitlearn.rst:115
msgid ""
"This tutorial uses |flowerdatasets|_ to easily download and partition the"
" `MNIST <https://huggingface.co/datasets/ylecun/mnist>`_ dataset. In this"
" example you'll make use of the |iidpartitioner|_ to generate "
"``num_partitions`` partitions. You can choose |otherpartitioners|_ "
"available in Flower Datasets. Each ``ClientApp`` will call this function "
"to create dataloaders with the data that correspond to their data "
"partition."
msgstr ""

#: ../../source/tutorial-quickstart-scikitlearn.rst:140
msgid ""
"We define the |logisticregression|_ model from scikit-learn in the "
"``get_model()`` function:"
msgstr ""

#: ../../source/tutorial-quickstart-scikitlearn.rst:153
msgid ""
"To perform the training and evaluation, we will make use of the "
"``.fit()`` and ``.score()`` methods available in the "
"``LogisticRegression`` class."
msgstr ""

#: ../../source/tutorial-quickstart-scikitlearn.rst:159
msgid ""
"The main changes we have to make to use scikit-learn with Flower will be "
"found in the ``get_model_params()``, ``set_model_params()``, and "
"``set_initial_params()`` functions. In ``get_model_params()``, the "
"coefficients and intercept of the logistic regression model are extracted"
" and represented as a list of NumPy arrays. In ``set_model_params()``, "
"that's the opposite: given a list of NumPy arrays it applies them to an "
"existing ``LogisticRegression`` model. Finally, in "
"``set_initial_params()``, we initialize the model parameters based on the"
" MNIST dataset, which has 10 classes (corresponding to the 10 digits) and"
" 784 features (corresponding to the size of the MNIST image array, which "
"is 28 × 28). Doing this is fairly easy in scikit-learn."
msgstr ""

#: ../../source/tutorial-quickstart-scikitlearn.rst:198
msgid ""
"The rest of the functionality is directly inspired by the centralized "
"case:"
msgstr ""

#: ../../source/tutorial-quickstart-scikitlearn.rst:226
msgid ""
"Finally, we can construct a ``ClientApp`` using the ``FlowerClient`` "
"defined above by means of a ``client_fn()`` callback. Note that the "
"``context`` enables you to get access to hyperparemeters defined in your "
"``pyproject.toml`` to configure the run. In this tutorial we access the "
"`local-epochs` setting to control the number of epochs a ``ClientApp`` "
"will perform when running the ``fit()`` method. You could define "
"additioinal hyperparameters in ``pyproject.toml`` and access them here."
msgstr ""

#: ../../source/tutorial-quickstart-scikitlearn.rst:257
msgid ""
"To construct a ``ServerApp`` we define a ``server_fn()`` callback with an"
" identical signature to that of ``client_fn()`` but the return type is "
"|serverappcomponents|_ as opposed to a |client|_ In this example we use "
"the `FedAvg` strategy. To it we pass a zero-initialized model that will "
"server as the global model to be federated. Note that the values of "
"``num-server-rounds``, ``penalty``, and ``local-epochs`` are read from "
"the run config. You can find the default values defined in the "
"``pyproject.toml``."
msgstr ""

#: ../../source/tutorial-quickstart-scikitlearn.rst:295
msgid ""
"Congratulations! You've successfully built and run your first federated "
"learning system in scikit-learn."
msgstr ""

#: ../../source/tutorial-quickstart-scikitlearn.rst:300
#, fuzzy
msgid ""
"Check the source code of the extended version of this tutorial in "
"|quickstart_sklearn_link|_ in the Flower GitHub repository."
msgstr ""
"此示例的`完整源代码 <https://github.com/adap/flower/blob/main/examples/xgboost-"
"quickstart/>`_ 可在 :code:`examples/xgboost-quickstart` 中找到。"

#: ../../source/tutorial-quickstart-tensorflow.rst:-1
#, fuzzy
msgid ""
"Check out this Federated Learning quickstart tutorial for using Flower "
"with TensorFlow to train a CNN model on CIFAR-10."
msgstr "查看此联邦学习快速入门教程，了解如何使用 Flower 和 TensorFlow 在 CIFAR-10 上训练 MobilNetV2 模型。"

#: ../../source/tutorial-quickstart-tensorflow.rst:4
msgid "Quickstart TensorFlow"
msgstr "快速入门 TensorFlow"

#: ../../source/tutorial-quickstart-tensorflow.rst:6
#, fuzzy
msgid ""
"In this tutorial we will learn how to train a Convolutional Neural "
"Network on CIFAR-10 using the Flower framework and TensorFlow. First of "
"all, it is recommended to create a virtual environment and run everything"
" within a :doc:`virtualenv <contributor-how-to-set-up-a-virtual-env>`."
msgstr ""
"首先，建议创建一个虚拟环境，并在 `virtualenv <https://flower.ai/docs/recommended-env-"
"setup.html>`_ 中运行一切。"

#: ../../source/tutorial-quickstart-tensorflow.rst:11
msgid ""
"Let's use `flwr new` to create a complete Flower+TensorFlow project. It "
"will generate all the files needed to run, by default with the Flower "
"Simulation Engine, a federation of 10 nodes using `FedAvg "
"<https://flower.ai/docs/framework/ref-"
"api/flwr.server.strategy.FedAvg.html#flwr.server.strategy.FedAvg>`_. The "
"dataset will be partitioned using Flower Dataset's `IidPartitioner "
"<https://flower.ai/docs/datasets/ref-"
"api/flwr_datasets.partitioner.IidPartitioner.html#flwr_datasets.partitioner.IidPartitioner>`_."
msgstr ""

#: ../../source/tutorial-quickstart-tensorflow.rst:26
msgid ""
"Then, run the command below. You will be prompted to select one of the "
"available templates (choose ``TensorFlow``), give a name to your project,"
" and type in your developer name:"
msgstr ""

#: ../../source/tutorial-quickstart-tensorflow.rst:114
msgid ""
"This tutorial uses `Flower Datasets <https://flower.ai/docs/datasets/>`_ "
"to easily download and partition the `CIFAR-10` dataset. In this example "
"you'll make use of the `IidPartitioner <https://flower.ai/docs/datasets"
"/ref-"
"api/flwr_datasets.partitioner.IidPartitioner.html#flwr_datasets.partitioner.IidPartitioner>`_"
" to generate `num_partitions` partitions. You can choose `other "
"partitioners <https://flower.ai/docs/datasets/ref-"
"api/flwr_datasets.partitioner.html>`_ available in Flower Datasets. Each "
"``ClientApp`` will call this function to create the ``NumPy`` arrays that"
" correspond to their data partition."
msgstr ""

#: ../../source/tutorial-quickstart-tensorflow.rst:141
msgid ""
"Next, we need a model. We defined a simple Convolutional Neural Network "
"(CNN), but feel free to replace it with a more sophisticated model if "
"you'd like:"
msgstr ""

#: ../../source/tutorial-quickstart-tensorflow.rst:170
msgid ""
"With `TensorFlow`, we can use the built-in ``get_weights()`` and "
"``set_weights()`` functions, which simplifies the implementation with "
"`Flower`. The rest of the functionality in the ClientApp is directly "
"inspired by the centralized case. The ``fit()`` method in the client "
"trains the model using the local dataset. Similarly, the ``evaluate()`` "
"method is used to evaluate the model received on a held-out validation "
"set that the client might have:"
msgstr ""

#: ../../source/tutorial-quickstart-tensorflow.rst:203
msgid ""
"Finally, we can construct a ``ClientApp`` using the ``FlowerClient`` "
"defined above by means of a ``client_fn()`` callback. Note that the "
"`context` enables you to get access to hyperparameters defined in your "
"``pyproject.toml`` to configure the run. For example, in this tutorial we"
" access the `local-epochs` setting to control the number of epochs a "
"``ClientApp`` will perform when running the ``fit()`` method, in addition"
" to `batch-size`. You could define additional hyperparameters in "
"``pyproject.toml`` and access them here."
msgstr ""

#: ../../source/tutorial-quickstart-tensorflow.rst:234
msgid ""
"To construct a ``ServerApp`` we define a ``server_fn()`` callback with an"
" identical signature to that of ``client_fn()`` but the return type is "
"`ServerAppComponents <https://flower.ai/docs/framework/ref-"
"api/flwr.server.ServerAppComponents.html#serverappcomponents>`_ as "
"opposed to a `Client <https://flower.ai/docs/framework/ref-"
"api/flwr.client.Client.html#client>`_. In this example we use the "
"`FedAvg`. To it we pass a randomly initialized model that will serve as "
"the global model to federate."
msgstr ""

#: ../../source/tutorial-quickstart-tensorflow.rst:270
#, fuzzy
msgid ""
"Check the source code of the extended version of this tutorial in "
"|quickstart_tf_link|_ in the Flower GitHub repository."
msgstr ""
"此示例的`完整源代码 <https://github.com/adap/flower/blob/main/examples/xgboost-"
"quickstart/>`_ 可在 :code:`examples/xgboost-quickstart` 中找到。"

#: ../../source/tutorial-quickstart-tensorflow.rst:282
msgid ""
"The video shown below shows how to setup a TensorFlow + Flower project "
"using our previously recommended APIs. A new video tutorial will be "
"released that shows the new APIs (as the content above does)"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:-1
msgid ""
"Check out this Federated Learning quickstart tutorial for using Flower "
"with XGBoost to train classification models on trees."
msgstr "查看此联邦学习 快速入门教程，了解如何使用 Flower 和 XGBoost 上训练分类模型。"

#: ../../source/tutorial-quickstart-xgboost.rst:4
msgid "Quickstart XGBoost"
msgstr "XGBoost快速入门"

#: ../../source/tutorial-quickstart-xgboost.rst:9
msgid ""
"EXtreme Gradient Boosting (**XGBoost**) is a robust and efficient "
"implementation of gradient-boosted decision tree (**GBDT**), that "
"maximises the computational boundaries for boosted tree methods. It's "
"primarily designed to enhance both the performance and computational "
"speed of machine learning models. In XGBoost, trees are constructed "
"concurrently, unlike the sequential approach taken by GBDT."
msgstr ""
"EXtreme Gradient "
"Boosting（**XGBoost**）是梯度提升决策树（**GBDT**）的一种稳健而高效的实现方法，能最大限度地提高提升树方法的计算边界。它主要用于提高机器学习模型的性能和计算速度。在"
" XGBoost 中，决策树是并发构建的，与 GBDT 采用的顺序方法不同。"

#: ../../source/tutorial-quickstart-xgboost.rst:15
msgid ""
"Often, for tabular data on medium-sized datasets with fewer than 10k "
"training examples, XGBoost surpasses the results of deep learning "
"techniques."
msgstr "对于训练示例少于 10k 的中型数据集上的表格数据，XGBoost 的结果往往超过深度学习技术。"

#: ../../source/tutorial-quickstart-xgboost.rst:19
#, fuzzy
msgid "Why Federated XGBoost?"
msgstr "为什么选择联邦 XGBoost？"

#: ../../source/tutorial-quickstart-xgboost.rst:21
#, fuzzy
msgid ""
"As the demand for data privacy and decentralized learning grows, there's "
"an increasing requirement to implement federated XGBoost systems for "
"specialised applications, like survival analysis and financial fraud "
"detection."
msgstr "事实上，随着对数据隐私和分散学习的需求不断增长，越来越多的专业应用（如生存分析和金融欺诈检测）需要实施联邦 XGBoost 系统。"

#: ../../source/tutorial-quickstart-xgboost.rst:25
#, fuzzy
msgid ""
"Federated learning ensures that raw data remains on the local device, "
"making it an attractive approach for sensitive domains where data privacy"
" is paramount. Given the robustness and efficiency of XGBoost, combining "
"it with federated learning offers a promising solution for these specific"
" challenges."
msgstr ""
"联邦学习可确保原始数据保留在本地设备上，因此对于数据安全和隐私至关重要的敏感领域来说，这是一种极具吸引力的方法。鉴于 XGBoost "
"的稳健性和高效性，将其与联邦学习相结合为应对这些特定挑战提供了一种前景广阔的解决方案。"

#: ../../source/tutorial-quickstart-xgboost.rst:31
msgid "Environment Setup"
msgstr "环境设定"

#: ../../source/tutorial-quickstart-xgboost.rst:33
#, fuzzy
msgid ""
"In this tutorial, we learn how to train a federated XGBoost model on the "
"HIGGS dataset using Flower and the ``xgboost`` package to perform a "
"binary classification task. We use a simple example (`full code xgboost-"
"quickstart <https://github.com/adap/flower/tree/main/examples/xgboost-"
"quickstart>`_) to demonstrate how federated XGBoost works, and then we "
"dive into a more complex comprehensive example (`full code xgboost-"
"comprehensive <https://github.com/adap/flower/tree/main/examples/xgboost-"
"comprehensive>`_) to run various experiments."
msgstr ""
"在本教程中，我们将学习如何使用 Flower 和 :code:`xgboost` 软件包在 HIGGS 数据集上训练联邦 XGBoost "
"模型。我们将使用一个包含两个 * 客户端* 和一个 * 服务器* 的简单示例 (`完整代码 xgboost-quickstart "
"<https://github.com/adap/flower/tree/main/examples/xgboost-"
"quickstart>`_)来演示联邦 XGBoost 如何工作，然后我们将深入到一个更复杂的示例 (`完整代码 xgboost-"
"comprehensive <https://github.com/adap/flower/tree/main/examples/xgboost-"
"comprehensive>`_)，以运行各种实验。"

#: ../../source/tutorial-quickstart-xgboost.rst:42
#, fuzzy
msgid ""
"It is recommended to create a virtual environment and run everything "
"within a :doc:`virtualenv <contributor-how-to-set-up-a-virtual-env>`."
msgstr ""
"建议创建一个虚拟环境，并在此 `virtualenv <https://flower.ai/docs/recommended-env-"
"setup.html>`_ 中运行所有内容。"

#: ../../source/tutorial-quickstart-xgboost.rst:45
msgid ""
"We first need to install Flower and Flower Datasets. You can do this by "
"running :"
msgstr "我们首先需要安装 Flower 和 Flower Datasets。您可以通过运行 ："

#: ../../source/tutorial-quickstart-xgboost.rst:52
#, fuzzy
msgid ""
"Since we want to use ``xgboost`` package to build up XGBoost trees, let's"
" go ahead and install ``xgboost``:"
msgstr "既然我们要使用 :code:`xgboost` 软件包来构建 XGBoost 树，那就继续安装 :code:`xgboost`："

#: ../../source/tutorial-quickstart-xgboost.rst:60
#, fuzzy
msgid "The Configurations"
msgstr "配置值"

#: ../../source/tutorial-quickstart-xgboost.rst:62
msgid ""
"We define all required configurations / hyper-parameters inside the "
"``pyproject.toml`` file:"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:84
#, fuzzy
msgid ""
"The ``local-epochs`` represents the number of iterations for local tree "
"boost. We use CPU for the training in default. One can assign it to a GPU"
" by setting ``tree_method`` to ``gpu_hist``. We use AUC as evaluation "
"metric."
msgstr ""
"代码:`num_local_round`表示本地树的迭代次数。我们默认使用 CPU 进行训练。可以通过将 :code:`tree_method` "
"设置为 :code:`gpu_hist`，将其转换为 GPU。我们使用 AUC 作为评估指标。"

#: ../../source/tutorial-quickstart-xgboost.rst:91
msgid ""
"This tutorial uses `Flower Datasets <https://flower.ai/docs/datasets/>`_ "
"to easily download and partition the `HIGGS` dataset."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:105
#, fuzzy
msgid ""
"In this example, we split the dataset into 20 partitions with uniform "
"distribution (`IidPartitioner <https://flower.ai/docs/datasets/ref-"
"api/flwr_datasets.partitioner.IidPartitioner.html#flwr_datasets.partitioner.IidPartitioner>`_)."
" Then, we load the partition for the given client based on "
"``partition_id``."
msgstr ""
"在此示例中，我们将数据集分割成两个均匀分布的分区（:code:`IidPartitioner(num_partitions=2)`）。然后，我们根据"
" :code:`node_id` 为给定客户端加载分区："

#: ../../source/tutorial-quickstart-xgboost.rst:110
#, fuzzy
msgid ""
"Subsequently, we train/test split using the given partition (client's "
"local data), and reformat data to DMatrix for the ``xgboost`` package."
msgstr "然后，我们在给定的分区（客户端的本地数据）上进行训练/测试分割，并为 :code:`xgboost` 软件包转换数据格式。"

#: ../../source/tutorial-quickstart-xgboost.rst:124
#, fuzzy
msgid ""
"The functions of ``train_test_split`` and "
"``transform_dataset_to_dmatrix`` are defined as below:"
msgstr ":code:`train_test_split` 和 :code:`transform_dataset_too_dmatrix` 的函数定义如下："

#: ../../source/tutorial-quickstart-xgboost.rst:151
#, fuzzy
msgid ""
"*Clients* are responsible for generating individual weight-updates for "
"the model based on their local datasets. Let's first see how we define "
"Flower client for XGBoost. We follow the general rule to define "
"``FlowerClient`` class inherited from ``fl.client.Client``."
msgstr ""
"加载数据集后，我们定义 Flower 客户端。我们按照一般规则定义从 :code:`fl.client.Client` 继承而来的 "
":code:`XgbClient` 类。"

#: ../../source/tutorial-quickstart-xgboost.rst:176
msgid ""
"All required parameters defined above are passed to ``FlowerClient``'s "
"constructor."
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:178
#, fuzzy
msgid ""
"Then, we override ``fit`` and ``evaluate`` methods insides "
"``FlowerClient`` class as follows."
msgstr ""
"然后，我们在 :code:`XgbClient` 类中重写 :code:`get_parameters`、:code:`fit` 和 "
":code:`evaluate` 方法如下。"

#: ../../source/tutorial-quickstart-xgboost.rst:217
#, fuzzy
msgid ""
"In ``fit``, at the first round, we call ``xgb.train()`` to build up the "
"first set of trees. From the second round, we load the global model sent "
"from server to new build Booster object, and then update model weights on"
" local training data with function ``_local_boost`` as follows:"
msgstr ""
"在 :code:`fit`中，第一轮我们调用 :code:`xgb.train()`来建立第一组树，返回的 Booster 对象和 config "
"分别存储在 :code:`self.bst` 和 :code:`self.config` 中。从第二轮开始，我们将服务器发送的全局模型加载到 "
":code:`self.bst`，然后使用函数 :code:`local_boost`更新本地训练数据的模型权重，如下所示："

#: ../../source/tutorial-quickstart-xgboost.rst:237
#, fuzzy
msgid ""
"Given ``num_local_round``, we update trees by calling "
"``bst_input.update`` method. After training, the last "
"``N=num_local_round`` trees will be extracted to send to the server."
msgstr ""
"给定 :code:`num_local_round`，我们通过调用 "
":code:`self.bst.update`方法更新树。训练结束后，我们将提取最后一个 :code:`N=num_local_round` "
"树并发送给服务器。"

#: ../../source/tutorial-quickstart-xgboost.rst:265
#, fuzzy
msgid ""
"In ``evaluate``, after loading the global model, we call ``bst.eval_set``"
" function to conduct evaluation on valid set. The AUC value will be "
"returned."
msgstr "在 :code:`evaluate`中，我们调用 :code:`self.bst.eval_set`函数对有效集合进行评估。将返回 AUC 值。"

#: ../../source/tutorial-quickstart-xgboost.rst:271
#, fuzzy
msgid ""
"After the local training on clients, clients' model updates are sent to "
"the *server*, which aggregates them to produce a better model. Finally, "
"the *server* sends this improved model version back to each *client* to "
"complete a federated round."
msgstr ""
"然后，这些更新会被发送到*服务器*，由*服务器*聚合后生成一个更好的模型。最后，*服务器*将这个改进版的模型发回给每个*客户端*，以完成一轮完整的"
" FL。"

#: ../../source/tutorial-quickstart-xgboost.rst:275
#, fuzzy
msgid ""
"In the file named ``server_app.py``, we define a strategy for XGBoost "
"bagging aggregation:"
msgstr "我们首先定义了 XGBoost bagging聚合策略。"

#: ../../source/tutorial-quickstart-xgboost.rst:308
#, fuzzy
msgid ""
"An ``evaluate_metrics_aggregation`` function is defined to collect and "
"wighted average the AUC values from clients. The ``config_func`` function"
" is to return the current FL round number to client's ``fit()`` and "
"``evaluate()`` methods."
msgstr ""
"本示例使用两个客户端。我们定义了一个 :code:`evaluate_metrics_aggregation` 函数，用于收集客户机的 AUC "
"值并求取平均值。"

#: ../../source/tutorial-quickstart-xgboost.rst:313
#, fuzzy
msgid "Tree-based Bagging Aggregation"
msgstr "基于树的bagging聚合"

#: ../../source/tutorial-quickstart-xgboost.rst:315
msgid ""
"You must be curious about how bagging aggregation works. Let's look into "
"the details."
msgstr "您一定很好奇bagging聚合是如何工作的。让我们来详细了解一下。"

#: ../../source/tutorial-quickstart-xgboost.rst:317
#, fuzzy
msgid ""
"In file ``flwr.server.strategy.fedxgb_bagging.py``, we define "
"``FedXgbBagging`` inherited from ``flwr.server.strategy.FedAvg``. Then, "
"we override the ``aggregate_fit``, ``aggregate_evaluate`` and "
"``evaluate`` methods as follows:"
msgstr ""
"在文件 :code:`flwr.server.strategy.fedxgb_bagging.py`中，我们定义了从 "
":code:`flwr.server.strategy.FedAvg`继承的 :code:`FedXgbBagging`。然后，我们覆盖 "
":code:`aggregate_fit`、:code:`aggregate_evaluate` 和 :code:`evaluate` 方法如下："

#: ../../source/tutorial-quickstart-xgboost.rst:414
#, fuzzy
msgid ""
"In ``aggregate_fit``, we sequentially aggregate the clients' XGBoost "
"trees by calling ``aggregate()`` function:"
msgstr ""
"在 :code:`aggregate_fit` 中，我们通过调用 :code:`aggregate()` 函数，按顺序聚合客户端的 XGBoost"
" 树："

#: ../../source/tutorial-quickstart-xgboost.rst:474
#, fuzzy
msgid ""
"In this function, we first fetch the number of trees and the number of "
"parallel trees for the current and previous model by calling "
"``_get_tree_nums``. Then, the fetched information will be aggregated. "
"After that, the trees (containing model weights) are aggregated to "
"generate a new tree model."
msgstr ""
"在该函数中，我们首先通过调用 :code:`_get_tree_nums` "
"获取当前模型和上一个模型的树数和并行树数。然后，对获取的信息进行聚合。然后，聚合树（包含模型参数）生成新的树模型。"

#: ../../source/tutorial-quickstart-xgboost.rst:479
#, fuzzy
msgid ""
"After traversal of all clients' models, a new global model is generated, "
"followed by serialisation, and sending the global model back to each "
"client."
msgstr "在遍历所有客户端的模型后，会生成一个新的全局模型，然后进行序列化，并发回给每个客户端。"

#: ../../source/tutorial-quickstart-xgboost.rst:483
msgid "Launch Federated XGBoost!"
msgstr "启动联邦 XGBoost！"

#: ../../source/tutorial-quickstart-xgboost.rst:533
#, fuzzy
msgid ""
"Congratulations! You've successfully built and run your first federated "
"XGBoost system. The AUC values can be checked in ``History (metrics, "
"distributed, evaluate)``. One can see that the average AUC increases over"
" FL rounds."
msgstr ""
"恭喜您！您已成功构建并运行了第一个联邦 XGBoost 系统。可以在 :code:`metrics_distributed` 中查看 AUC "
"值。我们可以看到，平均 AUC 随 FL 轮数的增加而增加。"

#: ../../source/tutorial-quickstart-xgboost.rst:547
#, fuzzy
msgid ""
"Check the full `source code "
"<https://github.com/adap/flower/blob/main/examples/xgboost-quickstart>`_ "
"for this example in ``examples/xgboost-quickstart`` in the Flower GitHub "
"repository."
msgstr ""
"此示例的`完整源代码 <https://github.com/adap/flower/blob/main/examples/xgboost-"
"quickstart/>`_ 可在 :code:`examples/xgboost-quickstart` 中找到。"

#: ../../source/tutorial-quickstart-xgboost.rst:552
msgid "Comprehensive Federated XGBoost"
msgstr "综合的联邦 XGBoost"

#: ../../source/tutorial-quickstart-xgboost.rst:554
#, fuzzy
msgid ""
"Now that you know how federated XGBoost works with Flower, it's time to "
"run some more comprehensive experiments by customising the experimental "
"settings. In the xgboost-comprehensive example (`full code "
"<https://github.com/adap/flower/tree/main/examples/xgboost-"
"comprehensive>`_), we provide more options to define various experimental"
" setups, including aggregation strategies, data partitioning and "
"centralised / distributed evaluation. Let's take a look!"
msgstr ""
"既然您已经知道联合 XGBoost 如何与 Flower 协同工作，那么现在就该通过自定义实验设置来运行一些更综合的实验了。在 xgboost-"
"comprehensive 示例 (`完整代码 "
"<https://github.com/adap/flower/tree/main/examples/xgboost-"
"comprehensive>`_)中，我们提供了更多选项来定义各种实验设置，包括数据分区和集中/分布式评估。让我们一起来看看！"

#: ../../source/tutorial-quickstart-xgboost.rst:562
#, fuzzy
msgid "Cyclic Training"
msgstr "集中式训练"

#: ../../source/tutorial-quickstart-xgboost.rst:564
#, fuzzy
msgid ""
"In addition to bagging aggregation, we offer a cyclic training scheme, "
"which performs FL in a client-by-client fashion. Instead of aggregating "
"multiple clients, there is only one single client participating in the "
"training per round in the cyclic training scenario. The trained local "
"XGBoost trees will be passed to the next client as an initialised model "
"for next round's boosting."
msgstr ""
"除了袋式聚合，我们还提供了一种循环训练方案，它以逐个客户端的方式执行 "
"FL。在循环训练方案中，每轮只有一个客户端参与训练，而不是多个客户端聚合在一起。训练好的本地 XGBoost "
"树将传递给下一个客户端，作为下一轮提升的初始化模型。"

#: ../../source/tutorial-quickstart-xgboost.rst:570
#, fuzzy
msgid "To do this, we first customise a ``ClientManager`` in ``server_app.py``:"
msgstr "为此，我们首先要在 :code:`server_utils.py` 中自定义一个 :code:`ClientManager`："

#: ../../source/tutorial-quickstart-xgboost.rst:610
#, fuzzy
msgid ""
"The customised ``ClientManager`` samples all available clients in each FL"
" round based on the order of connection to the server. Then, we define a "
"new strategy ``FedXgbCyclic`` in "
"``flwr.server.strategy.fedxgb_cyclic.py``, in order to sequentially "
"select only one client in given round and pass the received model to the "
"next client."
msgstr ""
"定制的 :code:`ClientManager` 会根据连接服务器的顺序，在每轮 FL 中对所有可用客户端进行采样。然后，我们在 "
":code:`flwr.server.strategy.fedxgb_cyclic.py`\"中定义了一个新策略 "
":code:`FedXgbCyclic`，以便在给定回合中按顺序只选择一个客户端，并将接收到的模型传递给下一个客户端。"

#: ../../source/tutorial-quickstart-xgboost.rst:652
#, fuzzy
msgid ""
"Unlike the original ``FedAvg``, we don't perform aggregation here. "
"Instead, we just make a copy of the received client model as global model"
" by overriding ``aggregate_fit``."
msgstr ""
"与最初的 :code:`FedAvg` 不同，我们在这里不执行聚合。相反，我们只是通过覆盖 :code:`aggregate_fit` "
"将接收到的客户端模型复制为全局模型。"

#: ../../source/tutorial-quickstart-xgboost.rst:655
#, fuzzy
msgid ""
"Also, the customised ``configure_fit`` and ``configure_evaluate`` methods"
" ensure the clients to be sequentially selected given FL round:"
msgstr ""
"此外，定制的 :code:`configure_fit` 和 :code:`configure_evaluate` 方法可确保在 FL "
"轮中按顺序选择客户："

#: ../../source/tutorial-quickstart-xgboost.rst:685
#, fuzzy
msgid "Customised Data Partitioning"
msgstr "定制数据分区"

#: ../../source/tutorial-quickstart-xgboost.rst:687
#, fuzzy
msgid ""
"In ``task.py``, we use the ``instantiate_fds`` function to instantiate "
"Flower Datasets and the data partitioner based on the given "
"``partitioner_type`` and ``num_partitions``. Currently, we provide four "
"supported partitioner type to simulate the uniformity/non-uniformity in "
"data quantity (uniform, linear, square, exponential)."
msgstr ""
"在 :code:`dataset.py` 中，我们有一个函数 :code:`instantiate_partitioner` 来根据给定的 "
":code:`num_partitions` 和 :code:`partitioner_type` "
"来实例化数据分区器。目前，我们提供四种支持的分区器类型（均匀、线性、正方形、指数）来模拟数据量的均匀性/非均匀性。"

#: ../../source/tutorial-quickstart-xgboost.rst:726
#, fuzzy
msgid "Customised Centralised / Distributed Evaluation"
msgstr "定制的集中/分布式评估"

#: ../../source/tutorial-quickstart-xgboost.rst:728
#, fuzzy
msgid ""
"To facilitate centralised evaluation, we define a function in "
"``server_app.py``:"
msgstr "为便于集中评估，我们在 :code:`server.py` 中定义了一个函数："

#: ../../source/tutorial-quickstart-xgboost.rst:759
#, fuzzy
msgid ""
"This function returns an evaluation function, which instantiates a "
"``Booster`` object and loads the global model weights to it. The "
"evaluation is conducted by calling ``eval_set()`` method, and the tested "
"AUC value is reported."
msgstr ""
"此函数返回一个评估函数，该函数实例化一个 :code:`Booster` 对象，并向其加载全局模型参数。评估通过调用 "
":code:`eval_set()` 方法进行，并报告测试的 AUC 值。"

#: ../../source/tutorial-quickstart-xgboost.rst:763
#, fuzzy
msgid ""
"As for distributed evaluation on the clients, it's same as the quick-"
"start example by overriding the ``evaluate()`` method insides the "
"``XgbClient`` class in ``client_app.py``."
msgstr ""
"至于客户端上的分布式评估，与快速启动示例相同，通过覆盖 :code:`client.py` 中 :code:`XgbClient` 类内部的 "
":code:`evaluate()` 方法。"

#: ../../source/tutorial-quickstart-xgboost.rst:768
#, fuzzy
msgid "Arguments Explainer"
msgstr "参数解析器"

#: ../../source/tutorial-quickstart-xgboost.rst:770
msgid ""
"We define all hyper-parameters under ``[tool.flwr.app.config]`` entry in "
"``pyproject.toml``:"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:799
#, fuzzy
msgid ""
"On the server side, we allow user to specify training strategies / FL "
"rounds / participating clients / clients for evaluation, and evaluation "
"fashion. Note that with ``centralised-eval = true``, the sever will do "
"centralised evaluation and all functionalities for client evaluation will"
" be disabled."
msgstr ""
"这允许用户指定总客户数/FL 轮数/参与客户数/评估客户数以及评估方式。请注意，如果使用 :code:`--centralised-"
"eval`，服务器将进行集中评估，客户端评估的所有功能将被禁用。"

#: ../../source/tutorial-quickstart-xgboost.rst:804
#, fuzzy
msgid ""
"On the client side, we can define various options for client data "
"partitioning. Besides, clients also have an option to conduct evaluation "
"on centralised test set by setting ``centralised-eval = true``, as well "
"as an option to perform scaled learning rate based on the number of "
"clients by setting ``scaled-lr = true``."
msgstr "这定义了客户端数据分区的各种选项。此外，通过设置 :code:`-centralised-eval`，客户端还可以选择在集中测试集上进行评估。"

#: ../../source/tutorial-quickstart-xgboost.rst:810
#, fuzzy
msgid "Example Commands"
msgstr "命令示例"

#: ../../source/tutorial-quickstart-xgboost.rst:812
msgid "To run bagging aggregation for 5 rounds evaluated on centralised test set:"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:818
msgid ""
"To run cyclic training with linear partitioner type evaluated on "
"centralised test set:"
msgstr ""

#: ../../source/tutorial-quickstart-xgboost.rst:827
#, fuzzy
msgid ""
"The full `code <https://github.com/adap/flower/blob/main/examples"
"/xgboost-comprehensive/>`_ for this comprehensive example can be found in"
" ``examples/xgboost-comprehensive`` in the Flower GitHub repository."
msgstr ""
"此综合示例的全部`源代码 <https://github.com/adap/flower/blob/main/examples/xgboost-"
"comprehensive/>`_ 可在 :code:`examples/xgboost-comprehensive` 中找到。"

#: ../../source/tutorial-quickstart-xgboost.rst:833
#, fuzzy
msgid "Video Tutorial"
msgstr "教程"

#: ../../source/tutorial-quickstart-xgboost.rst:837
msgid ""
"The video shown below shows how to setup a XGBoost + Flower project using"
" our previously recommended APIs. A new video tutorial will be released "
"that shows the new APIs (as the content above does)"
msgstr ""

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:9
msgid "Build a strategy from scratch"
msgstr "从零开始制定策略"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:11
#, fuzzy
msgid ""
"Welcome to the third part of the Flower federated learning tutorial. In "
"previous parts of this tutorial, we introduced federated learning with "
"PyTorch and the Flower framework (`part 1 "
"<https://flower.ai/docs/framework/tutorial-get-started-with-flower-"
"pytorch.html>`__) and we learned how strategies can be used to customize "
"the execution on both the server and the clients (`part 2 "
"<https://flower.ai/docs/framework/tutorial-use-a-federated-learning-"
"strategy-pytorch.html>`__)."
msgstr ""
"欢迎来到 Flower 联邦学习教程的第三部分。在本教程的前几部分，我们介绍了 PyTorch 和 Flower 的联邦学习（`part 1 "
"<https://flower.ai/docs/framework/tutorial-get-started-with-flower-"
"pytorch.html>`__），并学习了如何使用策略来定制服务器和客户端的执行（`part 2 "
"<https://flower.ai/docs/framework/tutorial-use-a-federated-learning-"
"strategy-pytorch.html>`__）。"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:13
#, fuzzy
msgid ""
"In this notebook, we'll continue to customize the federated learning "
"system we built previously by creating a custom version of FedAvg using "
"the Flower framework, Flower Datasets, and PyTorch."
msgstr ""
"在本笔记中，我们将通过创建 FedAvg 的自定义版本（再次使用 `Flower <https://flower.ai/>`__ 和 "
"`PyTorch <https://pytorch.org/>`__），继续定制我们之前构建的联邦学习系统。"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:15
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:16
#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:15
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:15
#, fuzzy
msgid ""
"`Star Flower on GitHub <https://github.com/adap/flower>`__ ⭐️ and join "
"the Flower community on Flower Discuss and the Flower Slack to connect, "
"ask questions, and get help: - `Join Flower Discuss "
"<https://discuss.flower.ai/>`__ We'd love to hear from you in the "
"``Introduction`` topic! If anything is unclear, post in ``Flower Help - "
"Beginners``. - `Join Flower Slack <https://flower.ai/join-slack>`__ We'd "
"love to hear from you in the ``#introductions`` channel! If anything is "
"unclear, head over to the ``#questions`` channel."
msgstr ""
"`Star Flower on GitHub <https://github.com/adap/flower>`__ ⭐️ 并加入 Slack "
"上的 Flower 社区，进行交流、提问并获得帮助： 加入 Slack <https://flower.ai/join-slack>`__ 🌼 "
"我们希望在 ``#introductions`` 频道听到您的声音！如果有任何不清楚的地方，请访问 ``#questions`` 频道。"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:18
#, fuzzy
msgid "Let's build a new ``Strategy`` from scratch! 🌼"
msgstr "让我们从头开始构建一个新的``Strategy``！"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:30
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:30
msgid "Preparation"
msgstr "准备工作"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:32
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:33
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:32
msgid ""
"Before we begin with the actual code, let's make sure that we have "
"everything we need."
msgstr "在开始实际代码之前，让我们先确保我们已经准备好了所需的一切。"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:44
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:45
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:44
msgid "Installing dependencies"
msgstr "安装依赖项"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:46
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:47
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:46
msgid "First, we install the necessary packages:"
msgstr "首先，我们安装必要的软件包："

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:66
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:67
#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:66
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:66
msgid ""
"Now that we have all dependencies installed, we can import everything we "
"need for this tutorial:"
msgstr "现在我们已经安装了所有依赖项，可以导入本教程所需的所有内容："

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:106
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:106
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:106
msgid ""
"It is possible to switch to a runtime that has GPU acceleration enabled "
"(on Google Colab: ``Runtime > Change runtime type > Hardware acclerator: "
"GPU > Save``). Note, however, that Google Colab is not always able to "
"offer GPU acceleration. If you see an error related to GPU availability "
"in one of the following sections, consider switching back to CPU-based "
"execution by setting ``DEVICE = torch.device(\"cpu\")``. If the runtime "
"has GPU acceleration enabled, you should see the output ``Training on "
"cuda``, otherwise it'll say ``Training on cpu``."
msgstr ""
"可以切换到已启用 GPU 加速的运行时（在 Google Colab 上： 运行时 > 更改运行时类型 > 硬件加速： GPU > "
"保存``）。但请注意，Google Colab 并非总能提供 GPU 加速。如果在以下部分中看到与 GPU 可用性相关的错误，请考虑通过设置 "
"``DEVICE = torch.device(\"cpu\")`` 切回基于 CPU 的执行。如果运行时已启用 GPU "
"加速，你应该会看到输出``Training on cuda``，否则会显示``Training on cpu``。"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:119
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:119
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:119
msgid "Data loading"
msgstr "数据加载"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:121
msgid ""
"Let's now load the CIFAR-10 training and test set, partition them into "
"ten smaller datasets (each split into training and validation set), and "
"wrap everything in their own ``DataLoader``."
msgstr ""
"现在，让我们加载 CIFAR-10 训练集和测试集，将它们分割成十个较小的数据集（每个数据集又分为训练集和验证集），并将所有数据都封装在各自的 "
"``DataLoader`` 中。"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:163
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:163
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:169
msgid "Model training/evaluation"
msgstr "模型培训/评估"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:165
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:165
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:171
msgid ""
"Let's continue with the usual model definition (including "
"``set_parameters`` and ``get_parameters``), training and test functions:"
msgstr "让我们继续使用常见的模型定义（包括 `set_parameters` 和 `get_parameters`）、训练和测试函数："

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:256
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:262
msgid "Flower client"
msgstr "Flower 客户端"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:258
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:264
#, fuzzy
msgid ""
"To implement the Flower client, we (again) create a subclass of "
"``flwr.client.NumPyClient`` and implement the three methods "
"``get_parameters``, ``fit``, and ``evaluate``. Here, we also pass the "
"``partition_id`` to the client and use it log additional details. We then"
" create an instance of ``ClientApp`` and pass it the ``client_fn``."
msgstr ""
"为了实现 Flower 客户端，我们（再次）创建了 ``flwr.client.NumPyClient`` 的子类，并实现了 "
"``get_parameters``、``fit`` 和 ``evaluate``三个方法。在这里，我们还将 ``cid`` "
"传递给客户端，并使用它记录其他详细信息："

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:311
msgid "Let's test what we have so far before we continue:"
msgstr "在继续之前，让我们先测试一下我们目前掌握的情况："

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:357
msgid "Build a Strategy from scratch"
msgstr "从零开始构建策略"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:359
msgid ""
"Let’s overwrite the ``configure_fit`` method such that it passes a higher"
" learning rate (potentially also other hyperparameters) to the optimizer "
"of a fraction of the clients. We will keep the sampling of the clients as"
" it is in ``FedAvg`` and then change the configuration dictionary (one of"
" the ``FitIns`` attributes)."
msgstr ""
"让我们重写 ``configure_fit`` 方法，使其向一部分客户的优化器传递更高的学习率（可能还有其他超参数）。我们将保持 "
"``FedAvg`` 中的客户端采样，然后更改配置字典（``FitIns`` 属性之一）。"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:523
msgid ""
"The only thing left is to use the newly created custom Strategy "
"``FedCustom`` when starting the experiment:"
msgstr "剩下的唯一工作就是在启动实验时使用新创建的自定义策略 ``FedCustom`` ："

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:559
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:998
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:841
msgid "Recap"
msgstr "回顾"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:561
msgid ""
"In this notebook, we’ve seen how to implement a custom strategy. A custom"
" strategy enables granular control over client node configuration, result"
" aggregation, and more. To define a custom strategy, you only have to "
"overwrite the abstract methods of the (abstract) base class ``Strategy``."
" To make custom strategies even more powerful, you can pass custom "
"functions to the constructor of your new class (``__init__``) and then "
"call these functions whenever needed."
msgstr ""
"在本笔记中，我们了解了如何实施自定义策略。自定义策略可以对客户端节点配置、结果聚合等进行细粒度控制。要定义自定义策略，只需覆盖（抽象）基类 "
"``Strategy`` "
"的抽象方法即可。为使自定义策略更加强大，您可以将自定义函数传递给新类的构造函数（`__init__``），然后在需要时调用这些函数。"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:575
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:1014
#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:813
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:859
#, fuzzy
msgid ""
"Before you continue, make sure to join the Flower community on Flower "
"Discuss (`Join Flower Discuss <https://discuss.flower.ai>`__) and on "
"Slack (`Join Slack <https://flower.ai/join-slack/>`__)."
msgstr ""
"在继续之前，请务必加入 Slack 上的 Flower 社区：`Join Slack <https://flower.ai/join-"
"slack/>`__"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:577
#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:1016
#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:815
#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:861
#: ../../source/tutorial-series-what-is-federated-learning.ipynb:371
msgid ""
"There's a dedicated ``#questions`` channel if you need help, but we'd "
"also love to hear who you are in ``#introductions``!"
msgstr "如果您需要帮助，我们有专门的 ``#questions`` 频道，但我们也很乐意在 ``#introductions`` 中了解您是谁！"

#: ../../source/tutorial-series-build-a-strategy-from-scratch-pytorch.ipynb:579
msgid ""
"The `Flower Federated Learning Tutorial - Part 4 "
"<https://flower.ai/docs/framework/tutorial-customize-the-client-"
"pytorch.html>`__ introduces ``Client``, the flexible API underlying "
"``NumPyClient``."
msgstr ""
"Flower联邦学习教程 - 第4部分 <https://flower.ai/docs/framework/tutorial-customize-"
"the-client-pytorch.html>`__ 介绍了``Client``，它是``NumPyClient``底层的灵活应用程序接口。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:9
msgid "Customize the client"
msgstr "自定义客户端"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:11
msgid ""
"Welcome to the fourth part of the Flower federated learning tutorial. In "
"the previous parts of this tutorial, we introduced federated learning "
"with PyTorch and Flower (`part 1 <https://flower.ai/docs/framework"
"/tutorial-get-started-with-flower-pytorch.html>`__), we learned how "
"strategies can be used to customize the execution on both the server and "
"the clients (`part 2 <https://flower.ai/docs/framework/tutorial-use-a"
"-federated-learning-strategy-pytorch.html>`__), and we built our own "
"custom strategy from scratch (`part 3 <https://flower.ai/docs/framework"
"/tutorial-build-a-strategy-from-scratch-pytorch.html>`__)."
msgstr ""
"欢迎来到 Flower 联邦学习教程的第四部分。在本教程的前几部分中，我们介绍了 PyTorch 和 Flower 的联邦学习（`part 1 "
"<https://flower.ai/docs/framework/tutorial-get-started-with-flower-"
"pytorch.html>`__），了解了如何使用策略来定制服务器和客户端的执行（`part 2 "
"<https://flower.ai/docs/framework/tutorial-use-a-federated-learning-"
"strategy-pytorch.html>`__），并从头开始构建了我们自己的定制策略（`part 3 "
"<https://flower.ai/docs/framework/tutorial-build-a-strategy-from-scratch-"
"pytorch.html>`__）。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:14
msgid ""
"In this notebook, we revisit ``NumPyClient`` and introduce a new "
"baseclass for building clients, simply named ``Client``. In previous "
"parts of this tutorial, we've based our client on ``NumPyClient``, a "
"convenience class which makes it easy to work with machine learning "
"libraries that have good NumPy interoperability. With ``Client``, we gain"
" a lot of flexibility that we didn't have before, but we'll also have to "
"do a few things the we didn't have to do before."
msgstr ""
"在本笔记中，我们将重温 ``NumPyClient`` 并引入一个用于构建客户端的新基类，简单命名为 "
"``Client``。在本教程的前几部分中，我们的客户端基于``NumPyClient``，这是一个便捷类，可以让我们轻松地与具有良好 NumPy"
" 互操作性的机器学习库协同工作。有了 ``Client``，我们获得了很多以前没有的灵活性，但我们也必须做一些以前不需要做的事情。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:19
#, fuzzy
msgid ""
"Let's go deeper and see what it takes to move from ``NumPyClient`` to "
"``Client``! 🌼"
msgstr "让我们深入了解一下从 ``NumPyClient`` 到 ``Client`` 的过程！"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:31
#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:30
msgid "Step 0: Preparation"
msgstr "步骤 0：准备工作"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:121
#, fuzzy
msgid ""
"Let's now define a loading function for the CIFAR-10 training and test "
"set, partition them into ``num_partitions`` smaller datasets (each split "
"into training and validation set), and wrap everything in their own "
"``DataLoader``."
msgstr ""
"现在，让我们加载 CIFAR-10 训练集和测试集，将它们分割成十个较小的数据集（每个数据集又分为训练集和验证集），并将所有数据都封装在各自的 "
"``DataLoader`` 中。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:256
msgid "Step 1: Revisiting NumPyClient"
msgstr "步骤 1：重温 NumPyClient"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:258
#, fuzzy
msgid ""
"So far, we've implemented our client by subclassing "
"``flwr.client.NumPyClient``. The three methods we implemented are "
"``get_parameters``, ``fit``, and ``evaluate``."
msgstr ""
"到目前为止，我们通过子类化 ``flwr.client.NumPyClient`` "
"实现了我们的客户端。我们实现了三个方法：``get_parameters``, ``fit`, 和``evaluate``。最后，我们用一个名为 "
"``client_fn`` 的函数来创建该类的实例："

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:299
msgid ""
"Then, we define the function ``numpyclient_fn`` that is used by Flower to"
" create the ``FlowerNumpyClient`` instances on demand. Finally, we create"
" the ``ClientApp`` and pass the ``numpyclient_fn`` to it."
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:328
#, fuzzy
msgid ""
"We've seen this before, there's nothing new so far. The only *tiny* "
"difference compared to the previous notebook is naming, we've changed "
"``FlowerClient`` to ``FlowerNumPyClient`` and ``client_fn`` to "
"``numpyclient_fn``. Next, we configure the number of federated learning "
"rounds using ``ServerConfig`` and create the ``ServerApp`` with this "
"config:"
msgstr ""
"我们以前见过这种情况，目前没有什么新东西。与之前的笔记相比，唯一*小*的不同是命名，我们把 ``FlowerClient`` 改成了 "
"``FlowerNumPyClient``，把 `client_fn` 改成了 ``numpyclient_fn``。让我们运行它看看输出结果："

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:355
msgid ""
"Finally, we specify the resources for each client and run the simulation "
"to see the output we get:"
msgstr ""

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:389
#, fuzzy
msgid ""
"This works as expected, ten clients are training for three rounds of "
"federated learning."
msgstr "结果不出所料，两个客户端正在进行三轮联邦学习训练。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:391
#, fuzzy
msgid ""
"Let's dive a little bit deeper and discuss how Flower executes this "
"simulation. Whenever a client is selected to do some work, "
"``run_simulation`` launches the ``ClientApp`` object which in turn calls "
"the function ``numpyclient_fn`` to create an instance of our "
"``FlowerNumPyClient`` (along with loading the model and the data)."
msgstr ""
"让我们再深入一点，讨论一下 Flower 是如何执行模拟的。每当一个客户端被选中进行工作时，`start_simulation`` 就会调用函数 "
"`numpyclient_fn` 来创建我们的 ``FlowerNumPyClient`` 实例（同时加载模型和数据）。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:393
msgid ""
"But here's the perhaps surprising part: Flower doesn't actually use the "
"``FlowerNumPyClient`` object directly. Instead, it wraps the object to "
"makes it look like a subclass of ``flwr.client.Client``, not "
"``flwr.client.NumPyClient``. In fact, the Flower core framework doesn't "
"know how to handle ``NumPyClient``'s, it only knows how to handle "
"``Client``'s. ``NumPyClient`` is just a convenience abstraction built on "
"top of ``Client``."
msgstr ""
"但令人惊讶的部分也许就在这里： Flower 实际上并不直接使用 ``FlowerNumPyClient`` "
"对象。相反，它封装了该对象，使其看起来像 ``flwr.client.Client`` 的子类，而不是 "
"``flwr.client.NumPyClient``。事实上，Flower 核心框架不知道如何处理 "
"``NumPyClient``，它只知道如何处理 ``Client``。``NumPyClient`` "
"只是建立在``Client``之上的便捷抽象类。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:395
msgid ""
"Instead of building on top of ``NumPyClient``, we can directly build on "
"top of ``Client``."
msgstr "与其在 ``NumPyClient`` 上构建，我们可以直接在 ``Client`` 上构建。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:407
msgid "Step 2: Moving from ``NumPyClient`` to ``Client``"
msgstr "步骤 2：从 ``NumPyClient`` 移至 ``Client``"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:409
msgid ""
"Let's try to do the same thing using ``Client`` instead of "
"``NumPyClient``."
msgstr "让我们尝试使用 ``Client`` 代替 ``NumPyClient`` 做同样的事情。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:519
msgid ""
"Before we discuss the code in more detail, let's try to run it! Gotta "
"make sure our new ``Client``-based client works, right?"
msgstr "在详细讨论代码之前，让我们试着运行它！必须确保我们基于 ``Client`` 的新客户端能正常运行，对吗？"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:545
msgid ""
"That's it, we're now using ``Client``. It probably looks similar to what "
"we've done with ``NumPyClient``. So what's the difference?"
msgstr "就是这样，我们现在开始使用 ``Client``。它看起来可能与我们使用 ``NumPyClient`` 所做的类似。那么有什么不同呢？"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:547
msgid ""
"First of all, it's more code. But why? The difference comes from the fact"
" that ``Client`` expects us to take care of parameter serialization and "
"deserialization. For Flower to be able to send parameters over the "
"network, it eventually needs to turn these parameters into ``bytes``. "
"Turning parameters (e.g., NumPy ``ndarray``'s) into raw bytes is called "
"serialization. Turning raw bytes into something more useful (like NumPy "
"``ndarray``'s) is called deserialization. Flower needs to do both: it "
"needs to serialize parameters on the server-side and send them to the "
"client, the client needs to deserialize them to use them for local "
"training, and then serialize the updated parameters again to send them "
"back to the server, which (finally!) deserializes them again in order to "
"aggregate them with the updates received from other clients."
msgstr ""
"首先，它的代码更多。但为什么呢？区别在于 ``Client`` 希望我们处理参数的序列化和反序列化。Flower "
"要想通过网络发送参数，最终需要将这些参数转化为 ``字节``。把参数（例如 NumPy 的 ``ndarray`` "
"参数）变成原始字节叫做序列化。将原始字节转换成更有用的东西（如 NumPy ``ndarray`）称为反序列化。Flower "
"需要同时做这两件事：它需要在服务器端序列化参数并将其发送到客户端，客户端需要反序列化参数以便将其用于本地训练，然后再次序列化更新后的参数并将其发送回服务器，服务器（最后）再次反序列化参数以便将其与从其他客户端接收到的更新汇总在一起。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:550
msgid ""
"The only *real* difference between Client and NumPyClient is that "
"NumPyClient takes care of serialization and deserialization for you. It "
"can do so because it expects you to return parameters as NumPy ndarray's,"
" and it knows how to handle these. This makes working with machine "
"learning libraries that have good NumPy support (most of them) a breeze."
msgstr ""
"Client 与 NumPyClient 之间的唯一**真正区别在于，NumPyClient "
"会为你处理序列化和反序列化。NumPyClient之所以能做到这一点，是因为它预计你会以NumPy "
"ndarray的形式返回参数，而且它知道如何处理这些参数。这使得与具有良好 NumPy 支持的大多数机器学习库一起工作变得轻而易举。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:552
msgid ""
"In terms of API, there's one major difference: all methods in Client take"
" exactly one argument (e.g., ``FitIns`` in ``Client.fit``) and return "
"exactly one value (e.g., ``FitRes`` in ``Client.fit``). The methods in "
"``NumPyClient`` on the other hand have multiple arguments (e.g., "
"``parameters`` and ``config`` in ``NumPyClient.fit``) and multiple return"
" values (e.g., ``parameters``, ``num_example``, and ``metrics`` in "
"``NumPyClient.fit``) if there are multiple things to handle. These "
"``*Ins`` and ``*Res`` objects in ``Client`` wrap all the individual "
"values you're used to from ``NumPyClient``."
msgstr ""
"在 API 方面，有一个主要区别：Client 中的所有方法都只接受一个参数（例如，``Client.fit`` 中的 "
"``FitIns``），并只返回一个值（例如，``Client.fit`` 中的 "
"``FitRes``）。另一方面，``NumPyClient``中的方法有多个参数（例如，``NumPyClient.fit``中的``parameters``和``config``）和多个返回值（例如，``NumPyClient.fit``中的``parameters``、``num_example``和``metrics``）。在"
" ``Client`` 中的这些 ``*Ins`` 和 ``*Res`` 对象封装了你在 ``NumPyClient`` 中习惯使用的所有单个值。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:565
msgid "Step 3: Custom serialization"
msgstr "步骤 3：自定义序列化"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:567
msgid ""
"Here we will explore how to implement custom serialization with a simple "
"example."
msgstr "下面我们将通过一个简单的示例来探讨如何实现自定义序列化。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:569
msgid ""
"But first what is serialization? Serialization is just the process of "
"converting an object into raw bytes, and equally as important, "
"deserialization is the process of converting raw bytes back into an "
"object. This is very useful for network communication. Indeed, without "
"serialization, you could not just a Python object through the internet."
msgstr ""
"首先，什么是序列化？序列化只是将对象转换为原始字节的过程，同样重要的是，反序列化是将原始字节转换回对象的过程。这对网络通信非常有用。事实上，如果没有序列化，你就无法通过互联网传输一个"
" Python 对象。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:571
msgid ""
"Federated Learning relies heavily on internet communication for training "
"by sending Python objects back and forth between the clients and the "
"server. This means that serialization is an essential part of Federated "
"Learning."
msgstr "通过在客户端和服务器之间来回发送 Python 对象，联合学习在很大程度上依赖于互联网通信进行训练。这意味着序列化是联邦学习的重要组成部分。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:573
msgid ""
"In the following section, we will write a basic example where instead of "
"sending a serialized version of our ``ndarray``\\ s containing our "
"parameters, we will first convert the ``ndarray`` into sparse matrices, "
"before sending them. This technique can be used to save bandwidth, as in "
"certain cases where the weights of a model are sparse (containing many 0 "
"entries), converting them to a sparse matrix can greatly improve their "
"bytesize."
msgstr ""
"在下面的章节中，我们将编写一个基本示例，在发送包含参数的 ``ndarray`` 前，我们将首先把 ``ndarray`` "
"转换为稀疏矩阵，而不是发送序列化版本。这种技术可以用来节省带宽，因为在某些情况下，模型的参数是稀疏的（包含许多 0 "
"条目），将它们转换成稀疏矩阵可以大大提高它们的字节数。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:576
msgid "Our custom serialization/deserialization functions"
msgstr "我们的定制序列化/反序列化功能"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:578
msgid ""
"This is where the real serialization/deserialization will happen, "
"especially in ``ndarray_to_sparse_bytes`` for serialization and "
"``sparse_bytes_to_ndarray`` for deserialization."
msgstr ""
"这才是真正的序列化/反序列化，尤其是在用于序列化的 ``ndarray_too_sparse_bytes`` 和用于反序列化的 "
"``sparse_bytes_too_ndarray`` 中。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:580
msgid ""
"Note that we imported the ``scipy.sparse`` library in order to convert "
"our arrays."
msgstr "请注意，为了转换数组，我们导入了 ``scipy.sparse`` 库。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:668
msgid "Client-side"
msgstr "客户端"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:670
msgid ""
"To be able to serialize our ``ndarray``\\ s into sparse parameters, we "
"will just have to call our custom functions in our "
"``flwr.client.Client``."
msgstr "为了能够将我们的 ``ndarray`` 序列化为稀疏参数，我们只需在 ``flwr.client.Client`` 中调用我们的自定义函数。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:672
msgid ""
"Indeed, in ``get_parameters`` we need to serialize the parameters we got "
"from our network using our custom ``ndarrays_to_sparse_parameters`` "
"defined above."
msgstr ""
"事实上，在 `get_parameters` 中，我们需要使用上文定义的自定义 `ndarrays_too_sparse_parameters` "
"序列化从网络中获取的参数。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:674
msgid ""
"In ``fit``, we first need to deserialize the parameters coming from the "
"server using our custom ``sparse_parameters_to_ndarrays`` and then we "
"need to serialize our local results with "
"``ndarrays_to_sparse_parameters``."
msgstr ""
"在 ``fit`` 中，我们首先需要使用自定义的 ``sparse_parameters_to_ndarrays`` "
"反序列化来自服务器的参数，然后使用 ``ndarrays_to_sparse_parameters`` 序列化本地结果。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:676
msgid ""
"In ``evaluate``, we will only need to deserialize the global parameters "
"with our custom function."
msgstr "在 ``evaluate`` 中，我们只需要用自定义函数反序列化全局参数。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:781
msgid "Server-side"
msgstr "服务器端"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:783
msgid ""
"For this example, we will just use ``FedAvg`` as a strategy. To change "
"the serialization and deserialization here, we only need to reimplement "
"the ``evaluate`` and ``aggregate_fit`` functions of ``FedAvg``. The other"
" functions of the strategy will be inherited from the super class "
"``FedAvg``."
msgstr ""
"在本例中，我们将只使用 ``FedAvg`` 作为策略。要改变这里的序列化和反序列化，我们只需重新实现 ``FedAvg`` 的 "
"``evaluate`` 和 ``aggregate_fit`` 函数。策略的其他函数将从超类 ``FedAvg`` 继承。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:785
msgid "As you can see only one line as change in ``evaluate``:"
msgstr "正如你所看到的，``evaluate``中只修改了一行："

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:791
msgid ""
"And for ``aggregate_fit``, we will first deserialize every result we "
"received:"
msgstr "而对于 ``aggregate_fit``，我们将首先反序列化收到的每个结果："

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:800
msgid "And then serialize the aggregated result:"
msgstr "然后将汇总结果序列化："

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:959
msgid "We can now run our custom serialization example!"
msgstr "现在我们可以运行自定义序列化示例！"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:1000
msgid ""
"In this part of the tutorial, we've seen how we can build clients by "
"subclassing either ``NumPyClient`` or ``Client``. ``NumPyClient`` is a "
"convenience abstraction that makes it easier to work with machine "
"learning libraries that have good NumPy interoperability. ``Client`` is a"
" more flexible abstraction that allows us to do things that are not "
"possible in ``NumPyClient``. In order to do so, it requires us to handle "
"parameter serialization and deserialization ourselves."
msgstr ""
"在本部分教程中，我们已经了解了如何通过子类化 ``NumPyClient`` 或 ``Client`` 来构建客户端。NumPyClient "
"\"是一个便捷的抽象类，可以让我们更容易地与具有良好NumPy互操作性的机器学习库一起工作。``Client``是一个更灵活的抽象类，允许我们做一些在`NumPyClient``中做不到的事情。为此，它要求我们自己处理参数序列化和反序列化。"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:1018
msgid ""
"This is the final part of the Flower tutorial (for now!), "
"congratulations! You're now well equipped to understand the rest of the "
"documentation. There are many topics we didn't cover in the tutorial, we "
"recommend the following resources:"
msgstr "这暂时是 Flower 教程的最后一部分，恭喜您！您现在已经具备了理解其余文档的能力。本教程还有许多内容没有涉及，我们推荐您参考以下资源："

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:1020
msgid "`Read Flower Docs <https://flower.ai/docs/>`__"
msgstr "阅读Flower文档 <https://flower.ai/docs/>`__"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:1021
#, fuzzy
msgid "`Check out Flower Code Examples <https://flower.ai/docs/examples/>`__"
msgstr "查看 Flower 代码示例 <https://github.com/adap/flower/tree/main/examples>`__"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:1022
msgid ""
"`Use Flower Baselines for your research "
"<https://flower.ai/docs/baselines/>`__"
msgstr "使用 \"Flower Baselines \"进行研究 <https://flower.ai/docs/baselines/>`__"

#: ../../source/tutorial-series-customize-the-client-pytorch.ipynb:1023
#, fuzzy
msgid ""
"`Watch Flower AI Summit 2024 videos <https://flower.ai/conf/flower-ai-"
"summit-2024/>`__"
msgstr "观看 2023 年Flower峰会视频 <https://flower.ai/conf/flower-summit-2023/>`__"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:9
msgid "Get started with Flower"
msgstr "开始使用Flower"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:11
#: ../../source/tutorial-series-what-is-federated-learning.ipynb:11
msgid "Welcome to the Flower federated learning tutorial!"
msgstr "欢迎阅读Flower联邦学习教程！"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:13
#, fuzzy
msgid ""
"In this notebook, we'll build a federated learning system using the "
"Flower framework, Flower Datasets and PyTorch. In part 1, we use PyTorch "
"for the model training pipeline and data loading. In part 2, we federate "
"the PyTorch project using Flower."
msgstr ""
"在本笔记中，我们将使用 Flower 和 PyTorch 构建一个联邦学习系统。在第一部分中，我们使用 PyTorch "
"进行模型训练和数据加载。在第二部分中，我们将继续使用 Flower 联邦化基于 PyTorch 的框架。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:18
#, fuzzy
msgid "Let's get started! 🌼"
msgstr "让我们开始吧！"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:32
msgid ""
"Before we begin with any actual code, let's make sure that we have "
"everything we need."
msgstr "在开始编写实际代码之前，让我们先确保我们已经准备好了所需的一切。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:44
#, fuzzy
msgid "Install dependencies"
msgstr "安装依赖项"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:46
#, fuzzy
msgid ""
"Next, we install the necessary packages for PyTorch (``torch`` and "
"``torchvision``), Flower Datasets (``flwr-datasets``) and Flower "
"(``flwr``):"
msgstr "接下来，我们为 PyTorch（`torch`` 和`torchvision``）和 Flower（`flwr`）安装必要的软件包："

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:109
#, fuzzy
msgid ""
"It is possible to switch to a runtime that has GPU acceleration enabled "
"(on Google Colab: ``Runtime > Change runtime type > Hardware accelerator:"
" GPU > Save``). Note, however, that Google Colab is not always able to "
"offer GPU acceleration. If you see an error related to GPU availability "
"in one of the following sections, consider switching back to CPU-based "
"execution by setting ``DEVICE = torch.device(\"cpu\")``. If the runtime "
"has GPU acceleration enabled, you should see the output ``Training on "
"cuda``, otherwise it'll say ``Training on cpu``."
msgstr ""
"可以切换到已启用 GPU 加速的运行时（在 Google Colab 上： 运行时 > 更改运行时类型 > 硬件加速： GPU > "
"保存``）。但请注意，Google Colab 并非总能提供 GPU 加速。如果在以下部分中看到与 GPU 可用性相关的错误，请考虑通过设置 "
"``DEVICE = torch.device(\"cpu\")`` 切回基于 CPU 的执行。如果运行时已启用 GPU "
"加速，你应该会看到输出``Training on cuda``，否则会显示``Training on cpu``。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:122
#, fuzzy
msgid "Load the data"
msgstr "加载数据"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:124
#, fuzzy
msgid ""
"Federated learning can be applied to many different types of tasks across"
" different domains. In this tutorial, we introduce federated learning by "
"training a simple convolutional neural network (CNN) on the popular "
"CIFAR-10 dataset. CIFAR-10 can be used to train image classifiers that "
"distinguish between images from ten different classes: 'airplane', "
"'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', and "
"'truck'."
msgstr ""
"联邦学习可应用于不同领域的多种不同类型任务。在本教程中，我们将通过在流行的 CIFAR-10 数据集上训练一个简单的卷积神经网络 (CNN) "
"来介绍联合学习。CIFAR-10 可用于训练图像分类器，以区分来自十个不同类别的图像："

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:135
#, fuzzy
msgid ""
"We simulate having multiple datasets from multiple organizations (also "
"called the \"cross-silo\" setting in federated learning) by splitting the"
" original CIFAR-10 dataset into multiple partitions. Each partition will "
"represent the data from a single organization. We're doing this purely "
"for experimentation purposes, in the real world there's no need for data "
"splitting because each organization already has their own data (the data "
"is naturally partitioned)."
msgstr ""
"我们通过将原始 CIFAR-10 数据集拆分成多个分区来模拟来自多个组织的多个数据集（也称为联邦学习中的 \"跨分区 "
"\"设置）。每个分区代表一个组织的数据。我们这样做纯粹是为了实验目的，在现实世界中不需要拆分数据，因为每个组织都已经有了自己的数据（所以数据是自然分区的）。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:137
#, fuzzy
msgid ""
"Each organization will act as a client in the federated learning system. "
"Having ten organizations participate in a federation means having ten "
"clients connected to the federated learning server."
msgstr "每个组织都将充当联邦学习系统中的客户端。因此，有十个组织参与联邦学习，就意味着有十个客户端连接到联邦学习服务器："

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:148
#, fuzzy
msgid ""
"We use the Flower Datasets library (``flwr-datasets``) to partition "
"CIFAR-10 into ten partitions using ``FederatedDataset``. We will create a"
" small training and test set for each of the ten organizations and wrap "
"each of these into a PyTorch ``DataLoader``:"
msgstr ""
"现在，让我们从 ``flwr-datasets`` 中创建 Federated Dataset 抽象，以分割 "
"CIFAR-10。我们将为每个边缘设备创建小型训练集和测试集，并将它们分别封装到 PyTorch ``DataLoader`` 中："

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:196
#, fuzzy
msgid ""
"We now have a function that can return a training set and validation set "
"(``trainloader`` and ``valloader``) representing one dataset from one of "
"ten different organizations. Each ``trainloader``/``valloader`` pair "
"contains 4000 training examples and 1000 validation examples. There's "
"also a single ``testloader`` (we did not split the test set). Again, this"
" is only necessary for building research or educational systems, actual "
"federated learning systems have their data naturally distributed across "
"multiple partitions."
msgstr ""
"现在，我们有一个包含十个训练集和十个验证集（`trainloaders`` 和`valloaders``）的列表，代表十个不同组织的数据。每对 "
"``trainloader``/``valloader`` 都包含 4500 个训练示例和 500 个验证数据。还有一个单独的 "
"``测试加载器``（我们没有拆分测试集）。同样，这只有在构建研究或教育系统时才有必要，实际的联邦学习系统的数据自然分布在多个分区中。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:199
#, fuzzy
msgid ""
"Let's take a look at the first batch of images and labels in the first "
"training set (i.e., ``trainloader`` from ``partition_id=0``) before we "
"move on:"
msgstr "在继续之前，让我们先看看第一个训练集中的第一批图像和标签（即 ``trainloaders[0]``）："

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:241
#, fuzzy
msgid ""
"The output above shows a random batch of images from the ``trainloader`` "
"from the first of ten partitions. It also prints the labels associated "
"with each image (i.e., one of the ten possible labels we've seen above). "
"If you run the cell again, you should see another batch of images."
msgstr ""
"上面的输出显示了来自十个 \"trainloader \"列表中第一个 \"trainloader "
"\"的随机图像。它还打印了与每幅图像相关的标签（即我们上面看到的十个可能标签之一）。如果您再次运行该单元，应该会看到另一批图像。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:253
msgid "Step 1: Centralized Training with PyTorch"
msgstr "步骤 1：使用 PyTorch 进行集中训练"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:264
msgid ""
"Next, we're going to use PyTorch to define a simple convolutional neural "
"network. This introduction assumes basic familiarity with PyTorch, so it "
"doesn't cover the PyTorch-related aspects in full detail. If you want to "
"dive deeper into PyTorch, we recommend `DEEP LEARNING WITH PYTORCH: A 60 "
"MINUTE BLITZ "
"<https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html>`__."
msgstr ""
"接下来，我们将使用 PyTorch 来定义一个简单的卷积神经网络。本介绍假定您对 PyTorch 有基本的了解，因此不会详细介绍与 PyTorch"
" 相关的内容。如果你想更深入地了解 PyTorch，我们推荐你阅读 `DEEP LEARNING WITH PYTORCH： a 60 "
"minute blitz "
"<https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html>`__。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:276
#, fuzzy
msgid "Define the model"
msgstr "定义模型"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:278
msgid ""
"We use the simple CNN described in the `PyTorch tutorial "
"<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#define-a"
"-convolutional-neural-network>`__:"
msgstr ""
"我们使用` PyTorch 教程 "
"<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#define-a"
"-convolutional-neural-network>`__ 中描述的简单 CNN："

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:315
msgid "Let's continue with the usual training and test functions:"
msgstr "让我们继续进行常规的训练和测试功能："

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:375
#, fuzzy
msgid "Train the model"
msgstr "训练模型"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:377
#, fuzzy
msgid ""
"We now have all the basic building blocks we need: a dataset, a model, a "
"training function, and a test function. Let's put them together to train "
"the model on the dataset of one of our organizations "
"(``partition_id=0``). This simulates the reality of most machine learning"
" projects today: each organization has their own data and trains models "
"only on this internal data:"
msgstr "现在我们拥有了所需的所有基本构件：数据集、模型、训练函数和测试函数。让我们把它们放在一起，在我们其中一个组织的数据集（``trainloaders[0]``）上训练模型。这模拟了当今大多数机器学习项目的实际情况：每个组织都有自己的数据，并且只在这些内部数据上训练模型："

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:406
#, fuzzy
msgid ""
"Training the simple CNN on our CIFAR-10 split for 5 epochs should result "
"in a test set accuracy of about 41%, which is not good, but at the same "
"time, it doesn't really matter for the purposes of this tutorial. The "
"intent was just to show a simple centralized training pipeline that sets "
"the stage for what comes next - federated learning!"
msgstr ""
"在我们的 CIFAR-10 分片上对简单 CNN 进行 5 个遍历的训练后，测试集的准确率应为 "
"41%，这并不理想，但同时对本教程而言也并不重要。我们只是想展示一个简单的集中式训练流程，为接下来的联邦学习做好铺垫！"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:418
msgid "Step 2: Federated Learning with Flower"
msgstr "步骤 2：使用 Flower 联邦学习"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:420
msgid ""
"Step 1 demonstrated a simple centralized training pipeline. All data was "
"in one place (i.e., a single ``trainloader`` and a single ``valloader``)."
" Next, we'll simulate a situation where we have multiple datasets in "
"multiple organizations and where we train a model over these "
"organizations using federated learning."
msgstr ""
"步骤 1 演示了一个简单的集中式训练流程。所有数据都在一个地方（即一个 \"trainloader \"和一个 "
"\"valloader\"）。接下来，我们将模拟在多个组织中拥有多个数据集的情况，并使用联邦学习在这些组织中训练一个模型。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:432
#, fuzzy
msgid "Update model parameters"
msgstr "更新模型参数"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:434
#, fuzzy
msgid ""
"In federated learning, the server sends global model parameters to the "
"client, and the client updates the local model with parameters received "
"from the server. It then trains the model on the local data (which "
"changes the model parameters locally) and sends the updated/changed model"
" parameters back to the server (or, alternatively, it sends just the "
"gradients back to the server, not the full model parameters)."
msgstr "在联邦学习中，服务器将全局模型参数发送给客户端，客户端根据从服务器接收到的参数更新本地模型。然后，客户端根据本地数据对模型进行训练（在本地更改模型参数），并将更新/更改后的模型参数发回服务器（或者，客户端只将梯度参数发回服务器，而不是全部模型参数）。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:436
msgid ""
"We need two helper functions to update the local model with parameters "
"received from the server and to get the updated model parameters from the"
" local model: ``set_parameters`` and ``get_parameters``. The following "
"two functions do just that for the PyTorch model above."
msgstr ""
"我们需要两个辅助函数，用从服务器接收到的参数更新本地模型，并从本地模型获取更新后的模型参数：`` "
"set_parameters```和`get_parameters``。下面两个函数就是为上面的 PyTorch 模型做这些工作的。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:438
#, fuzzy
msgid ""
"The details of how this works are not really important here (feel free to"
" consult the PyTorch documentation if you want to learn more). In "
"essence, we use ``state_dict`` to access PyTorch model parameter tensors."
" The parameter tensors are then converted to/from a list of NumPy "
"ndarray's (which the Flower ``NumPyClient`` knows how to "
"serialize/deserialize):"
msgstr ""
"在这里，如何工作的细节并不重要（如果你想了解更多，请随时查阅 PyTorch 文档）。本质上，我们使用 ``state_dict`` 访问 "
"PyTorch 模型参数张量。然后，参数张量会被转换成/转换成 NumPy ndarray 列表（Flower 知道如何序列化/反序列化）："

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:466
#, fuzzy
msgid "Define the Flower ClientApp"
msgstr "Flower 客户端。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:468
#, fuzzy
msgid ""
"With that out of the way, let's move on to the interesting part. "
"Federated learning systems consist of a server and multiple clients. In "
"Flower, we create a ``ServerApp`` and a ``ClientApp`` to run the server-"
"side and client-side code, respectively."
msgstr ""
"说完这些，让我们进入有趣的部分。联邦学习系统由一个服务器和多个客户端组成。在 Flower 中，我们通过实现 "
"``flwr.client.Client`` 或 ``flwr.client.NumPyClient`` "
"的子类来创建客户端。在本教程中，我们使用``NumPyClient``，因为它更容易实现，需要我们编写的模板也更少。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:470
#, fuzzy
msgid ""
"The first step toward creating a ``ClientApp`` is to implement a "
"subclasses of ``flwr.client.Client`` or ``flwr.client.NumPyClient``. We "
"use ``NumPyClient`` in this tutorial because it is easier to implement "
"and requires us to write less boilerplate. To implement ``NumPyClient``, "
"we create a subclass that implements the three methods "
"``get_parameters``, ``fit``, and ``evaluate``:"
msgstr ""
"说完这些，让我们进入有趣的部分。联邦学习系统由一个服务器和多个客户端组成。在 Flower 中，我们通过实现 "
"``flwr.client.Client`` 或 ``flwr.client.NumPyClient`` "
"的子类来创建客户端。在本教程中，我们使用``NumPyClient``，因为它更容易实现，需要我们编写的模板也更少。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:472
msgid "``get_parameters``: Return the current local model parameters"
msgstr "``get_parameters``： 返回当前本地模型参数"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:473
#, fuzzy
msgid ""
"``fit``: Receive model parameters from the server, train the model on the"
" local data, and return the updated model parameters to the server"
msgstr "``fit``： 从服务器接收模型参数，在本地数据上训练模型参数，并将（更新的）模型参数返回服务器"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:474
#, fuzzy
msgid ""
"``evaluate``: Receive model parameters from the server, evaluate the "
"model on the local data, and return the evaluation result to the server"
msgstr "``evaluate ``： 从服务器接收模型参数，在本地数据上评估模型参数，并将评估结果返回服务器"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:476
msgid ""
"We mentioned that our clients will use the previously defined PyTorch "
"components for model training and evaluation. Let's see a simple Flower "
"client implementation that brings everything together:"
msgstr ""
"我们提到，我们的客户端将使用之前定义的 PyTorch 组件进行模型训练和评估。让我们来看看一个简单的 Flower "
"客户端实现，它将一切都整合在一起："

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:513
#, fuzzy
msgid ""
"Our class ``FlowerClient`` defines how local training/evaluation will be "
"performed and allows Flower to call the local training/evaluation through"
" ``fit`` and ``evaluate``. Each instance of ``FlowerClient`` represents a"
" *single client* in our federated learning system. Federated learning "
"systems have multiple clients (otherwise, there's not much to federate), "
"so each client will be represented by its own instance of "
"``FlowerClient``. If we have, for example, three clients in our workload,"
" then we'd have three instances of ``FlowerClient`` (one on each of the "
"machines we'd start the client on). Flower calls ``FlowerClient.fit`` on "
"the respective instance when the server selects a particular client for "
"training (and ``FlowerClient.evaluate`` for evaluation)."
msgstr ""
"我们的类 ``FlowerClient`` 定义了本地训练/评估的执行方式，并允许 Flower 通过 ``fit`` 和 "
"``evaluate`` 调用本地训练/评估。每个 ``FlowerClient`` "
"实例都代表联邦学习系统中的*单个客户端*。联邦学习系统有多个客户端（否则就没有什么可联邦的），因此每个客户端都将由自己的 "
"``FlowerClient`` 实例来代表。例如，如果我们的工作负载中有三个客户端，那么我们就会有三个 ``FlowerClient`` "
"实例。当服务器选择特定客户端进行训练时，Flower 会调用相应实例上的 ``FlowerClient.fit`` （评估时调用 "
"``FlowerClient.evaluate``）。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:516
#, fuzzy
msgid ""
"In this notebook, we want to simulate a federated learning system with 10"
" clients *on a single machine*. This means that the server and all 10 "
"clients will live on a single machine and share resources such as CPU, "
"GPU, and memory. Having 10 clients would mean having 10 instances of "
"``FlowerClient`` in memory. Doing this on a single machine can quickly "
"exhaust the available memory resources, even if only a subset of these "
"clients participates in a single round of federated learning."
msgstr ""
"在本笔记中，我们要模拟一个联邦学习系统，在一台机器上有 10 个客户端。这意味着服务器和所有 10 个客户端都将位于一台机器上，并共享 "
"CPU、GPU 和内存等资源。有 10 个客户端就意味着内存中有 10 个 ``FlowerClient`` "
"实例。在单台机器上这样做会很快耗尽可用的内存资源，即使这些客户端中只有一个子集参与了一轮联邦学习。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:518
#, fuzzy
msgid ""
"In addition to the regular capabilities where server and clients run on "
"multiple machines, Flower, therefore, provides special simulation "
"capabilities that create ``FlowerClient`` instances only when they are "
"actually necessary for training or evaluation. To enable the Flower "
"framework to create clients when necessary, we need to implement a "
"function that creates a ``FlowerClient`` instance on demand. We typically"
" call this function ``client_fn``. Flower calls ``client_fn`` whenever it"
" needs an instance of one particular client to call ``fit`` or "
"``evaluate`` (those instances are usually discarded after use, so they "
"should not keep any local state). In federated learning experiments using"
" Flower, clients are identified by a partition ID, or ``partition-id``. "
"This ``partition-id`` is used to load different local data partitions for"
" different clients, as can be seen below. The value of ``partition-id`` "
"is retrieved from the ``node_config`` dictionary in the ``Context`` "
"object, which holds the information that persists throughout each "
"training round."
msgstr ""
"除了服务器和客户端在多台机器上运行的常规功能外，Flower 还提供了特殊的模拟功能，即只有在训练或评估实际需要时才创建 "
"``FlowerClient`` 实例。为了让 Flower 框架能在必要时创建客户端，我们需要实现一个名为 ``client_fn`` "
"的函数，它能按需创建一个 ``FlowerClient`` 实例。每当 Flower 需要一个特定的客户端实例来调用 ``fit`` 或 "
"``evaluate`` 时，它就会调用 "
"``client_fn``（这些实例在使用后通常会被丢弃，因此它们不应保留任何本地状态）。客户端由一个客户端 ID 或简短的 ``cid`` "
"标识。例如，可以使用 ``cid`` 为不同的客户端加载不同的本地数据分区，如下所示："

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:522
#, fuzzy
msgid ""
"With this, we have the class ``FlowerClient`` which defines client-side "
"training/evaluation and ``client_fn`` which allows Flower to create "
"``FlowerClient`` instances whenever it needs to call ``fit`` or "
"``evaluate`` on one particular client. Last, but definitely not least, we"
" create an instance of ``ClientApp`` and pass it the ``client_fn``. "
"``ClientApp`` is the entrypoint that a running Flower client uses to call"
" your code (as defined in, for example, ``FlowerClient.fit``)."
msgstr ""
"现在我们有了定义客户端训练/评估的类 ``FlowerClient`` 和允许 Flower 在需要调用某个客户端的 ``fit` 或 "
"``evaluate` 时创建 ``FlowerClient`` 实例的 ``client_fn` 类。最后一步是使用 "
"``flwr.simulation.start_simulation`` 启动实际模拟。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:563
#, fuzzy
msgid "Define the Flower ServerApp"
msgstr "Flower 服务器。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:565
#, fuzzy
msgid ""
"On the server side, we need to configure a strategy which encapsulates "
"the federated learning approach/algorithm, for example, *Federated "
"Averaging* (FedAvg). Flower has a number of built-in strategies, but we "
"can also use our own strategy implementations to customize nearly all "
"aspects of the federated learning approach. For this example, we use the "
"built-in ``FedAvg`` implementation and customize it using a few basic "
"parameters:"
msgstr ""
"Flower 有许多内置策略，但我们也可以使用自己的策略实现来定制联邦学习方法的几乎所有方面。在本例中，我们使用内置的 ``FedAvg`` "
"实现，并使用一些基本参数对其进行定制。最后一步是实际调用 ``start_simulation``开始模拟："

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:592
msgid ""
"Similar to ``ClientApp``, we create a ``ServerApp`` using a utility "
"function ``server_fn``. In ``server_fn``, we pass an instance of "
"``ServerConfig`` for defining the number of federated learning rounds "
"(``num_rounds``) and we also pass the previously created ``strategy``. "
"The ``server_fn`` returns a ``ServerAppComponents`` object containing the"
" settings that define the ``ServerApp`` behaviour. ``ServerApp`` is the "
"entrypoint that Flower uses to call all your server-side code (for "
"example, the strategy)."
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:629
#, fuzzy
msgid "Run the training"
msgstr "开始训练"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:631
msgid ""
"In simulation, we often want to control the amount of resources each "
"client can use. In the next cell, we specify a ``backend_config`` "
"dictionary with the ``client_resources`` key (required) for defining the "
"amount of CPU and GPU resources each client can access."
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:659
msgid ""
"The last step is the actual call to ``run_simulation`` which - you "
"guessed it - runs the simulation. ``run_simulation`` accepts a number of "
"arguments: - ``server_app`` and ``client_app``: the previously created "
"``ServerApp`` and ``ClientApp`` objects, respectively - "
"``num_supernodes``: the number of ``SuperNodes`` to simulate which equals"
" the number of clients for Flower simulation - ``backend_config``: the "
"resource allocation used in this simulation"
msgstr ""

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:686
msgid "Behind the scenes"
msgstr "幕后"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:688
msgid "So how does this work? How does Flower execute this simulation?"
msgstr "那么它是如何工作的呢？Flower 如何进行模拟？"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:690
#, fuzzy, python-format
msgid ""
"When we call ``run_simulation``, we tell Flower that there are 10 clients"
" (``num_supernodes=10``, where 1 ``SuperNode`` launches 1 ``ClientApp``)."
" Flower then goes ahead an asks the ``ServerApp`` to issue an "
"instructions to those nodes using the ``FedAvg`` strategy. ``FedAvg`` "
"knows that it should select 100% of the available clients "
"(``fraction_fit=1.0``), so it goes ahead and selects 10 random clients "
"(i.e., 100% of 10)."
msgstr ""
"当我们调用 ``start_simulation`` 时，我们会告诉 Flower 有 10 "
"个客户（`num_clients=10``）。然后，Flower 会要求 ``FedAvg`` 策略选择客户。``FedAvg`` 知道它应该选择"
" 100%的可用客户（``fraction_fit=1.0``），所以它会随机选择 10 个客户（即 10 的 100%）。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:692
#, fuzzy
msgid ""
"Flower then asks the selected 10 clients to train the model. Each of the "
"10 ``ClientApp`` instances receives a message, which causes it to call "
"``client_fn`` to create an instance of ``FlowerClient``. It then calls "
"``.fit()`` on each the ``FlowerClient`` instances and returns the "
"resulting model parameter updates to the ``ServerApp``. When the "
"``ServerApp`` receives the model parameter updates from the clients, it "
"hands those updates over to the strategy (*FedAvg*) for aggregation. The "
"strategy aggregates those updates and returns the new global model, which"
" then gets used in the next round of federated learning."
msgstr ""
"然后，Flower 会要求选定的 10 "
"个客户端对模型进行训练。服务器收到客户端的模型参数更新后，会将这些更新交给策略（*FedAvg*）进行聚合。策略会聚合这些更新并返回新的全局模型，然后将其用于下一轮联邦学习。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:705
msgid "Where's the accuracy?"
msgstr "准确度在哪里找？"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:707
msgid ""
"You may have noticed that all metrics except for ``losses_distributed`` "
"are empty. Where did the ``{\"accuracy\": float(accuracy)}`` go?"
msgstr ""
"您可能已经注意到，除了 ``losses_distributed`` 以外，所有指标都是空的。{\"准确度\": "
"float(准确度)}``去哪儿了？"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:709
msgid ""
"Flower can automatically aggregate losses returned by individual clients,"
" but it cannot do the same for metrics in the generic metrics dictionary "
"(the one with the ``accuracy`` key). Metrics dictionaries can contain "
"very different kinds of metrics and even key/value pairs that are not "
"metrics at all, so the framework does not (and can not) know how to "
"handle these automatically."
msgstr ""
"Flower 可以自动汇总单个客户端返回的损失值，但无法对通用度量字典中的度量进行同样的处理（即带有 \"准确度 "
"\"键的度量字典）。度量值字典可以包含非常不同种类的度量值，甚至包含根本不是度量值的键/值对，因此框架不知道（也无法知道）如何自动处理这些度量值。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:711
msgid ""
"As users, we need to tell the framework how to handle/aggregate these "
"custom metrics, and we do so by passing metric aggregation functions to "
"the strategy. The strategy will then call these functions whenever it "
"receives fit or evaluate metrics from clients. The two possible functions"
" are ``fit_metrics_aggregation_fn`` and "
"``evaluate_metrics_aggregation_fn``."
msgstr ""
"作为用户，我们需要告诉框架如何处理/聚合这些自定义指标，为此，我们将指标聚合函数传递给策略。然后，只要从客户端接收到拟合或评估指标，策略就会调用这些函数。两个可能的函数是"
" ``fit_metrics_aggregation_fn`` 和 ``evaluate_metrics_aggregation_fn``。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:713
msgid ""
"Let's create a simple weighted averaging function to aggregate the "
"``accuracy`` metric we return from ``evaluate``:"
msgstr "让我们创建一个简单的加权平均函数来汇总从 ``evaluate`` 返回的 ``accuracy`` 指标："

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:781
msgid ""
"We now have a full system that performs federated training and federated "
"evaluation. It uses the ``weighted_average`` function to aggregate custom"
" evaluation metrics and calculates a single ``accuracy`` metric across "
"all clients on the server side."
msgstr ""
"我们现在有了一个完整的系统，可以执行联邦训练和联邦评估。它使用 ``weighted_average`` "
"函数汇总自定义评估指标，并在服务器端计算所有客户端的单一 ``accuracy`` 指标。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:783
msgid ""
"The other two categories of metrics (``losses_centralized`` and "
"``metrics_centralized``) are still empty because they only apply when "
"centralized evaluation is being used. Part two of the Flower tutorial "
"will cover centralized evaluation."
msgstr ""
"其他两类指标（`losses_centralized`` 和 "
"`metrics_centralized`）仍然是空的，因为它们只适用于集中评估。Flower 教程的第二部分将介绍集中式评估。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:795
msgid "Final remarks"
msgstr "结束语"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:797
msgid ""
"Congratulations, you just trained a convolutional neural network, "
"federated over 10 clients! With that, you understand the basics of "
"federated learning with Flower. The same approach you've seen can be used"
" with other machine learning frameworks (not just PyTorch) and tasks (not"
" just CIFAR-10 images classification), for example NLP with Hugging Face "
"Transformers or speech with SpeechBrain."
msgstr ""
"恭喜您，你刚刚训练了一个由 10 个客户端组成的卷积神经网络！这样，你就了解了使用 Flower "
"进行联邦学习的基础知识。你所看到的方法同样适用于其他机器学习框架（不只是 PyTorch）和任务（不只是 CIFAR-10 图像分类），例如使用 "
"Hugging Face Transformers 的 NLP 或使用 SpeechBrain 的语音。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:799
msgid ""
"In the next notebook, we're going to cover some more advanced concepts. "
"Want to customize your strategy? Initialize parameters on the server "
"side? Or evaluate the aggregated model on the server side? We'll cover "
"all this and more in the next tutorial."
msgstr "在下一个笔记中，我们将介绍一些更先进的概念。想定制你的策略吗？在服务器端初始化参数？或者在服务器端评估聚合模型？我们将在下一个教程中介绍所有这些内容以及更多。"

#: ../../source/tutorial-series-get-started-with-flower-pytorch.ipynb:817
msgid ""
"The `Flower Federated Learning Tutorial - Part 2 "
"<https://flower.ai/docs/framework/tutorial-use-a-federated-learning-"
"strategy-pytorch.html>`__ goes into more depth about strategies and all "
"the advanced things you can build with them."
msgstr ""
"`Flower 联邦学习教程 - 第 2 部分 <https://flower.ai/docs/framework/tutorial-use-a"
"-federated-learning-strategy-pytorch.html>`__ 更深入地介绍了策略以及可以使用策略构建的所有高级功能。"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:9
msgid "Use a federated learning strategy"
msgstr "使用联邦学习策略"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:11
msgid ""
"Welcome to the next part of the federated learning tutorial. In previous "
"parts of this tutorial, we introduced federated learning with PyTorch and"
" Flower (`part 1 <https://flower.ai/docs/framework/tutorial-get-started-"
"with-flower-pytorch.html>`__)."
msgstr ""
"欢迎来到联邦学习教程的下一部分。在本教程的前几部分，我们介绍了使用 PyTorch 和 Flower 进行联邦学习（`第 1 部分 "
"<https://flower.ai/docs/framework/tutorial-get-started-with-flower-"
"pytorch.html>`___）。"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:13
#, fuzzy
msgid ""
"In this notebook, we'll begin to customize the federated learning system "
"we built in the introductory notebook again, using the Flower framework, "
"Flower Datasets, and PyTorch."
msgstr ""
"在本笔记中，我们将开始定制在入门笔记中构建的联邦学习系统（再次使用 `Flower <https://flower.ai/>`__ 和 "
"`PyTorch <https://pytorch.org/>`__）。"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:18
#, fuzzy
msgid "Let's move beyond FedAvg with Flower strategies! 🌼"
msgstr "让我们超越 FedAvg，采用Flower策略！"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:121
#, fuzzy
msgid ""
"Let's now load the CIFAR-10 training and test set, partition them into "
"ten smaller datasets (each split into training and validation set), and "
"wrap everything in their own ``DataLoader``. We introduce a new parameter"
" ``num_partitions`` which allows us to call ``load_datasets`` with "
"different numbers of partitions."
msgstr ""
"现在，让我们加载 CIFAR-10 训练集和测试集，将它们分割成 10 "
"个较小的数据集（每个数据集又分为训练集和验证集），并将所有数据都封装在各自的 ``DataLoader`` 中。我们引入了一个新参数 "
"``num_clients``，它允许我们使用不同数量的客户端调用 ``load_datasets``。"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:321
msgid "Strategy customization"
msgstr "策略定制"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:323
msgid ""
"So far, everything should look familiar if you've worked through the "
"introductory notebook. With that, we're ready to introduce a number of "
"new features."
msgstr "到目前为止，如果您已经阅读过入门笔记本，那么一切都应该很熟悉了。接下来，我们将介绍一些新功能。"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:335
msgid "Server-side parameter **initialization**"
msgstr "服务器端参数 **初始化**"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:337
#, fuzzy
msgid ""
"Flower, by default, initializes the global model by asking one random "
"client for the initial parameters. In many cases, we want more control "
"over parameter initialization though. Flower therefore allows you to "
"directly pass the initial parameters to the Strategy. We create an "
"instance of ``Net()`` and get the paramaters as follows:"
msgstr ""
"默认情况下，Flower 会通过向一个随机客户端询问初始参数来初始化全局模型。但在许多情况下，我们需要对参数初始化进行更多控制。因此，Flower"
" 允许您直接将初始参数传递给策略："

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:358
msgid ""
"Next, we create a ``server_fn`` that returns the components needed for "
"the server. Within ``server_fn``, we create a Strategy that uses the "
"initial parameters."
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:393
#, fuzzy
msgid ""
"Passing ``initial_parameters`` to the ``FedAvg`` strategy prevents Flower"
" from asking one of the clients for the initial parameters. In "
"``server_fn``, we pass this new ``strategy`` and a ``ServerConfig`` for "
"defining the number of federated learning rounds (``num_rounds``)."
msgstr ""
"向 ``FedAvg`` 策略传递 ``initial_parameters`` 可以防止 Flower "
"向其中一个客户端询问初始参数。如果我们仔细观察，就会发现日志中没有显示对 ``FlowerClient.get_parameters`` "
"方法的任何调用。"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:395
msgid ""
"Similar to the ``ClientApp``, we now create the ``ServerApp`` using the "
"``server_fn``:"
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:416
msgid ""
"Last but not least, we specify the resources for each client and run the "
"simulation."
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:448
#, fuzzy
msgid ""
"If we look closely, we can see that the logs do not show any calls to the"
" ``FlowerClient.get_parameters`` method."
msgstr ""
"向 ``FedAvg`` 策略传递 ``initial_parameters`` 可以防止 Flower "
"向其中一个客户端询问初始参数。如果我们仔细观察，就会发现日志中没有显示对 ``FlowerClient.get_parameters`` "
"方法的任何调用。"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:460
msgid "Starting with a customized strategy"
msgstr "从定制战略开始"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:462
#, fuzzy
msgid ""
"We've seen the function ``run_simulation`` before. It accepts a number of"
" arguments, amongst them the ``server_app`` which wraps around the "
"strategy and number of training rounds, ``client_app`` which wraps around"
" the ``client_fn`` used to create ``FlowerClient`` instances, and the "
"number of clients to simulate which equals ``num_supernodes``."
msgstr ""
"我们以前见过函数 ``start_simulation``。它接受许多参数，其中包括用于创建 ``FlowerClient`` 实例的 "
"``client_fn``、要模拟的客户数量 ``num_clients``、回合数 ``num_rounds``和策略。"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:464
msgid ""
"The strategy encapsulates the federated learning approach/algorithm, for "
"example, ``FedAvg`` or ``FedAdagrad``. Let's try to use a different "
"strategy this time:"
msgstr "该策略封装了联邦学习方法/算法，例如`FedAvg``或`FedAdagrad``。这次让我们尝试使用不同的策略："

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:509
msgid "Server-side parameter **evaluation**"
msgstr "服务器端参数**评估**"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:511
msgid ""
"Flower can evaluate the aggregated model on the server-side or on the "
"client-side. Client-side and server-side evaluation are similar in some "
"ways, but different in others."
msgstr "Flower 可以在服务器端或客户端评估聚合模型。客户端和服务器端评估在某些方面相似，但也有不同之处。"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:513
msgid ""
"**Centralized Evaluation** (or *server-side evaluation*) is conceptually "
"simple: it works the same way that evaluation in centralized machine "
"learning does. If there is a server-side dataset that can be used for "
"evaluation purposes, then that's great. We can evaluate the newly "
"aggregated model after each round of training without having to send the "
"model to clients. We're also fortunate in the sense that our entire "
"evaluation dataset is available at all times."
msgstr "**集中评估**（或*服务器端评估*）在概念上很简单：它的工作方式与集中式机器学习中的评估方式相同。如果有一个服务器端数据集可用于评估目的，那就太好了。我们可以在每一轮训练后对新聚合的模型进行评估，而无需将模型发送给客户端。我们也很幸运，因为我们的整个评估数据集随时可用。"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:515
msgid ""
"**Federated Evaluation** (or *client-side evaluation*) is more complex, "
"but also more powerful: it doesn't require a centralized dataset and "
"allows us to evaluate models over a larger set of data, which often "
"yields more realistic evaluation results. In fact, many scenarios require"
" us to use **Federated Evaluation** if we want to get representative "
"evaluation results at all. But this power comes at a cost: once we start "
"to evaluate on the client side, we should be aware that our evaluation "
"dataset can change over consecutive rounds of learning if those clients "
"are not always available. Moreover, the dataset held by each client can "
"also change over consecutive rounds. This can lead to evaluation results "
"that are not stable, so even if we would not change the model, we'd see "
"our evaluation results fluctuate over consecutive rounds."
msgstr "**联邦评估**（或*客户端评估*）更为复杂，但也更为强大：它不需要集中的数据集，允许我们在更大的数据集上对模型进行评估，这通常会产生更真实的评估结果。事实上，如果我们想得到有代表性的评估结果，很多情况下都需要使用**联邦评估**。但是，这种能力是有代价的：一旦我们开始在客户端进行评估，我们就应该意识到，如果这些客户端并不总是可用，我们的评估数据集可能会在连续几轮学习中发生变化。此外，每个客户端所拥有的数据集也可能在连续几轮学习中发生变化。这可能会导致评估结果不稳定，因此即使我们不改变模型，也会看到评估结果在连续几轮中波动。"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:518
msgid ""
"We've seen how federated evaluation works on the client side (i.e., by "
"implementing the ``evaluate`` method in ``FlowerClient``). Now let's see "
"how we can evaluate aggregated model parameters on the server-side:"
msgstr ""
"我们已经了解了联邦评估如何在客户端工作（即通过在 ``FlowerClient`` 中实现 ``evaluate`` "
"方法）。现在让我们看看如何在服务器端评估聚合模型参数："

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:549
msgid ""
"We create a ``FedAvg`` strategy and pass ``evaluate_fn`` to it. Then, we "
"create a ``ServerApp`` that uses this strategy."
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:586
#, fuzzy
msgid "Finally, we run the simulation."
msgstr "运行模拟"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:613
msgid "Sending/receiving arbitrary values to/from clients"
msgstr "向/从客户端发送/接收任意值"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:615
msgid ""
"In some situations, we want to configure client-side execution (training,"
" evaluation) from the server-side. One example for that is the server "
"asking the clients to train for a certain number of local epochs. Flower "
"provides a way to send configuration values from the server to the "
"clients using a dictionary. Let's look at an example where the clients "
"receive values from the server through the ``config`` parameter in "
"``fit`` (``config`` is also available in ``evaluate``). The ``fit`` "
"method receives the configuration dictionary through the ``config`` "
"parameter and can then read values from this dictionary. In this example,"
" it reads ``server_round`` and ``local_epochs`` and uses those values to "
"improve the logging and configure the number of local training epochs:"
msgstr ""
"在某些情况下，我们希望从服务器端配置客户端的执行（训练、评估）。其中一个例子就是服务器要求客户端训练一定数量的本地遍历。Flower "
"提供了一种使用字典从服务器向客户端发送配置值的方法。让我们来看一个例子：客户端通过 ``fit`` 中的 ``config`` "
"参数从服务器接收配置值（``evaluate`` 中也有 ``config`` 参数）。``fit`` 方法通过 ``config`` "
"参数接收配置字典，然后从字典中读取值。在本例中，它读取了 ``server_round`` 和 "
"``local_epochs``，并使用这些值来改进日志记录和配置本地训练遍历的数量："

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:674
msgid ""
"So how can we send this config dictionary from server to clients? The "
"built-in Flower Strategies provide way to do this, and it works similarly"
" to the way server-side evaluation works. We provide a function to the "
"strategy, and the strategy calls this function for every round of "
"federated learning:"
msgstr ""
"那么，如何将配置字典从服务器发送到客户端呢？内置的 \"Flower策略\"（Flower "
"Strategies）提供了这样的方法，其工作原理与服务器端评估的工作原理类似。我们为策略提供一个函数，策略会在每一轮联邦学习中调用这个函数："

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:704
#, fuzzy
msgid ""
"Next, we'll pass this function to the FedAvg strategy before starting the"
" simulation:"
msgstr "接下来，我们只需在开始模拟前将此函数传递给 FedAvg 策略即可："

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:749
msgid ""
"As we can see, the client logs now include the current round of federated"
" learning (which they read from the ``config`` dictionary). We can also "
"configure local training to run for one epoch during the first and second"
" round of federated learning, and then for two epochs during the third "
"round."
msgstr ""
"我们可以看到，客户端日志现在包含了当前一轮的联邦学习（从 ``config`` "
"字典中读取）。我们还可以将本地训练配置为在第一轮和第二轮联邦学习期间运行一个遍历，然后在第三轮联邦学习期间运行两个遍历。"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:751
msgid ""
"Clients can also return arbitrary values to the server. To do so, they "
"return a dictionary from ``fit`` and/or ``evaluate``. We have seen and "
"used this concept throughout this notebook without mentioning it "
"explicitly: our ``FlowerClient`` returns a dictionary containing a custom"
" key/value pair as the third return value in ``evaluate``."
msgstr ""
"客户端还可以向服务器返回任意值。为此，它们会从 ``fit`` 和/或 ``evaluate`` "
"返回一个字典。我们在本笔记中看到并使用了这一概念，但并未明确提及：我们的 ``FlowerClient`` 返回一个包含自定义键/值对的字典，作为"
" ``evaluate`` 中的第三个返回值。"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:763
msgid "Scaling federated learning"
msgstr "扩大联邦学习的规模"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:765
msgid ""
"As a last step in this notebook, let's see how we can use Flower to "
"experiment with a large number of clients."
msgstr "作为本笔记的最后一步，让我们看看如何使用 Flower 对大量客户端进行实验。"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:785
msgid ""
"Note that we can reuse the ``ClientApp`` for different ``num-partitions``"
" since the Context is defined by the ``num_supernodes`` argument in "
"``run_simulation()``."
msgstr ""

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:787
#, fuzzy, python-format
msgid ""
"We now have 1000 partitions, each holding 45 training and 5 validation "
"examples. Given that the number of training examples on each client is "
"quite small, we should probably train the model a bit longer, so we "
"configure the clients to perform 3 local training epochs. We should also "
"adjust the fraction of clients selected for training during each round "
"(we don't want all 1000 clients participating in every round), so we "
"adjust ``fraction_fit`` to ``0.025``, which means that only 2.5% of "
"available clients (so 25 clients) will be selected for training each "
"round:"
msgstr ""
"现在我们有 1000 个分区，每个分区有 45 个训练数据和 5 "
"个验证数据。鉴于每个客户端上的训练示例数量较少，我们可能需要对模型进行更长时间的训练，因此我们将客户端配置为执行 3 "
"个本地训练遍历。我们还应该调整每轮训练中被选中的客户端的比例（我们不希望每轮训练都有 1000 个客户端参与），因此我们将 "
"``fraction_fit`` 调整为 ``0.05``，这意味着每轮训练只选中 5%的可用客户端（即 50 个客户端）："

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:843
msgid ""
"In this notebook, we've seen how we can gradually enhance our system by "
"customizing the strategy, initializing parameters on the server side, "
"choosing a different strategy, and evaluating models on the server-side. "
"That's quite a bit of flexibility with so little code, right?"
msgstr "在本笔记中，我们看到了如何通过自定义策略、在服务器端初始化参数、选择不同的策略以及在服务器端评估模型来逐步增强我们的系统。用这么少的代码就能实现这么大的灵活性，不是吗？"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:845
msgid ""
"In the later sections, we've seen how we can communicate arbitrary values"
" between server and clients to fully customize client-side execution. "
"With that capability, we built a large-scale Federated Learning "
"simulation using the Flower Virtual Client Engine and ran an experiment "
"involving 1000 clients in the same workload - all in a Jupyter Notebook!"
msgstr ""
"在后面的章节中，我们将看到如何在服务器和客户端之间传递任意值，以完全自定义客户端执行。有了这种能力，我们使用 Flower "
"虚拟客户端引擎构建了一个大规模的联邦学习模拟，并在 Jupyter Notebook 中进行了一次实验，在相同的工作负载中运行了 1000 "
"个客户端！"

#: ../../source/tutorial-series-use-a-federated-learning-strategy-pytorch.ipynb:863
msgid ""
"The `Flower Federated Learning Tutorial - Part 3 "
"<https://flower.ai/docs/framework/tutorial-build-a-strategy-from-scratch-"
"pytorch.html>`__ shows how to build a fully custom ``Strategy`` from "
"scratch."
msgstr ""
"`Flower 联邦学习教程 - 第 3 部分 <https://flower.ai/docs/framework/tutorial-"
"build-a-strategy-from-scratch-pytorch.html>`__ 展示了如何从头开始构建完全自定义的 \"策略\"。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:9
msgid "What is Federated Learning?"
msgstr "什么是联邦学习？"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:13
msgid ""
"In this tutorial, you will learn what federated learning is, build your "
"first system in Flower, and gradually extend it. If you work through all "
"parts of the tutorial, you will be able to build advanced federated "
"learning systems that approach the current state of the art in the field."
msgstr ""
"在本教程中，你将了解什么是联邦学习，用 Flower "
"搭建第一个系统，并逐步对其进行扩展。如果你能完成本教程的所有部分，你就能构建高级的联邦学习系统，从而接近该领域当前的技术水平。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:15
#, fuzzy
msgid ""
"🧑‍🏫 This tutorial starts from zero and expects no familiarity with "
"federated learning. Only a basic understanding of data science and Python"
" programming is assumed."
msgstr "🧑‍🏫 本教程从零开始，不要求熟悉联邦学习。仅假定对数据科学和 Python 编程有基本了解。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:17
msgid ""
"`Star Flower on GitHub <https://github.com/adap/flower>`__ ⭐️ and join "
"the open-source Flower community on Slack to connect, ask questions, and "
"get help: `Join Slack <https://flower.ai/join-slack>`__ 🌼 We'd love to "
"hear from you in the ``#introductions`` channel! And if anything is "
"unclear, head over to the ``#questions`` channel."
msgstr ""
"`Star Flower on GitHub <https://github.com/adap/flower>`__ ⭐️ 并加入 Slack "
"上的开源 Flower 社区，进行交流、提问并获得帮助： 加入 Slack <https://flower.ai/join-slack>`__ 🌼"
" 我们希望在 ``#introductions`` 频道听到您的声音！如果有任何不清楚的地方，请访问 ``#questions`` 频道。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:19
msgid "Let's get started!"
msgstr "让我们开始吧！"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:31
#, fuzzy
msgid "Classical Machine Learning"
msgstr "经典机器学习"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:33
#, fuzzy
msgid ""
"Before we begin discussing federated learning, let us quickly recap how "
"most machine learning works today."
msgstr "在开始讨论联邦学习之前，让我们先快速回顾一下目前大多数机器学习的工作原理。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:35
msgid ""
"In machine learning, we have a model, and we have data. The model could "
"be a neural network (as depicted here), or something else, like classical"
" linear regression."
msgstr "在机器学习中，我们有一个模型和数据。模型可以是一个神经网络（如图所示），也可以是其他东西，比如经典的线性回归。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:41
msgid "|c9344c3dfee24383908fabaac40a8504|"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:109
msgid "Model and data"
msgstr "模型和数据"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:47
msgid ""
"We train the model using the data to perform a useful task. A task could "
"be to detect objects in images, transcribe an audio recording, or play a "
"game like Go."
msgstr "我们使用数据来训练模型，以完成一项有用的任务。任务可以是检测图像中的物体、转录音频或玩围棋等游戏。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:53
msgid "|c10cd8f2177641bd8091c7b76d318ff9|"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:111
msgid "Train model using data"
msgstr "使用数据训练模型"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:59
#, fuzzy
msgid ""
"In practice, the training data we work with doesn't originate on the "
"machine we train the model on."
msgstr "实际上，我们使用的训练数据并不来自我们训练模型的机器。它是在其他地方创建的。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:61
#, fuzzy
msgid ""
"This data gets created \"somewhere else\". For instance, the data can "
"originate on a smartphone by the user interacting with an app, a car "
"collecting sensor data, a laptop receiving input via the keyboard, or a "
"smart speaker listening to someone trying to sing a song."
msgstr "它源于智能手机上用户与应用程序的交互、汽车上传感器数据的收集、笔记本电脑上键盘输入的接收，或者智能扬声器上某人试着唱的歌。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:67
msgid "|3c59c315e67945ea8b839381c5deb6c2|"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:113
msgid "Data on a phone"
msgstr "手机上的数据"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:73
msgid ""
"What's also important to mention, this \"somewhere else\" is usually not "
"just one place, it's many places. It could be several devices all running"
" the same app. But it could also be several organizations, all generating"
" data for the same task."
msgstr ""
"值得一提的是，这个 \"其他地方 "
"\"通常不只是一个地方，而是很多地方。它可能是多个运行同一应用程序的设备。但也可能是多个组织，都在为同一任务生成数据。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:79
msgid "|eadf87e1e20549789512f7aa9199fcff|"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:115
msgid "Data is on many devices"
msgstr "数据存在于多种设备中"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:85
#, fuzzy
msgid ""
"So to use machine learning, or any kind of data analysis, the approach "
"that has been used in the past was to collect all this data on a central "
"server. This server can be located somewhere in a data center, or "
"somewhere in the cloud."
msgstr "因此，要使用机器学习或任何类型的数据分析，过去使用的方法是在中央服务器上收集所有数据。这个服务器可以在数据中心的某个地方，也可以在云端的某个地方。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:91
msgid "|66ce8f21aeb443fca1fc88f727458417|"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:117
msgid "Central data collection"
msgstr "集中数据收集"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:97
msgid ""
"Once all the data is collected in one place, we can finally use machine "
"learning algorithms to train our model on the data. This is the machine "
"learning approach that we've basically always relied on."
msgstr "一旦所有数据都收集到一处，我们最终就可以使用机器学习算法在数据上训练我们的模型。这就是我们基本上一直依赖的机器学习方法。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:103
msgid "|f5768015a1014396b4761bb6cb3677f5|"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:119
msgid "Central model training"
msgstr "集中模型训练"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:130
msgid "Challenges of classical machine learning"
msgstr "经典机器学习面临的挑战"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:132
#, fuzzy
msgid ""
"This classical machine learning approach we've just seen can be used in "
"some cases. Great examples include categorizing holiday photos, or "
"analyzing web traffic. Cases, where all the data is naturally available "
"on a centralized server."
msgstr "我们刚刚看到的经典机器学习方法可以在某些情况下使用。很好的例子包括对假日照片进行分类或分析网络流量。在这些案例中，所有数据自然都可以在中央服务器上获得。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:138
msgid "|a746aa3f56064617a4e00f4c6a0cb140|"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:173
msgid "Centralized possible"
msgstr "可集中管理"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:144
msgid ""
"But the approach can not be used in many other cases. Cases, where the "
"data is not available on a centralized server, or cases where the data "
"available on one server is not enough to train a good model."
msgstr "但这种方法并不适用于许多其他情况。例如，集中服务器上没有数据，或者一台服务器上的数据不足以训练出一个好的模型。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:150
msgid "|cf8f676dd3534a44995c1b40910fd030|"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:175
msgid "Centralized impossible"
msgstr "无法集中"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:156
#, fuzzy
msgid ""
"There are many reasons why the classical centralized machine learning "
"approach does not work for a large number of highly important real-world "
"use cases. Those reasons include:"
msgstr "传统的集中式机器学习方法无法满足现实世界中大量极为重要的使用案例，原因有很多。这些原因包括："

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:158
#, fuzzy
msgid ""
"**Regulations**: GDPR (Europe), CCPA (California), PIPEDA (Canada), LGPD "
"(Brazil), PDPL (Argentina), KVKK (Turkey), POPI (South Africa), FSS "
"(Russia), CDPR (China), PDPB (India), PIPA (Korea), APPI (Japan), PDP "
"(Indonesia), PDPA (Singapore), APP (Australia), and other regulations "
"protect sensitive data from being moved. In fact, those regulations "
"sometimes even prevent single organizations from combining their own "
"users' data for machine learning training because those users live in "
"different parts of the world, and their data is governed by different "
"data protection regulations."
msgstr ""
"**法规**： "
"GDPR（欧洲）、CCPA（加利福尼亚）、PIPEDA（加拿大）、LGPD（巴西）、PDPL（阿根廷）、KVKK（土耳其）、POPI（南非）、FSS（俄罗斯）、CDPR（中国）、PDPB（印度）、PIPA（韩国）、APPI（日本）、PDP（印度尼西亚）、PDPA（新加坡）、APP（澳大利亚）等法规保护敏感数据不被移动。事实上，这些法规有时甚至会阻止单个组织将自己的用户数据用于人工智能培训，因为这些用户生活在世界不同地区，他们的数据受不同的数据保护法规管辖。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:160
msgid ""
"**User preference**: In addition to regulation, there are use cases where"
" users just expect that no data leaves their device, ever. If you type "
"your passwords and credit card info into the digital keyboard of your "
"phone, you don't expect those passwords to end up on the server of the "
"company that developed that keyboard, do you? In fact, that use case was "
"the reason federated learning was invented in the first place."
msgstr ""
"**用户偏好**： "
"除了法规之外，在一些使用案例中，用户只是希望数据永远不会离开他们的设备。如果你在手机的数字键盘上输入密码和信用卡信息，你不会希望这些密码最终出现在开发该键盘的公司的服务器上吧？事实上，这种用例正是联邦学习发明的初衷。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:161
msgid ""
"**Data volume**: Some sensors, like cameras, produce such a high data "
"volume that it is neither feasible nor economic to collect all the data "
"(due to, for example, bandwidth or communication efficiency). Think about"
" a national rail service with hundreds of train stations across the "
"country. If each of these train stations is outfitted with a number of "
"security cameras, the volume of raw on-device data they produce requires "
"incredibly powerful and exceedingly expensive infrastructure to process "
"and store. And most of the data isn't even useful."
msgstr ""
"**数据量**： "
"有些传感器（如摄像头）产生的数据量很大，收集所有数据既不可行，也不经济（例如，由于带宽或通信效率的原因）。试想一下全国铁路服务，全国有数百个火车站。如果每个火车站都安装了许多安全摄像头，那么它们所产生的大量原始设备数据就需要功能强大且极其昂贵的基础设施来处理和存储。而大部分数据甚至都是无用的。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:164
msgid "Examples where centralized machine learning does not work include:"
msgstr "集中式机器学习不起作用的例子包括："

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:166
#, fuzzy
msgid ""
"Sensitive healthcare records from multiple hospitals to train cancer "
"detection models."
msgstr "用多家医院的敏感医疗记录训练癌症检测模型"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:167
#, fuzzy
msgid ""
"Financial information from different organizations to detect financial "
"fraud."
msgstr "不同组织的财务信息，以侦查财务欺诈行为"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:168
#, fuzzy
msgid "Location data from your electric car to make better range prediction."
msgstr "通过电动汽车的定位数据更好地预测续航里程"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:169
#, fuzzy
msgid "End-to-end encrypted messages to train better auto-complete models."
msgstr "端到端加密信息可训练出更好的自动完成模型"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:171
msgid ""
"The popularity of privacy-enhancing systems like the `Brave "
"<https://brave.com/>`__ browser or the `Signal <https://signal.org/>`__ "
"messenger shows that users care about privacy. In fact, they choose the "
"privacy-enhancing version over other alternatives, if such an alternative"
" exists. But what can we do to apply machine learning and data science to"
" these cases to utilize private data? After all, these are all areas that"
" would benefit significantly from recent advances in AI."
msgstr ""
"像 `Brave <https://brave.com/>`__浏览器或 `Signal "
"<https://signal.org/>`__信息管理器这样的隐私增强系统的流行表明，用户关心隐私。事实上，他们会选择隐私性更好的产品。但是，我们能做些什么来将机器学习和数据科学应用到这些情况中，以利用隐私数据呢？毕竟，这些领域都将从人工智能的最新进展中受益匪浅。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:186
#, fuzzy
msgid "Federated Learning"
msgstr "联邦学习"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:188
#, fuzzy
msgid ""
"Federated Learning simply reverses this approach. It enables machine "
"learning on distributed data by moving the training to the data, instead "
"of moving the data to the training. Here's a one-liner explanation:"
msgstr "联邦学习简单地颠覆了这种方法。它通过将训练转移到数据上，而不是将数据转移到训练上，在分布式数据上实现机器学习。下面是一句话的解释："

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:190
#, fuzzy
msgid "Centralized machine learning: move the data to the computation"
msgstr "集中式机器学习：将数据转移到计算中心"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:191
#, fuzzy
msgid "Federated (machine) Learning: move the computation to the data"
msgstr "联邦式（机器）学习：将计算转移到数据上"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:193
#, fuzzy
msgid ""
"By doing so, Federated Learning enables us to use machine learning (and "
"other data science approaches) in areas where it wasn't possible before. "
"We can now train excellent medical AI models by enabling different "
"hospitals to work together. We can solve financial fraud by training AI "
"models on the data of different financial institutions. We can build "
"novel privacy-enhancing applications (such as secure messaging) that have"
" better built-in AI than their non-privacy-enhancing alternatives. And "
"those are just a few of the examples that come to mind. As we deploy "
"Federated Learning, we discover more and more areas that can suddenly be "
"reinvented because they now have access to vast amounts of previously "
"inaccessible data."
msgstr "这样，我们就能在以前不可能的领域使用机器学习（和其他数据科学方法）。现在，我们可以通过让不同的医院协同工作来训练优秀的医疗人工智能模型。我们可以通过在不同金融机构的数据上训练人工智能模型来解决金融欺诈问题。我们可以构建新颖的隐私增强型应用（如安全信息），其内置的人工智能比非隐私增强型应用更好。以上只是我想到的几个例子。随着联邦学习的部署，我们会发现越来越多的领域可以突然重获新生，因为它们现在可以访问大量以前无法访问的数据。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:196
#, fuzzy
msgid ""
"So how does Federated Learning work, exactly? Let's start with an "
"intuitive explanation."
msgstr "那么，联邦学习究竟是如何运作的呢？让我们从直观的解释开始。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:199
msgid "Federated learning in five steps"
msgstr "联邦学习的五个步骤"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:202
msgid "Step 0: Initialize global model"
msgstr "步骤 0：初始化全局模型"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:204
msgid ""
"We start by initializing the model on the server. This is exactly the "
"same in classic centralized learning: we initialize the model parameters,"
" either randomly or from a previously saved checkpoint."
msgstr "我们首先在服务器上初始化模型。这与经典的集中式学习完全相同：我们随机或从先前保存的检查点初始化模型参数。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:210
msgid "|d1c0e3a4c9dc4bfd88ee6f1fe626edaf|"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:307
msgid "Initialize global model"
msgstr "初始化全局模型"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:217
msgid ""
"Step 1: Send model to a number of connected organizations/devices (client"
" nodes)"
msgstr "第 1 步：将模型发送到多个连接的组织/设备（客户节点）"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:219
#, fuzzy
msgid ""
"Next, we send the parameters of the global model to the connected client "
"nodes (think: edge devices like smartphones or servers belonging to "
"organizations). This is to ensure that each participating node starts its"
" local training using the same model parameters. We often use only a few "
"of the connected nodes instead of all nodes. The reason for this is that "
"selecting more and more client nodes has diminishing returns."
msgstr "接下来，我们会将全局模型的参数发送到连接的客户端节点（如智能手机等边缘设备或企业的服务器）。这是为了确保每个参与节点都使用相同的模型参数开始本地训练。我们通常只使用几个连接节点，而不是所有节点。这样做的原因是，选择越来越多的客户端节点会导致收益递减。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:225
msgid "|1d8d6298a4014ec3a717135bcc7a94f9|"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:309
msgid "Send global model"
msgstr "发送全局模型"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:232
msgid ""
"Step 2: Train model locally on the data of each organization/device "
"(client node)"
msgstr "步骤 2：在本地对每个机构/设备（客户端节点）的数据进行模型训练"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:234
msgid ""
"Now that all (selected) client nodes have the latest version of the "
"global model parameters, they start the local training. They use their "
"own local dataset to train their own local model. They don't train the "
"model until full convergence, but they only train for a little while. "
"This could be as little as one epoch on the local data, or even just a "
"few steps (mini-batches)."
msgstr ""
"现在，所有（选定的）客户端节点都有了最新版本的全局模型参数，它们开始进行本地训练。它们使用自己的本地数据集来训练自己的本地模型。它们不会一直训练到模型完全收敛为止，而只是训练一小段时间。这可能只是本地数据上的一个遍历，甚至只是几个步骤"
"（mini-batches）。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:240
msgid "|e3ea79200ff44d459358b9f4713e582b|"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:311
msgid "Train on local data"
msgstr "根据本地数据进行训练"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:247
msgid "Step 3: Return model updates back to the server"
msgstr "步骤 3：将模型参数更新返回服务器"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:249
msgid ""
"After local training, each client node has a slightly different version "
"of the model parameters they originally received. The parameters are all "
"different because each client node has different examples in its local "
"dataset. The client nodes then send those model updates back to the "
"server. The model updates they send can either be the full model "
"parameters or just the gradients that were accumulated during local "
"training."
msgstr "经过本地训练后，每个客户节点最初收到的模型参数都会略有不同。参数之所以不同，是因为每个客户端节点的本地数据集中都有不同的数据。然后，客户端节点将这些模型更新发回服务器。它们发送的模型更新既可以是完整的模型参数，也可以只是本地训练过程中积累的梯度。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:255
msgid "|3e1061718a4a49d485764d30a4bfecdd|"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:313
msgid "Send model updates"
msgstr "发送模型参数更新"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:262
msgid "Step 4: Aggregate model updates into a new global model"
msgstr "步骤 4：将模型更新聚合到新的全局模型中"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:264
msgid ""
"The server receives model updates from the selected client nodes. If it "
"selected 100 client nodes, it now has 100 slightly different versions of "
"the original global model, each trained on the local data of one client. "
"But didn't we want to have one model that contains the learnings from the"
" data of all 100 client nodes?"
msgstr ""
"服务器从选定的客户端节点接收模型更新。如果服务器选择了 100 个客户端节点，那么它现在就拥有 100 "
"个略有不同的原始全局模型版本，每个版本都是根据一个客户端的本地数据训练出来的。难道我们不希望有一个包含所有 100 个客户节点数据的模型吗？"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:266
#, fuzzy
msgid ""
"In order to get one single model, we have to combine all the model "
"updates we received from the client nodes. This process is called "
"*aggregation*, and there are many different ways to do it. The most basic"
" way is called *Federated Averaging* (`McMahan et al., 2016 "
"<https://arxiv.org/abs/1602.05629>`__), often abbreviated as *FedAvg*. "
"*FedAvg* takes the 100 model updates and, as the name suggests, averages "
"them. To be more precise, it takes the *weighted average* of the model "
"updates, weighted by the number of examples each client used for "
"training. The weighting is important to make sure that each data example "
"has the same \"influence\" on the resulting global model. If one client "
"has 10 examples, and another client has 100 examples, then - without "
"weighting - each of the 10 examples would influence the global model ten "
"times as much as each of the 100 examples."
msgstr ""
"为了得到一个单一的模型，我们必须将从客户端节点收到的所有模型更新合并起来。这个过程称为*聚合*，有许多不同的方法。最基本的方法称为 "
"*Federated Averaging* (`McMahan等人，2016 "
"<https://arxiv.org/abs/1602.05629>`__)，通常缩写为*FedAvg*。*FedAvg* 可以把100 "
"个模型更新进行平均。更准确地说，它取的是模型更新的*加权平均值*，根据每个客户端用于训练的数据数量进行加权。加权对于确保每个数据示例对生成的全局模型具有相同的"
" \"影响 \"非常重要。如果一个客户端有 10 个数据点，而另一个客户有 100 个数据点，那么在不加权的情况下，10 个示例对全局模型的影响是"
" 100 个示例的 10 倍。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:273
msgid "|7750e597d1ea4e319f7e0a40539bf214|"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:315
msgid "Aggregate model updates"
msgstr "聚合模型参数更新"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:280
msgid "Step 5: Repeat steps 1 to 4 until the model converges"
msgstr "步骤 5：重复步骤 1 至 4，直至模型收敛"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:282
msgid ""
"Steps 1 to 4 are what we call a single round of federated learning. The "
"global model parameters get sent to the participating client nodes (step "
"1), the client nodes train on their local data (step 2), they send their "
"updated models to the server (step 3), and the server then aggregates the"
" model updates to get a new version of the global model (step 4)."
msgstr ""
"步骤 1 至 4 就是我们所说的单轮联邦学习。全局模型参数被发送到参与的客户端节点（第 1 步），客户端节点对其本地数据进行训练（第 2 "
"步），然后将更新后的模型发送到服务器（第 3 步），服务器汇总模型更新，得到新版本的全局模型（第 4 步）。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:284
msgid ""
"During a single round, each client node that participates in that "
"iteration only trains for a little while. This means that after the "
"aggregation step (step 4), we have a model that has been trained on all "
"the data of all participating client nodes, but only for a little while. "
"We then have to repeat this training process over and over again to "
"eventually arrive at a fully trained model that performs well across the "
"data of all client nodes."
msgstr ""
"在一轮迭代中，每个参与迭代的客户节点只训练一小段时间。这意味着，在聚合步骤（步骤 "
"4）之后，我们的模型已经在所有参与的客户节点的所有数据上训练过了，但只训练了一小会儿。然后，我们必须一次又一次地重复这一训练过程，最终得到一个经过全面训练的模型，该模型在所有客户节点的数据中都表现良好。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:289
msgid ""
"Congratulations, you now understand the basics of federated learning. "
"There's a lot more to discuss, of course, but that was federated learning"
" in a nutshell. In later parts of this tutorial, we will go into more "
"detail. Interesting questions include: How can we select the best client "
"nodes that should participate in the next round? What's the best way to "
"aggregate model updates? How can we handle failing client nodes "
"(stragglers)?"
msgstr ""
"恭喜您，现在您已经了解了联邦学习的基础知识。当然，要讨论的内容还有很多，但这只是联邦学习的一个缩影。在本教程的后半部分，我们将进行更详细的介绍。有趣的问题包括"
" 我们如何选择最好的客户端节点参与下一轮学习？聚合模型更新的最佳方法是什么？如何处理失败的客户端节点（落伍者）？"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:294
msgid ""
"Just like we can train a model on the decentralized data of different "
"client nodes, we can also evaluate the model on that data to receive "
"valuable metrics. This is called federated evaluation, sometimes "
"abbreviated as FE. In fact, federated evaluation is an integral part of "
"most federated learning systems."
msgstr ""
"就像我们可以在不同客户节点的分散数据上训练一个模型一样，我们也可以在这些数据上对模型进行评估，以获得有价值的指标。这就是所谓的联邦评估，有时简称为"
" FE。事实上，联邦评估是大多数联邦学习系统不可或缺的一部分。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:297
#, fuzzy
msgid "Federated Analytics"
msgstr "联邦分析"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:299
msgid ""
"In many cases, machine learning isn't necessary to derive value from "
"data. Data analysis can yield valuable insights, but again, there's often"
" not enough data to get a clear answer. What's the average age at which "
"people develop a certain type of health condition? Federated analytics "
"enables such queries over multiple client nodes. It is usually used in "
"conjunction with other privacy-enhancing technologies like secure "
"aggregation to prevent the server from seeing the results submitted by "
"individual client nodes."
msgstr "在很多情况下，机器学习并不是从数据中获取价值的必要条件。数据分析可以产生有价值的见解，但同样，往往没有足够的数据来获得明确的答案。人们患某种健康疾病的平均年龄是多少？联邦分析可以通过多个客户端节点进行此类查询。它通常与安全聚合等其他隐私增强技术结合使用，以防止服务器看到单个客户端节点提交的结果。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:305
msgid ""
"Differential privacy (DP) is often mentioned in the context of Federated "
"Learning. It is a privacy-preserving method used when analyzing and "
"sharing statistical data, ensuring the privacy of individual "
"participants. DP achieves this by adding statistical noise to the model "
"updates, ensuring any individual participants’ information cannot be "
"distinguished or re-identified. This technique can be considered an "
"optimization that provides a quantifiable privacy protection measure."
msgstr ""
"差分隐私（DP）经常在联邦学习中被提及。这是一种在分析和共享统计数据时使用的隐私保护方法，可确保单个参与者的隐私。DP "
"通过在模型更新中添加统计噪声来实现这一目的，确保任何个体参与者的信息都无法被区分或重新识别。这种技术可被视为一种优化，提供了一种可量化的隐私保护措施。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:326
msgid "Flower"
msgstr "Flower"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:328
msgid ""
"Federated learning, federated evaluation, and federated analytics require"
" infrastructure to move machine learning models back and forth, train and"
" evaluate them on local data, and then aggregate the updated models. "
"Flower provides the infrastructure to do exactly that in an easy, "
"scalable, and secure way. In short, Flower presents a unified approach to"
" federated learning, analytics, and evaluation. It allows the user to "
"federate any workload, any ML framework, and any programming language."
msgstr ""
"联邦学习、联邦评估和联邦分析需要基础框架来来回移动机器学习模型，在本地数据上对其进行训练和评估，然后汇总更新的模型。Flower "
"提供的基础架构正是以简单、可扩展和安全的方式实现这些目标的。简而言之，Flower "
"为联邦学习、分析和评估提供了一种统一的方法。它允许用户联邦化任何工作负载、任何 ML 框架和任何编程语言。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:334
msgid "|dd4434075f374e99ac07f509a883778f|"
msgstr ""

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:340
msgid ""
"Flower federated learning server and client nodes (car, scooter, personal"
" computer, roomba, and phone)"
msgstr "Flower联邦学习服务器和客户端节点（汽车、滑板车、个人电脑、roomba 和电话）"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:351
#, fuzzy
msgid "Final Remarks"
msgstr "结束语"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:353
msgid ""
"Congratulations, you just learned the basics of federated learning and "
"how it relates to the classic (centralized) machine learning!"
msgstr "恭喜您，您刚刚了解了联邦学习的基础知识，以及它与传统（集中式）机器学习的关系！"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:355
msgid ""
"In the next part of this tutorial, we are going to build a first "
"federated learning system with Flower."
msgstr "在本教程的下一部分，我们将用 Flower 建立第一个联邦学习系统。"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:369
msgid ""
"Before you continue, make sure to join the Flower community on Slack: "
"`Join Slack <https://flower.ai/join-slack/>`__"
msgstr ""
"在继续之前，请务必加入 Slack 上的 Flower 社区：`Join Slack <https://flower.ai/join-"
"slack/>`__"

#: ../../source/tutorial-series-what-is-federated-learning.ipynb:373
msgid ""
"The `Flower Federated Learning Tutorial - Part 1 "
"<https://flower.ai/docs/framework/tutorial-get-started-with-flower-"
"pytorch.html>`__ shows how to build a simple federated learning system "
"with PyTorch and Flower."
msgstr ""
"`Flower 联邦学习教程 - 第 1 部分 <https://flower.ai/docs/framework/tutorial-get-"
"started-with-flower-pytorch.html>`__ 展示了如何使用 PyTorch 和 Flower "
"构建一个简单的联邦学习系统。"

#~ msgid "Before the release"
#~ msgstr "发布前"

#~ msgid ""
#~ "Update the changelog (``changelog.md``) with"
#~ " all relevant changes that happened "
#~ "after the last release. If the "
#~ "last release was tagged ``v1.2.0``, you"
#~ " can use the following URL to "
#~ "see all commits that got merged "
#~ "into ``main`` since then:"
#~ msgstr ""
#~ "更新更新日志 (``changelog.md``)，加入上次发布后发生的所有相关变更。如果上次发布的版本被标记为 "
#~ "``v1.2.0``，则可以使用以下 URL 查看此后合并到 ``main`` 的所有提交："

#~ msgid ""
#~ "`GitHub: Compare v1.2.0...main "
#~ "<https://github.com/adap/flower/compare/v1.2.0...main>`_"
#~ msgstr ""
#~ "`GitHub: Compare v1.2.0...main "
#~ "<https://github.com/adap/flower/compare/v1.2.0...main>`_"

#~ msgid ""
#~ "Thank the authors who contributed since"
#~ " the last release. This can be "
#~ "done by running the ``./dev/add-"
#~ "shortlog.sh`` convenience script (it can "
#~ "be ran multiple times and will "
#~ "update the names in the list if"
#~ " new contributors were added in the"
#~ " meantime)."
#~ msgstr ""
#~ "感谢自上次发布以来做出贡献的作者。可以通过运行 ``./dev/add-shortlog.sh`` "
#~ "方便脚本来完成（可以多次运行，如果在此期间有新的贡献者加入，则会更新列表中的名字）。"

#~ msgid ""
#~ "Update the ``changelog.md`` section header "
#~ "``Unreleased`` to contain the version "
#~ "number and date for the release "
#~ "you are building. Create a pull "
#~ "request with the change."
#~ msgstr ""
#~ "更新 ``changelog.md`` 部分的标题 ``Unreleased`` "
#~ "以包含你正在构建的版本的版本号和日期。创建一个包含更改的拉取请求。"

#~ msgid ""
#~ "Second, create a virtual environment "
#~ "(and activate it). If you chose to"
#~ " use :code:`pyenv` (with the :code"
#~ ":`pyenv-virtualenv` plugin) and already "
#~ "have it installed , you can use"
#~ " the following convenience script (by "
#~ "default it will use :code:`Python "
#~ "3.8.17`, but you can change it by"
#~ " providing a specific :code:`<version>`)::"
#~ msgstr ""
#~ "其次，创建虚拟环境（并激活它）。如果您选择使用 :code:`pyenv`（使用 :code:`pyenv-"
#~ "virtualenv`插件），并且已经安装了该插件，则可以使用下面的便捷脚本（默认情况下使用 "
#~ ":code:`Python3.8.17`，但您可以通过提供特定的 :code:`<版本>`来更改）：："

#~ msgid "flwr (Python API reference)"
#~ msgstr "flwr（Python API 参考）"

#~ msgid "..."
#~ msgstr "..."

#~ msgid "Starting a client with an insecure server connection:"
#~ msgstr "使用不安全的服务器连接启动客户端："

#~ msgid "server.strategy.FedAvg"
#~ msgstr "server.strategy.FedAvg"

#~ msgid "server.strategy.FedAvgM"
#~ msgstr "server.strategy.FedAvgM"

#~ msgid "Configurable FedAvg with Momentum strategy implementation."
#~ msgstr "可配置的 FedAvg 动量策略实施。"

#~ msgid "Fraction of clients used during training. Defaults to 0.1."
#~ msgstr "训练期间使用客户的比例。默认为 0.1。"

#~ msgid "Fraction of clients used during validation. Defaults to 0.1."
#~ msgstr "验证过程中使用的客户端比例。默认为 0.1。"

#~ msgid "server.strategy.FedMedian"
#~ msgstr "server.strategy.FedMedian"

#~ msgid "server.strategy.QFedAvg"
#~ msgstr "server.strategy.QFedAvg"

#~ msgid "server.strategy.FedOpt"
#~ msgstr "server.strategy.FedOpt"

#~ msgid "Configurable FedAdagrad strategy implementation."
#~ msgstr "可配置的 FedAdagrad 策略实施。"

#~ msgid "Federated Optim strategy interface."
#~ msgstr "Federated Optim 策略界面。"

#~ msgid "server.strategy.FedProx"
#~ msgstr "server.strategy.FedProx"

#~ msgid "Configurable FedProx strategy implementation."
#~ msgstr "可配置的 FedProx 策略实施。"

#~ msgid "server.strategy.FedAdagrad"
#~ msgstr "server.strategy.FedAdagrad"

#~ msgid "Paper: https://arxiv.org/abs/2003.00295"
#~ msgstr "论文： https://arxiv.org/abs/2003.00295"

#~ msgid "Federated learning strategy using Adagrad on server-side."
#~ msgstr "在服务器端使用 Adagrad 的联邦学习策略。"

#~ msgid "server.strategy.FedAdam"
#~ msgstr "server.strategy.FedAdam"

#~ msgid "server.strategy.FedYogi"
#~ msgstr "server.strategy.FedYogi"

#~ msgid "Adaptive Federated Optimization using Yogi."
#~ msgstr "使用 Yogi 的自适应联合优化。"

#~ msgid "Federated learning strategy using Yogi on server-side."
#~ msgstr "在服务器端使用 Yogi 的联邦学习策略。"

#~ msgid "Paper: https://arxiv.org/abs/1803.01498"
#~ msgstr "论文：https://arxiv.org/abs/1803.01498"

#~ msgid "server.strategy.Krum"
#~ msgstr "server.strategy.Krum"

#~ msgid "Configurable Krum strategy implementation."
#~ msgstr "可配置的 Krum 策略实施。"

#~ msgid "server.strategy.Bulyan"
#~ msgstr "server.strategy.Bulyan"

#~ msgid "Bulyan strategy implementation."
#~ msgstr "Bulyan策略的实施。"

#~ msgid "server.strategy.FedXgbNnAvg"
#~ msgstr "server.strategy.FedXgbNnAvg"

#~ msgid "Federated XGBoost [Ma et al., 2023] strategy."
#~ msgstr "Federated XGBoost [Ma 等人，2023] 策略。"

#~ msgid "server.strategy.DPFedAvgAdaptive"
#~ msgstr "server.strategy.DPFedAvgAdaptive"

#~ msgid ""
#~ "**Fix the incorrect return types of "
#~ "Strategy** "
#~ "([#2432](https://github.com/adap/flower/pull/2432/files))"
#~ msgstr ""
#~ "**修复策略的错误返回类型** "
#~ "([#2432](https://github.com/adap/flower/pull/2432/files))"

#~ msgid ""
#~ "The types of the return values in"
#~ " the docstrings in two methods "
#~ "(`aggregate_fit` and `aggregate_evaluate`) now "
#~ "match the hint types in the code."
#~ msgstr ""
#~ "两个方法（\"aggregate_fit \"和 "
#~ "\"aggregate_evaluate\"）的文档说明中的返回值类型现在与代码中的提示类型一致。"

#~ msgid ""
#~ "**Update Flower Examples** "
#~ "([#2384](https://github.com/adap/flower/pull/2384),[#2425](https://github.com/adap/flower/pull/2425),"
#~ " [#2526](https://github.com/adap/flower/pull/2526))"
#~ msgstr ""
#~ "** 更新 Flower Examples** "
#~ "([#2384](https://github.com/adap/flower/pull/2384),[#2425](https://github.com/adap/flower/pull/2425),"
#~ " [#2526](https://github.com/adap/flower/pull/2526))"

#~ msgid ""
#~ "That's it for the client. We only"
#~ " have to implement :code:`Client` or "
#~ ":code:`NumPyClient` and call "
#~ ":code:`fl.client.start_client()`. The string "
#~ ":code:`\"0.0.0.0:8080\"` tells the client "
#~ "which server to connect to. In our"
#~ " case we can run the server and"
#~ " the client on the same machine, "
#~ "therefore we use :code:`\"0.0.0.0:8080\"`. If"
#~ " we run a truly federated workload"
#~ " with the server and clients running"
#~ " on different machines, all that "
#~ "needs to change is the "
#~ ":code:`server_address` we pass to the "
#~ "client."
#~ msgstr ""
#~ "对于客户端就需要做这么多。我们仅需要实现 "
#~ ":code:`Client`或者:code:`NumPyClient`然后调用:code:`fl.client.start_client()`。字符串"
#~ " :code:`\"0.0.0.0:8080\"` "
#~ "告诉客户端要连接到哪个服务器。在我们的例子中，我们可以在同一台机器上运行服务器和客户端，因此我们使用:code:`\"0.0.0.0:8080\"`。如果我们运行真正联邦学习的工作负载，服务器和客户端在不同的机器上运行，则需要更改的只是我们传递给客户端的"
#~ " server_address 。"

#~ msgid ""
#~ "That's it for the client. We only"
#~ " have to implement :code:`Client` or "
#~ ":code:`NumPyClient` and call "
#~ ":code:`fl.client.start_client()`. The string "
#~ ":code:`\"[::]:8080\"` tells the client which"
#~ " server to connect to. In our "
#~ "case we can run the server and "
#~ "the client on the same machine, "
#~ "therefore we use :code:`\"[::]:8080\"`. If "
#~ "we run a truly federated workload "
#~ "with the server and clients running "
#~ "on different machines, all that needs"
#~ " to change is the :code:`server_address`"
#~ " we point the client at."
#~ msgstr ""
#~ "对于客户来说就是这样了。我们只需实现 :code:`Client` 或 "
#~ ":code:`NumPyClient` 并调用:code:`fl.client.start_client()` "
#~ "即可。字符串 :code:`\"[::]:8080\"` "
#~ "告诉客户端要连接到哪个服务器。在我们的例子中，我们可以在同一台机器上运行服务器和客户端，因此我们使用 "
#~ ":code:`\"[::]:8080\"`。如果我们运行真正联邦的工作负载，服务器和客户端运行在不同的机器上，则需要更改的只是我们指向客户端的"
#~ " server_address 。"

#~ msgid ""
#~ "Let's now load the CIFAR-10 training "
#~ "and test set, partition them into "
#~ "ten smaller datasets (each split into"
#~ " training and validation set), and "
#~ "wrap the resulting partitions by "
#~ "creating a PyTorch ``DataLoader`` for "
#~ "each of them:"
#~ msgstr ""
#~ "现在，让我们加载 CIFAR-10 训练集和测试集，将它们分割成 10 "
#~ "个较小的数据集（每个数据集又分为训练集和验证集），并通过为每个数据集创建 PyTorch "
#~ "``DataLoader`` 来包装由此产生的分割集："

#~ msgid "|e1dd4b4129b040bea23a894266227080|"
#~ msgstr "|e1dd4b4129b040bea23a894266227080|"

#~ msgid "|c0d4cc6a442948dca8da40d2440068d9|"
#~ msgstr "|c0d4cc6a442948dca8da40d2440068d9|"

#~ msgid "|174e1e4fa1f149a19bfbc8bc1126f46a|"
#~ msgstr "|174e1e4fa1f149a19bfbc8bc1126f46a|"

#~ msgid "|4e021a3dc08249d2a89daa3ab03c2714|"
#~ msgstr "|4e021a3dc08249d2a89daa3ab03c2714|"

#~ msgid "|e74a1d5ce7eb49688651f2167a59065b|"
#~ msgstr "|e74a1d5ce7eb49688651f2167a59065b|"

#~ msgid "|eb29ec4c7aef4e93976795ed72df647e|"
#~ msgstr "|eb29ec4c7aef4e93976795ed72df647e|"

#~ msgid "|c2f699d8ac484f5081721a6f1511f70d|"
#~ msgstr "|c2f699d8ac484f5081721a6f1511f70d|"

#~ msgid "|cf42accdacbf4e5eb4fa0503108ba7a7|"
#~ msgstr "|cf42accdacbf4e5eb4fa0503108ba7a7|"

#~ msgid "|5ec8356bc2564fa09178b1ceed5beccc|"
#~ msgstr "|5ec8356bc2564fa09178b1ceed5beccc|"

#~ msgid "|7c9329e97bd0430bad335ab605a897a7|"
#~ msgstr "|7c9329e97bd0430bad335ab605a897a7|"

#~ msgid "|88002bbce1094ba1a83c9151df18f707|"
#~ msgstr "|88002bbce1094ba1a83c9151df18f707|"

#~ msgid "|391766aee87c482c834c93f7c22225e2|"
#~ msgstr "|391766aee87c482c834c93f7c22225e2|"

#~ msgid "|93b9a15bd27f4e91b40f642c253dfaac|"
#~ msgstr "|93b9a15bd27f4e91b40f642c253dfaac|"

#~ msgid "|a23d9638f96342ef9d25209951e2d564|"
#~ msgstr "|a23d9638f96342ef9d25209951e2d564|"

#~ msgid "Upload the whl (e.g., ``flwr-1.6.0-py3-none-any.whl``)"
#~ msgstr "上传 whl（例如 ``flwr-1.6.0-py3-none-any.whl``)"

#~ msgid ""
#~ "Change ``!pip install -q 'flwr[simulation]'"
#~ " torch torchvision matplotlib`` to ``!pip"
#~ " install -q 'flwr-1.6.0-py3-none-"
#~ "any.whl[simulation]' torch torchvision matplotlib``"
#~ msgstr ""
#~ "将``!pip install -q 'flwr[simulation]' torch"
#~ " torchvision matplotlib``更改为``!pip install -q "
#~ "'flwr-1.6.0-py3-none-any.whl[simulation]' torch "
#~ "torch torchvision matplotlib``"

#~ msgid ""
#~ "All that's left to do it to "
#~ "define a function that loads both "
#~ "model and data, creates a "
#~ ":code:`CifarClient`, and starts this client."
#~ " You load your data and model "
#~ "by using :code:`cifar.py`. Start "
#~ ":code:`CifarClient` with the function "
#~ ":code:`fl.client.start_numpy_client()` by pointing "
#~ "it at the same IP address we "
#~ "used in :code:`server.py`:"
#~ msgstr ""
#~ "剩下要做的就是定义一个加载模型和数据的函数，创建一个 :code:`CifarClient` 并启动该客户端。使用"
#~ " :code:`cifar.py` 加载数据和模型。使用函数 "
#~ ":code:`fl.client.start_numpy_client()` 启动 "
#~ ":code:`CifarClient`，将其指向我们在 :code:`server.py` 中使用的相同 "
#~ "IP 地址："

#~ msgid ""
#~ "The :code:`VirtualClientEngine` schedules, launches"
#~ " and manages `virtual` clients. These "
#~ "clients are identical to `non-virtual`"
#~ " clients (i.e. the ones you launch"
#~ " via the command `flwr.client.start_numpy_client"
#~ " <ref-api-flwr.html#start-numpy-client>`_)"
#~ " in the sense that they can be"
#~ " configure by creating a class "
#~ "inheriting, for example, from "
#~ "`flwr.client.NumPyClient <ref-api-"
#~ "flwr.html#flwr.client.NumPyClient>`_ and therefore "
#~ "behave in an identical way. In "
#~ "addition to that, clients managed by "
#~ "the :code:`VirtualClientEngine` are:"
#~ msgstr ""
#~ "代码:`VirtualClientEngine`调度、启动和管理`虚拟`客户端。这些客户端与 \"非虚拟 "
#~ "\"客户端（即通过命令 `flwr.client.start_numpy_client <ref-"
#~ "api-flwr.html#start-numpy-"
#~ "client>`_启动的客户端）完全相同，它们可以通过创建一个继承自 \"flwr.client.NumPyClient "
#~ "<ref-api-flwr.html#flwr.client.NumPyClient>`_\" "
#~ "的类来配置，因此行为方式也完全相同。除此之外，由 :code:`VirtualClientEngine` "
#~ "管理的客户端还包括："

#~ msgid "Example: Walk-Through PyTorch & MNIST"
#~ msgstr "实例： PyTorch 和 MNIST 的演练"

#~ msgid ""
#~ "In this tutorial we will learn, "
#~ "how to train a Convolutional Neural "
#~ "Network on MNIST using Flower and "
#~ "PyTorch."
#~ msgstr "在本教程中，我们将学习如何使用 Flower 和 PyTorch 在 MNIST 上训练卷积神经网络。"

#~ msgid ""
#~ "Since we want to use PyTorch to"
#~ " solve a computer vision task, let's"
#~ " go ahead an install PyTorch and "
#~ "the **torchvision** library:"
#~ msgstr "我们想用 PyTorch 来做计算机视觉任务，需要先安装 PyTorch 和 **torchvision** 库："

#~ msgid "Ready... Set... Train!"
#~ msgstr "准备...设置...训练!"

#~ msgid ""
#~ "Now that we have all our "
#~ "dependencies installed, let's run a "
#~ "simple distributed training with two "
#~ "clients and one server. Our training "
#~ "procedure and network architecture are "
#~ "based on PyTorch's `Basic MNIST Example"
#~ " <https://github.com/pytorch/examples/tree/master/mnist>`_. "
#~ "This will allow you see how easy"
#~ " it is to wrap your code with"
#~ " Flower and begin training in a "
#~ "federated way. We provide you with "
#~ "two helper scripts, namely *run-"
#~ "server.sh*, and *run-clients.sh*. Don't "
#~ "be afraid to look inside, they are"
#~ " simple enough =)."
#~ msgstr ""
#~ "现在我们已经安装了所有的依赖包，让我们用两个客户端和一个服务器来运行一个简单的分布式训练。我们的训练过程和网络架构基于 "
#~ "PyTorch 的 `Basic MNIST Example "
#~ "<https://github.com/pytorch/examples/tree/master/mnist>`_。您会发现用 "
#~ "Flower 来封装您的代码并进行联邦学习训练是多么容易。我们为您提供了两个辅助脚本，即 *run-"
#~ "server.sh* 和 *run-clients.sh*。别害怕，它们很简单 =)。"

#~ msgid ""
#~ "Go ahead and launch on a terminal"
#~ " the *run-server.sh* script first as"
#~ " follows:"
#~ msgstr "首先在终端上启动 *run-server.sh* 脚本，如下所示："

#~ msgid "Now that the server is up and running, go ahead and launch the clients."
#~ msgstr "现在服务器已经启动并运行，请继续启动客户端。"

#~ msgid ""
#~ "Et voilà! You should be seeing the"
#~ " training procedure and, after a few"
#~ " iterations, the test accuracy for "
#~ "each client."
#~ msgstr "然后就可以了！您应该能看到训练过程，以及经过几次反复后，每个客户端的测试准确率。"

#~ msgid "Now, let's see what is really happening inside."
#~ msgstr "现在，让我们看看里面到底发生了什么。"

#~ msgid ""
#~ "Inside the server helper script *run-"
#~ "server.sh* you will find the following"
#~ " code that basically runs the "
#~ ":code:`server.py`"
#~ msgstr "在服务器辅助脚本 *run-server.sh* 中，你可以找到以下代码，这些代码基本上都是运行 :code:`server.py` 的代码"

#~ msgid ""
#~ "We can go a bit deeper and "
#~ "see that :code:`server.py` simply launches "
#~ "a server that will coordinate three "
#~ "rounds of training. Flower Servers are"
#~ " very customizable, but for simple "
#~ "workloads, we can start a server "
#~ "using the :ref:`start_server <flwr-server-"
#~ "start_server-apiref>` function and leave "
#~ "all the configuration possibilities at "
#~ "their default values, as seen below."
#~ msgstr ""
#~ "我们可以再深入一点，:code:`server.py` 只是启动了一个服务器，该服务器将协调三轮训练。Flower "
#~ "服务器是非常容易修改的，但对于简单的工作，我们可以使用 :ref:`start_server <flwr-"
#~ "server-start_server-apiref>`函数启动服务器，并将所有可能的配置保留为默认值，如下所示。"

#~ msgid ""
#~ "Next, let's take a look at the "
#~ "*run-clients.sh* file. You will see "
#~ "that it contains the main loop "
#~ "that starts a set of *clients*."
#~ msgstr "接下来，让我们看看 *run-clients.sh* 文件。您会看到它包含了用来启动多个 *客户端* 的代码。"

#~ msgid ""
#~ "**cid**: is the client ID. It is"
#~ " an integer that uniquely identifies "
#~ "client identifier."
#~ msgstr "**cid**：是客户 ID。它是一个整数，可唯一标识客户标识符。"

#~ msgid "**sever_address**: String that identifies IP and port of the server."
#~ msgstr "**sever_address**： 标识服务器 IP 和端口的字符串。"

#~ msgid ""
#~ "**nb_clients**: This defines the number "
#~ "of clients being created. This piece "
#~ "of information is not required by "
#~ "the client, but it helps us "
#~ "partition the original MNIST dataset to"
#~ " make sure that every client is "
#~ "working on unique subsets of both "
#~ "*training* and *test* sets."
#~ msgstr ""
#~ "**nb_clients**： 这定义了正在创建的客户端数量。客户端并不需要这一信息，但它有助于我们对原始 "
#~ "MNIST 数据集进行划分，以确保每个客户端都在 *training* 和 *test*"
#~ " 数据集上有独立的数据。"

#~ msgid ""
#~ "Again, we can go deeper and look"
#~ " inside :code:`flwr_example/quickstart-"
#~ "pytorch/client.py`. After going through the"
#~ " argument parsing code at the "
#~ "beginning of our :code:`main` function, "
#~ "you will find a call to "
#~ ":code:`mnist.load_data`. This function is "
#~ "responsible for partitioning the original "
#~ "MNIST datasets (*training* and *test*) "
#~ "and returning a :code:`torch.utils.data.DataLoader`"
#~ " s for each of them. We then"
#~ " instantiate a :code:`PytorchMNISTClient` object"
#~ " with our client ID, our DataLoaders,"
#~ " the number of epochs in each "
#~ "round, and which device we want to"
#~ " use for training (CPU or GPU)."
#~ msgstr ""
#~ "我们可以深入看一下 :code:`flwr_example/quickstart-"
#~ "pytorch/client.py`。查看 :code:`main` 函数开头的参数解析代码后，你会发现一个对"
#~ " :code:`mnist.load_data` 的调用。该函数负责分割原始 MNIST "
#~ "数据集（*training* 和 *test*），并为每个数据集返回一个 "
#~ ":code:`torch.utils.data.DataLoader` 。然后，我们实例化一个 "
#~ ":code:`PytorchMNISTClient` 对象，其中包含我们的客户端 ID、 "
#~ "DataLoader、每一轮中的遍历数，以及我们希望用于训练的设备（CPU 或 GPU）。"

#~ msgid ""
#~ "The :code:`PytorchMNISTClient` object when "
#~ "finally passed to :code:`fl.client.start_client` "
#~ "along with the server's address as "
#~ "the training process begins."
#~ msgstr ""
#~ "当训练过程开始时，:code:`PytorchMNISTClient` 对象会连同服务器地址一起传递给 "
#~ ":code:`fl.client.start_client`。"

#~ msgid "A Closer Look"
#~ msgstr "仔细看一下"

#~ msgid ""
#~ "Now, let's look closely into the "
#~ ":code:`PytorchMNISTClient` inside :code:`flwr_example"
#~ ".quickstart-pytorch.mnist` and see what it"
#~ " is doing:"
#~ msgstr ""
#~ "现在，让我们仔细研究一下 :code:`flwr_example.quickstart-pytorch.mnist`"
#~ " 中的 :code:`PytorchMNISTClient`，看看它在做什么："

#~ msgid ""
#~ "The first thing to notice is that"
#~ " :code:`PytorchMNISTClient` instantiates a CNN"
#~ " model inside its constructor"
#~ msgstr "首先要注意的是 :code:`PytorchMNISTClient` 在其构造函数中实例化了一个 CNN 模型"

#~ msgid ""
#~ "The code for the CNN is available"
#~ " under :code:`quickstart-pytorch.mnist` and "
#~ "it is reproduced below. It is the"
#~ " same network found in `Basic MNIST"
#~ " Example "
#~ "<https://github.com/pytorch/examples/tree/master/mnist>`_."
#~ msgstr ""
#~ "CNN 的代码可在 :code:`quickstart-pytorch.mnist` "
#~ "下找到，现复制如下。它与 `Basic MNIST Example "
#~ "<https://github.com/pytorch/examples/tree/master/mnist>`_中的网络相同。"

#~ msgid ""
#~ "The second thing to notice is that"
#~ " :code:`PytorchMNISTClient` class inherits from"
#~ " the :code:`fl.client.Client`, and hence it"
#~ " must implement the following methods:"
#~ msgstr ""
#~ "第二件要注意的事是 :code:`PytorchMNISTClient` 类继承自 "
#~ ":code:`fl.client.Client`，因此它必须实现以下方法："

#~ msgid ""
#~ "When comparing the abstract class to "
#~ "its derived class :code:`PytorchMNISTClient` "
#~ "you will notice that :code:`fit` calls"
#~ " a :code:`train` function and that "
#~ ":code:`evaluate` calls a :code:`test`: "
#~ "function."
#~ msgstr ""
#~ "将抽象类与其派生类 :code:`PytorchMNISTClient` 进行比较时，您会发现 "
#~ ":code:`fit` 调用了一个 :code:`train` 函数，而 "
#~ ":code:`evaluate` 则调用了一个 :code:`test`: 函数。"

#~ msgid ""
#~ "These functions can both be found "
#~ "inside the same :code:`quickstart-"
#~ "pytorch.mnist` module:"
#~ msgstr "这些函数都可以在同一个 :code:`quickstart-pytorch.mnist` 模块中找到："

#~ msgid ""
#~ "Observe that these functions encapsulate "
#~ "regular training and test loops and "
#~ "provide :code:`fit` and :code:`evaluate` with"
#~ " final statistics for each round. You"
#~ " could substitute them with your "
#~ "custom train and test loops and "
#~ "change the network architecture, and the"
#~ " entire example would still work "
#~ "flawlessly. As a matter of fact, "
#~ "why not try and modify the code"
#~ " to an example of your liking?"
#~ msgstr ""
#~ "请注意，这些函数封装了常规的训练和测试循环，并为 :code:`fit` 和 "
#~ ":code:`evaluate` "
#~ "提供了每轮的最终统计数据。您可以用自定义的训练和测试循环来替代它们，并改变网络结构，整个示例仍然可以完美运行。事实上，为什么不按照自己的喜好修改代码呢？"

#~ msgid "Give It a Try"
#~ msgstr "试试看"

#~ msgid ""
#~ "Looking through the quickstart code "
#~ "description above will have given a "
#~ "good understanding of how *clients* and"
#~ " *servers* work in Flower, how to "
#~ "run a simple experiment, and the "
#~ "internals of a client wrapper. Here "
#~ "are a few things you could try "
#~ "on your own and get more "
#~ "experience with Flower:"
#~ msgstr ""
#~ "通过上面的快速入门代码描述，你将对 Flower "
#~ "中*客户端*和*服务器*的工作方式、如何运行一个简单的实验以及客户端封装器的内部结构有一个很好的了解。您可以自己尝试以下内容，以获得更多使用"
#~ " Flower 的经验："

#~ msgid ""
#~ "Try and change :code:`PytorchMNISTClient` so"
#~ " it can accept different architectures."
#~ msgstr "尝试修改 :code:`PytorchMNISTClient`，使其可以接受不同的架构。"

#~ msgid ""
#~ "Modify the :code:`train` function so "
#~ "that it accepts different optimizers"
#~ msgstr "修改 :code:`train` 函数，使其接受不同的优化器"

#~ msgid ""
#~ "Modify the :code:`test` function so that"
#~ " it proves not only the top-1 "
#~ "(regular accuracy) but also the top-5"
#~ " accuracy?"
#~ msgstr "修改 :code:`test` 函数，使其不仅能输出前 1 名（常规精确度），还能证明前 5 名的精确度？"

#~ msgid ""
#~ "Go larger! Try to adapt the code"
#~ " to larger images and datasets. Why"
#~ " not try training on ImageNet with"
#~ " a ResNet-50?"
#~ msgstr "让我们尝试让代码适应更大的图像和数据集。为什么不尝试使用 ResNet-50 在 ImageNet 上进行训练呢？"

#~ msgid "You are ready now. Enjoy learning in a federated way!"
#~ msgstr "您现在已经准备就绪。尽情享受联邦学习的乐趣吧！"

#~ msgid "Differential privacy"
#~ msgstr "差别隐私"

#~ msgid ""
#~ "Flower provides differential privacy (DP) "
#~ "wrapper classes for the easy integration"
#~ " of the central DP guarantees "
#~ "provided by DP-FedAvg into training "
#~ "pipelines defined in any of the "
#~ "various ML frameworks that Flower is "
#~ "compatible with."
#~ msgstr ""
#~ "Flower 提供了差分隐私 (DP) 封装类，可将 DP-FedAvg "
#~ "提供的核心 DP 轻松集成到 Flower 兼容的各种 ML "
#~ "框架中定义的训练模式中。"

#~ msgid ""
#~ "Please note that these components are"
#~ " still experimental; the correct "
#~ "configuration of DP for a specific "
#~ "task is still an unsolved problem."
#~ msgstr "请注意，这些组件仍处于试验阶段，如何为特定任务正确配置 DP 仍是一个尚未解决的问题。"

#~ msgid ""
#~ "The name DP-FedAvg is misleading "
#~ "since it can be applied on top "
#~ "of any FL algorithm that conforms "
#~ "to the general structure prescribed by"
#~ " the FedOpt family of algorithms."
#~ msgstr "DP-FedAvg 这个名称容易引起误解，因为它可以应用于任何符合 FedOpt 系列算法规定的一般结构的 FL 算法之上。"

#~ msgid "DP-FedAvg"
#~ msgstr "DP-FedAvg"

#~ msgid ""
#~ "DP-FedAvg, originally proposed by "
#~ "McMahan et al. [mcmahan]_ and extended"
#~ " by Andrew et al. [andrew]_, is "
#~ "essentially FedAvg with the following "
#~ "modifications."
#~ msgstr "DP-FedAvg 最初由McMahan等人提出，并由Andrew等人加以扩展。"

#~ msgid ""
#~ "**Clipping** : The influence of each "
#~ "client's update is bounded by clipping"
#~ " it. This is achieved by enforcing"
#~ " a cap on the L2 norm of "
#~ "the update, scaling it down if "
#~ "needed."
#~ msgstr "**裁剪** ： 裁剪会影响到每个客户端的模型参数。具体做法是对参数的 L2 准则设置上限，必要时将其缩减。"

#~ msgid ""
#~ "**Noising** :  Gaussian noise, calibrated "
#~ "to the clipping threshold, is added "
#~ "to the average computed at the "
#~ "server."
#~ msgstr "**噪声** ： 在服务器计算出的平均值中加入高斯噪声，该噪声根据剪切阈值进行校准。"

#~ msgid ""
#~ "The distribution of the update norm "
#~ "has been shown to vary from "
#~ "task-to-task and to evolve as "
#~ "training progresses. This variability is "
#~ "crucial in understanding its impact on"
#~ " differential privacy guarantees, emphasizing "
#~ "the need for an adaptive approach "
#~ "[andrew]_ that continuously adjusts the "
#~ "clipping threshold to track a "
#~ "prespecified quantile of the update norm"
#~ " distribution."
#~ msgstr "事实证明，参数更新准则的分布会随着任务的不同而变化，并随着训练的进展而演变。因此，我们采用了一种自适应方法，该方法会不断调整剪切阈值，以跟踪参数更新准则分布的预设量化值。"

#~ msgid "Simplifying Assumptions"
#~ msgstr "简化假设"

#~ msgid ""
#~ "We make (and attempt to enforce) a"
#~ " number of assumptions that must be"
#~ " satisfied to ensure that the "
#~ "training process actually realizes the "
#~ ":math:`(\\epsilon, \\delta)` guarantees the "
#~ "user has in mind when configuring "
#~ "the setup."
#~ msgstr ""
#~ "我们提出（并试图执行）了一系列必须满足的假设，以确保训练过程真正实现用户在配置设置时所定的 "
#~ ":math:`(\\epsilon,\\delta)` 。"

#~ msgid ""
#~ "**Fixed-size subsampling** :Fixed-size "
#~ "subsamples of the clients must be "
#~ "taken at each round, as opposed to"
#~ " variable-sized Poisson subsamples."
#~ msgstr "** 固定大小的子样本** :与可变大小的泊松分布子样本相比，每轮必须抽取固定大小的客户端子样本。"

#~ msgid ""
#~ "**Unweighted averaging** : The contributions"
#~ " from all the clients must weighted"
#~ " equally in the aggregate to "
#~ "eliminate the requirement for the server"
#~ " to know in advance the sum of"
#~ " the weights of all clients available"
#~ " for selection."
#~ msgstr "**非加权平均**： 所有客户端的贡献必须加权相等，这样服务器就不需要事先知道所有客户的权重总和。"

#~ msgid ""
#~ "**No client failures** : The set "
#~ "of available clients must stay constant"
#~ " across all rounds of training. In"
#~ " other words, clients cannot drop out"
#~ " or fail."
#~ msgstr "**没有失败的客户端** ： 在各轮训练中，可用客户端的数量必须保持不变。换句话说，客户端不能退出或失败。"

#~ msgid ""
#~ "The first two are useful for "
#~ "eliminating a multitude of complications "
#~ "associated with calibrating the noise to"
#~ " the clipping threshold, while the "
#~ "third one is required to comply "
#~ "with the assumptions of the privacy "
#~ "analysis."
#~ msgstr "前两种方法有助于消除将噪声校准为削波阈值所带来的诸多复杂问题，而第三种方法则需要符合隐私分析的假设。"

#~ msgid ""
#~ "These restrictions are in line with "
#~ "constraints imposed by Andrew et al. "
#~ "[andrew]_."
#~ msgstr "这些限制与 Andrew 等人所施加的限制一致。"

#~ msgid "Customizable Responsibility for Noise injection"
#~ msgstr "可定制的噪声注入"

#~ msgid ""
#~ "In contrast to other implementations "
#~ "where the addition of noise is "
#~ "performed at the server, you can "
#~ "configure the site of noise injection"
#~ " to better match your threat model."
#~ " We provide users with the "
#~ "flexibility to set up the training "
#~ "such that each client independently adds"
#~ " a small amount of noise to the"
#~ " clipped update, with the result that"
#~ " simply aggregating the noisy updates "
#~ "is equivalent to the explicit addition"
#~ " of noise to the non-noisy "
#~ "aggregate at the server."
#~ msgstr "与其他在服务器上添加噪声的实现方法不同，您可以配置噪声注入的位置，以便更好地匹配您的威胁模型。我们为用户提供了设置训练的灵活性，使每个客户端都能独立地为剪切参数更新添加少量噪声，这样，只需聚合噪声更新，就相当于在服务器上为非噪声聚合添加噪声了。"

#~ msgid ""
#~ "To be precise, if we let :math:`m`"
#~ " be the number of clients sampled "
#~ "each round and :math:`\\sigma_\\Delta` be "
#~ "the scale of the total Gaussian "
#~ "noise that needs to be added to"
#~ " the sum of the model updates, "
#~ "we can use simple maths to show"
#~ " that this is equivalent to each "
#~ "client adding noise with scale "
#~ ":math:`\\sigma_\\Delta/\\sqrt{m}`."
#~ msgstr ""
#~ "准确地说，我们假设每轮采样的客户端数量为:math:`m`，:math:`\\sigma_\\Delta` "
#~ "为需要添加到模型更新总和中的总高斯噪声的规模，我们就可以用简单的数学方法证明了，这相当于每个客户端都添加了规模为 "
#~ ":math:`\\sigma_\\Delta/\\sqrt{m}` 的噪声。"

#~ msgid "Wrapper-based approach"
#~ msgstr "基于封装的方法"

#~ msgid ""
#~ "Introducing DP to an existing workload"
#~ " can be thought of as adding an"
#~ " extra layer of security around it."
#~ " This inspired us to provide the "
#~ "additional server and client-side logic"
#~ " needed to make the training process"
#~ " differentially private as wrappers for "
#~ "instances of the :code:`Strategy` and "
#~ ":code:`NumPyClient` abstract classes respectively."
#~ " This wrapper-based approach has the"
#~ " advantage of being easily composable "
#~ "with other wrappers that someone might"
#~ " contribute to the Flower library in"
#~ " the future, e.g., for secure "
#~ "aggregation. Using Inheritance instead can "
#~ "be tedious because that would require"
#~ " the creation of new sub- classes "
#~ "every time a new class implementing "
#~ ":code:`Strategy` or :code:`NumPyClient` is "
#~ "defined."
#~ msgstr ""
#~ "在现有工作负载中引入 DP "
#~ "可以被认为是在其周围增加了一层额外的安全性。受此启发，我们提供了额外的服务器端和客户端逻辑，分别作为 "
#~ ":code:`Strategy` 和 :code:`NumPyClient` "
#~ "抽象类实例的封装器，使训练过程具有不同的隐私性。这种基于封装器的方法的优点是可以很容易地与将来有人贡献给 Flower "
#~ "的其他封装器（例如用于安全聚合的封装器）进行组合。使用继承可能会比较繁琐，因为每次定义实现 :code:`Strategy`"
#~ " 或 :code:`NumPyClient` 的新类时，都需要创建新的子类。"

#~ msgid ""
#~ "The first version of our solution "
#~ "was to define a decorator whose "
#~ "constructor accepted, among other things, "
#~ "a boolean-valued variable indicating "
#~ "whether adaptive clipping was to be "
#~ "enabled or not. We quickly realized "
#~ "that this would clutter its "
#~ ":code:`__init__()` function with variables "
#~ "corresponding to hyperparameters of adaptive"
#~ " clipping that would remain unused "
#~ "when it was disabled. A cleaner "
#~ "implementation could be achieved by "
#~ "splitting the functionality into two "
#~ "decorators, :code:`DPFedAvgFixed` and "
#~ ":code:`DPFedAvgAdaptive`, with the latter sub-"
#~ " classing the former. The constructors "
#~ "for both classes accept a boolean "
#~ "parameter :code:`server_side_noising`, which, as "
#~ "the name suggests, determines where "
#~ "noising is to be performed."
#~ msgstr ""
#~ "我们的第一版解决方案是定义一个装饰器，其构造函数接受一个布尔值变量，表示是否启用自适应剪裁。我们很快意识到，这样会使其 "
#~ ":code:`__init__()` "
#~ "函数中与自适应裁剪超参数相对应的变量变得杂乱无章，而这些变量在自适应裁剪被禁用时将保持未使用状态。要实现更简洁的功能，可以将该功能拆分为两个装饰器，即"
#~ " :code:`DPFedAvgFixed` 和 "
#~ ":code:`DPFedAvgAdaptive`，后者是前者的子类。这两个类的构造函数都接受一个布尔参数 "
#~ ":code:`server_side_noising`，顾名思义，它决定了在哪里加噪声。"

#~ msgid ""
#~ "The server-side capabilities required "
#~ "for the original version of DP-"
#~ "FedAvg, i.e., the one which performed"
#~ " fixed clipping, can be completely "
#~ "captured with the help of wrapper "
#~ "logic for just the following two "
#~ "methods of the :code:`Strategy` abstract "
#~ "class."
#~ msgstr ""
#~ "只需对 :code:`Strategy` 抽象类的以下两个方法进行封装，就能完全捕获 DP-"
#~ "FedAvg 原始版本（即执行固定剪裁的版本）所需的服务器端功能。"

#~ msgid ""
#~ ":code:`configure_fit()` : The config "
#~ "dictionary being sent by the wrapped "
#~ ":code:`Strategy` to each client needs to"
#~ " be augmented with an additional "
#~ "value equal to the clipping threshold"
#~ " (keyed under :code:`dpfedavg_clip_norm`) and,"
#~ " if :code:`server_side_noising=true`, another one"
#~ " equal to the scale of the "
#~ "Gaussian noise that needs to be "
#~ "added at the client (keyed under "
#~ ":code:`dpfedavg_noise_stddev`). This entails "
#~ "*post*-processing of the results returned "
#~ "by the wrappee's implementation of "
#~ ":code:`configure_fit()`."
#~ msgstr ""
#~ ":code:`configure_fit()` ：由封装的 :code:`Strategy` "
#~ "发送到每个客户端的配置字典需要使用等于裁剪阈值的附加值（在 :code:`dpfedavg_clip_norm` "
#~ "下键入）进行扩充。并且，如果 "
#~ "server_side_noising=true，则另一个值等于需要在客户端添加的高斯噪声的大小（在 "
#~ "dpfedavg_noise_stddev 下键入）。这需要对封装后的configure_fit() "
#~ "所返回的结果进行后处理。"

#~ msgid ""
#~ ":code:`aggregate_fit()`: We check whether any"
#~ " of the sampled clients dropped out"
#~ " or failed to upload an update "
#~ "before the round timed out. In "
#~ "that case, we need to abort the"
#~ " current round, discarding any successful"
#~ " updates that were received, and move"
#~ " on to the next one. On the "
#~ "other hand, if all clients responded "
#~ "successfully, we must force the "
#~ "averaging of the updates to happen "
#~ "in an unweighted manner by intercepting"
#~ " the :code:`parameters` field of "
#~ ":code:`FitRes` for each received update "
#~ "and setting it to 1. Furthermore, "
#~ "if :code:`server_side_noising=true`, each update "
#~ "is perturbed with an amount of "
#~ "noise equal to what it would have"
#~ " been subjected to had client-side"
#~ " noising being enabled. This entails "
#~ "*pre*-processing of the arguments to "
#~ "this method before passing them on "
#~ "to the wrappee's implementation of "
#~ ":code:`aggregate_fit()`."
#~ msgstr ""
#~ ":code:`aggregate_fit()`： "
#~ "我们会检查是否有任何客户端在本轮超时前退出或未能上传参数更新。在这种情况下，我们需要中止当前一轮，丢弃已收到的所有参数更新，然后继续下一轮。另一方面，如果所有客户端都成功响应，我们就必须通过拦截"
#~ " :code:`FitRes` 的 :code:`parameters` 字段并将其设置为 "
#~ "1，强制以不加权的方式平均更新。此外，如果 "
#~ ":code:`server_side_noising=true`，每次更新都会受到一定量的噪声扰动，其扰动量相当于启用客户端噪声时的扰动量。"
#~ " 这就需要在将本方法的参数传递给封装的 :code:`aggregate_fit()` "
#~ "之前，对参数进行*预*处理。"

#~ msgid ""
#~ "We can't directly change the aggregation"
#~ " function of the wrapped strategy to"
#~ " force it to add noise to the"
#~ " aggregate, hence we simulate client-"
#~ "side noising to implement server-side"
#~ " noising."
#~ msgstr "我们无法直接改变封装策略的聚合函数，迫使它在聚合中添加噪声，因此我们模拟客户端噪声来实现服务器端噪声。"

#~ msgid ""
#~ "These changes have been put together "
#~ "into a class called :code:`DPFedAvgFixed`, "
#~ "whose constructor accepts the strategy "
#~ "being decorated, the clipping threshold "
#~ "and the number of clients sampled "
#~ "every round as compulsory arguments. The"
#~ " user is expected to specify the "
#~ "clipping threshold since the order of"
#~ " magnitude of the update norms is "
#~ "highly dependent on the model being "
#~ "trained and providing a default value"
#~ " would be misleading. The number of"
#~ " clients sampled at every round is"
#~ " required to calculate the amount of"
#~ " noise that must be added to "
#~ "each individual update, either by the"
#~ " server or the clients."
#~ msgstr ""
#~ "这些变化被整合到一个名为 :code:`DPFedAvgFixed` "
#~ "的类中，其构造函数接受被装饰的策略、剪切阈值和每轮采样的客户数作为必选参数。用户需要指定剪切阈值，因为参数更新规范的数量级在很大程度上取决于正在训练的模型，提供默认值会产生误导。每轮采样的客户端数量是计算服务器或客户在每次参数更新时添加的噪音量所必需的。"

#~ msgid ""
#~ "The additional functionality required to "
#~ "facilitate adaptive clipping has been "
#~ "provided in :code:`DPFedAvgAdaptive`, a "
#~ "subclass of :code:`DPFedAvgFixed`. It "
#~ "overrides the above-mentioned methods to"
#~ " do the following."
#~ msgstr ""
#~ "自适应剪裁所需的附加功能在 :code:`DPFedAvgAdaptive` 中提供，其是 "
#~ ":code:`DPFedAvgFixed` 的子类。它重写了上述方法，以实现以下功能。"

#~ msgid ""
#~ ":code:`configure_fit()` : It intercepts the"
#~ " config dict returned by "
#~ ":code:`super.configure_fit()` to add the "
#~ "key-value pair "
#~ ":code:`dpfedavg_adaptive_clip_enabled:True` to it, "
#~ "which the client interprets as an "
#~ "instruction to include an indicator bit"
#~ " (1 if update norm <= clipping "
#~ "threshold, 0 otherwise) in the results"
#~ " returned by it."
#~ msgstr ""
#~ ":code:`configure_fit()`：它截取由 :code:`super.configure_fit()` "
#~ "返回的 config 字典，并在其中添加键-值对 "
#~ ":code:`dpfedavg_adaptive_clip_enabled:True\"，客户端将其解释为在返回结果中包含一个指示位（如果参数更新范式"
#~ " <= 剪裁阈值，则为 1，否则为 0）的指令。"

#~ msgid ""
#~ ":code:`aggregate_fit()` : It follows a "
#~ "call to :code:`super.aggregate_fit()` with one"
#~ " to :code:`__update_clip_norm__()`, a procedure"
#~ " which adjusts the clipping threshold "
#~ "on the basis of the indicator bits"
#~ " received from the sampled clients."
#~ msgstr ":code:`aggregate_fit()`：在调用:code:`super.aggregate_fit()`后，再调用:code:`__update_clip_norm__()`，该过程根据从采样客户端接收到的指示位调整裁剪阈值。"

#~ msgid ""
#~ "The client-side capabilities required "
#~ "can be completely captured through "
#~ "wrapper logic for just the :code:`fit()`"
#~ " method of the :code:`NumPyClient` abstract"
#~ " class. To be precise, we need "
#~ "to *post-process* the update computed"
#~ " by the wrapped client to clip "
#~ "it, if necessary, to the threshold "
#~ "value supplied by the server as "
#~ "part of the config dictionary. In "
#~ "addition to this, it may need to"
#~ " perform some extra work if either"
#~ " (or both) of the following keys "
#~ "are also present in the dict."
#~ msgstr ""
#~ "客户端所需的功能完全可以通过 :code:`NumPyClient` 抽象类的 "
#~ ":code:`fit()` "
#~ "方法的封装逻辑来实现。准确地说，我们需要对封装客户端计算的参数更新进行处理，以便在必要时将其剪切到服务器作为配置字典的一部分提供的阈值。除此之外，如果配置字典中还存在以下任一（或两个）键，客户端可能还需要执行一些额外的工作。"

#~ msgid ""
#~ ":code:`dpfedavg_noise_stddev` : Generate and "
#~ "add the specified amount of noise "
#~ "to the clipped update."
#~ msgstr "code:`dpfedavg_noise_stddev`：生成并在剪切参数更新中添加指定数量的噪声。"

#~ msgid ""
#~ ":code:`dpfedavg_adaptive_clip_enabled` : Augment the"
#~ " metrics dict in the :code:`FitRes` "
#~ "object being returned to the server "
#~ "with an indicator bit, calculated as "
#~ "described earlier."
#~ msgstr ""
#~ ":code:`dpfedavg_adaptive_clip_enabled`：在返回给服务器的 :code:`FitRes`"
#~ " 对象中的度量值字典中增加一个指标位，计算方法如前所述。"

#~ msgid "Performing the :math:`(\\epsilon, \\delta)` analysis"
#~ msgstr "进行 :math:`(epsilon, \\delta)` 分析"

#~ msgid ""
#~ "Assume you have trained for :math:`n`"
#~ " rounds with sampling fraction :math:`q`"
#~ " and noise multiplier :math:`z`. In "
#~ "order to calculate the :math:`\\epsilon` "
#~ "value this would result in for a"
#~ " particular :math:`\\delta`, the following "
#~ "script may be used."
#~ msgstr ""
#~ "假设您已经训练了 :math:`n` 轮，采样比例为 :math:`q`，噪声乘数为 "
#~ ":math:`z`。为了计算特定 :math:`\\delta` 的 :math:`epsilon`"
#~ " 值，可以使用下面的脚本。"

#~ msgid "Flower driver SDK."
#~ msgstr "Flower 服务器。"

#~ msgid "driver"
#~ msgstr "服务器"

#~ msgid "Get task results."
#~ msgstr "汇总训练结果。"

#~ msgid "Request for run ID."
#~ msgstr "Flower 基线申请"

#~ msgid "Get client IDs."
#~ msgstr "返回客户端（本身）。"

#~ msgid ""
#~ "Flower usage examples used to be "
#~ "bundled with Flower in a package "
#~ "called ``flwr_example``. We are migrating "
#~ "those examples to standalone projects to"
#~ " make them easier to use. All "
#~ "new examples are based in the "
#~ "directory `examples "
#~ "<https://github.com/adap/flower/tree/main/examples>`_."
#~ msgstr ""
#~ "Flower 的使用示例曾与 Flower 捆绑在一个名为 ``flwr_example``"
#~ " 的软件包中。我们正在将这些示例迁移到独立项目中，以使它们更易于使用。所有新示例都位于目录 `examples "
#~ "<https://github.com/adap/flower/tree/main/examples>`_。"

#~ msgid "Quickstart TensorFlow/Keras"
#~ msgstr "快速入门 TensorFlow/Keras"

#~ msgid "Legacy Examples (`flwr_example`)"
#~ msgstr "传统示例 (`flwr_example`)"

#~ msgid ""
#~ "The useage examples in `flwr_example` "
#~ "are deprecated and will be removed "
#~ "in the future. New examples are "
#~ "provided as standalone projects in "
#~ "`examples <https://github.com/adap/flower/tree/main/examples>`_."
#~ msgstr ""
#~ "在 `flwr_example` 中的使用示例已被弃用，今后将被移除。新示例将作为独立项目在 "
#~ "`examples <https://github.com/adap/flower/tree/main/examples>`_"
#~ " 中提供。"

#~ msgid "Extra Dependencies"
#~ msgstr "额外依赖"

#~ msgid ""
#~ "The core Flower framework keeps a "
#~ "minimal set of dependencies. The "
#~ "examples demonstrate Flower in the "
#~ "context of different machine learning "
#~ "frameworks, so additional dependencies need"
#~ " to be installed before an example"
#~ " can be run."
#~ msgstr ""
#~ "Flower 核心框架只保留了最低限度的依赖项。这些示例在不同机器学习框架的背景下演示了 "
#~ "Flower，因此在运行示例之前需要安装额外的依赖项。"

#~ msgid "For PyTorch examples::"
#~ msgstr "PyTorch 示例：："

#~ msgid "For TensorFlow examples::"
#~ msgstr "TensorFlow 示例：："

#~ msgid "For both PyTorch and TensorFlow examples::"
#~ msgstr "PyTorch 和 TensorFlow 示例：："

#~ msgid ""
#~ "Please consult :code:`pyproject.toml` for a"
#~ " full list of possible extras "
#~ "(section :code:`[tool.poetry.extras]`)."
#~ msgstr ""
#~ "请参阅 :code:`pyproject.toml`，了解可能的 extras 的完整列表（章节 "
#~ ":code:`[tool.poems.extras]`）。"

#~ msgid "PyTorch Examples"
#~ msgstr "PyTorch 示例"

#~ msgid ""
#~ "Our PyTorch examples are based on "
#~ "PyTorch 1.7. They should work with "
#~ "other releases as well. So far, we"
#~ " provide the following examples."
#~ msgstr "我们的 PyTorch 示例基于 PyTorch 1.7。它们应该也能在其他版本中使用。到目前为止，我们提供了以下示例。"

#~ msgid "CIFAR-10 Image Classification"
#~ msgstr "CIFAR-10 图像分类"

#~ msgid ""
#~ "`CIFAR-10 and CIFAR-100 "
#~ "<https://www.cs.toronto.edu/~kriz/cifar.html>`_ are "
#~ "popular RGB image datasets. The Flower"
#~ " CIFAR-10 example uses PyTorch to "
#~ "train a simple CNN classifier in a"
#~ " federated learning setup with two "
#~ "clients."
#~ msgstr ""
#~ "CIFAR-10 和 CIFAR-100 "
#~ "<https://www.cs.toronto.edu/~kriz/cifar.html>``_ 是流行的 RGB"
#~ " 图像数据集。Flower CIFAR-10 示例使用 PyTorch "
#~ "在有两个客户端的联邦学习设置中训练一个简单的 CNN 分类器。"

#~ msgid "First, start a Flower server:"
#~ msgstr "首先，启动 Flower 服务器："

#~ msgid "$ ./src/py/flwr_example/pytorch_cifar/run-server.sh"
#~ msgstr "$ ./src/py/flwr_example/pytorch_cifar/run-server.sh"

#~ msgid "Then, start the two clients in a new terminal window:"
#~ msgstr "然后，在新的终端窗口中启动两个客户端："

#~ msgid "$ ./src/py/flwr_example/pytorch_cifar/run-clients.sh"
#~ msgstr "$ ./src/py/flwr_example/pytorch_cifar/run-clients.sh"

#~ msgid "For more details, see :code:`src/py/flwr_example/pytorch_cifar`."
#~ msgstr "更多详情，请参阅 :code:`src/py/flwr_example/pytorch_cifar`。"

#~ msgid "ImageNet-2012 Image Classification"
#~ msgstr "ImageNet-2012 图像分类"

#~ msgid ""
#~ "`ImageNet-2012 <http://www.image-net.org/>`_ is "
#~ "one of the major computer vision "
#~ "datasets. The Flower ImageNet example "
#~ "uses PyTorch to train a ResNet-18 "
#~ "classifier in a federated learning setup"
#~ " with ten clients."
#~ msgstr ""
#~ "ImageNet-2012 <http://www.image-net.org/>`_ "
#~ "是主要的计算机视觉数据集之一。Flower ImageNet 示例使用 PyTorch "
#~ "在有十个客户端的联邦学习设置中训练 ResNet-18 分类器。"

#~ msgid "$ ./src/py/flwr_example/pytorch_imagenet/run-server.sh"
#~ msgstr "$ ./src/py/flwr_example/pytorch_imagenet/run-server.sh"

#~ msgid "$ ./src/py/flwr_example/pytorch_imagenet/run-clients.sh"
#~ msgstr "$ ./src/py/flwr_example/pytorch_imagenet/run-clients.sh"

#~ msgid "For more details, see :code:`src/py/flwr_example/pytorch_imagenet`."
#~ msgstr "更多详情，请参阅 :code:`src/py/flwr_example/pytorch_imagenet`。"

#~ msgid "TensorFlow Examples"
#~ msgstr "TensorFlow 示例"

#~ msgid ""
#~ "Our TensorFlow examples are based on "
#~ "TensorFlow 2.0 or newer. So far, "
#~ "we provide the following examples."
#~ msgstr "我们的 TensorFlow 示例基于 TensorFlow 2.0 或更新版本。到目前为止，我们提供了以下示例。"

#~ msgid "Fashion-MNIST Image Classification"
#~ msgstr "Fashion-MNIST 图像分类"

#~ msgid ""
#~ "`Fashion-MNIST <https://github.com/zalandoresearch"
#~ "/fashion-mnist>`_ is often used as "
#~ "the \"Hello, world!\" of machine "
#~ "learning. We follow this tradition and"
#~ " provide an example which samples "
#~ "random local datasets from Fashion-MNIST"
#~ " and trains a simple image "
#~ "classification model over those partitions."
#~ msgstr ""
#~ "`Fashion-MNIST <https://github.com/zalandoresearch"
#~ "/fashion-mnist>`_ 经常被用作机器学习的 \"你好，世界！\"。我们遵循这一传统"
#~ "，提供了一个从Fashion-MNIST 中随机抽样本地数据集的示例，并在这些分区上训练一个简单的图像分类模型。"

#~ msgid "$ ./src/py/flwr_example/tensorflow_fashion_mnist/run-server.sh"
#~ msgstr "$ ./src/py/flwr_example/tensorflow_fashion_mnist/run-server.sh"

#~ msgid "$ ./src/py/flwr_example/tensorflow_fashion_mnist/run-clients.sh"
#~ msgstr "$ ./src/py/flwr_example/tensorflow_fashion_mnist/run-clients.sh"

#~ msgid ""
#~ "For more details, see "
#~ ":code:`src/py/flwr_example/tensorflow_fashion_mnist`."
#~ msgstr "更多详情，请参阅 :code:`src/py/flwr_example/tensorflow_fashion_mnist`。"

#~ msgid "``BASE_IMAGE_TAG``"
#~ msgstr "基本图像标签"

#~ msgid "The image tag of the base image."
#~ msgstr "基础图像的图像标记。"

#~ msgid ""
#~ "It is important to follow the "
#~ "instructions described in comments. For "
#~ "instance, in order to not break "
#~ "how our changelog system works, you "
#~ "should read the information above the"
#~ " ``Changelog entry`` section carefully. You"
#~ " can also checkout some examples and"
#~ " details in the :ref:`changelogentry` "
#~ "appendix."
#~ msgstr ""
#~ "请务必遵守注释中的说明。例如，为了不破坏我们的更新日志系统，你应该仔细阅读\"`更新日志条目``\"部分上面的信息。您还可以查看 "
#~ ":ref:`changelogentry` 附录中的一些示例和细节。"

#~ msgid "Open a PR (as shown above)"
#~ msgstr "打开 PR（如上图所示）"

#~ msgid "How to write a good PR title"
#~ msgstr "如何撰写好的公关标题"

#~ msgid ""
#~ "A well-crafted PR title helps team"
#~ " members quickly understand the purpose "
#~ "and scope of the changes being "
#~ "proposed. Here's a guide to help "
#~ "you write a good GitHub PR title:"
#~ msgstr "一个精心撰写的公关标题能帮助团队成员迅速了解所提修改的目的和范围。以下指南可帮助您撰写一个好的 GitHub PR 标题："

#~ msgid ""
#~ "1. Be Clear and Concise: Provide a"
#~ " clear summary of the changes in "
#~ "a concise manner. 1. Use Actionable "
#~ "Verbs: Start with verbs like \"Add,\""
#~ " \"Update,\" or \"Fix\" to indicate "
#~ "the purpose. 1. Include Relevant "
#~ "Information: Mention the affected feature "
#~ "or module for context. 1. Keep it"
#~ " Short: Avoid lengthy titles for easy"
#~ " readability. 1. Use Proper Capitalization"
#~ " and Punctuation: Follow grammar rules "
#~ "for clarity."
#~ msgstr ""
#~ "1. 简明扼要： 以简明扼要的方式清楚地概述变化。1. 使用可操作的动词： 使用 "
#~ "\"添加\"、\"更新 \"或 \"修复 \"等动词来表明目的。1. 包含相关信息： "
#~ "提及受影响的功能或模块以了解上下文。1. 简短：避免冗长的标题，以方便阅读。1. 使用正确的大小写和标点符号："
#~ " 遵守语法规则，以确保清晰。"

#~ msgid ""
#~ "Let's start with a few examples "
#~ "for titles that should be avoided "
#~ "because they do not provide meaningful"
#~ " information:"
#~ msgstr "让我们先举例说明几个应该避免使用的标题，因为它们不能提供有意义的信息："

#~ msgid "Implement Algorithm"
#~ msgstr "执行算法"

#~ msgid "Add my_new_file.py to codebase"
#~ msgstr "在代码库中添加 my_new_file.py"

#~ msgid "Improve code in module"
#~ msgstr "改进模块中的代码"

#~ msgid "Change SomeModule"
#~ msgstr "更改 SomeModule"

#~ msgid ""
#~ "Here are a few positive examples "
#~ "which provide helpful information without "
#~ "repeating how they do it, as that"
#~ " is already visible in the \"Files"
#~ " changed\" section of the PR:"
#~ msgstr "这里有几个正面的例子，提供了有用的信息，但没有重复他们是如何做的，因为在 PR 的 \"已更改文件 \"部分已经可以看到："

#~ msgid "Update docs banner to mention Flower Summit 2023"
#~ msgstr "更新文件横幅，提及 2023 年 Flower 峰会"

#~ msgid "Remove unnecessary XGBoost dependency"
#~ msgstr "移除不必要的 XGBoost 依赖性"

#~ msgid "Remove redundant attributes in strategies subclassing FedAvg"
#~ msgstr "删除 FedAvg 子类化策略中的多余属性"

#~ msgid ""
#~ "Add CI job to deploy the staging"
#~ " system when the ``main`` branch "
#~ "changes"
#~ msgstr "添加 CI 作业，以便在 \"主 \"分支发生变化时部署暂存系统"

#~ msgid ""
#~ "Add new amazing library which will "
#~ "be used to improve the simulation "
#~ "engine"
#~ msgstr "添加新的惊人库，用于改进模拟引擎"

#~ msgid "Changelog entry"
#~ msgstr "更新日志"

#~ msgid ""
#~ "When opening a new PR, inside its"
#~ " description, there should be a "
#~ "``Changelog entry`` header."
#~ msgstr "打开一个新 PR 时，在其描述中应有一个 ``Changelog entry`` 标头。"

#~ msgid ""
#~ "Above this header you should see "
#~ "the following comment that explains how"
#~ " to write your changelog entry:"
#~ msgstr "在页眉上方，你会看到以下注释，说明如何编写更新日志条目："

#~ msgid ""
#~ "Inside the following 'Changelog entry' "
#~ "section, you should put the description"
#~ " of your changes that will be "
#~ "added to the changelog alongside your"
#~ " PR title."
#~ msgstr "在下面的 \"更新日志条目 \"部分中，您应该在 PR 标题旁边写上将添加到更新日志中的更改描述。"

#~ msgid ""
#~ "If the section is completely empty "
#~ "(without any token) or non-existent, "
#~ "the changelog will just contain the "
#~ "title of the PR for the changelog"
#~ " entry, without any description."
#~ msgstr "如果该部分完全为空（没有任何标记）或不存在，更新日志将只包含更新日志条目的 PR 标题，而不包含任何描述。"

#~ msgid ""
#~ "If the section contains some text "
#~ "other than tokens, it will use it"
#~ " to add a description to the "
#~ "change."
#~ msgstr "如果该部分包含标记以外的文本，它将使用这些文本为更改添加说明。"

#~ msgid ""
#~ "If the section contains one of the"
#~ " following tokens it will ignore any"
#~ " other text and put the PR "
#~ "under the corresponding section of the"
#~ " changelog:"
#~ msgstr "如果该部分包含以下标记之一，它将忽略任何其他文本，并将 PR 放在更新日志的相应部分下："

#~ msgid "<general> is for classifying a PR as a general improvement."
#~ msgstr "<general> 用于将 PR 划分为一般改进。"

#~ msgid "<skip> is to not add the PR to the changelog"
#~ msgstr "<skip>表示不将 PR 添加到更新日志中"

#~ msgid "<baselines> is to add a general baselines change to the PR"
#~ msgstr "<baselines> 是指在 PR 中添加一般基线更改"

#~ msgid "<examples> is to add a general examples change to the PR"
#~ msgstr "<examples> 是在 PR 中添加对一般示例的修改"

#~ msgid "<sdk> is to add a general sdk change to the PR"
#~ msgstr "<sdk> 是指在 PR 中添加一般的 sdk 更改"

#~ msgid "<simulations> is to add a general simulations change to the PR"
#~ msgstr "<simulations>（模拟）是在 PR 中添加一般模拟变更"

#~ msgid "Note that only one token should be used."
#~ msgstr "请注意，只能使用一个标记。"

#~ msgid ""
#~ "Its content must have a specific "
#~ "format. We will break down what "
#~ "each possibility does:"
#~ msgstr "其内容必须有特定的格式。我们将分析每种可能性的作用："

#~ msgid ""
#~ "If the ``### Changelog entry`` section"
#~ " contains nothing or doesn't exist, "
#~ "the following text will be added "
#~ "to the changelog::"
#~ msgstr "如果 ``#### Changelog entry`` 部分不包含任何内容或不存在，则会在更新日志中添加以下文本：："

#~ msgid ""
#~ "If the ``### Changelog entry`` section"
#~ " contains a description (and no "
#~ "token), the following text will be "
#~ "added to the changelog::"
#~ msgstr "如果 ``#### Changelog entry`` 部分包含描述（但没有标记），则会在更新日志中添加以下文本：："

#~ msgid ""
#~ "If the ``### Changelog entry`` section"
#~ " contains ``<skip>``, nothing will change"
#~ " in the changelog."
#~ msgstr "如果 ``#### Changelog entry`` 部分包含 ``<skip>``，更新日志中将不会有任何更改。"

#~ msgid ""
#~ "If the ``### Changelog entry`` section"
#~ " contains ``<general>``, the following text"
#~ " will be added to the changelog::"
#~ msgstr "如果 ``### Changelog entry`` 部分包含 ``<general>``，则会在更新日志中添加以下文本：："

#~ msgid ""
#~ "If the ``### Changelog entry`` section"
#~ " contains ``<baselines>``, the following "
#~ "text will be added to the "
#~ "changelog::"
#~ msgstr "如果``### 更新日志条目``部分包含``<基准线>``，则会在更新日志中添加以下文本：："

#~ msgid ""
#~ "If the ``### Changelog entry`` section"
#~ " contains ``<examples>``, the following "
#~ "text will be added to the "
#~ "changelog::"
#~ msgstr "如果``### 更新日志条目``部分包含``<示例>``，则会在更新日志中添加以下文本：："

#~ msgid ""
#~ "If the ``### Changelog entry`` section"
#~ " contains ``<sdk>``, the following text "
#~ "will be added to the changelog::"
#~ msgstr "如果``### 更新日志条目``部分包含``<sdk>``，则会在更新日志中添加以下文本：："

#~ msgid ""
#~ "If the ``### Changelog entry`` section"
#~ " contains ``<simulations>``, the following "
#~ "text will be added to the "
#~ "changelog::"
#~ msgstr "如果 ``### Changelog entry`` 部分包含 ``<simulations>``，则会在更新日志中添加以下文本：："

#~ msgid ""
#~ "Note that only one token must be"
#~ " provided, otherwise, only the first "
#~ "action (in the order listed above), "
#~ "will be performed."
#~ msgstr "请注意，必须只提供一个标记，否则将只执行第一个操作（按上述顺序）。"

#~ msgid "Example: MXNet - Run MXNet Federated"
#~ msgstr "示例： MXNet - 运行联邦式 MXNet"

#~ msgid ""
#~ "This tutorial will show you how to"
#~ " use Flower to build a federated "
#~ "version of an existing MXNet workload."
#~ " We are using MXNet to train a"
#~ " Sequential model on the MNIST "
#~ "dataset. We will structure the example"
#~ " similar to our `PyTorch - From "
#~ "Centralized To Federated "
#~ "<https://github.com/adap/flower/blob/main/examples/pytorch-"
#~ "from-centralized-to-federated>`_ walkthrough. "
#~ "MXNet and PyTorch are very similar "
#~ "and a very good comparison between "
#~ "MXNet and PyTorch is given `here "
#~ "<https://mxnet.apache.org/versions/1.7.0/api/python/docs/tutorials"
#~ "/getting-started/to-mxnet/pytorch.html>`_. First, "
#~ "we build a centralized training approach"
#~ " based on the `Handwritten Digit "
#~ "Recognition "
#~ "<https://mxnet.apache.org/versions/1.7.0/api/python/docs/tutorials/packages/gluon/image/mnist.html>`_"
#~ " tutorial. Then, we build upon the"
#~ " centralized training code to run the"
#~ " training in a federated fashion."
#~ msgstr ""
#~ "本教程将向您展示如何使用 Flower 构建现有 MXNet 的联学习版本。我们将使用"
#~ " MXNet 在 MNIST 数据集上训练一个序列模型。另外，我们将采用与我们的 "
#~ "`PyTorch - 从集中式到联邦式 "
#~ "<https://github.com/adap/flower/blob/main/examples/pytorch-"
#~ "from-centralized-to-federated>`_ 教程类似的示例结构。MXNet"
#~ " 和 PyTorch 非常相似，参考 `此处 "
#~ "<https://mxnet.apache.org/versions/1.7.0/api/python/docs/tutorials"
#~ "/getting-started/to-mxnet/pytorch.html>`_对 MXNet "
#~ "和 PyTorch 进行了详细的比较。首先，我们根据 `手写数字识别 "
#~ "<https://mxnet.apache.org/versions/1.7.0/api/python/docs/tutorials/packages/gluon/image/mnist.html>`"
#~ " 教程 建立了集中式训练方法。然后，我们在集中式训练代码的基础上，以联邦方式运行训练。"

#~ msgid ""
#~ "Before we start setting up our "
#~ "MXNet example, we install the "
#~ ":code:`mxnet` and :code:`flwr` packages:"
#~ msgstr "在开始设置 MXNet 示例之前，我们先安装 :code:`mxnet` 和 :code:`flwr` 软件包："

#~ msgid "MNIST Training with MXNet"
#~ msgstr "使用 MXNet 进行 MNIST 训练"

#~ msgid ""
#~ "We begin with a brief description "
#~ "of the centralized training code based"
#~ " on a :code:`Sequential` model. If "
#~ "you want a more in-depth "
#~ "explanation of what's going on then "
#~ "have a look at the official `MXNet"
#~ " tutorial "
#~ "<https://mxnet.apache.org/versions/1.7.0/api/python/docs/tutorials/>`_."
#~ msgstr ""
#~ "首先，我们将简要介绍基于 :code:`Sequential` "
#~ "模型的集中式训练代码。如果您想获得更深入的解释，请参阅官方的 `MXNet教程 "
#~ "<https://mxnet.apache.org/versions/1.7.0/api/python/docs/tutorials/>`_。"

#~ msgid ""
#~ "Let's create a new file "
#~ "called:code:`mxnet_mnist.py` with all the "
#~ "components required for a traditional "
#~ "(centralized) MNIST training. First, the "
#~ "MXNet package :code:`mxnet` needs to be"
#~ " imported. You can see that we "
#~ "do not yet import the :code:`flwr` "
#~ "package for federated learning. This "
#~ "will be done later."
#~ msgstr ""
#~ "让我们创建一个名为:code:`mxnet_mnist.py`的新文件，其中包含传统（集中式）MNIST "
#~ "训练所需的所有组件。首先，需要导入 MXNet 包 "
#~ ":code:`mxnet`。您可以看到，我们尚未导入用于联合学习的 :code:`flwr` 包，这将在稍后完成。"

#~ msgid ""
#~ "The :code:`load_data()` function loads the "
#~ "MNIST training and test sets."
#~ msgstr ":code:`load_data()` 函数加载 MNIST 训练集和测试集。"

#~ msgid ""
#~ "As already mentioned, we will use "
#~ "the MNIST dataset for this machine "
#~ "learning workload. The model architecture "
#~ "(a very simple :code:`Sequential` model) "
#~ "is defined in :code:`model()`."
#~ msgstr ""
#~ "如前所述，我们将使用 MNIST 数据集进行机器学习。模型架构（一个非常简单的 "
#~ ":code:`Sequential` 模型）在 :code:`model()` 中定义。"

#~ msgid ""
#~ "We now need to define the training"
#~ " (function :code:`train()`) which loops "
#~ "over the training set and measures "
#~ "the loss for each batch of "
#~ "training examples."
#~ msgstr "现在，我们需要定义训练函数（ :code:`train()`），该函数在训练集上循环训练，并计算每批训练示例的损失值。"

#~ msgid ""
#~ "The evaluation of the model is "
#~ "defined in function :code:`test()`. The "
#~ "function loops over all test samples "
#~ "and measures the loss and accuracy "
#~ "of the model based on the test "
#~ "dataset."
#~ msgstr "模型的评估在函数 :code:`test()` 中定义。该函数循环遍历所有测试样本，并根据测试数据集计算模型的损失值和准确度。"

#~ msgid ""
#~ "Having defined the data loading, model"
#~ " architecture, training, and evaluation we"
#~ " can put everything together and "
#~ "train our model on MNIST. Note "
#~ "that the GPU/CPU device for the "
#~ "training and testing is defined within"
#~ " the :code:`ctx` (context)."
#~ msgstr ""
#~ "在定义了数据加载、模型架构、训练和评估之后，我们就可以把所有放在一起，在 MNIST "
#~ "上训练我们的模型了。请注意，用于训练和测试的 GPU/CPU 设备是在 :code:`ctx`中定义的。"

#~ msgid "You can now run your (centralized) MXNet machine learning workload:"
#~ msgstr "现在，您可以运行（集中式）MXNet 机器学习工作："

#~ msgid ""
#~ "So far this should all look fairly"
#~ " familiar if you've used MXNet (or"
#~ " even PyTorch) before. Let's take the"
#~ " next step and use what we've "
#~ "built to create a simple federated "
#~ "learning system consisting of one server"
#~ " and two clients."
#~ msgstr ""
#~ "到目前为止，如果你以前使用过 MXNet（甚至 "
#~ "PyTorch），这一切看起来应该相当熟悉。下一步，让我们利用已构建的内容创建一个简单联邦学习系统（由一个服务器和两个客户端组成）。"

#~ msgid "MXNet meets Flower"
#~ msgstr "MXNet 结合 Flower"

#~ msgid ""
#~ "So far, it was not easily possible"
#~ " to use MXNet workloads for federated"
#~ " learning because federated learning is "
#~ "not supported in MXNet. Since Flower "
#~ "is fully agnostic towards the underlying"
#~ " machine learning framework, it can "
#~ "be used to federated arbitrary machine"
#~ " learning workloads. This section will "
#~ "show you how Flower can be used"
#~ " to federate our centralized MXNet "
#~ "workload."
#~ msgstr ""
#~ "由于 MXNet 目前不支持联邦学习，因此无法轻松地直接将 MXNet "
#~ "用于联邦学习之中。Flower 与底层机器学习框架完全无关，因此它可用于任意联邦式机器学习工作。本节将向你展示如何使用 "
#~ "Flower 将我们的集中式 MXNet 改为联邦式训练。"

#~ msgid ""
#~ "The concept to federate an existing "
#~ "workload is always the same and "
#~ "easy to understand. We have to "
#~ "start a *server* and then use the"
#~ " code in :code:`mxnet_mnist.py` for the "
#~ "*clients* that are connected to the "
#~ "*server*. The *server* sends model "
#~ "parameters to the clients. The *clients*"
#~ " run the training and update the "
#~ "parameters. The updated parameters are "
#~ "sent back to the *server* which "
#~ "averages all received parameter updates. "
#~ "This describes one round of the "
#~ "federated learning process and we repeat"
#~ " this for multiple rounds."
#~ msgstr ""
#~ "将现有模型框架联邦化的概念始终是相同的，也很容易理解。我们必须启动一个*服务器*，然后对连接到*服务器*的*客户端*使用 "
#~ ":code:`mxnet_mnist.py`中的代码。*服务器*向客户端发送模型参数，然后*客户端*运行训练并更新参数。更新后的参数被发回*服务器*，然后会对所有收到的参数更新进行平均聚合。以上描述的是一轮联邦学习过程，我们将重复进行多轮学习。"

#~ msgid ""
#~ "Finally, we will define our *client* "
#~ "logic in :code:`client.py` and build "
#~ "upon the previously defined MXNet "
#~ "training in :code:`mxnet_mnist.py`. Our "
#~ "*client* needs to import :code:`flwr`, "
#~ "but also :code:`mxnet` to update the "
#~ "parameters on our MXNet model:"
#~ msgstr ""
#~ "最后，我们将在 :code:`client.py` 中定义我们的 *client* "
#~ "逻辑，并以之前在 :code:`mxnet_mnist.py` 中定义的 MXNet "
#~ "训练为基础。我们的 *client* 不仅需要导入 :code:`flwr`，还需要导入 "
#~ ":code:`mxnet`，以更新 MXNet 模型的参数："

#~ msgid ""
#~ "Implementing a Flower *client* basically "
#~ "means implementing a subclass of either"
#~ " :code:`flwr.client.Client` or "
#~ ":code:`flwr.client.NumPyClient`. Our implementation "
#~ "will be based on "
#~ ":code:`flwr.client.NumPyClient` and we'll call "
#~ "it :code:`MNISTClient`. :code:`NumPyClient` is "
#~ "slightly easier to implement than "
#~ ":code:`Client` if you use a framework"
#~ " with good NumPy interoperability (like "
#~ "PyTorch or MXNet) because it avoids "
#~ "some of the boilerplate that would "
#~ "otherwise be necessary. :code:`MNISTClient` "
#~ "needs to implement four methods, two "
#~ "methods for getting/setting model parameters,"
#~ " one method for training the model,"
#~ " and one method for testing the "
#~ "model:"
#~ msgstr ""
#~ "实现 Flower *client*基本上意味着要实现 "
#~ ":code:`flwr.client.Client` 或 "
#~ ":code:`flwr.client.NumPyClient` 的子类。我们的代码实现将基于 "
#~ ":code:`flwr.client.NumPyClient`，并将其命名为 "
#~ ":code:`MNISTClient`。如果使用具有良好 NumPy 互操作性的框架（如 PyTorch"
#~ " 或 MXNet），:code:`NumPyClient` 比 "
#~ ":code:`Client`更容易实现，因为它避免了一些不必要的操作。:code:`MNISTClient` "
#~ "需要实现四个方法，两个用于获取/设置模型参数，一个用于训练模型，一个用于测试模型："

#~ msgid "transform MXNet :code:`NDArray`'s to NumPy :code:`ndarray`'s"
#~ msgstr "将 MXNet :code:`NDArray` 转换为 NumPy :code:`ndarray`"

#~ msgid ""
#~ "The challenging part is to transform "
#~ "the MXNet parameters from :code:`NDArray` "
#~ "to :code:`NumPy Arrays` to make it "
#~ "readable for Flower."
#~ msgstr ""
#~ "具有挑战性的部分是将 MXNet 参数从 :code:`NDArray` 转换为 "
#~ ":code:`NumPy Arrays` 以便 Flower 可以读取。"

#~ msgid ""
#~ "The two :code:`NumPyClient` methods "
#~ ":code:`fit` and :code:`evaluate` make use "
#~ "of the functions :code:`train()` and "
#~ ":code:`test()` previously defined in "
#~ ":code:`mxnet_mnist.py`. So what we really "
#~ "do here is we tell Flower through"
#~ " our :code:`NumPyClient` subclass which of"
#~ " our already defined functions to "
#~ "call for training and evaluation. We "
#~ "included type annotations to give you"
#~ " a better understanding of the data"
#~ " types that get passed around."
#~ msgstr ""
#~ "这两个 :code:`NumPyClient` 方法 :code:`fit` 和 "
#~ ":code:`evaluate` 使用了之前在 :code:`mxnet_mnist.py` "
#~ "中定义的函数 :code:`train()` 和 :code:`test()`。因此，我们要做的就是通过"
#~ " :code:`NumPyClient` 子类告知 Flower "
#~ "在训练和评估时要调用哪些已定义的函数。我们加入了类型注解，以便让您更好地理解传递的数据类型。"

#~ msgid ""
#~ "Having defined data loading, model "
#~ "architecture, training, and evaluation we "
#~ "can put everything together and train"
#~ " our :code:`Sequential` model on MNIST."
#~ msgstr ""
#~ "在定义了数据加载、模型架构、训练和评估之后，我们就可以将所有内容整合在一起，在 MNIST 上训练我们的 "
#~ ":code:`Sequential` 模型。"

#~ msgid ""
#~ "in each window (make sure that the"
#~ " server is still running before you"
#~ " do so) and see your MXNet "
#~ "project run federated learning across "
#~ "two clients. Congratulations!"
#~ msgstr "确保服务器仍在运行后，然后就能在每个窗口中看到 MXNet 项目在两个客户端上运行联邦学习了。祝贺!"

#~ msgid ""
#~ "The full source code for this "
#~ "example: `MXNet: From Centralized To "
#~ "Federated (Code) "
#~ "<https://github.com/adap/flower/blob/main/examples/mxnet-"
#~ "from-centralized-to-federated>`_. Our "
#~ "example is of course somewhat over-"
#~ "simplified because both clients load the"
#~ " exact same dataset, which isn't "
#~ "realistic. You're now prepared to "
#~ "explore this topic further. How about"
#~ " using a CNN or using a "
#~ "different dataset? How about adding more"
#~ " clients?"
#~ msgstr ""
#~ "此示例的完整源代码在：\"MXNet： From Centralized To "
#~ "Federated (Code) "
#~ "<https://github.com/adap/flower/blob/main/examples/mxnet-"
#~ "from-centralized-to-"
#~ "federated>`_。当然，我们的示例有些过于简单，因为两个客户端都加载了完全相同的数据集，这并不真实。现在您已经准备好进一步探讨了。使用"
#~ " CNN 或使用不同的数据集会如何？添加更多客户端会如何？"

#~ msgid "with the following command sequence:"
#~ msgstr "使用以下命令序列："

#~ msgid ""
#~ "In case you are a researcher you"
#~ " might be just fine using the "
#~ "self-signed certificates generated using "
#~ "the scripts which are part of this"
#~ " guide."
#~ msgstr "如果你是一名研究人员，使用本指南中的脚本生成的自签名证书就可以了。"

#~ msgid ""
#~ "We are now going to show how "
#~ "to write a sever which uses the"
#~ " previously generated scripts."
#~ msgstr "现在，我们将展示如何编写一个使用先前生成的脚本的服务器。"

#~ msgid ""
#~ "When providing certificates, the server "
#~ "expects a tuple of three certificates."
#~ " :code:`Path` can be used to easily"
#~ " read the contents of those files "
#~ "into byte strings, which is the "
#~ "data type :code:`start_server` expects."
#~ msgstr ""
#~ "在提供证书时，服务器希望得到由三个证书组成的元组。 :code:`Path` "
#~ "可用于轻松地将这些文件的内容读取为字节字符串，这就是 :code:`start_server` 期望的数据类型。"

#~ msgid "Flower server"
#~ msgstr "Flower 服务器"

#~ msgid "flower-driver-api"
#~ msgstr "flower-driver-api"

#~ msgid "flower-fleet-api"
#~ msgstr "flower-fleet-api"

#~ msgid ""
#~ ":py:obj:`start_driver <flwr.server.start_driver>`\\ "
#~ "\\(\\*\\[\\, server\\_address\\, server\\, ...\\]\\)"
#~ msgstr ""
#~ ":py:obj:`start_driver <flwr.server.start_driver>`\\ "
#~ "\\(\\*\\[\\, server\\_address\\, server\\, ...\\]\\)"

#~ msgid "Start a Flower Driver API server."
#~ msgstr "启动基于 Ray 的Flower模拟服务器。"

#~ msgid ""
#~ ":py:obj:`Driver <flwr.server.Driver>`\\ "
#~ "\\(\\[driver\\_service\\_address\\, ...\\]\\)"
#~ msgstr ""
#~ "Flower 1.0: ``start_server(..., "
#~ "config=flwr.server.ServerConfig(num_rounds=3, "
#~ "round_timeout=600.0), ...)``"

#~ msgid "`Driver` class provides an interface to the Driver API."
#~ msgstr "`Driver` 类为驱动程序 API 提供了一个接口。"

#~ msgid ""
#~ "The IPv4 or IPv6 address of the"
#~ " Driver API server. Defaults to "
#~ "`\"[::]:9091\"`."
#~ msgstr "服务器的 IPv4 或 IPv6 地址。默认为 `\"[::]:8080\"。"

#~ msgid ":py:obj:`close <flwr.server.Driver.close>`\\ \\(\\)"
#~ msgstr "server.strategy.Strategy"

#~ msgid "Disconnect from the SuperLink if connected."
#~ msgstr "如果已连接，请断开与超级链接的连接。"

#~ msgid "start\\_driver"
#~ msgstr "启动客户端"

#~ msgid ""
#~ "The IPv4 or IPv6 address of the"
#~ " Driver API server. Defaults to "
#~ "`\"[::]:8080\"`."
#~ msgstr "服务器的 IPv4 或 IPv6 地址。默认为 `\"[::]:8080\"。"

#~ msgid ""
#~ "A server implementation, either "
#~ "`flwr.server.Server` or a subclass thereof."
#~ " If no instance is provided, then "
#~ "`start_driver` will create one."
#~ msgstr "服务器实现，可以是 `flwr.server.Server` 或其子类。如果没有提供实例，`start_server` 将创建一个。"

#~ msgid ""
#~ "An implementation of the class "
#~ "`flwr.server.ClientManager`. If no implementation"
#~ " is provided, then `start_driver` will "
#~ "use `flwr.server.SimpleClientManager`."
#~ msgstr ""
#~ "抽象基类 `flwr.server.ClientManager` "
#~ "的实现。如果没有提供实现，`start_server` 将使用 "
#~ "`flwr.server.client_manager.SimpleClientManager`。"

#~ msgid "The Driver object to use."
#~ msgstr "要使用的驱动程序对象。"

#~ msgid "Starting a driver that connects to an insecure server:"
#~ msgstr "启动不安全的服务器："

#~ msgid "Starting a driver that connects to an SSL-enabled server:"
#~ msgstr "启动支持 SSL 的服务器："

#~ msgid ""
#~ ":py:obj:`run_simulation_from_cli "
#~ "<flwr.simulation.run_simulation_from_cli>`\\ \\(\\)"
#~ msgstr ""

#~ msgid "Run Simulation Engine from the CLI."
#~ msgstr ""

#~ msgid "run\\_simulation\\_from\\_cli"
#~ msgstr "运行模拟"

#~ msgid ""
#~ "Check out this Federated Learning "
#~ "quickstart tutorial for using Flower "
#~ "with MXNet to train a Sequential "
#~ "model on MNIST."
#~ msgstr "查看此联邦学习 快速入门教程，了解如何使用 Flower 和 MXNet 在 MNIST 上训练序列模型。"

#~ msgid "Quickstart MXNet"
#~ msgstr "快速入门 MXNet"

#~ msgid ""
#~ "MXNet is no longer maintained and "
#~ "has been moved into `Attic "
#~ "<https://attic.apache.org/projects/mxnet.html>`_. As a "
#~ "result, we would encourage you to "
#~ "use other ML frameworks alongside "
#~ "Flower, for example, PyTorch. This "
#~ "tutorial might be removed in future "
#~ "versions of Flower."
#~ msgstr ""

#~ msgid ""
#~ "In this tutorial, we will learn "
#~ "how to train a :code:`Sequential` model"
#~ " on MNIST using Flower and MXNet."
#~ msgstr "在本教程中，我们将学习如何使用 Flower 和 MXNet 在 MNIST 上训练 :code:`Sequential` 模型。"

#~ msgid "Since we want to use MXNet, let's go ahead and install it:"
#~ msgstr "既然我们要使用 MXNet，那就继续安装吧："

#~ msgid ""
#~ "Now that we have all our "
#~ "dependencies installed, let's run a "
#~ "simple distributed training with two "
#~ "clients and one server. Our training "
#~ "procedure and network architecture are "
#~ "based on MXNet´s `Hand-written Digit "
#~ "Recognition tutorial "
#~ "<https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/image/mnist.html>`_."
#~ msgstr ""
#~ "现在，我们已经安装了所有依赖项，让我们用两个客户端和一个服务器来运行一个简单的分布式训练。我们的训练程序和网络架构基于 "
#~ "MXNet 的 `手写数字识别教程 "
#~ "<https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/image/mnist.html>`_\"。"

#~ msgid ""
#~ "In a file called :code:`client.py`, "
#~ "import Flower and MXNet related "
#~ "packages:"
#~ msgstr "在名为 :code:`client.py` 的文件中，导入 Flower 和 MXNet 相关软件包："

#~ msgid "In addition, define the device allocation in MXNet with:"
#~ msgstr "此外，还可以在 MXNet 中定义设备分配："

#~ msgid ""
#~ "We use MXNet to load MNIST, a "
#~ "popular image classification dataset of "
#~ "handwritten digits for machine learning. "
#~ "The MXNet utility :code:`mx.test_utils.get_mnist()`"
#~ " downloads the training and test "
#~ "data."
#~ msgstr ""
#~ "我们使用 MXNet 加载 MNIST，这是一个用于机器学习的流行手写数字图像分类数据集。MXNet"
#~ " 工具 :code:`mx.test_utils.get_mnist()` 会下载训练和测试数据。"

#~ msgid ""
#~ "Define the training and loss with "
#~ "MXNet. We train the model by "
#~ "looping over the dataset, measure the"
#~ " corresponding loss, and optimize it."
#~ msgstr "用 MXNet 定义训练和损失值。我们在数据集上循环训练模型，测量相应的损失值，并对其进行优化。"

#~ msgid ""
#~ "Next, we define the validation of "
#~ "our machine learning model. We loop "
#~ "over the test set and measure both"
#~ " loss and accuracy on the test "
#~ "set."
#~ msgstr "接下来，我们定义机器学习模型的验证。我们在测试集上循环，测量测试集上的损失值和准确率。"

#~ msgid ""
#~ "After defining the training and testing"
#~ " of a MXNet machine learning model,"
#~ " we use these functions to implement"
#~ " a Flower client."
#~ msgstr "在定义了 MXNet 机器学习模型的训练和测试后，我们使用这些函数实现了 Flower 客户端。"

#~ msgid "Our Flower clients will use a simple :code:`Sequential` model:"
#~ msgstr "我们的 Flower 客户端将使用简单的 :code:`Sequential` 模型："

#~ msgid ""
#~ "After loading the dataset with "
#~ ":code:`load_data()` we perform one forward "
#~ "propagation to initialize the model and"
#~ " model parameters with :code:`model(init)`. "
#~ "Next, we implement a Flower client."
#~ msgstr ""
#~ "使用 :code:`load_data()` 加载数据集后，我们会执行一次前向传播，使用 "
#~ ":code:`model(init)` 初始化模型和模型参数。接下来，我们实现一个 Flower "
#~ "客户端。"

#~ msgid ""
#~ "Flower provides a convenience class "
#~ "called :code:`NumPyClient` which makes it "
#~ "easier to implement the :code:`Client` "
#~ "interface when your workload uses MXNet."
#~ " Implementing :code:`NumPyClient` usually means"
#~ " defining the following methods "
#~ "(:code:`set_parameters` is optional though):"
#~ msgstr ""
#~ "Flower 提供了一个名为 :code:`NumPyClient` 的便捷类，当您的工作负载使用"
#~ " MXNet 时，它可以让您更轻松地实现 :code:`Client` 接口。实现 "
#~ ":code:`NumPyClient` 通常意味着定义以下方法（:code:`set_parameters` "
#~ "是可选的）："

#~ msgid "They can be implemented in the following way:"
#~ msgstr "它们可以通过以下方式实现："

#~ msgid ""
#~ "We can now create an instance of"
#~ " our class :code:`MNISTClient` and add "
#~ "one line to actually run this "
#~ "client:"
#~ msgstr "现在我们可以创建一个 :code:`MNISTClient` 类的实例，并添加一行来实际运行该客户端："

#~ msgid ""
#~ "That's it for the client. We only"
#~ " have to implement :code:`Client` or "
#~ ":code:`NumPyClient` and call "
#~ ":code:`fl.client.start_client()` or "
#~ ":code:`fl.client.start_numpy_client()`. The string "
#~ ":code:`\"0.0.0.0:8080\"` tells the client "
#~ "which server to connect to. In our"
#~ " case we can run the server and"
#~ " the client on the same machine, "
#~ "therefore we use :code:`\"0.0.0.0:8080\"`. If"
#~ " we run a truly federated workload"
#~ " with the server and clients running"
#~ " on different machines, all that "
#~ "needs to change is the "
#~ ":code:`server_address` we pass to the "
#~ "client."
#~ msgstr ""
#~ "这就是客户端。我们只需实现 :code:`Client` 或 :code:`NumPyClient`"
#~ " 并调用 :code:`fl.client.start_client()` 或 "
#~ ":code:`fl.client.start_numpy_client()`。字符串 "
#~ ":code:`\"0.0.0.0:8080\"`会告诉客户端要连接的服务器。在本例中，我们可以在同一台机器上运行服务器和客户端，因此我们使用"
#~ " "
#~ ":code:`\"0.0.0.0:8080\"`。如果我们运行的是真正的联邦工作负载，服务器和客户端运行在不同的机器上，那么需要改变的只是传递给客户端的"
#~ " :code:`server_address`。"

#~ msgid ""
#~ "With both client and server ready, "
#~ "we can now run everything and see"
#~ " federated learning in action. Federated"
#~ " learning systems usually have a "
#~ "server and multiple clients. We "
#~ "therefore have to start the server "
#~ "first:"
#~ msgstr "客户端和服务器都准备就绪后，我们现在就可以运行一切，看看联邦学习的运行情况。联邦学习系统通常有一个服务器和多个客户端。因此，我们必须先启动服务器："

#~ msgid ""
#~ "Congratulations! You've successfully built and"
#~ " run your first federated learning "
#~ "system. The full `source code "
#~ "<https://github.com/adap/flower/blob/main/examples/quickstart-"
#~ "mxnet/client.py>`_ for this example can "
#~ "be found in :code:`examples/quickstart-mxnet`."
#~ msgstr ""
#~ "恭喜您！您已经成功构建并运行了第一个联邦学习系统。本示例的`完整源代码 "
#~ "<https://github.com/adap/flower/blob/main/examples/quickstart-"
#~ "mxnet/client.py>`_ 可在 :code:`examples/quickstart-"
#~ "mxnet` 中找到。"

#~ msgid ":code:`load_mnist()`"
#~ msgstr ":code:`load_mnist()`"

#~ msgid "Loads the MNIST dataset using OpenML"
#~ msgstr "使用 OpenML 加载 MNIST 数据集"

#~ msgid ":code:`shuffle()`"
#~ msgstr ":code:`shuffle()`"

#~ msgid "Shuffles data and its label"
#~ msgstr "对数据及其标签进行洗牌"

#~ msgid ":code:`partition()`"
#~ msgstr ":code:`partition()`"

#~ msgid "Splits datasets into a number of partitions"
#~ msgstr "将数据集分割成多个分区"

#~ msgid ""
#~ "We load the MNIST dataset from "
#~ "`OpenML "
#~ "<https://www.openml.org/search?type=data&sort=runs&id=554>`_, a"
#~ " popular image classification dataset of"
#~ " handwritten digits for machine learning."
#~ " The utility :code:`utils.load_mnist()` downloads"
#~ " the training and test data. The "
#~ "training set is split afterwards into"
#~ " 10 partitions with :code:`utils.partition()`."
#~ msgstr ""
#~ "我们从 `OpenML <https://www.openml.org/d/554>`_ 中加载 "
#~ "MNIST 数据集，这是一个用于机器学习的流行手写数字图像分类数据集。实用程序 "
#~ ":code:`utils.load_mnist()` 下载训练和测试数据。然后使用 "
#~ ":code:`utils.partition()`将训练集分割成 10 个分区。"

#~ msgid "Let's get stated!"
#~ msgstr "让我们开始吧！"

#~ msgid "|2b5c62c529f6416f840c594cce062fbb|"
#~ msgstr ""

#~ msgid "|90b334680cb7467d9a04d39b8e8dca9f|"
#~ msgstr ""

#~ msgid "|65764ceee89f4335bfd93fd0b115e831|"
#~ msgstr ""

#~ msgid "|d97319ec28bb407ea0ab9705e38f3bcf|"
#~ msgstr ""

#~ msgid "|11e95ac83a8548d8b3505b4663187d07|"
#~ msgstr ""

#~ msgid "|1dab2f3a23674abc8a6731f20fa10730|"
#~ msgstr ""

#~ msgid "|7f0ee162da38450788493a21627306f7|"
#~ msgstr ""

#~ msgid "|296a1fb72c514b23b3d8905ff0ff98c6|"
#~ msgstr ""

#~ msgid "|5b1408eec0d746cdb91162a9107b6089|"
#~ msgstr ""

#~ msgid "|aef19f4b122c4e8d9f4c57f99bcd5dd2|"
#~ msgstr ""

#~ msgid "|2881a86d8fc54ba29d96b29fc2819f4a|"
#~ msgstr ""

#~ msgid "|ec1fe880237247e0975f52766775ab84|"
#~ msgstr ""

#~ msgid "|9fdf048ed58d4467b2718cdf4aaf1ec3|"
#~ msgstr ""

#~ msgid "|ff726bc5505e432388ee2fdd6ef420b9|"
#~ msgstr ""

#~ msgid ""
#~ "Currently, Flower provides two images, a"
#~ " ``base`` image and a ``superlink`` "
#~ "image. The base image, as the name"
#~ " suggests, contains basic dependencies that"
#~ " the SuperLink needs. This includes "
#~ "system dependencies, Python and Python "
#~ "tools. The SuperLink image is based "
#~ "on the base image, but it "
#~ "additionally installs the SuperLink using "
#~ "``pip``."
#~ msgstr ""
#~ "目前，Flower "
#~ "提供两个镜像，一个基础镜像和一个服务器镜像。不久还将推出客户端镜像。基础镜像，顾名思义，包含服务器和客户端都需要的基本依赖项。其中包括系统依赖项、Python"
#~ " 和 Python 工具。服务器镜像基于基础镜像，但它会使用 ``pip`` 额外安装"
#~ " Flower 服务器。"

#~ msgid "``3.11``"
#~ msgstr "``1.0.0rc1``"

#~ msgid "Defaults to ``22.04``."
#~ msgstr "默认为 ``22.04``。"

#~ msgid "Building the SuperLink image"
#~ msgstr "启动服务器"

#~ msgid "Defaults to ``flwr/base``."
#~ msgstr "默认为 ``flwr/server``。"

#~ msgid "The Python version of the base image."
#~ msgstr "基础镜像的存储库名称。"

#~ msgid "Defaults to ``py3.11``."
#~ msgstr "默认为 ``22.04``。"

#~ msgid "Defaults to ``ubuntu22.04``."
#~ msgstr "默认为 ``py3.11-ubuntu22.04``。"

#~ msgid "Defaults to ``flwr``."
#~ msgstr "默认为 ``flwr/server``。"

#~ msgid ""
#~ "The name of image is ``flwr_superlink``"
#~ " and the tag ``0.1.0``. Remember that"
#~ " the build arguments as well as "
#~ "the name and tag can be adapted"
#~ " to your needs. These values serve"
#~ " as examples only."
#~ msgstr "图像名称为 ``flwr_server``，标记为 ``0.1.0``。请记住，编译参数以及名称和标记都可以根据需要进行调整。这些值仅供参考。"

#~ msgid "Creating New Messages"
#~ msgstr "创建新信息"

#~ msgid ""
#~ "This is a simple guide for "
#~ "creating a new type of message "
#~ "between the server and clients in "
#~ "Flower."
#~ msgstr "这是一个如何用Flower在服务器和客户端之间创建新类型的信息的简要指导。"

#~ msgid ""
#~ "Let's suppose we have the following "
#~ "example functions in :code:`server.py` and "
#~ ":code:`numpy_client.py`..."
#~ msgstr "假设我们在脚本code:`server.py`和code:`numpy_client.py`中有以下的示例函数..."

#~ msgid "Server's side:"
#~ msgstr "在服务器端："

#~ msgid "Client's side:"
#~ msgstr "在客户端："

#~ msgid ""
#~ "Let's now see what we need to "
#~ "implement in order to get this "
#~ "simple function between the server and"
#~ " client to work!"
#~ msgstr "现在让我们来看看，为了让服务器和客户端之间的这个简单的函数正常工作，我们需要实现哪些功能！"

#~ msgid "Message Types for Protocol Buffers"
#~ msgstr "协议缓冲区的信息类型"

#~ msgid ""
#~ "The first thing we need to do "
#~ "is to define a message type for"
#~ " the RPC system in :code:`transport.proto`."
#~ " Note that we have to do it "
#~ "for both the request and response "
#~ "messages. For more details on the "
#~ "syntax of proto3, please see the  "
#~ "`official documentation <https://protobuf.dev"
#~ "/programming-guides/proto3/>`_."
#~ msgstr ""
#~ "我们需要做的第一件事是在脚本code:`transport.proto`中定义 RPC "
#~ "系统的消息类型。请注意，我们必须对请求信息和响应信息都这样做。有关 proto3 语法的更多详情，请参阅官方文档"
#~ " <https://developers.google.com/protocol-"
#~ "buffers/docs/proto3>`_。"

#~ msgid "Within the :code:`ServerMessage` block:"
#~ msgstr "在 :code:`ServerMessage` 代码块中："

#~ msgid "Within the ClientMessage block:"
#~ msgstr "在 ClientMessage 代码块中："

#~ msgid ""
#~ "Make sure to also add a field "
#~ "of the newly created message type "
#~ "in :code:`oneof msg`."
#~ msgstr "确保在 :code:`oneof msg` 中也添加一个新创建的消息类型字段。"

#~ msgid "Once that is done, we will compile the file with:"
#~ msgstr "完成后，我们将使用："

#~ msgid "If it compiles successfully, you should see the following message:"
#~ msgstr "如果编译成功，你应该会看到以下信息："

#~ msgid "Serialization and Deserialization Functions"
#~ msgstr "序列化和反序列化函数"

#~ msgid ""
#~ "Our next step is to add functions"
#~ " to serialize and deserialize Python "
#~ "datatypes to or from our defined "
#~ "RPC message types. You should add "
#~ "these functions in :code:`serde.py`."
#~ msgstr ""
#~ "下一步是添加函数，以便将 Python 数据类型序列化和反序列化为我们定义的 RPC "
#~ "消息类型或从我们定义的 RPC 消息类型反序列化和反序列化 Python 数据类型。您应该在"
#~ " :code:`serde.py` 中添加这些函数。"

#~ msgid "The four functions:"
#~ msgstr "四种函数："

#~ msgid "Sending the Message from the Server"
#~ msgstr "从服务器发送信息"

#~ msgid ""
#~ "Now write the request function in "
#~ "your Client Proxy class (e.g., "
#~ ":code:`grpc_client_proxy.py`) using the serde "
#~ "functions you just created:"
#~ msgstr "现在，在客户端代理类（例如 :code:`grpc_client_proxy.py`）中使用刚才创建的 serde 函数编写请求函数："

#~ msgid "Receiving the Message by the Client"
#~ msgstr "由客户端接收信息"

#~ msgid ""
#~ "Last step! Modify the code in "
#~ ":code:`message_handler.py` to check the field"
#~ " of your message and call the "
#~ ":code:`example_response` function. Remember to "
#~ "use the serde functions!"
#~ msgstr ""
#~ "最后一步 修改 :code:`message_handler.py` 中的代码，检查信息的字段并调用"
#~ " :code:`example_response` 函数。记住使用 serde 函数！"

#~ msgid "Within the handle function:"
#~ msgstr "在句柄函数内："

#~ msgid "And add a new function:"
#~ msgstr "并增加一个新函数："

#~ msgid "Hopefully, when you run your program you will get the intended result!"
#~ msgstr "希望您在运行程序时能得到预期的结果！"

#~ msgid ":py:obj:`run_driver_api <flwr.server.run_driver_api>`\\ \\(\\)"
#~ msgstr ":py:obj:`run_driver_api <flwr.server.run_driver_api>`\\ \\(\\)"

#~ msgid "Run Flower server (Driver API)."
#~ msgstr "flower-driver-api"

#~ msgid ":py:obj:`run_fleet_api <flwr.server.run_fleet_api>`\\ \\(\\)"
#~ msgstr ":py:obj:`run_fleet_api <flwr.server.run_fleet_api>`\\ \\(\\)"

#~ msgid "Run Flower server (Fleet API)."
#~ msgstr "Flower 服务器。"

#~ msgid "Unreleased"
#~ msgstr "尚未发布"

#~ msgid "|d8bf04f23d9b46d8a23cc6f4887d7873|"
#~ msgstr "|d8bf04f23d9b46d8a23cc6f4887d7873|"

#~ msgid "|5aa1711387d74d0f8b9c499e1a51627e|"
#~ msgstr "|5aa1711387d74d0f8b9c499e1a51627e|"

#~ msgid "|2bc8e069228d4873804061ff4a95048c|"
#~ msgstr "|2bc8e069228d4873804061ff4a95048c|"

#~ msgid "|c258488766324dc9a6807f0e7c4fd5f4|"
#~ msgstr "|c258488766324dc9a6807f0e7c4fd5f4|"

#~ msgid "|d5f962c3f4ec48529efda980868c14b0|"
#~ msgstr "|d5f962c3f4ec48529efda980868c14b0|"

#~ msgid "|a5eccea18d4c43a68b54b65043cabef8|"
#~ msgstr "|a5eccea18d4c43a68b54b65043cabef8|"

#~ msgid "|f17662f7df2d42f68cac70a1fdeda8a7|"
#~ msgstr "|f17662f7df2d42f68cac70a1fdeda8a7|"

#~ msgid "|241fc906441a4f038c625a19d30d01b2|"
#~ msgstr "|241fc906441a4f038c625a19d30d01b2|"

#~ msgid "|0aa5aa05810b44b6a835cecce28f3137|"
#~ msgstr "|0aa5aa05810b44b6a835cecce28f3137|"

#~ msgid "|c742940dd4bf4de09d8d0d5e8d179638|"
#~ msgstr "|c742940dd4bf4de09d8d0d5e8d179638|"

#~ msgid "|1f169ab4601a47e1a226f1628f4ebddb|"
#~ msgstr "|1f169ab4601a47e1a226f1628f4ebddb|"

#~ msgid "|12cfa9cde14440ecb8c8f6c1d7185bec|"
#~ msgstr "|12cfa9cde14440ecb8c8f6c1d7185bec|"

#~ msgid "|72939caf6e294b0986fee6dde96614d7|"
#~ msgstr "|72939caf6e294b0986fee6dde96614d7|"

#~ msgid "|83a8daee45da4a98b8d6f24ae098fc50|"
#~ msgstr "|83a8daee45da4a98b8d6f24ae098fc50|"

#~ msgid "Edge Client Engine"
#~ msgstr "边缘客户端引擎"

#~ msgid ""
#~ "`Flower <https://flower.ai>`_ core framework "
#~ "architecture with Edge Client Engine"
#~ msgstr "具有边缘客户端引擎的`Flower <https://flower.ai>`核心架构"

#~ msgid "Virtual Client Engine"
#~ msgstr "虚拟客户端引擎"

#~ msgid ""
#~ "`Flower <https://flower.ai>`_ core framework "
#~ "architecture with Virtual Client Engine"
#~ msgstr "具有虚拟客户端引擎的`Flower <https://flower.ai>`核心架构"

#~ msgid "Virtual Client Engine and Edge Client Engine in the same workload"
#~ msgstr "可同步进行的虚拟客户端引擎和边缘客户端引擎"

#~ msgid ""
#~ "`Flower <https://flower.ai>`_ core framework "
#~ "architecture with both Virtual Client "
#~ "Engine and Edge Client Engine"
#~ msgstr "具有虚拟客户端引擎和边缘客户端引擎的`Flower <https://flower.ai>`核心架构"

#~ msgid "Clone the flower repository."
#~ msgstr "**叉花仓库**"

#~ msgid ""
#~ "Please follow the first section on "
#~ ":doc:`Run Flower using Docker <how-"
#~ "to-run-flower-using-docker>` which "
#~ "covers this step in more detail."
#~ msgstr ""
#~ "请阅读 :doc:`Run Flower using Docker "
#~ "<how-to-run-flower-using-docker>` "
#~ "的第一节，其中更详细地介绍了这一步骤。"

#~ msgid "``22.04``"
#~ msgstr "``1.0.0rc1``"

#~ msgid "``23.0.1``"
#~ msgstr "``1.0.0rc1``"

#~ msgid "``69.0.2``"
#~ msgstr "``1.0.0b0``"

#~ msgid "``1.8.0``"
#~ msgstr "``1.0.0b0``"

#~ msgid "Building the SuperLink/SuperNode or ServerApp image"
#~ msgstr "启动服务器"

#~ msgid "``1.8.0-py3.10-ubuntu22.04``"
#~ msgstr ""

#~ msgid ""
#~ "The following example creates a "
#~ "SuperLink/SuperNode or ServerApp image with"
#~ " the official Flower base image:"
#~ msgstr "下面的示例使用官方的 Flower 基本镜像 py3.11-ubuntu22.04 和 Flower 1.7.0 创建了一个服务器镜像："

#~ msgid "Trigger the CI for building the Docker images."
#~ msgstr "官方 Ubuntu Docker 映像的版本。"

#~ msgid ""
#~ "To trigger the workflow, a collaborator"
#~ " must create a ``workflow_dispatch`` event"
#~ " in the GitHub CI. This can be"
#~ " done either through the UI or "
#~ "via the GitHub CLI. The event "
#~ "requires only one input, the Flower "
#~ "version, to be released."
#~ msgstr ""

#~ msgid "**Via the UI**"
#~ msgstr "**审查 PR**"

#~ msgid ""
#~ "Go to the ``Build docker images`` "
#~ "workflow `page "
#~ "<https://github.com/adap/flower/actions/workflows/docker-"
#~ "images.yml>`_."
#~ msgstr ""

#~ msgid ""
#~ "Click on the ``Run workflow`` button "
#~ "and type the new version of Flower"
#~ " in the ``Version of Flower`` input"
#~ " field."
#~ msgstr ""

#~ msgid "Click on the **green** ``Run workflow`` button."
#~ msgstr ""

#~ msgid "**Via the GitHub CI**"
#~ msgstr ""

#~ msgid ""
#~ "Make sure you are logged in via"
#~ " ``gh auth login`` and that the "
#~ "current working directory is the root"
#~ " of the Flower repository."
#~ msgstr ""

#~ msgid ""
#~ "Trigger the workflow via ``gh workflow"
#~ " run docker-images.yml -f flwr-"
#~ "version=<NEW_VERSION>``."
#~ msgstr ""

#~ msgid "Example: JAX - Run JAX Federated"
#~ msgstr "示例： JAX - 运行联邦式 JAX"

#~ msgid ""
#~ "The simplest way to get started "
#~ "with Flower is by using the "
#~ "pre-made Docker images, which you can"
#~ " find on `Docker Hub "
#~ "<https://hub.docker.com/u/flwr>`__. Supported "
#~ "architectures include ``amd64`` and "
#~ "``arm64v8``."
#~ msgstr ""
#~ "开始使用 Flower 的最简单方法是使用预制的 Docker 镜像，您可以在 "
#~ "`Docker Hub <https://hub.docker.com/r/flwr/server/tags>`_"
#~ " 上找到这些镜像。"

#~ msgid ""
#~ "If you do not see the version "
#~ "of Docker but instead get an error"
#~ " saying that the command was not "
#~ "found, you will need to install "
#~ "Docker first. You can find installation"
#~ " instruction `here <https://docs.docker.com/get-"
#~ "docker/>`_."
#~ msgstr ""
#~ "如果没有看到 Docker 的版本，而是出现找不到命令的错误，则需要先安装 Docker。你可以在"
#~ " <https://docs.docker.com/get-docker/>`_ 找到安装说明。"

#~ msgid ""
#~ "On Linux, Docker commands require "
#~ "``sudo`` privilege. If you want to "
#~ "avoid using ``sudo``, you can follow "
#~ "the `Post-installation steps "
#~ "<https://docs.docker.com/engine/install/linux-postinstall/>`_"
#~ " on the official Docker website."
#~ msgstr ""
#~ "在 Linux 上，Docker 命令需要 ``sudo`` "
#~ "权限。如果你想避免使用 ``sudo``，可以按照 Docker 官方网站上的 `安装后步骤"
#~ " <https://docs.docker.com/engine/install/linux-"
#~ "postinstall/>`_进行操作。"

#~ msgid ""
#~ "To ensure optimal performance and "
#~ "compatibility, the SuperLink, SuperNode and"
#~ " ServerApp image must have the same"
#~ " version when running together. This "
#~ "guarantees seamless integration and avoids "
#~ "potential conflicts or issues that may"
#~ " arise from using different versions."
#~ msgstr ""
#~ "为确保最佳性能和兼容性，SuperLink、SuperNode 和 ServerApp "
#~ "映像在一起运行时必须具有相同的版本。这可确保无缝集成，并避免因使用不同版本而可能产生的潜在冲突或问题。"

#~ msgid "Flower SuperLink"
#~ msgstr "flower-superlink"

#~ msgid "Quickstart"
#~ msgstr "快速入门 JAX"

#~ msgid "If you're looking to try out Flower, you can use the following command:"
#~ msgstr "如果您想试用 Flower，可以使用以下命令："

#~ msgid ""
#~ "The command pulls the Docker image "
#~ "with the tag ``1.8.0`` from Docker "
#~ "Hub. The tag specifies the Flower "
#~ "version. In this case, Flower 1.8.0. "
#~ "The ``--rm`` flag tells Docker to "
#~ "remove the container after it exits."
#~ msgstr ""
#~ "该命令将从 Docker Hub 提取标签为``1.7.0-py3.11-ubuntu22.04``的"
#~ " Docker 镜像。标签包含使用 Flower、Python 和 Ubuntu"
#~ " 的信息。在本例中，它使用了 Flower 1.7.0、Python 3.11 和"
#~ " Ubuntu 22.04。rm \"标记告诉 Docker 在退出后移除容器。"

#~ msgid ""
#~ "The ``-p <host>:<container>`` flag tells "
#~ "Docker to map the ports "
#~ "``9091``/``9092`` of the host to "
#~ "``9091``/``9092`` of the container, allowing"
#~ " you to access the Driver API "
#~ "on ``http://localhost:9091`` and the Fleet "
#~ "API on ``http://localhost:9092``. Lastly, any"
#~ " flag that comes after the tag "
#~ "is passed to the Flower SuperLink. "
#~ "Here, we are passing the flag "
#~ "``--insecure``."
#~ msgstr ""
#~ "``-p <host>:<container>`` 标记会告诉 Docker 将主机的端口"
#~ " ``9091``/``9092`` 映射到容器的端口 ``9091``/`9092``，这样你就可以在"
#~ " ``http://localhost:9091`` 上访问 Driver API，在 "
#~ "``http://localhost:9092`` 上访问 Fleet "
#~ "API。最后，标签后面的任何标志都会传递给 Flower 服务器。在这里，我们传递的标志是 "
#~ "``--insecure`` 。"

#~ msgid ""
#~ "The ``--insecure`` flag enables insecure "
#~ "communication (using HTTP, not HTTPS) "
#~ "and should only be used for "
#~ "testing purposes. We strongly recommend "
#~ "enabling `SSL <https://flower.ai/docs/framework/how-"
#~ "to-run-flower-using-docker.html#enabling-"
#~ "ssl-for-secure-connections>`__ when "
#~ "deploying to a production environment."
#~ msgstr ""
#~ "不安全 \"标志启用不安全通信（使用 HTTP，而非 "
#~ "HTTPS），只能用于测试目的。我们强烈建议在部署到生产环境时启用 `SSL "
#~ "<https://flower.ai/docs/framework/how-to-run-"
#~ "flower-using-docker.html#enabling-ssl-for-"
#~ "secure-connections>`_。"

#~ msgid ""
#~ "You can use ``--help`` to view all"
#~ " available flags that the SuperLink "
#~ "supports:"
#~ msgstr "您可以使用 ``--help`` 查看服务器支持的所有可用标记："

#~ msgid "Mounting a volume to store the state on the host system"
#~ msgstr "在主机系统上挂载卷以存储状态"

#~ msgid ""
#~ "If you want to persist the state"
#~ " of the SuperLink on your host "
#~ "system, all you need to do is "
#~ "specify a directory where you want "
#~ "to save the file on your host "
#~ "system and a name for the database"
#~ " file. By default, the SuperLink "
#~ "container runs with a non-root "
#~ "user called ``app`` with the user "
#~ "ID ``49999``. It is recommended to "
#~ "create new directory and change the "
#~ "user ID of the directory to "
#~ "``49999`` to ensure the mounted "
#~ "directory has the proper permissions. If"
#~ " you later want to delete the "
#~ "directory, you can change the user "
#~ "ID back to the current user ID "
#~ "by running ``sudo chown -R $USER:$(id"
#~ " -gn) state``."
#~ msgstr ""

#~ msgid ""
#~ "Assuming all files we need are in"
#~ " the local ``certificates`` directory, we"
#~ " can use the flag ``--volume`` to "
#~ "mount the local directory into the "
#~ "``/app/certificates/`` directory of the "
#~ "container. This allows the SuperLink to"
#~ " access the files within the "
#~ "container. The ``ro`` stands for "
#~ "``read-only``. Docker volumes default to"
#~ " ``read-write``; that option tells "
#~ "Docker to make the volume ``read-"
#~ "only`` instead. Finally, we pass the "
#~ "names of the certificates and key "
#~ "file to the SuperLink with the "
#~ "``--ssl-ca-certfile``, ``--ssl-certfile`` "
#~ "and ``--ssl-keyfile`` flag."
#~ msgstr ""
#~ "假设我们需要的所有文件都在本地的 ``certificates`` 目录中，我们可以使用标记 "
#~ "``-v`` 将本地目录挂载到容器的 ``/app/`` "
#~ "目录中。这样，服务器就可以访问容器内的文件。最后，我们使用 ``--certificates`` "
#~ "标志将证书名称传递给服务器。"

#~ msgid ""
#~ "Because Flower containers, by default, "
#~ "run with a non-root user ``app``,"
#~ " the mounted files and directories "
#~ "must have the proper permissions for "
#~ "the user ID ``49999``. For example, "
#~ "to change the user ID of all "
#~ "files in the ``certificates/`` directory, "
#~ "you can run ``sudo chown -R "
#~ "49999:49999 certificates/*``."
#~ msgstr ""

#~ msgid ""
#~ "The SuperNode Docker image comes with"
#~ " a pre-installed version of Flower"
#~ " and serves as a base for "
#~ "building your own SuperNode image."
#~ msgstr "超级节点 Docker 镜像预装了 Flower 版本，可作为构建自己的超级节点镜像的基础。"

#~ msgid ""
#~ "We will use the ``quickstart-pytorch``"
#~ " example, which you can find in "
#~ "the Flower repository, to illustrate how"
#~ " you can dockerize your ClientApp."
#~ msgstr ""
#~ "我们将使用 \"quickstart-pytorch\"（快速启动-pytorch）示例来说明如何对 "
#~ "ClientApp 进行 docker 化。"

#~ msgid ""
#~ "Before we can start, we need to"
#~ " meet a few prerequisites in our "
#~ "local development environment. You can "
#~ "skip the first part if you want"
#~ " to run your ClientApp instead of "
#~ "the ``quickstart-pytorch`` example."
#~ msgstr "在开始之前，我们需要在本地开发环境中满足一些先决条件。"

#~ msgid "Let's assume the following project layout:"
#~ msgstr "假设项目布局如下"

#~ msgid ""
#~ "First, we need to create a "
#~ "``requirements.txt`` file in the directory "
#~ "where the ``ClientApp`` code is located."
#~ " In the file, we list all the"
#~ " dependencies that the ClientApp requires."
#~ msgstr ""
#~ "首先，我们需要在 ``ClientApp`` 代码所在的目录中创建一个 "
#~ "``requirements.txt`` 文件。在该文件中，我们列出了 ClientApp "
#~ "需要的所有依赖项。"

#~ msgid ""
#~ "Note that `flwr <https://pypi.org/project/flwr/>`__"
#~ " is already installed in the "
#~ "``flwr/supernode`` base image, so you "
#~ "only need to include other package "
#~ "dependencies in your ``requirements.txt``, "
#~ "such as ``torch``, ``tensorflow``, etc."
#~ msgstr ""
#~ "请注意，`flwr <https://pypi.org/project/flwr/>`__ "
#~ "已经安装在`flwr/supernode``基础镜像中，因此只需在`requirements.txt``中包含其他依赖包，如`torch``、`tensorflow`等。"

#~ msgid ""
#~ "Next, we create a Dockerfile. If "
#~ "you use the ``quickstart-pytorch`` "
#~ "example, create a new file called "
#~ "``Dockerfile.supernode`` in ``examples/quickstart-"
#~ "pytorch``."
#~ msgstr ""
#~ "接下来，我们创建一个 Dockerfile。如果使用 ``quickstart-pytorch``"
#~ " 示例，请在 ``examples/quickstart-pytorch`` 中创建一个名为"
#~ " ``Dockerfile.supernode`` 的新文件。"

#~ msgid ""
#~ "The ``Dockerfile.supernode`` contains the "
#~ "instructions that assemble the SuperNode "
#~ "image."
#~ msgstr "Dockerfile.supernode \"包含组装超级节点映像的指令。"

#~ msgid ""
#~ "In the first two lines, we "
#~ "instruct Docker to use the SuperNode "
#~ "image tagged ``nightly`` as a base "
#~ "image and set our working directory "
#~ "to ``/app``. The following instructions "
#~ "will now be executed in the "
#~ "``/app`` directory. Next, we install the"
#~ " ClientApp dependencies by copying the "
#~ "``requirements.txt`` file into the image "
#~ "and run ``pip install``. In the "
#~ "last two lines, we copy the "
#~ "``client.py`` module into the image and"
#~ " set the entry point to ``flower-"
#~ "client-app`` with the argument "
#~ "``client:app``. The argument is the "
#~ "object reference of the ClientApp "
#~ "(``<module>:<attribute>``) that will be run"
#~ " inside the ClientApp."
#~ msgstr ""
#~ "在前两行中，我们指示 Docker 使用标记为 ``nightly`` 的 "
#~ "SuperNode 镜像作为基础镜像，并将工作目录设置为 ``/app``。下面的指令将在 "
#~ "``/app`` 目录中执行。接下来，我们通过将 ``requirements.txt`` "
#~ "文件复制到映像中并运行 ``pip install`` 来安装 ClientApp "
#~ "依赖项。最后两行，我们将 ``client.py`` 模块复制到映像中，并将入口点设置为 "
#~ "``flower-client-app``，参数为 ``client:app``。参数是将在 "
#~ "ClientApp 内运行的 ClientApp 的对象引用（``<模块>:<属性>``）。"

#~ msgid "Building the SuperNode Docker image"
#~ msgstr "启动服务器"

#~ msgid ""
#~ "We gave the image the name "
#~ "``flwr_supernode``, and the tag ``0.0.1``. "
#~ "Remember that the here chosen values "
#~ "only serve as an example. You can"
#~ " change them to your needs."
#~ msgstr ""
#~ "我们将图像命名为 ``flwr_supernode``，标签为 "
#~ "``0.0.1``。请记住，这里选择的值只是一个示例。您可以根据自己的需要进行更改。"

#~ msgid "Running the SuperNode Docker image"
#~ msgstr "启动服务器"

#~ msgid "Now that we have built the SuperNode image, we can finally run it."
#~ msgstr "现在，我们已经构建了超级节点镜像，终于可以运行它了。"

#~ msgid "Let's break down each part of this command:"
#~ msgstr "让我们来分析一下这条命令的各个部分："

#~ msgid ""
#~ "``--rm``: This option specifies that the"
#~ " container should be automatically removed"
#~ " when it stops."
#~ msgstr "`-rm``： 该选项指定容器停止时应自动移除。"

#~ msgid "``--insecure``: This option enables insecure communication."
#~ msgstr "不安全\"： 该选项启用不安全通信。"

#~ msgid ""
#~ "``--superlink 192.168.1.100:9092``: This option "
#~ "specifies the address of the SuperLinks"
#~ " Fleet"
#~ msgstr "``--server 192.168.1.100:9092``: 该选项指定超级链接舰队的地址"

#~ msgid "API to connect to. Remember to update it with your SuperLink IP."
#~ msgstr "要连接的 API。记住用您的超级链接 IP 更新它。"

#~ msgid ""
#~ "To test running Flower locally, you "
#~ "can create a `bridge network "
#~ "<https://docs.docker.com/network/network-tutorial-"
#~ "standalone/#use-user-defined-bridge-"
#~ "networks>`__, use the ``--network`` argument"
#~ " and pass the name of the "
#~ "Docker network to run your SuperNodes."
#~ msgstr ""
#~ "要测试在本地运行 Flower，可以创建一个 \"桥接网络 "
#~ "<https://docs.docker.com/network/network-tutorial-"
#~ "standalone/#use-user-defined-bridge-"
#~ "networks>`__\"，使用\"--网络 \"参数并传递 Docker "
#~ "网络的名称，以运行超级节点。"

#~ msgid ""
#~ "Any argument that comes after the "
#~ "tag is passed to the Flower "
#~ "SuperNode binary. To see all available"
#~ " flags that the SuperNode supports, "
#~ "run:"
#~ msgstr "标记后的任何参数都将传递给 Flower 超级节点二进制文件。要查看超级节点支持的所有可用标记，请运行"

#~ msgid ""
#~ "To enable SSL, we will need to "
#~ "mount a PEM-encoded root certificate "
#~ "into your SuperNode container."
#~ msgstr "要启用 SSL，我们需要将 PEM 编码的根证书挂载到 SuperNode 容器中。"

#~ msgid ""
#~ "Similar to the SuperNode image, the "
#~ "ServerApp Docker image comes with a "
#~ "pre-installed version of Flower and "
#~ "serves as a base for building your"
#~ " own ServerApp image."
#~ msgstr ""
#~ "与 SuperNode 映像类似，ServerApp Docker 映像也预装了 "
#~ "Flower 版本，可作为构建自己的 ServerApp 映像的基础。"

#~ msgid ""
#~ "We will use the same ``quickstart-"
#~ "pytorch`` example as we do in the"
#~ " Flower SuperNode section. If you "
#~ "have not already done so, please "
#~ "follow the `SuperNode Prerequisites`_ before"
#~ " proceeding."
#~ msgstr ""
#~ "我们将使用与 \"Flower SuperNode \"部分相同的 "
#~ "\"quickstart-pytorch \"示例。如果您还没有这样做，请在继续之前遵循 "
#~ "\"SuperNode 先决条件\"。"

#~ msgid "Creating a ServerApp Dockerfile"
#~ msgstr "创建 ServerApp Dockerfile"

#~ msgid ""
#~ "First, we need to create a "
#~ "Dockerfile in the directory where the"
#~ " ``ServerApp`` code is located. If "
#~ "you use the ``quickstart-pytorch`` "
#~ "example, create a new file called "
#~ "``Dockerfile.serverapp`` in ``examples/quickstart-"
#~ "pytorch``."
#~ msgstr ""
#~ "首先，我们需要在 ``ServerApp`` 代码所在的目录中创建一个 Dockerfile。如果使用"
#~ " ``quickstart-pytorch`` 示例，请在 ``examples"
#~ "/quickstart-pytorch`` 中创建一个名为 ``Dockerfile.serverapp``"
#~ " 的新文件。"

#~ msgid ""
#~ "The ``Dockerfile.serverapp`` contains the "
#~ "instructions that assemble the ServerApp "
#~ "image."
#~ msgstr "Dockerfile.serverapp \"包含组装 ServerApp 镜像的说明。"

#~ msgid ""
#~ "In the first two lines, we "
#~ "instruct Docker to use the ServerApp "
#~ "image tagged ``1.8.0`` as a base "
#~ "image and set our working directory "
#~ "to ``/app``. The following instructions "
#~ "will now be executed in the "
#~ "``/app`` directory. In the last two "
#~ "lines, we copy the ``server.py`` module"
#~ " into the image and set the "
#~ "entry point to ``flower-server-app`` "
#~ "with the argument ``server:app``. The "
#~ "argument is the object reference of "
#~ "the ServerApp (``<module>:<attribute>``) that "
#~ "will be run inside the ServerApp "
#~ "container."
#~ msgstr ""
#~ "在前两行中，我们指示 Docker 使用标记为 ``1.8.0`` 的 "
#~ "ServerApp 镜像作为基础镜像，并将工作目录设置为 ``/app``。下面的指令将在 "
#~ "``/app`` 目录中执行。在最后两行中，我们将 ``server.py`` "
#~ "模块复制到映像中，并将入口点设置为 ``flower-server-app``，参数为 "
#~ "``server:app``。参数是将在 ServerApp 容器内运行的 ServerApp "
#~ "的对象引用（``<模块>:<属性>``）。"

#~ msgid "Building the ServerApp Docker image"
#~ msgstr "启动服务器"

#~ msgid "Running the ServerApp Docker image"
#~ msgstr "启动服务器"

#~ msgid "Now that we have built the ServerApp image, we can finally run it."
#~ msgstr "现在我们已经构建了 ServerApp 镜像，终于可以运行它了。"

#~ msgid ""
#~ "``--superlink 192.168.1.100:9091``: This option "
#~ "specifies the address of the SuperLinks"
#~ " Driver"
#~ msgstr "``--server 192.168.1.100:9091``: 此选项指定超级链接驱动程序的地址"

#~ msgid ""
#~ "To test running Flower locally, you "
#~ "can create a `bridge network "
#~ "<https://docs.docker.com/network/network-tutorial-"
#~ "standalone/#use-user-defined-bridge-"
#~ "networks>`__, use the ``--network`` argument"
#~ " and pass the name of the "
#~ "Docker network to run your ServerApps."
#~ msgstr ""
#~ "要测试在本地运行 Flower，可以创建一个 ``bridge network "
#~ "<https://docs.docker.com/network/network-tutorial-"
#~ "standalone/#use-user-defined-bridge-"
#~ "networks>`___，使用 ``--network`` 参数并传递 Docker "
#~ "网络的名称，以运行 ServerApps。"

#~ msgid ""
#~ "Any argument that comes after the "
#~ "tag is passed to the Flower "
#~ "ServerApp binary. To see all available"
#~ " flags that the ServerApp supports, "
#~ "run:"
#~ msgstr "标记后的任何参数都将传递给 Flower ServerApp 二进制文件。要查看 ServerApp 支持的所有可用标记，请运行"

#~ msgid ""
#~ "To enable SSL, we will need to "
#~ "mount a PEM-encoded root certificate "
#~ "into your ServerApp container."
#~ msgstr "要启用 SSL，需要 CA 证书、服务器证书和服务器私钥。"

#~ msgid ""
#~ "Assuming the certificate already exists "
#~ "locally, we can use the flag "
#~ "``--volume`` to mount the local "
#~ "certificate into the container's ``/app/`` "
#~ "directory. This allows the ServerApp to"
#~ " access the certificate within the "
#~ "container. Use the ``--root-certificates`` "
#~ "flags when starting the container."
#~ msgstr ""
#~ "假设我们需要的所有文件都在本地的 ``certificates`` 目录中，我们可以使用标记 "
#~ "``-v`` 将本地目录挂载到容器的 ``/app/`` "
#~ "目录中。这样，服务器就可以访问容器内的文件。最后，我们使用 ``--certificates`` "
#~ "标志将证书名称传递给服务器。"

#~ msgid "Run with root user privileges"
#~ msgstr ""

#~ msgid ""
#~ "Flower Docker images, by default, run"
#~ " with a non-root user "
#~ "(username/groupname: ``app``, UID/GID: ``49999``)."
#~ " Using root user is not recommended"
#~ " unless it is necessary for specific"
#~ " tasks during the build process. "
#~ "Always make sure to run the "
#~ "container as a non-root user in"
#~ " production to maintain security best "
#~ "practices."
#~ msgstr ""

#~ msgid "**Run a container with root user privileges**"
#~ msgstr ""

#~ msgid "**Run the build process with root user privileges**"
#~ msgstr ""

#~ msgid ":py:obj:`run_client_app <flwr.client.run_client_app>`\\ \\(\\)"
#~ msgstr ":py:obj:`run_client_app <flwr.client.run_client_app>`\\ \\(\\)"

#~ msgid ":py:obj:`run_supernode <flwr.client.run_supernode>`\\ \\(\\)"
#~ msgstr ":py:obj:`run_superlink <flwr.server.run_superlink>`\\ \\(\\)"

#~ msgid "d defaults to None."
#~ msgstr "d 默认为 \"无\"。"

#~ msgid "Update R from dict/iterable E and F."
#~ msgstr "根据二进制/可迭代 E 和 F 更新 R。"

#~ msgid ""
#~ ":py:obj:`RUN_DRIVER_API_ENTER "
#~ "<flwr.common.EventType.RUN_DRIVER_API_ENTER>`\\"
#~ msgstr ""
#~ ":py:obj:`RUN_DRIVER_API_ENTER "
#~ "<flwr.common.EventType.RUN_DRIVER_API_ENTER>`\\"

#~ msgid ""
#~ ":py:obj:`RUN_DRIVER_API_LEAVE "
#~ "<flwr.common.EventType.RUN_DRIVER_API_LEAVE>`\\"
#~ msgstr ""
#~ ":py:obj:`RUN_DRIVER_API_LEAVE "
#~ "<flwr.common.EventType.RUN_DRIVER_API_LEAVE>`\\"

#~ msgid ""
#~ ":py:obj:`RUN_FLEET_API_ENTER "
#~ "<flwr.common.EventType.RUN_FLEET_API_ENTER>`\\"
#~ msgstr ""
#~ ":py:obj:`RUN_FLEET_API_ENTER "
#~ "<flwr.common.EventType.RUN_FLEET_API_ENTER>`\\"

#~ msgid ""
#~ ":py:obj:`RUN_FLEET_API_LEAVE "
#~ "<flwr.common.EventType.RUN_FLEET_API_LEAVE>`\\"
#~ msgstr ""
#~ ":py:obj:`RUN_FLEET_API_LEAVE "
#~ "<flwr.common.EventType.RUN_FLEET_API_LEAVE>`\\"

#~ msgid ":py:obj:`DRIVER_CONNECT <flwr.common.EventType.DRIVER_CONNECT>`\\"
#~ msgstr ":py:obj:`DRIVER_CONNECT <flwr.common.EventType.DRIVER_CONNECT>`\\"

#~ msgid ":py:obj:`DRIVER_DISCONNECT <flwr.common.EventType.DRIVER_DISCONNECT>`\\"
#~ msgstr ":py:obj:`DRIVER_DISCONNECT <flwr.common.EventType.DRIVER_DISCONNECT>`\\"

#~ msgid ""
#~ ":py:obj:`START_DRIVER_ENTER "
#~ "<flwr.common.EventType.START_DRIVER_ENTER>`\\"
#~ msgstr ""
#~ ":py:obj:`START_DRIVER_ENTER "
#~ "<flwr.common.EventType.START_DRIVER_ENTER>`\\"

#~ msgid ""
#~ ":py:obj:`START_DRIVER_LEAVE "
#~ "<flwr.common.EventType.START_DRIVER_LEAVE>`\\"
#~ msgstr ""
#~ ":py:obj:`START_DRIVER_LEAVE "
#~ "<flwr.common.EventType.START_DRIVER_LEAVE>`\\"

#~ msgid ""
#~ "An identifier that can be used "
#~ "when loading a particular data partition"
#~ " for a ClientApp. Making use of "
#~ "this identifier is more relevant when"
#~ " conducting simulations."
#~ msgstr "为 ClientApp 加载特定数据分区时可使用的标识符。在进行模拟时，使用该标识符更有意义。"

#~ msgid ":py:obj:`partition_id <flwr.common.Metadata.partition_id>`\\"
#~ msgstr ":py:obj:`partition_id <flwr.common.Metadata.partition_id>`\\"

#~ msgid "An identifier telling which data partition a ClientApp should use."
#~ msgstr "告诉 ClientApp 应使用哪个数据分区的标识符。"

#~ msgid ":py:obj:`run_superlink <flwr.server.run_superlink>`\\ \\(\\)"
#~ msgstr ":py:obj:`run_superlink <flwr.server.run_superlink>`\\ \\(\\)"

#~ msgid "Run Flower SuperLink (Driver API and Fleet API)."
#~ msgstr "运行 Flower 服务器（Driver API 和 Fleet API）。"

#~ msgid "run\\_driver\\_api"
#~ msgstr "flower-driver-api"

#~ msgid "run\\_fleet\\_api"
#~ msgstr "run\\_fleet\\_api"

#~ msgid ""
#~ "The protocol involves four main stages:"
#~ " - 'setup': Send SecAgg+ configuration "
#~ "to clients and collect their public "
#~ "keys. - 'share keys': Broadcast public"
#~ " keys among clients and collect "
#~ "encrypted secret"
#~ msgstr ""
#~ "协议包括四个主要阶段： - 设置\"： 向客户端发送 SecAgg+ "
#~ "配置并收集其公钥。- 共享密钥\"： 在客户端之间广播公钥，并收集加密密钥。"

#~ msgid "key shares."
#~ msgstr "关键股份。"

#~ msgid ""
#~ "The protocol involves four main stages:"
#~ " - 'setup': Send SecAgg configuration "
#~ "to clients and collect their public "
#~ "keys. - 'share keys': Broadcast public"
#~ " keys among clients and collect "
#~ "encrypted secret"
#~ msgstr ""
#~ "协议包括四个主要阶段： - 设置\"： 向客户端发送 SecAgg "
#~ "配置并收集它们的公钥。- 共享密钥\"： 在客户端之间广播公钥并收集加密密钥。"

#~ msgid ""
#~ "'A dictionary, e.g {\"<keyA>\": <value>, "
#~ "\"<keyB>\": <value>} to configure a "
#~ "backend. Values supported in <value> are"
#~ " those included by "
#~ "`flwr.common.typing.ConfigsRecordValues`."
#~ msgstr ""
#~ "字典，例如 {\"<keyA>\"： <value>, \"<keyB>\"： "
#~ "<value>} 来配置后端。<value> 中支持的值是 "
#~ "`flwr.common.typing.ConfigsRecordValues`中包含的值。"

#~ msgid ""
#~ "The total number of clients in "
#~ "this simulation. This must be set "
#~ "if `clients_ids` is not set and "
#~ "vice-versa."
#~ msgstr "本次模拟的客户总数。如果未设置 `clients_ids`，则必须设置该参数，反之亦然。"

#~ msgid ""
#~ "In this tutorial we will learn how"
#~ " to train a Convolutional Neural "
#~ "Network on CIFAR10 using Flower and "
#~ "PyTorch."
#~ msgstr "在本教程中，我们将学习如何使用 Flower 和 PyTorch 在 CIFAR10 上训练卷积神经网络。"

#~ msgid ""
#~ "*Clients* are responsible for generating "
#~ "individual weight-updates for the model"
#~ " based on their local datasets. These"
#~ " updates are then sent to the "
#~ "*server* which will aggregate them to"
#~ " produce a better model. Finally, the"
#~ " *server* sends this improved version "
#~ "of the model back to each "
#~ "*client*. A complete cycle of weight "
#~ "updates is called a *round*."
#~ msgstr "*客户端*负责在其本地数据集上更新模型参数。然后，这些参数会被发送到*服务器*，由*服务器*聚合后生成一个更好的模型。最后，*服务器*将改进后的模型发送回每个*客户端*。一个完整的模型参数更新周期称为一*轮*。"

#~ msgid ""
#~ "Now that we have a rough idea "
#~ "of what is going on, let's get "
#~ "started. We first need to install "
#~ "Flower. You can do this by running"
#~ " :"
#~ msgstr "现在，我们已经有了一个大致的概念了，那就让我们开始吧。首先，我们需要安装 Flower。可以通过运行 ："

#~ msgid ""
#~ "Since we want to use PyTorch to"
#~ " solve a computer vision task, let's"
#~ " go ahead and install PyTorch and "
#~ "the **torchvision** library:"
#~ msgstr "既然我们想用 PyTorch 解决计算机视觉任务，那就继续安装 PyTorch 和 **torchvision** 库吧："

#~ msgid ""
#~ "Now that we have all our "
#~ "dependencies installed, let's run a "
#~ "simple distributed training with two "
#~ "clients and one server. Our training "
#~ "procedure and network architecture are "
#~ "based on PyTorch's `Deep Learning with"
#~ " PyTorch "
#~ "<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_."
#~ msgstr ""
#~ "现在我们已经安装了所有的依赖项，让我们用两个客户端和一个服务器来运行一个简单的分布式训练。我们的训练过程和网络架构基于 "
#~ "PyTorch 的《Deep Learning with PyTorch "
#~ "<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_》。"

#~ msgid ""
#~ "In a file called :code:`client.py`, "
#~ "import Flower and PyTorch related "
#~ "packages:"
#~ msgstr "在名为 :code:`client.py` 的文件中，导入 Flower 和 PyTorch 相关软件包："

#~ msgid "In addition, we define the device allocation in PyTorch with:"
#~ msgstr "此外，我们还在 PyTorch 中定义了设备分配："

#~ msgid ""
#~ "We use PyTorch to load CIFAR10, a"
#~ " popular colored image classification "
#~ "dataset for machine learning. The "
#~ "PyTorch :code:`DataLoader()` downloads the "
#~ "training and test data that are "
#~ "then normalized."
#~ msgstr ""
#~ "我们使用 PyTorch 来加载 "
#~ "CIFAR10，这是一个用于机器学习的流行彩色图像分类数据集。PyTorch "
#~ ":code:`DataLoader()`下载训练数据和测试数据，然后进行归一化处理。"

#~ msgid ""
#~ "Define the loss and optimizer with "
#~ "PyTorch. The training of the dataset "
#~ "is done by looping over the "
#~ "dataset, measure the corresponding loss "
#~ "and optimize it."
#~ msgstr "使用 PyTorch 定义损失和优化器。数据集的训练是通过循环数据集、测量相应的损失值并对其进行优化来完成的。"

#~ msgid ""
#~ "Define then the validation of the  "
#~ "machine learning network. We loop over"
#~ " the test set and measure the "
#~ "loss and accuracy of the test set."
#~ msgstr "然后定义机器学习网络的验证。我们在测试集上循环，计算测试集的损失值和准确率。"

#~ msgid ""
#~ "After defining the training and testing"
#~ " of a PyTorch machine learning model,"
#~ " we use the functions for the "
#~ "Flower clients."
#~ msgstr "在定义了 PyTorch 机器学习模型的训练和测试之后，我们将这些功能用于 Flower 客户端。"

#~ msgid ""
#~ "The Flower clients will use a "
#~ "simple CNN adapted from 'PyTorch: A "
#~ "60 Minute Blitz':"
#~ msgstr "Flower 客户端将使用一个简单的从“PyTorch： 60 分钟突击\"改编的CNN："

#~ msgid ""
#~ "After loading the data set with "
#~ ":code:`load_data()` we define the Flower "
#~ "interface."
#~ msgstr "使用 :code:`load_data()` 加载数据集后，我们定义了 Flower 接口。"

#~ msgid ""
#~ "Flower provides a convenience class "
#~ "called :code:`NumPyClient` which makes it "
#~ "easier to implement the :code:`Client` "
#~ "interface when your workload uses "
#~ "PyTorch. Implementing :code:`NumPyClient` usually"
#~ " means defining the following methods "
#~ "(:code:`set_parameters` is optional though):"
#~ msgstr ""
#~ "Flower 提供了一个名为 :code:`NumPyClient` 的便捷类，当您的工作负载使用"
#~ " PyTorch 时，它使 :code:`Client` 接口的实现变得更容易。实现 "
#~ ":code:`NumPyClient` 通常意味着定义以下方法（:code:`set_parameters` "
#~ "是可选的）："

#~ msgid "which can be implemented in the following way:"
#~ msgstr "可以通过以下方式实现："

#~ msgid ""
#~ "Congratulations! You've successfully built and"
#~ " run your first federated learning "
#~ "system. The full `source code "
#~ "<https://github.com/adap/flower/blob/main/examples/quickstart-"
#~ "pytorch/client.py>`_ for this example can "
#~ "be found in :code:`examples/quickstart-"
#~ "pytorch`."
#~ msgstr ""
#~ "恭喜您！您已经成功构建并运行了第一个联邦学习系统。本示例的`完整源代码 "
#~ "<https://github.com/adap/flower/blob/main/examples/quickstart-"
#~ "pytorch/client.py>`_ 可以在 :code:`examples/quickstart-"
#~ "pytorch` 中找到。"

#~ msgid ""
#~ "The :code:`self.bst` is used to keep "
#~ "the Booster objects that remain "
#~ "consistent across rounds, allowing them "
#~ "to store predictions from trees "
#~ "integrated in earlier rounds and "
#~ "maintain other essential data structures "
#~ "for training."
#~ msgstr ""
#~ "代码:`self.bst`用于保存在各轮中保持一致的 Booster "
#~ "对象，使其能够存储在前几轮中集成的树的预测结果，并维护其他用于训练的重要数据结构。"

#~ msgid "Implementing a Flower client"
#~ msgstr "实现 Flower 客户端"

#~ msgid ""
#~ "To implement the Flower client, we "
#~ "create a subclass of "
#~ "``flwr.client.NumPyClient`` and implement the "
#~ "three methods ``get_parameters``, ``fit``, and"
#~ " ``evaluate``:"
#~ msgstr ""
#~ "为实现 Flower 客户端，我们创建了 ``flwr.client.NumPyClient`` "
#~ "的子类，并实现了 ``get_parameters``、``fit`` 和``evaluate`` "
#~ "三个方法："

#~ msgid ""
#~ "The function ``start_simulation`` accepts a"
#~ " number of arguments, amongst them "
#~ "the ``client_fn`` used to create "
#~ "``FlowerClient`` instances, the number of "
#~ "clients to simulate (``num_clients``), the "
#~ "number of federated learning rounds "
#~ "(``num_rounds``), and the strategy. The "
#~ "strategy encapsulates the federated learning"
#~ " approach/algorithm, for example, *Federated "
#~ "Averaging* (FedAvg)."
#~ msgstr ""
#~ "函数 ``start_simulation`` 接受许多参数，其中包括用于创建 "
#~ "``FlowerClient`` 实例的 "
#~ "``client_fn``、要模拟的客户端数量（``num_clients``）、联邦学习轮数（``num_rounds``）和策略。策略封装了联邦学习方法/算法，例如*联邦平均*"
#~ " (FedAvg)。"

#~ msgid ""
#~ "The only thing left to do is "
#~ "to tell the strategy to call this"
#~ " function whenever it receives evaluation"
#~ " metric dictionaries from the clients:"
#~ msgstr "剩下要做的就是告诉策略，每当它从客户端接收到评估度量字典时，都要调用这个函数："

#~ msgid "|93b02017c78049bbbd5ae456dcb2c91b|"
#~ msgstr ""

#~ msgid "|01471150fd5144c080a176b43e92a3ff|"
#~ msgstr ""

#~ msgid "|9bc21c7dbd17444a8f070c60786e3484|"
#~ msgstr ""

#~ msgid "|3047bbce54b34099ae559963d0420d79|"
#~ msgstr ""

#~ msgid "|e9f8ce948593444fb838d2f354c7ec5d|"
#~ msgstr ""

#~ msgid "|c24c1478b30e4f74839208628a842d1e|"
#~ msgstr ""

#~ msgid "|1b3613d7a58847b59e1d3180802dbc09|"
#~ msgstr ""

#~ msgid "|9980b5213db547d0b8024a50992b9e3f|"
#~ msgstr ""

#~ msgid "|c7afb4c92d154bfaa5e8cb9a150e17f1|"
#~ msgstr ""

#~ msgid "|032eb6fed6924ac387b9f13854919196|"
#~ msgstr ""

#~ msgid "|fbf225add7fd4df5a9bf25a95597d954|"
#~ msgstr ""

#~ msgid "|7efbe3d29d8349b89594e8947e910525|"
#~ msgstr ""

#~ msgid "|329fb3c04c744eda83bb51fa444c2266|"
#~ msgstr ""

#~ msgid "|c00bf2750bc24d229737a0fe1395f0fc|"
#~ msgstr ""

#~ msgid "run\\_client\\_app"
#~ msgstr "run\\_client\\_app"

#~ msgid "run\\_supernode"
#~ msgstr "flower-superlink"

#~ msgid "Retrieve the corresponding layout by the string key."
#~ msgstr ""

#~ msgid ""
#~ "When there isn't an exact match, "
#~ "all the existing keys in the "
#~ "layout map will be treated as a"
#~ " regex and map against the input "
#~ "key again. The first match will be"
#~ " returned, based on the key insertion"
#~ " order. Return None if there isn't"
#~ " any match found."
#~ msgstr ""

#~ msgid "the string key as the query for the layout."
#~ msgstr ""

#~ msgid "Corresponding layout based on the query."
#~ msgstr ""

#~ msgid "run\\_server\\_app"
#~ msgstr "run\\_server\\_app"

#~ msgid "run\\_superlink"
#~ msgstr "flower-superlink"

#~ msgid "Start a Ray-based Flower simulation server."
#~ msgstr "启动基于 Ray 的Flower模拟服务器。"

#~ msgid ""
#~ "A function creating `Client` instances. "
#~ "The function must have the signature "
#~ "`client_fn(context: Context). It should return"
#~ " a single client instance of type "
#~ "`Client`. Note that the created client"
#~ " instances are ephemeral and will "
#~ "often be destroyed after a single "
#~ "method invocation. Since client instances "
#~ "are not long-lived, they should "
#~ "not attempt to carry state over "
#~ "method invocations. Any state required "
#~ "by the instance (model, dataset, "
#~ "hyperparameters, ...) should be (re-)created"
#~ " in either the call to `client_fn`"
#~ " or the call to any of the "
#~ "client methods (e.g., load evaluation "
#~ "data in the `evaluate` method itself)."
#~ msgstr ""
#~ "创建客户端实例的函数。该函数必须接受一个名为 `cid` 的 `str` 参数。它应返回一个"
#~ " Client "
#~ "类型的客户端实例。请注意，创建的客户端实例是短暂的，通常在调用一个方法后就会被销毁。由于客户机实例不是长期存在的，它们不应试图在方法调用时携带状态数据。实例所需的任何状态数据（模型、数据集、超参数......）都应在调用"
#~ " `client_fn` 或任何客户端方法（例如，在 `evaluate` "
#~ "方法中加载评估数据）时（重新）创建。"

#~ msgid "The total number of clients in this simulation."
#~ msgstr "需要等待的客户数量。"

#~ msgid ""
#~ "UNSUPPORTED, WILL BE REMOVED. USE "
#~ "`num_clients` INSTEAD. List `client_id`s for"
#~ " each client. This is only required"
#~ " if `num_clients` is not set. Setting"
#~ " both `num_clients` and `clients_ids` with"
#~ " `len(clients_ids)` not equal to "
#~ "`num_clients` generates an error. Using "
#~ "this argument will raise an error."
#~ msgstr ""
#~ "列出每个客户的 `client_id`。只有在未设置 `num_clients` "
#~ "时才需要这样做。同时设置`num_clients`和`clients_ids`，且`len(clients_ids)`不等于`num_clients`，会产生错误。"

#~ msgid ""
#~ "CPU and GPU resources for a single"
#~ " client. Supported keys are `num_cpus` "
#~ "and `num_gpus`. To understand the GPU"
#~ " utilization caused by `num_gpus`, as "
#~ "well as using custom resources, please"
#~ " consult the Ray documentation."
#~ msgstr ""
#~ "\"num_gpus\"： 0.0` 单个客户端的 CPU 和 GPU "
#~ "资源。支持的键值为 `num_cpus` 和 `num_gpus`。要了解 "
#~ "`num_gpus` 所导致的 GPU 利用率，以及使用自定义资源的情况，请查阅 Ray"
#~ " 文档。"

#~ msgid ""
#~ "An implementation of the abstract base"
#~ " class `flwr.server.Server`. If no instance"
#~ " is provided, then `start_server` will "
#~ "create one."
#~ msgstr "抽象基类 `flwr.server.Server`的实现。如果没有提供实例，`start_server` 将创建一个。"

#~ msgid ""
#~ "An implementation of the abstract base"
#~ " class `flwr.server.Strategy`. If no "
#~ "strategy is provided, then `start_server` "
#~ "will use `flwr.server.strategy.FedAvg`."
#~ msgstr ""
#~ "抽象基类 `flwr.server.strategy` 的实现。如果没有提供策略，`start_server`"
#~ " 将使用 `flwr.server.strategy.FedAvg`。"

#~ msgid ""
#~ "An implementation of the abstract base"
#~ " class `flwr.server.ClientManager`. If no "
#~ "implementation is provided, then "
#~ "`start_simulation` will use "
#~ "`flwr.server.client_manager.SimpleClientManager`."
#~ msgstr ""
#~ "抽象基类 `flwr.server.ClientManager` "
#~ "的实现。如果没有提供实现，`start_simulation` 将使用 "
#~ "`flwr.server.client_manager.SimpleClientManager`。"

#~ msgid ""
#~ "Optional dictionary containing arguments for"
#~ " the call to `ray.init`. If "
#~ "ray_init_args is None (the default), Ray"
#~ " will be initialized with the "
#~ "following default args:  { "
#~ "\"ignore_reinit_error\": True, \"include_dashboard\": "
#~ "False }  An empty dictionary can "
#~ "be used (ray_init_args={}) to prevent "
#~ "any arguments from being passed to "
#~ "ray.init."
#~ msgstr ""
#~ "可选字典，包含调用 `ray.init` 时的参数。如果 ray_init_args 为"
#~ " None（默认值），则将使用以下默认参数初始化 Ray： { "
#~ "\"ignore_reinit_error\"： True, \"include_dashboard\"： "
#~ "False }  可以使用空字典（ray_init_args={}）来防止向 ray.init "
#~ "传递任何参数。"

#~ msgid ""
#~ "Optional dictionary containing arguments for"
#~ " the call to `ray.init`. If "
#~ "ray_init_args is None (the default), Ray"
#~ " will be initialized with the "
#~ "following default args:"
#~ msgstr ""
#~ "可选字典，包含调用 `ray.init` 时的参数。如果 ray_init_args 为"
#~ " None（默认值），则将使用以下默认参数初始化 Ray："

#~ msgid "{ \"ignore_reinit_error\": True, \"include_dashboard\": False }"
#~ msgstr "{ \"ignore_reinit_error\"： True, \"include_dashboard\"： False }"

#~ msgid ""
#~ "An empty dictionary can be used "
#~ "(ray_init_args={}) to prevent any arguments"
#~ " from being passed to ray.init."
#~ msgstr "可以使用空字典 (ray_init_args={}) 来防止向 ray.init 传递任何参数。"

#~ msgid ""
#~ "Set to True to prevent `ray.shutdown()`"
#~ " in case `ray.is_initialized()=True`."
#~ msgstr "设为 True 可在 `ray.is_initialized()=True` 情况下阻止 `ray.shutdown()` 。"

#~ msgid ""
#~ "Optionally specify the type of actor "
#~ "to use. The actor object, which "
#~ "persists throughout the simulation, will "
#~ "be the process in charge of "
#~ "executing a ClientApp wrapping input "
#~ "argument `client_fn`."
#~ msgstr "可选择指定要使用的actor类型。actor对象将在整个模拟过程中持续存在，它将是负责运行客户端作业（即其 `fit()`方法）的进程。"

#~ msgid ""
#~ "If you want to create your own "
#~ "Actor classes, you might need to "
#~ "pass some input argument. You can "
#~ "use this dictionary for such purpose."
#~ msgstr "如果您想创建自己的 Actor 类，可能需要传递一些输入参数。为此，您可以使用本字典。"

#~ msgid ""
#~ "(default: \"DEFAULT\") Optional string "
#~ "(\"DEFAULT\" or \"SPREAD\") for the VCE"
#~ " to choose in which node the "
#~ "actor is placed. If you are an "
#~ "advanced user needed more control you"
#~ " can use lower-level scheduling "
#~ "strategies to pin actors to specific "
#~ "compute nodes (e.g. via "
#~ "NodeAffinitySchedulingStrategy). Please note this"
#~ " is an advanced feature. For all "
#~ "details, please refer to the Ray "
#~ "documentation: https://docs.ray.io/en/latest/ray-"
#~ "core/scheduling/index.html"
#~ msgstr ""
#~ "(默认：\"DEFAULT\"）可选字符串（\"DEFAULT \"或 \"SPREAD\"），供 "
#~ "VCE "
#~ "选择将行为体放置在哪个节点上。如果你是需要更多控制权的高级用户，可以使用低级调度策略将actor固定到特定计算节点（例如，通过 "
#~ "NodeAffinitySchedulingStrategy）。请注意，这是一项高级功能。有关详细信息，请参阅 Ray "
#~ "文档：https://docs.ray.io/en/latest/ray-core/scheduling/index.html"

#~ msgid "**hist** -- Object containing metrics from training."
#~ msgstr "**hist** -- 包含训练指标的对象。"

#~ msgid ""
#~ "Check out this Federated Learning "
#~ "quickstart tutorial for using Flower "
#~ "with FastAI to train a vision "
#~ "model on CIFAR-10."
#~ msgstr "查看此联邦学习快速入门教程，了解如何使用 Flower 和 FastAI 在 CIFAR-10 上训练视觉模型。"

#~ msgid "Let's build a federated learning system using fastai and Flower!"
#~ msgstr "让我们用 fastai 和 Flower 建立一个联邦学习系统！"

#~ msgid ""
#~ "Please refer to the `full code "
#~ "example <https://github.com/adap/flower/tree/main/examples"
#~ "/quickstart-fastai>`_ to learn more."
#~ msgstr ""
#~ "请参阅 `完整代码示例 "
#~ "<https://github.com/adap/flower/tree/main/examples/quickstart-"
#~ "fastai>`_了解更多信息。"

#~ msgid ""
#~ "Let's build a federated learning system"
#~ " using Hugging Face Transformers and "
#~ "Flower!"
#~ msgstr "让我们用Hugging Face Transformers和Flower来构建一个联邦学习系统！"

#~ msgid "Dependencies"
#~ msgstr "依赖关系"

#~ msgid ""
#~ "To follow along this tutorial you "
#~ "will need to install the following "
#~ "packages: :code:`datasets`, :code:`evaluate`, "
#~ ":code:`flwr`, :code:`torch`, and "
#~ ":code:`transformers`. This can be done "
#~ "using :code:`pip`:"
#~ msgstr ""
#~ "要学习本教程，您需要安装以下软件包： :code:`datasets`、 :code:`evaluate`、 "
#~ ":code:`flwr`、 :code:`torch`和 :code:`transformers`。这可以通过"
#~ " :code:`pip` 来完成："

#~ msgid "Standard Hugging Face workflow"
#~ msgstr "标准Hugging Face工作流程"

#~ msgid "Handling the data"
#~ msgstr "处理数据"

#~ msgid ""
#~ "To fetch the IMDB dataset, we will"
#~ " use Hugging Face's :code:`datasets` "
#~ "library. We then need to tokenize "
#~ "the data and create :code:`PyTorch` "
#~ "dataloaders, this is all done in "
#~ "the :code:`load_data` function:"
#~ msgstr ""
#~ "为了获取 IMDB 数据集，我们将使用 Hugging Face 的 "
#~ ":code:`datasets` 库。然后，我们需要对数据进行标记化，并创建 :code:`PyTorch` "
#~ "数据加载器，这些都将在 :code:`load_data` 函数中完成："

#~ msgid "Training and testing the model"
#~ msgstr "训练和测试模型"

#~ msgid ""
#~ "Once we have a way of creating "
#~ "our trainloader and testloader, we can"
#~ " take care of the training and "
#~ "testing. This is very similar to "
#~ "any :code:`PyTorch` training or testing "
#~ "loop:"
#~ msgstr ""
#~ "有了创建 trainloader 和 testloader "
#~ "的方法后，我们就可以进行训练和测试了。这与任何 :code:`PyTorch` 训练或测试循环都非常相似："

#~ msgid "Creating the model itself"
#~ msgstr "创建模型本身"

#~ msgid ""
#~ "To create the model itself, we "
#~ "will just load the pre-trained "
#~ "distillBERT model using Hugging Face’s "
#~ ":code:`AutoModelForSequenceClassification` :"
#~ msgstr ""
#~ "要创建模型本身，我们只需使用 Hugging Face 的 "
#~ ":code:`AutoModelForSequenceClassification` 加载预训练的 "
#~ "distillBERT 模型："

#~ msgid "Creating the IMDBClient"
#~ msgstr "创建 IMDBClient"

#~ msgid ""
#~ "To federate our example to multiple "
#~ "clients, we first need to write "
#~ "our Flower client class (inheriting from"
#~ " :code:`flwr.client.NumPyClient`). This is very"
#~ " easy, as our model is a "
#~ "standard :code:`PyTorch` model:"
#~ msgstr ""
#~ "要将我们的示例联邦到多个客户端，我们首先需要编写 Flower 客户端类（继承自 "
#~ ":code:`flwr.client.NumPyClient`）。这很容易，因为我们的模型是一个标准的 "
#~ ":code:`PyTorch` 模型："

#~ msgid ""
#~ "The :code:`get_parameters` function lets the"
#~ " server get the client's parameters. "
#~ "Inversely, the :code:`set_parameters` function "
#~ "allows the server to send its "
#~ "parameters to the client. Finally, the"
#~ " :code:`fit` function trains the model "
#~ "locally for the client, and the "
#~ ":code:`evaluate` function tests the model "
#~ "locally and returns the relevant "
#~ "metrics."
#~ msgstr ""
#~ ":code:`get_parameters` "
#~ "函数允许服务器获取客户端的参数。相反，:code:`set_parameters`函数允许服务器将其参数发送给客户端。最后，:code:`fit`函数在本地为客户端训练模型，:code:`evaluate`函数在本地测试模型并返回相关指标。"

#~ msgid "Starting the server"
#~ msgstr "启动服务器"

#~ msgid ""
#~ "Now that we have a way to "
#~ "instantiate clients, we need to create"
#~ " our server in order to aggregate "
#~ "the results. Using Flower, this can "
#~ "be done very easily by first "
#~ "choosing a strategy (here, we are "
#~ "using :code:`FedAvg`, which will define "
#~ "the global weights as the average "
#~ "of all the clients' weights at "
#~ "each round) and then using the "
#~ ":code:`flwr.server.start_server` function:"
#~ msgstr ""
#~ "现在我们有了实例化客户端的方法，我们需要创建服务器，以便汇总结果。使用 Flower，首先选择一个策略（这里我们使用 "
#~ ":code:`FedAvg`，它将把全局模型参数定义为每轮所有客户端模型参数的平均值），然后使用 "
#~ ":code:`flwr.server.start_server`函数，就可以非常轻松地完成这项工作："

#~ msgid ""
#~ "The :code:`weighted_average` function is there"
#~ " to provide a way to aggregate "
#~ "the metrics distributed amongst the "
#~ "clients (basically this allows us to "
#~ "display a nice average accuracy and "
#~ "loss for every round)."
#~ msgstr ""
#~ "使用 :code:`weighted_average` "
#~ "函数是为了提供一种方法来汇总分布在客户端的指标（基本上，这可以让我们显示每一轮的平均精度和损失值）。"

#~ msgid "Putting everything together"
#~ msgstr "把所有东西放在一起"

#~ msgid "We can now start client instances using:"
#~ msgstr "现在我们可以使用："

#~ msgid ""
#~ "And they will be able to connect"
#~ " to the server and start the "
#~ "federated training."
#~ msgstr "他们就能连接到服务器，开始联邦训练。"

#~ msgid ""
#~ "If you want to check out "
#~ "everything put together, you should "
#~ "check out the `full code example "
#~ "<https://github.com/adap/flower/tree/main/examples/quickstart-"
#~ "huggingface>`_ ."
#~ msgstr ""
#~ "如果您想查看所有内容，请查看完整的代码示例： "
#~ "[https://github.com/adap/flower/tree/main/examples/quickstart-"
#~ "huggingface](https://github.com/adap/flower/tree/main/examples"
#~ "/quickstart-huggingface)."

#~ msgid ""
#~ "Of course, this is a very basic"
#~ " example, and a lot can be "
#~ "added or modified, it was just to"
#~ " showcase how simply we could "
#~ "federate a Hugging Face workflow using"
#~ " Flower."
#~ msgstr ""
#~ "当然，这只是一个非常基本的示例，还可以添加或修改很多内容，只是为了展示我们可以如何简单地使用 Flower "
#~ "联合Hugging Face的工作流程。"

#~ msgid ""
#~ "Note that in this example we used"
#~ " :code:`PyTorch`, but we could have "
#~ "very well used :code:`TensorFlow`."
#~ msgstr "请注意，在本例中我们使用了 :code:`PyTorch`，但也完全可以使用 :code:`TensorFlow`。"

#~ msgid ""
#~ "Check out this Federated Learning "
#~ "quickstart tutorial for using Flower "
#~ "with PyTorch Lightning to train an "
#~ "Auto Encoder model on MNIST."
#~ msgstr "查看此联邦学习快速入门教程，了解如何使用 Flower 和 PyTorch Lightning 在 MNIST 上训练自动编码器模型。"

#~ msgid ""
#~ "Let's build a horizontal federated "
#~ "learning system using PyTorch Lightning "
#~ "and Flower!"
#~ msgstr "让我们使用 PyTorch Lightning 和 Flower 构建一个水平联邦学习系统！"

#~ msgid ""
#~ "Please refer to the `full code "
#~ "example <https://github.com/adap/flower/tree/main/examples"
#~ "/quickstart-pytorch-lightning>`_ to learn "
#~ "more."
#~ msgstr ""
#~ "请参阅 `完整代码示例 "
#~ "<https://github.com/adap/flower/tree/main/examples/quickstart-"
#~ "pytorch-lightning>`_ 了解更多信息。"

#~ msgid "Let's build a federated learning system in less than 20 lines of code!"
#~ msgstr "让我们用不到 20 行代码构建一个联邦学习系统！"

#~ msgid "Before Flower can be imported we have to install it:"
#~ msgstr "在导入 Flower 之前，我们必须先安装它："

#~ msgid ""
#~ "Since we want to use the Keras "
#~ "API of TensorFlow (TF), we have to"
#~ " install TF as well:"
#~ msgstr "由于我们要使用 TensorFlow (TF) 的 Keras API，因此还必须安装 TF："

#~ msgid "Next, in a file called :code:`client.py`, import Flower and TensorFlow:"
#~ msgstr "接下来，在名为 :code:`client.py` 的文件中导入 Flower 和 TensorFlow："

#~ msgid ""
#~ "We use the Keras utilities of TF"
#~ " to load CIFAR10, a popular colored"
#~ " image classification dataset for machine"
#~ " learning. The call to "
#~ ":code:`tf.keras.datasets.cifar10.load_data()` downloads "
#~ "CIFAR10, caches it locally, and then "
#~ "returns the entire training and test "
#~ "set as NumPy ndarrays."
#~ msgstr ""
#~ "我们使用 TF 的 Keras 实用程序加载 "
#~ "CIFAR10，这是一个用于机器学习的流行彩色图像分类数据集。调用 "
#~ ":code:`tf.keras.datasets.cifar10.load_data()` 会下载 "
#~ "CIFAR10，将其缓存到本地，然后以 NumPy ndarrays 的形式返回整个训练集和测试集。"

#~ msgid ""
#~ "Next, we need a model. For the "
#~ "purpose of this tutorial, we use "
#~ "MobilNetV2 with 10 output classes:"
#~ msgstr "接下来，我们需要一个模型。在本教程中，我们使用带有 10 个输出类的 MobilNetV2："

#~ msgid ""
#~ "The Flower server interacts with clients"
#~ " through an interface called "
#~ ":code:`Client`. When the server selects "
#~ "a particular client for training, it "
#~ "sends training instructions over the "
#~ "network. The client receives those "
#~ "instructions and calls one of the "
#~ ":code:`Client` methods to run your code"
#~ " (i.e., to train the neural network"
#~ " we defined earlier)."
#~ msgstr ""
#~ "Flower 服务器通过一个名为 :code:`Client` "
#~ "的接口与客户端交互。当服务器选择一个特定的客户端进行训练时，它会通过网络发送训练指令。客户端接收到这些指令后，会调用 "
#~ ":code:`Client` 方法之一来运行您的代码（即训练我们之前定义的神经网络）。"

#~ msgid ""
#~ "Flower provides a convenience class "
#~ "called :code:`NumPyClient` which makes it "
#~ "easier to implement the :code:`Client` "
#~ "interface when your workload uses Keras."
#~ " The :code:`NumPyClient` interface defines "
#~ "three methods which can be implemented"
#~ " in the following way:"
#~ msgstr ""
#~ "Flower 提供了一个名为 :code:`NumPyClient` 的便捷类，当您的工作负载使用"
#~ " Keras 时，该类可以更轻松地实现 :code:`Client` "
#~ "接口。:code:`NumPyClient` 接口定义了三个方法，可以通过以下方式实现："

#~ msgid ""
#~ "We can now create an instance of"
#~ " our class :code:`CifarClient` and add "
#~ "one line to actually run this "
#~ "client:"
#~ msgstr "现在我们可以创建一个 :code:`CifarClient` 类的实例，并添加一行来实际运行该客户端："

#~ msgid ""
#~ "That's it for the client. We only"
#~ " have to implement :code:`Client` or "
#~ ":code:`NumPyClient` and call "
#~ ":code:`fl.client.start_client()`. If you implement"
#~ " a client of type :code:`NumPyClient` "
#~ "you'll need to first call its "
#~ ":code:`to_client()` method. The string "
#~ ":code:`\"[::]:8080\"` tells the client which"
#~ " server to connect to. In our "
#~ "case we can run the server and "
#~ "the client on the same machine, "
#~ "therefore we use :code:`\"[::]:8080\"`. If "
#~ "we run a truly federated workload "
#~ "with the server and clients running "
#~ "on different machines, all that needs"
#~ " to change is the :code:`server_address`"
#~ " we point the client at."
#~ msgstr ""
#~ "这就是客户端。我们只需实现 :code:`Client` 或 :code:`NumPyClient`"
#~ " 并调用 :code:`fl.client.start_client()` 或 "
#~ ":code:`fl.client.start_numpy_client()`。字符串 "
#~ ":code:`\"[::]:8080\"`会告诉客户端要连接的服务器。在本例中，我们可以在同一台机器上运行服务器和客户端，因此使用 "
#~ ":code:`\"[::]:8080\"。如果我们运行的是真正的联邦工作负载，服务器和客户端运行在不同的机器上，那么需要改变的只是客户端指向的"
#~ " :code:`server_address`。"

#~ msgid "Each client will have its own dataset."
#~ msgstr "每个客户都有自己的数据集。"

#~ msgid ""
#~ "You should now see how the "
#~ "training does in the very first "
#~ "terminal (the one that started the "
#~ "server):"
#~ msgstr "现在你应该能在第一个终端（启动服务器的终端）看到训练的效果了："

#~ msgid ""
#~ "Congratulations! You've successfully built and"
#~ " run your first federated learning "
#~ "system. The full `source code "
#~ "<https://github.com/adap/flower/blob/main/examples/quickstart-"
#~ "tensorflow/client.py>`_ for this can be "
#~ "found in :code:`examples/quickstart-"
#~ "tensorflow/client.py`."
#~ msgstr ""
#~ "恭喜您！您已经成功构建并运行了第一个联邦学习系统。`完整的源代码 "
#~ "<https://github.com/adap/flower/blob/main/examples/quickstart-"
#~ "tensorflow/client.py>`_ 可以在 :code:`examples/quickstart-"
#~ "tensorflow/client.py` 中找到。"

#~ msgid "|e5918c1c06a4434bbe4bf49235e40059|"
#~ msgstr ""

#~ msgid "|c0165741bd1944f09ec55ce49032377d|"
#~ msgstr ""

#~ msgid "|0a0ac9427ac7487b8e52d75ed514f04e|"
#~ msgstr ""

#~ msgid "|5defee3ea4ca40d99fcd3e4ea045be25|"
#~ msgstr ""

#~ msgid "|74f26ca701254d3db57d7899bd91eb55|"
#~ msgstr ""

#~ msgid "|bda79f21f8154258a40e5766b2634ad7|"
#~ msgstr ""

#~ msgid "|89d30862e62e4f9989e193483a08680a|"
#~ msgstr ""

#~ msgid "|77e9918671c54b4f86e01369c0785ce8|"
#~ msgstr ""

#~ msgid "|7e4ccef37cc94148a067107b34eb7447|"
#~ msgstr ""

#~ msgid "|28e47e4cded14479a0846c8e5f22c872|"
#~ msgstr ""

#~ msgid "|4b8c5d1afa144294b76ffc76e4658a38|"
#~ msgstr ""

#~ msgid "|9dbdb3a0f6cb4a129fac863eaa414c17|"
#~ msgstr ""

#~ msgid "|81749d0ac0834c36a83bd38f433fea31|"
#~ msgstr ""

#~ msgid "|ed9aae51da70428eab7eef32f21e819e|"
#~ msgstr ""

#~ msgid "|e87b69b2ada74ea49412df16f4a0b9cc|"
#~ msgstr ""

#~ msgid "|33cacb7d985c4906b348515c1a5cd993|"
#~ msgstr ""

#~ msgid "|cc080a555947492fa66131dc3a967603|"
#~ msgstr ""

#~ msgid "|085c3e0fb8664c6aa06246636524b20b|"
#~ msgstr ""

#~ msgid "|bfe69c74e48c45d49b50251c38c2a019|"
#~ msgstr ""

#~ msgid "|ebbecd651f0348d99c6511ea859bf4ca|"
#~ msgstr ""

#~ msgid "|163117eb654a4273babba413cf8065f5|"
#~ msgstr ""

#~ msgid "|452ac3ba453b4cd1be27be1ba7560d64|"
#~ msgstr ""

#~ msgid "|f403fcd69e4e44409627e748b404c086|"
#~ msgstr ""

#~ msgid "|4b00fe63870145968f8443619a792a42|"
#~ msgstr ""

#~ msgid "|368378731066486fa4397e89bc6b870c|"
#~ msgstr ""

#~ msgid "|a66aa83d85bf4ffba7ed660b718066da|"
#~ msgstr ""

#~ msgid "|82324b9af72a4582a81839d55caab767|"
#~ msgstr ""

#~ msgid "|fbf2da0da3cc4f8ab3b3eff852d80c41|"
#~ msgstr ""

#~ msgid ""
#~ "Some quickstart examples may have "
#~ "limitations or requirements that prevent "
#~ "them from running on every environment."
#~ " For more information, please see "
#~ "`Limitations`_."
#~ msgstr ""

#~ msgid ""
#~ "Change the application code. For "
#~ "example, change the  ``seed`` in "
#~ "``quickstart_docker/task.py`` to ``43`` and "
#~ "save it:"
#~ msgstr ""

#~ msgid ":code:`fit`"
#~ msgstr ":code:`fit`"

#~ msgid ""
#~ "Note that since version :code:`1.11.0`, "
#~ ":code:`flower-server-app` no longer "
#~ "supports passing a reference to a "
#~ "`ServerApp` attribute. Instead, you need "
#~ "to pass the path to Flower app "
#~ "via the argument :code:`--app`. This is"
#~ " the path to a directory containing"
#~ " a `pyproject.toml`. You can create a"
#~ " valid Flower app by executing "
#~ ":code:`flwr new` and following the "
#~ "prompt."
#~ msgstr ""

#~ msgid ""
#~ "All required parameters defined above "
#~ "are passed to :code:`XgbClient`'s constructor."
#~ msgstr ""

#~ msgid "|b8714c45b74b4d8fb008e2ebb3bc1d44|"
#~ msgstr ""

#~ msgid "|75f1561efcfd422ea67d28d1513120dc|"
#~ msgstr ""

#~ msgid "|6a1f51b235304558a9bdaaabfc93b8d2|"
#~ msgstr ""

#~ msgid "|35e70dab1fb544af9aa3a9c09c4f9797|"
#~ msgstr ""

#~ msgid "|d7efb5705dd3467f991ed23746824a07|"
#~ msgstr ""

#~ msgid "|94e7b021c7b540bfbedf7f082a41ff87|"
#~ msgstr ""

#~ msgid "|a80714782dde439ab73936518f91fc3c|"
#~ msgstr ""

#~ msgid "|c62080ca6197473da57d191c8225a9d9|"
#~ msgstr ""

#~ msgid "|21a8f1e6a5b14a7bbb8559979d0e8a2b|"
#~ msgstr ""

#~ msgid "|c310f2a22f7b4917bf42775aae7a1c09|"
#~ msgstr ""

#~ msgid "|a0c5b43401194535a8460bcf02e65f9a|"
#~ msgstr ""

#~ msgid "|aabfdbd5564e41a790f8ea93cc21a444|"
#~ msgstr ""

#~ msgid "|c9cc8f160fa647b09e742fe4dc8edb54|"
#~ msgstr ""

#~ msgid "|7e83aad011cd4907b2f02f907c6922e9|"
#~ msgstr ""

#~ msgid "|4627c2bb6cc443ae9e079f81f33c9dd9|"
#~ msgstr ""

#~ msgid "|131af8322dc5466b827afd24be98f8c0|"
#~ msgstr ""

#~ msgid "|f92920b87f3a40179bf7ddd0b6144c53|"
#~ msgstr ""

#~ msgid "|d62da263071d45a496f543e41fce3a19|"
#~ msgstr ""

#~ msgid "|ad851971645b4e1fbf8d15bcc0b2ee11|"
#~ msgstr ""

#~ msgid "|929e9a6de6b34edb8488e644e2bb5221|"
#~ msgstr ""

#~ msgid "|404cf9c9e8d64784a55646c0f9479cbc|"
#~ msgstr ""

#~ msgid "|b021ff9d25814458b1e631f8985a648b|"
#~ msgstr ""

#~ msgid "|e6ca84e1df244f238288a768352678e5|"
#~ msgstr ""

#~ msgid "|39c2422082554a21963baffb33a0d057|"
#~ msgstr ""

#~ msgid "|07ecf5fcd6814e88906accec6fa0fbfb|"
#~ msgstr ""

#~ msgid "|57e78c0ca8a94ba5a64a04b1f2280e55|"
#~ msgstr ""

#~ msgid "|9819b40e59ee40a4921e1244e8c99bac|"
#~ msgstr ""

#~ msgid "|797bf279c4894b5ead31dc9b0534ed62|"
#~ msgstr ""

#~ msgid "|3a7aceef05f0421794726ac54aaf12fd|"
#~ msgstr ""

#~ msgid "|d741075f8e624331b42c0746f7d258a0|"
#~ msgstr ""

#~ msgid "|8fc92d668bcb42b8bda55143847f2329|"
#~ msgstr ""

#~ msgid "|1c705d833a024f22adcaeb8ae3d13b0b|"
#~ msgstr ""

#~ msgid "|77a037b546a84262b608e04bc82a2c96|"
#~ msgstr ""

#~ msgid "|f568e24c9fb0435690ac628210a4be96|"
#~ msgstr ""

#~ msgid "|a7bf029981514e2593aa3a2b48c9d76a|"
#~ msgstr ""

#~ msgid "|3f645ad807f84be8b1f8f3267173939c|"
#~ msgstr ""

#~ msgid "|a06a9dbd603f45819afd8e8cfc3c4b8f|"
#~ msgstr ""

#~ msgid "|edcf9a04d96e42608fd01a333375febe|"
#~ msgstr ""

#~ msgid "|3dae22fe797043968e2b7aa7073c78bd|"
#~ msgstr ""

#~ msgid "|ba178f75267d4ad8aa7363f20709195f|"
#~ msgstr ""

#~ msgid "|c380c750bfd2444abce039a1c6fa8e60|"
#~ msgstr ""

#~ msgid "|e7cec00a114b48359935c6510595132e|"
#~ msgstr ""

#~ msgid ""
#~ "Include SecAgg, SecAgg+, and LightSecAgg "
#~ "protocol. The LightSecAgg protocol has "
#~ "not been implemented yet, so its "
#~ "diagram and abstraction may not be "
#~ "accurate in practice. The SecAgg "
#~ "protocol can be considered as a "
#~ "special case of the SecAgg+ protocol."
#~ msgstr ""
#~ "包括 SecAgg、SecAgg+ 和 LightSecAgg 协议。LightSecAgg"
#~ " 协议尚未实施，因此其图表和抽象在实践中可能并不准确。SecAgg 协议可视为 SecAgg+ "
#~ "协议的特例。"

#~ msgid "The ``SecAgg+`` abstraction"
#~ msgstr "代码：`SecAgg+` 抽象"

#~ msgid ""
#~ "In this implementation, each client will"
#~ " be assigned with a unique index "
#~ "(int) for secure aggregation, and thus"
#~ " many python dictionaries used have "
#~ "keys of int type rather than "
#~ "ClientProxy type."
#~ msgstr ""
#~ "在此实现中，将为每个客户端分配一个唯一索引（int），以确保聚合的安全性，因此使用的许多 python 字典的键都是"
#~ " int 类型，而不是 ClientProxy 类型。"

#~ msgid ""
#~ "The Flower server will execute and "
#~ "process received results in the "
#~ "following order:"
#~ msgstr "Flower 服务器将按以下顺序执行和处理收到的结果："

#~ msgid "The ``LightSecAgg`` abstraction"
#~ msgstr "代码：`LightSecAgg` 抽象"

#~ msgid "Types"
#~ msgstr "类型"

#~ msgid ""
#~ "Docker Compose is `installed "
#~ "<https://docs.docker.com/compose/install/>`_."
#~ msgstr ""

#~ msgid "Run the example:"
#~ msgstr "将示例联邦化"

#~ msgid "Follow the logs of the SuperExec service:"
#~ msgstr ""

#~ msgid "Only runs on AMD64."
#~ msgstr ""

#~ msgid ""
#~ "Use the method that works best for"
#~ " you to copy the ``server`` "
#~ "directory, the certificates, and your "
#~ "Flower project to the remote machine."
#~ msgstr ""

#~ msgid ""
#~ "The Path of the ``PROJECT_DIR`` should"
#~ " be relative to the location of "
#~ "the ``server`` Docker Compose files."
#~ msgstr ""

#~ msgid ""
#~ "The Path of the ``PROJECT_DIR`` should"
#~ " be relative to the location of "
#~ "the ``client`` Docker Compose files."
#~ msgstr ""

#~ msgid ""
#~ "The Path of the ``root-certificates``"
#~ " should be relative to the location"
#~ " of the ``pyproject.toml`` file."
#~ msgstr ""

#~ msgid "To run the project, execute:"
#~ msgstr ""

#~ msgid "Run the ``quickstart-docker`` project by executing the command:"
#~ msgstr ""

#~ msgid "Follow the SuperExec logs to track the execution of the run:"
#~ msgstr ""

#~ msgid "Execute the command to run the quickstart example:"
#~ msgstr ""

#~ msgid "Monitor the SuperExec logs and wait for the summary to appear:"
#~ msgstr ""

#~ msgid "Example: FedBN in PyTorch - From Centralized To Federated"
#~ msgstr "示例： PyTorch 中的 FedBN - 从集中式到联邦式"

#~ msgid "Centralized Training"
#~ msgstr "集中式训练"

#~ msgid ""
#~ "All files are revised based on "
#~ ":doc:`Example: PyTorch - From Centralized "
#~ "To Federated <example-pytorch-from-"
#~ "centralized-to-federated>`. The only thing"
#~ " to do is modifying the file "
#~ "called ``cifar.py``, revised part is "
#~ "shown below:"
#~ msgstr ""
#~ "所有文件均根据 `示例： PyTorch -从集中式到联邦式 "
#~ "<https://flower.ai/docs/examples/pytorch-from-"
#~ "centralized-to-federated.html>`_。唯一要做的就是修改名为 "
#~ ":code:`cifar.py` 的文件，修改部分如下所示："

#~ msgid ""
#~ "The model architecture defined in class"
#~ " Net() is added with Batch "
#~ "Normalization layers accordingly."
#~ msgstr "类 Net() 中定义的模型架构会相应添加Batch Normalization层。"

#~ msgid "You can now run your machine learning workload:"
#~ msgstr "现在，您可以运行您的机器学习工作了："

#~ msgid ""
#~ "So far this should all look fairly"
#~ " familiar if you've used PyTorch "
#~ "before. Let's take the next step "
#~ "and use what we've built to create"
#~ " a federated learning system within "
#~ "FedBN, the system consists of one "
#~ "server and two clients."
#~ msgstr ""
#~ "到目前为止，如果您以前使用过 PyTorch，这一切看起来应该相当熟悉。让我们进行下一步，使用我们所构建的内容在 "
#~ "FedBN 中创建一个联邦学习系统，该系统由一个服务器和两个客户端组成。"

#~ msgid "Federated Training"
#~ msgstr "联邦培训"

#~ msgid ""
#~ "If you have read :doc:`Example: PyTorch"
#~ " - From Centralized To Federated "
#~ "<example-pytorch-from-centralized-to-"
#~ "federated>`, the following parts are "
#~ "easy to follow, only ``get_parameters`` "
#~ "and ``set_parameters`` function in "
#~ "``client.py`` needed to revise. If not,"
#~ " please read the :doc:`Example: PyTorch "
#~ "- From Centralized To Federated "
#~ "<example-pytorch-from-centralized-to-"
#~ "federated>`. first."
#~ msgstr ""
#~ "如果你读过 `示例： PyTorch - 从集中式到联邦式 "
#~ "<https://flower.ai/docs/examples/pytorch-from-"
#~ "centralized-to-federated.html>`_，下面的部分就很容易理解了，只需要修改 "
#~ ":code:`get_parameters` 和 :code:`set_parameters` 中的"
#~ " :code:`client.py` 函数。如果没有，请阅读 `示例： PyTorch "
#~ "- 从集中式到联邦式 <https://flower.ai/docs/examples/pytorch-"
#~ "from-centralized-to-federated.html>`_。"

#~ msgid ""
#~ "Our example consists of one *server* "
#~ "and two *clients*. In FedBN, "
#~ "``server.py`` keeps unchanged, we can "
#~ "start the server directly."
#~ msgstr "我们的示例包括一个*服务器*和两个*客户端*。在 FedBN 中，:code:`server.py` 保持不变，我们可以直接启动服务器。"

#~ msgid "Now, you can now open two additional terminal windows and run"
#~ msgstr "现在，您可以打开另外两个终端窗口并运行程序"

#~ msgid ""
#~ "in each window (make sure that the"
#~ " server is still running before you"
#~ " do so) and see your (previously "
#~ "centralized) PyTorch project run federated "
#~ "learning with FedBN strategy across two"
#~ " clients. Congratulations!"
#~ msgstr "确保服务器仍在运行后，然后您就能看到您的 PyTorch 项目（之前是集中式的）通过 FedBN 策略在两个客户端上运行联合学习。祝贺！"

#~ msgid "Example: PyTorch - From Centralized To Federated"
#~ msgstr "实例： PyTorch - 从集中式到联邦式"

#~ msgid ""
#~ "This tutorial will show you how to"
#~ " use Flower to build a federated "
#~ "version of an existing machine learning"
#~ " workload. We are using PyTorch to"
#~ " train a Convolutional Neural Network "
#~ "on the CIFAR-10 dataset. First, we "
#~ "introduce this machine learning task "
#~ "with a centralized training approach "
#~ "based on the `Deep Learning with "
#~ "PyTorch "
#~ "<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_"
#~ " tutorial. Then, we build upon the"
#~ " centralized training code to run the"
#~ " training in a federated fashion."
#~ msgstr ""
#~ "本教程将向您展示如何使用 Flower 构建现有机器学习工作的联邦版本。我们使用 PyTorch "
#~ "在 CIFAR-10 数据集上训练一个卷积神经网络。首先，我们基于 \"Deep "
#~ "Learning with PyTorch "
#~ "<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_\"教程，采用集中式训练方法介绍了这项机器学习任务。然后，我们在集中式训练代码的基础上以联邦方式运行训练。"

#~ msgid ""
#~ "We begin with a brief description "
#~ "of the centralized CNN training code."
#~ " If you want a more in-depth"
#~ " explanation of what's going on then"
#~ " have a look at the official "
#~ "`PyTorch tutorial "
#~ "<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_."
#~ msgstr ""
#~ "我们首先简要介绍一下集中式 CNN 训练代码。如果您想获得更深入的解释，请参阅 PyTorch "
#~ "官方教程`PyTorch tutorial "
#~ "<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_。"

#~ msgid ""
#~ "Let's create a new file called "
#~ "``cifar.py`` with all the components "
#~ "required for a traditional (centralized) "
#~ "training on CIFAR-10. First, all "
#~ "required packages (such as ``torch`` and"
#~ " ``torchvision``) need to be imported. "
#~ "You can see that we do not "
#~ "import any package for federated "
#~ "learning. You can keep all these "
#~ "imports as they are even when we"
#~ " add the federated learning components "
#~ "at a later point."
#~ msgstr ""
#~ "让我们创建一个名为 :code:`cifar.py` 的新文件，其中包含 CIFAR-10 "
#~ "传统（集中）培训所需的所有组件。首先，需要导入所有必需的软件包（如 :code:`torch` 和 "
#~ ":code:`torchvision`）。您可以看到，我们没有导入任何用于联邦学习的软件包。即使在以后添加联邦学习组件时，也可以保留所有这些导入。"

#~ msgid ""
#~ "As already mentioned we will use "
#~ "the CIFAR-10 dataset for this machine"
#~ " learning workload. The model architecture"
#~ " (a very simple Convolutional Neural "
#~ "Network) is defined in ``class Net()``."
#~ msgstr ""
#~ "如前所述，我们将使用 CIFAR-10 数据集进行机器学习。模型架构（一个非常简单的卷积神经网络）在 "
#~ ":code:`class Net()` 中定义。"

#~ msgid ""
#~ "The ``load_data()`` function loads the "
#~ "CIFAR-10 training and test sets. The "
#~ "``transform`` normalized the data after "
#~ "loading."
#~ msgstr ""
#~ ":code:`load_data()` 函数加载 CIFAR-10 "
#~ "训练集和测试集。加载数据后，:code:`transform`函数对数据进行了归一化处理。"

#~ msgid ""
#~ "We now need to define the training"
#~ " (function ``train()``) which loops over"
#~ " the training set, measures the loss,"
#~ " backpropagates it, and then takes "
#~ "one optimizer step for each batch "
#~ "of training examples."
#~ msgstr "现在，我们需要定义训练函数（:code:`train()`），该函数在训练集上循环训练，计算损失值并反向传播，然后为每批训练数据在优化器上执行一个优化步骤。"

#~ msgid ""
#~ "The evaluation of the model is "
#~ "defined in the function ``test()``. The"
#~ " function loops over all test samples"
#~ " and measures the loss of the "
#~ "model based on the test dataset."
#~ msgstr "模型的评估在函数 :code:`test()` 中定义。该函数循环遍历所有测试样本，并计算测试数据集的模型损失值。"

#~ msgid ""
#~ "Having defined the data loading, model"
#~ " architecture, training, and evaluation we"
#~ " can put everything together and "
#~ "train our CNN on CIFAR-10."
#~ msgstr "在确定了数据加载、模型架构、训练和评估之后，我们就可以将所有整合在一起，在 CIFAR-10 上训练我们的 CNN。"

#~ msgid ""
#~ "So far, this should all look "
#~ "fairly familiar if you've used PyTorch"
#~ " before. Let's take the next step "
#~ "and use what we've built to create"
#~ " a simple federated learning system "
#~ "consisting of one server and two "
#~ "clients."
#~ msgstr ""
#~ "到目前为止，如果你以前用过 "
#~ "PyTorch，这一切看起来应该相当熟悉。让我们进行下一步，利用我们所构建的内容创建一个简单联邦学习系统（由一个服务器和两个客户端组成）。"

#~ msgid ""
#~ "The simple machine learning project "
#~ "discussed in the previous section trains"
#~ " the model on a single dataset "
#~ "(CIFAR-10), we call this centralized "
#~ "learning. This concept of centralized "
#~ "learning, as shown in the previous "
#~ "section, is probably known to most "
#~ "of you, and many of you have "
#~ "used it previously. Normally, if you'd"
#~ " want to run machine learning "
#~ "workloads in a federated fashion, then"
#~ " you'd have to change most of "
#~ "your code and set everything up "
#~ "from scratch. This can be a "
#~ "considerable effort."
#~ msgstr "上一节讨论的简单机器学习项目在单一数据集（CIFAR-10）上训练模型，我们称之为集中学习。如上一节所示，集中学习的概念可能为大多数人所熟知，而且很多人以前都使用过。通常情况下，如果要以联邦方式运行机器学习工作，就必须更改大部分代码，并从头开始设置一切。这可能是一个相当大的工作量。"

#~ msgid ""
#~ "However, with Flower you can evolve "
#~ "your pre-existing code into a "
#~ "federated learning setup without the "
#~ "need for a major rewrite."
#~ msgstr "不过，有了 Flower，您可以轻松地将已有的代码转变成联邦学习的模式，无需进行大量重写。"

#~ msgid ""
#~ "The concept is easy to understand. "
#~ "We have to start a *server* and"
#~ " then use the code in ``cifar.py``"
#~ " for the *clients* that are connected"
#~ " to the *server*. The *server* sends"
#~ " model parameters to the clients. The"
#~ " *clients* run the training and "
#~ "update the parameters. The updated "
#~ "parameters are sent back to the "
#~ "*server* which averages all received "
#~ "parameter updates. This describes one "
#~ "round of the federated learning process"
#~ " and we repeat this for multiple "
#~ "rounds."
#~ msgstr ""
#~ "这个概念很容易理解。我们必须启动一个*服务器*，然后对连接到*服务器*的*客户端*使用 "
#~ ":code:`cifar.py`中的代码。*服务器*向客户端发送模型参数，*客户端*运行训练并更新参数。更新后的参数被发回*服务器*，然后会对所有收到的参数更新进行平均聚合。以上描述的是一轮联邦学习过程，我们将重复进行多轮学习。"

#~ msgid ""
#~ "Our example consists of one *server* "
#~ "and two *clients*. Let's set up "
#~ "``server.py`` first. The *server* needs "
#~ "to import the Flower package ``flwr``."
#~ " Next, we use the ``start_server`` "
#~ "function to start a server and "
#~ "tell it to perform three rounds of"
#~ " federated learning."
#~ msgstr ""
#~ "我们的示例包括一个*服务器*和两个*客户端*。让我们先设置 :code:`server.py`。*服务器*需要导入 "
#~ "Flower 软件包 :code:`flwr`。接下来，我们使用 "
#~ ":code:`start_server` 函数启动服务器，并让它执行三轮联邦学习。"

#~ msgid "We can already start the *server*:"
#~ msgstr "我们已经可以启动*服务器*了："

#~ msgid ""
#~ "Finally, we will define our *client* "
#~ "logic in ``client.py`` and build upon"
#~ " the previously defined centralized "
#~ "training in ``cifar.py``. Our *client* "
#~ "needs to import ``flwr``, but also "
#~ "``torch`` to update the parameters on"
#~ " our PyTorch model:"
#~ msgstr ""
#~ "最后，我们将在 :code:`client.py` 中定义我们的 *client* "
#~ "逻辑，并以之前在 :code:`cifar.py` 中定义的集中式训练为基础。我们的 *client*"
#~ " 不仅需要导入 :code:`flwr`，还需要导入 :code:`torch`，以更新 "
#~ "PyTorch 模型的参数："

#~ msgid ""
#~ "Implementing a Flower *client* basically "
#~ "means implementing a subclass of either"
#~ " ``flwr.client.Client`` or ``flwr.client.NumPyClient``."
#~ " Our implementation will be based on"
#~ " ``flwr.client.NumPyClient`` and we'll call "
#~ "it ``CifarClient``. ``NumPyClient`` is "
#~ "slightly easier to implement than "
#~ "``Client`` if you use a framework "
#~ "with good NumPy interoperability (like "
#~ "PyTorch or TensorFlow/Keras) because it "
#~ "avoids some of the boilerplate that "
#~ "would otherwise be necessary. ``CifarClient``"
#~ " needs to implement four methods, two"
#~ " methods for getting/setting model "
#~ "parameters, one method for training the"
#~ " model, and one method for testing"
#~ " the model:"
#~ msgstr ""
#~ "实现 Flower *client*基本上意味着实现 "
#~ ":code:`flwr.client.Client` 或 "
#~ ":code:`flwr.client.NumPyClient` 的子类。我们的代码实现将基于 "
#~ ":code:`flwr.client.NumPyClient`，并将其命名为 "
#~ ":code:`CifarClient`。如果使用具有良好 NumPy 互操作性的框架（如 PyTorch"
#~ " 或 TensorFlow/Keras），:code:`NumPyClient`的实现比 "
#~ ":code:`Client`略微容易一些，因为它避免了一些不必要的操作。:code:`CifarClient` "
#~ "需要实现四个方法，两个用于获取/设置模型参数，一个用于训练模型，一个用于测试模型："

#~ msgid "``set_parameters``"
#~ msgstr ":code:`set_parameters`"

#~ msgid ""
#~ "set the model parameters on the "
#~ "local model that are received from "
#~ "the server"
#~ msgstr "在本地模型上设置从服务器接收的模型参数"

#~ msgid ""
#~ "loop over the list of model "
#~ "parameters received as NumPy ``ndarray``'s "
#~ "(think list of neural network layers)"
#~ msgstr "循环遍历以 NumPy :code:`ndarray` 形式接收的模型参数列表（可以看作神经网络的列表）"

#~ msgid "``get_parameters``"
#~ msgstr ":code:`get_parameters`"

#~ msgid ""
#~ "get the model parameters and return "
#~ "them as a list of NumPy "
#~ "``ndarray``'s (which is what "
#~ "``flwr.client.NumPyClient`` expects)"
#~ msgstr ""
#~ "获取模型参数，并以 NumPy :code:`ndarray`的列表形式返回（这正是 "
#~ ":code:`flwr.client.NumPyClient`所匹配的格式）"

#~ msgid "``fit``"
#~ msgstr ""

#~ msgid ""
#~ "update the parameters of the local "
#~ "model with the parameters received from"
#~ " the server"
#~ msgstr "用从服务器接收到的参数更新本地模型的参数"

#~ msgid "train the model on the local training set"
#~ msgstr "在本地训练集上训练模型"

#~ msgid "get the updated local model weights and return them to the server"
#~ msgstr "获取更新后的本地模型参数并发送回服务器"

#~ msgid "evaluate the updated model on the local test set"
#~ msgstr "在本地测试集上评估更新后的模型"

#~ msgid "return the local loss and accuracy to the server"
#~ msgstr "向服务器返回本地损失值和精确度"

#~ msgid ""
#~ "The two ``NumPyClient`` methods ``fit`` "
#~ "and ``evaluate`` make use of the "
#~ "functions ``train()`` and ``test()`` "
#~ "previously defined in ``cifar.py``. So "
#~ "what we really do here is we "
#~ "tell Flower through our ``NumPyClient`` "
#~ "subclass which of our already defined"
#~ " functions to call for training and"
#~ " evaluation. We included type annotations"
#~ " to give you a better understanding"
#~ " of the data types that get "
#~ "passed around."
#~ msgstr ""
#~ "这两个 :code:`NumPyClient` 中的方法 :code:`fit` 和 "
#~ ":code:`evaluate` 使用了之前在 :code:`cifar.py` 中定义的函数 "
#~ ":code:`train()` 和 :code:`test()`。因此，我们在这里要做的就是通过 "
#~ ":code:`NumPyClient` 子类告知 Flower "
#~ "在训练和评估时要调用哪些已定义的函数。我们加入了类型注解，以便让你更好地理解传递的数据类型。"

#~ msgid ""
#~ "All that's left to do it to "
#~ "define a function that loads both "
#~ "model and data, creates a "
#~ "``CifarClient``, and starts this client. "
#~ "You load your data and model by"
#~ " using ``cifar.py``. Start ``CifarClient`` "
#~ "with the function ``fl.client.start_client()`` "
#~ "by pointing it at the same IP "
#~ "address we used in ``server.py``:"
#~ msgstr "剩下的就是定义模型和数据加载函数了。创建一个:code:`CifarClient`类，并运行这个客服端。您将通过:code:`cifar.py`加载数据和模型。另外，通过:code:`fl.client.start_client()`函数来运行客户端:code:`CifarClient`，需要保证IP地址和:code:`server.py`中所使用的一致："

#~ msgid "And that's it. You can now open two additional terminal windows and run"
#~ msgstr "就是这样，现在你可以打开另外两个终端窗口，然后运行"

#~ msgid ""
#~ "in each window (make sure that the"
#~ " server is running before you do "
#~ "so) and see your (previously "
#~ "centralized) PyTorch project run federated "
#~ "learning across two clients. Congratulations!"
#~ msgstr "确保服务器正在运行后，您就能看到您的 PyTorch 项目（之前是集中式的）在两个客户端上运行联邦学习了。祝贺！"

#~ msgid ""
#~ "The full source code for this "
#~ "example: `PyTorch: From Centralized To "
#~ "Federated (Code) "
#~ "<https://github.com/adap/flower/blob/main/examples/pytorch-"
#~ "from-centralized-to-federated>`_. Our "
#~ "example is, of course, somewhat over-"
#~ "simplified because both clients load the"
#~ " exact same dataset, which isn't "
#~ "realistic. You're now prepared to "
#~ "explore this topic further. How about"
#~ " using different subsets of CIFAR-10 "
#~ "on each client? How about adding "
#~ "more clients?"
#~ msgstr ""
#~ "本示例的完整源代码为：`PyTorch： 从集中式到联合式 "
#~ "<https://github.com/adap/flower/blob/main/examples/pytorch-"
#~ "from-centralized-to-"
#~ "federated>`_。当然，我们的示例有些过于简单，因为两个客户端都加载了完全相同的数据集，这并不真实。现在，您已经准备好进一步探讨这一主题了。比如在每个客户端使用不同的"
#~ " CIFAR-10 子集会如何？增加更多客户端会如何？"

#~ msgid ""
#~ "To help you start and manage all"
#~ " of the concurrently executing training "
#~ "runs, Flower offers one additional "
#~ "long-running server-side service called "
#~ "**SuperExec**. When you type ``flwr "
#~ "run`` to start a new training run,"
#~ " the ``flwr`` CLI bundles your local"
#~ " project (mainly your ``ServerApp`` and "
#~ "``ClientApp``) and sends it to the "
#~ "**SuperExec**. The **SuperExec** will then "
#~ "take care of starting and managing "
#~ "your ``ServerApp``, which in turn "
#~ "selects SuperNodes to execute your "
#~ "``ClientApp``."
#~ msgstr ""

#~ msgid ""
#~ "This architecture allows many users to"
#~ " (concurrently) run their projects on "
#~ "the same federation, simply by typing"
#~ " ``flwr run`` on their local "
#~ "developer machine."
#~ msgstr ""

#~ msgid "Flower Deployment Engine with SuperExec"
#~ msgstr ""

#~ msgid "The SuperExec service for managing concurrent training runs in Flower."
#~ msgstr ""

#~ msgid "FED Template"
#~ msgstr "FED 模板"

#~ msgid "Table of Contents"
#~ msgstr "目录"

#~ msgid "[Table of Contents](#table-of-contents)"
#~ msgstr "[目录]（#table-of-contents）"

#~ msgid "[Summary](#summary)"
#~ msgstr "[总结](#summary)"

#~ msgid "[Motivation](#motivation)"
#~ msgstr "[动机](#motivation)"

#~ msgid "[Goals](#goals)"
#~ msgstr "[目标](#goals)"

#~ msgid "[Non-Goals](#non-goals)"
#~ msgstr "[非目标](#non-goals)"

#~ msgid "[Proposal](#proposal)"
#~ msgstr "[计划](#proposal)"

#~ msgid "[Drawbacks](#drawbacks)"
#~ msgstr "[缺点](#drawbacks)"

#~ msgid "[Alternatives Considered](#alternatives-considered)"
#~ msgstr "[备选方案](#alternatives-considered)"

#~ msgid "[Appendix](#appendix)"
#~ msgstr "[附录](#appendix)"

#~ msgid "Summary"
#~ msgstr "总结"

#~ msgid "\\[TODO - sentence 1: summary of the problem\\]"
#~ msgstr "\\[TODO - 句子 1: 问题概括\\]"

#~ msgid "\\[TODO - sentence 2: summary of the solution\\]"
#~ msgstr "\\[TODO - 句子 2: 解决方案概括\\]"

#~ msgid "Motivation"
#~ msgstr "动机"

#~ msgid "\\[TODO\\]"
#~ msgstr "\\[TODO\\]"

#~ msgid "Goals"
#~ msgstr "目标"

#~ msgid "Non-Goals"
#~ msgstr "非目标"

#~ msgid "Proposal"
#~ msgstr "提案"

#~ msgid "Drawbacks"
#~ msgstr "缺点"

#~ msgid "Alternatives Considered"
#~ msgstr "备选方案"

#~ msgid "\\[Alternative 1\\]"
#~ msgstr "\\[备选 1\\]"

#~ msgid "\\[Alternative 2\\]"
#~ msgstr "\\[备选 2\\]"

#~ msgid "Flower Enhancement Doc"
#~ msgstr "Flower 改善文档"

#~ msgid "[Enhancement Doc Template](#enhancement-doc-template)"
#~ msgstr "[增强文档模版](#enhancement-doc-template)"

#~ msgid "[Metadata](#metadata)"
#~ msgstr "[描述数据](#metadata)"

#~ msgid "[Workflow](#workflow)"
#~ msgstr "[工作流程](#workflow)"

#~ msgid "[GitHub Issues](#github-issues)"
#~ msgstr "[GitHub 问题](#github-issues)"

#~ msgid "[Google Docs](#google-docs)"
#~ msgstr "[谷歌文档](#google-docs)"

#~ msgid "A Flower Enhancement is a standardized development process to"
#~ msgstr "改善 Flower 功能是一个标准化的开发流程，目的是"

#~ msgid "provide a common structure for proposing larger changes"
#~ msgstr "为提出更大规模的改动提供一个共同的结构"

#~ msgid "ensure that the motivation for a change is clear"
#~ msgstr "确保改动的动机明确"

#~ msgid "persist project information in a version control system"
#~ msgstr "将项目信息保存在版本控制系统中"

#~ msgid "document the motivation for impactful user-facing changes"
#~ msgstr "记录面向用户的具有影响力的改动的动机"

#~ msgid "reserve GitHub issues for tracking work in flight"
#~ msgstr "保留 GitHub 问题，用于跟踪进行中的工作"

#~ msgid ""
#~ "ensure community participants can successfully"
#~ " drive changes to completion across "
#~ "one or more releases while stakeholders"
#~ " are adequately represented throughout the"
#~ " process"
#~ msgstr "确保社区参与者能够成功推动改动，完成一个或多个版本，同时利益相关者在整个过程中得到充分展现"

#~ msgid "Hence, an Enhancement Doc combines aspects of"
#~ msgstr "因此，\"增强文件\"将以下方面结合起来"

#~ msgid "a feature, and effort-tracking document"
#~ msgstr "一个功能和效力跟踪文档"

#~ msgid "a product requirements document"
#~ msgstr "一个产品需要文档"

#~ msgid "a design document"
#~ msgstr "一个设计文档"

#~ msgid ""
#~ "into one file, which is created "
#~ "incrementally in collaboration with the "
#~ "community."
#~ msgstr "该文件是与社区合作逐步创建的。"

#~ msgid ""
#~ "For far-fetching changes or features "
#~ "proposed to Flower, an abstraction "
#~ "beyond a single GitHub issue or "
#~ "pull request is required to understand"
#~ " and communicate upcoming changes to "
#~ "the project."
#~ msgstr ""
#~ "对于向 Flower 提出的远期变更或功能，需要一个超越单个 GitHub "
#~ "问题或拉取请求（pull request）的抽象概念，以了解和沟通项目即将发生的变更。"

#~ msgid ""
#~ "The purpose of this process is to"
#~ " reduce the amount of \"tribal "
#~ "knowledge\" in our community. By moving"
#~ " decisions from Slack threads, video "
#~ "calls, and hallway conversations into a"
#~ " well-tracked artifact, this process "
#~ "aims to enhance communication and "
#~ "discoverability."
#~ msgstr ""
#~ "这一流程的目的是减少我们社区中 \"部落知识 \"的数量。通过将决策从 Slack "
#~ "线程、视频通话和走廊对话转移到一个跟踪良好的工作环境中，该流程旨在加强沟通和可发现性。"

#~ msgid ""
#~ "Roughly any larger, user-facing "
#~ "enhancement should follow the Enhancement "
#~ "process. If an enhancement would be "
#~ "described in either written or verbal"
#~ " communication to anyone besides the "
#~ "author or developer, then consider "
#~ "creating an Enhancement Doc."
#~ msgstr "任何较大的、面向用户的增强都应遵循增强流程。如果要以书面或口头形式向作者或开发人员以外的任何人描述增强功能，则应考虑创建改善文档。"

#~ msgid ""
#~ "Similarly, any technical effort (refactoring,"
#~ " major architectural change) that will "
#~ "impact a large section of the "
#~ "development community should also be "
#~ "communicated widely. The Enhancement process"
#~ " is suited for this even if it"
#~ " will have zero impact on the "
#~ "typical user or operator."
#~ msgstr "同样，任何会对开发社区的大部分人产生影响的技术工作（重构、重大架构变更）也应广泛传播。即使对典型用户或操作员的影响为零，改进流程也适用于这种情况。"

#~ msgid ""
#~ "For small changes and additions, going"
#~ " through the Enhancement process would "
#~ "be time-consuming and unnecessary. This"
#~ " includes, for example, adding new "
#~ "Federated Learning algorithms, as these "
#~ "only add features without changing how"
#~ " Flower works or is used."
#~ msgstr ""
#~ "对于小的改动和添加，通过 \"改善\"程序既耗时又没有必要。例如，这包括添加新的联邦学习算法，因为这只会增加功能，而不会改变"
#~ " \"Flower \"的工作或使用方式。"

#~ msgid ""
#~ "Enhancements are different from feature "
#~ "requests, as they are already providing"
#~ " a laid-out path for implementation"
#~ " and are championed by members of "
#~ "the community."
#~ msgstr "增强功能与功能请求不同，因为它们已经提供了实施路径，并得到了社区成员的支持。"

#~ msgid ""
#~ "An Enhancement is captured in a "
#~ "Markdown file that follows a defined "
#~ "template and a workflow to review "
#~ "and store enhancement docs for reference"
#~ " — the Enhancement Doc."
#~ msgstr "增强功能被记录在一个 Markdown 文件中，该文件遵循已定义的模板和工作流程，用于审查和存储增强功能文档（即增强功能文档）以供参考。"

#~ msgid "Enhancement Doc Template"
#~ msgstr "增强文档模板"

#~ msgid ""
#~ "Each enhancement doc is provided as "
#~ "a Markdown file having the following "
#~ "structure"
#~ msgstr "每个增强文档都以 Markdown 文件的形式提供，其结构如下"

#~ msgid "Metadata (as [described below](#metadata) in form of a YAML preamble)"
#~ msgstr "描述数据（[如下所述](#metadata) 以 YAML 前言的形式出现）"

#~ msgid "Title (same as in metadata)"
#~ msgstr "标题（与描述数据中的标题相同）"

#~ msgid "Table of Contents (if needed)"
#~ msgstr "目录（如有需要）"

#~ msgid "Notes/Constraints/Caveats (optional)"
#~ msgstr "注意事项/限制/警告（可选）"

#~ msgid "Design Details (optional)"
#~ msgstr "设计细节（可选）"

#~ msgid "Graduation Criteria"
#~ msgstr "毕业标准"

#~ msgid "Upgrade/Downgrade Strategy (if applicable)"
#~ msgstr "升级/降级策略（如适用）"

#~ msgid "As a reference, this document follows the above structure."
#~ msgstr "作为参考，本文件采用上述结构。"

#~ msgid ""
#~ "**fed-number** (Required) The `fed-"
#~ "number` of the last Flower Enhancement"
#~ " Doc + 1. With this number, it"
#~ " becomes easy to reference other "
#~ "proposals."
#~ msgstr "**fed-number**（必填）上一个Flower增强文件的 \"fed-number \"+1。有了这个编号，就很容易参考其他提案。"

#~ msgid "**title** (Required) The title of the proposal in plain language."
#~ msgstr "**标题** （必填）用简明语言写出提案的标题。"

#~ msgid ""
#~ "**status** (Required) The current status "
#~ "of the proposal. See [workflow](#workflow) "
#~ "for the possible states."
#~ msgstr "**status** （必填）提案的当前状态。有关可能的状态，请参阅 [工作流程](#workflow)。"

#~ msgid ""
#~ "**authors** (Required) A list of authors"
#~ " of the proposal. This is simply "
#~ "the GitHub ID."
#~ msgstr "**作者**（必填） 提案的作者列表。这只是 GitHub ID。"

#~ msgid ""
#~ "**creation-date** (Required) The date "
#~ "that the proposal was first submitted"
#~ " in a PR."
#~ msgstr "**创建日期**（必填） 建议书在 PR 中首次提交的日期。"

#~ msgid ""
#~ "**last-updated** (Optional) The date "
#~ "that the proposal was last changed "
#~ "significantly."
#~ msgstr "**最后更新** （可选）提案最后一次重大修改的日期。"

#~ msgid ""
#~ "**see-also** (Optional) A list of "
#~ "other proposals that are relevant to "
#~ "this one."
#~ msgstr "**另见** （可选）与本提案相关的其他提案清单。"

#~ msgid "**replaces** (Optional) A list of proposals that this one replaces."
#~ msgstr "**取代**（可选） 这份提案所取代的提案列表。"

#~ msgid ""
#~ "**superseded-by** (Optional) A list of"
#~ " proposals that this one supersedes."
#~ msgstr "**被取代者** （可选） 此提案取代的提案列表。"

#~ msgid "Workflow"
#~ msgstr "工作流程"

#~ msgid ""
#~ "The idea forming the enhancement should"
#~ " already have been discussed or "
#~ "pitched in the community. As such, "
#~ "it needs a champion, usually the "
#~ "author, who shepherds the enhancement. "
#~ "This person also has to find "
#~ "committers to Flower willing to review"
#~ " the proposal."
#~ msgstr "形成增强功能的想法应该已经在社区中讨论过或提出过。因此，它需要一个支持者（通常是作者）来引导增强。这个人还必须找到愿意审核提案的提交者。"

#~ msgid ""
#~ "New enhancements are checked in with "
#~ "a file name in the form of "
#~ "`NNNN-YYYYMMDD-enhancement-title.md`, with "
#~ "`NNNN` being the Flower Enhancement Doc"
#~ " number, to `enhancements`. All "
#~ "enhancements start in `provisional` state "
#~ "as part of a pull request. "
#~ "Discussions are done as part of "
#~ "the pull request review."
#~ msgstr ""
#~ "新的增强功能以 `NNNN-YYYYMMDD-enhancement-title.md`"
#~ " 的文件名签入，其中 `NNNN` 是花朵增强文档的编号，并将其转入 "
#~ "`enhancements`。作为拉取请求（pull request）的一部分，所有增强功能都从 "
#~ "`provisional` 状态开始。讨论是作为拉取请求审查的一部分进行的。"

#~ msgid ""
#~ "Once an enhancement has been reviewed"
#~ " and approved, its status is changed"
#~ " to `implementable`. The actual "
#~ "implementation is then done in separate"
#~ " pull requests. These pull requests "
#~ "should mention the respective enhancement "
#~ "as part of their description. After "
#~ "the implementation is done, the proposal"
#~ " status is changed to `implemented`."
#~ msgstr ""
#~ "一旦增强功能通过审核和批准，其状态就会变为 "
#~ "`可实施`。实际的实施工作将在单独的拉取请求中完成。这些拉取请求应在其描述中提及相应的增强功能。实施完成后，提案状态将更改为 "
#~ "`已实施`。"

#~ msgid ""
#~ "Under certain conditions, other states "
#~ "are possible. An Enhancement has the "
#~ "following states:"
#~ msgstr "在某些条件下，还可能出现其他状态。增强提案具有以下状态："

#~ msgid ""
#~ "`provisional`: The enhancement has been "
#~ "proposed and is actively being defined."
#~ " This is the starting state while "
#~ "the proposal is being fleshed out "
#~ "and actively defined and discussed."
#~ msgstr "`暂定`： 已提出改进建议并正在积极定义。这是在提案得到充实、积极定义和讨论时的起始状态。"

#~ msgid "`implementable`: The enhancement has been reviewed and approved."
#~ msgstr "`可实施`： 增强功能已审核通过。"

#~ msgid ""
#~ "`implemented`: The enhancement has been "
#~ "implemented and is no longer actively"
#~ " changed."
#~ msgstr "`已实施`： 增强功能已实施，不再主动更改。"

#~ msgid ""
#~ "`deferred`: The enhancement is proposed "
#~ "but not actively being worked on."
#~ msgstr "`推迟`： 已提出改进建议，但尚未积极开展工作。"

#~ msgid ""
#~ "`rejected`: The authors and reviewers "
#~ "have decided that this enhancement is"
#~ " not moving forward."
#~ msgstr "`拒绝`： 作者和审稿人已决定不再推进该增强功能。"

#~ msgid "`withdrawn`: The authors have withdrawn the enhancement."
#~ msgstr "`撤回`： 作者已撤回增强功能。"

#~ msgid "`replaced`: The enhancement has been replaced by a new enhancement."
#~ msgstr "`已替换`： 增强功能已被新的增强功能取代。"

#~ msgid ""
#~ "Adding an additional process to the "
#~ "ones already provided by GitHub (Issues"
#~ " and Pull Requests) adds more "
#~ "complexity and can be a barrier "
#~ "for potential first-time contributors."
#~ msgstr "在 GitHub 已提供的流程（问题和拉取请求）之外再增加一个流程，会增加复杂性，并可能成为潜在首次贡献者的障碍。"

#~ msgid ""
#~ "Expanding the proposal template beyond "
#~ "the single-sentence description currently "
#~ "required in the features issue template"
#~ " may be a heavy burden for "
#~ "non-native English speakers."
#~ msgstr "对于英语非母语者来说，将提案模板扩展到目前要求的单句描述之外可能是一个沉重的负担。"

#~ msgid "GitHub Issues"
#~ msgstr "GitHub 问题"

#~ msgid ""
#~ "Using GitHub Issues for these kinds "
#~ "of enhancements is doable. One could "
#~ "use, for example, tags, to differentiate"
#~ " and filter them from other issues."
#~ " The main issue is in discussing "
#~ "and reviewing an enhancement: GitHub "
#~ "issues only have a single thread "
#~ "for comments. Enhancements usually have "
#~ "multiple threads of discussion at the"
#~ " same time for various parts of "
#~ "the doc. Managing these multiple "
#~ "discussions can be confusing when using"
#~ " GitHub Issues."
#~ msgstr ""
#~ "使用 GitHub Issues "
#~ "进行此类改进是可行的。例如，我们可以使用标签来区分和过滤这些问题。主要的问题在于讨论和审查增强功能： GitHub "
#~ "问题只有一个评论线程。而增强功能通常会同时有多个讨论线程，针对文档的不同部分。在使用 GitHub "
#~ "问题时，管理这些多重讨论会很混乱。"

#~ msgid "Google Docs"
#~ msgstr "谷歌文档"

#~ msgid ""
#~ "Google Docs allow for multiple threads"
#~ " of discussions. But as Google Docs"
#~ " are hosted outside the project, "
#~ "their discoverability by the community "
#~ "needs to be taken care of. A "
#~ "list of links to all proposals has"
#~ " to be managed and made available "
#~ "for the community. Compared to shipping"
#~ " proposals as part of Flower's "
#~ "repository, the potential for missing "
#~ "links is much higher."
#~ msgstr ""
#~ "谷歌文档允许多线程讨论。但是，由于谷歌文档是在项目之外托管的，因此需要注意它们是否能被社区发现。我们必须管理所有提案的链接列表，并提供给社区使用。与作为"
#~ " Flower 资源库一部分的提案相比，丢失链接的可能性要大得多。"

#~ msgid "FED - Flower Enhancement Doc"
#~ msgstr "FED - Flower 增强文件"

#~ msgid ""
#~ "Along with model parameters, Flower can"
#~ " send configuration values to clients. "
#~ "Configuration values can be used for "
#~ "various purposes. They are, for example,"
#~ " a popular way to control client-"
#~ "side hyperparameters from the server."
#~ msgstr "除了模型参数，Flower 还可以向客户端发送配置值。配置值有多种用途。它们是一种从服务器控制客户端超参数的常用方法。"

#~ msgid ""
#~ "Configuration values are represented as "
#~ "a dictionary with ``str`` keys and "
#~ "values of type ``bool``, ``bytes``, "
#~ "``double`` (64-bit precision float), ``int``,"
#~ " or ``str`` (or equivalent types in"
#~ " different languages). Here is an "
#~ "example of a configuration dictionary in"
#~ " Python:"
#~ msgstr ""
#~ "配置值以字典的形式表示，字典的键为 ``str``，值的类型为 "
#~ "``bool``、``bytes``、``double``（64 位精度浮点型）、``int``或 "
#~ "``str`（或不同语言中的等效类型）。下面是一个 Python 配置字典的示例："

#~ msgid ""
#~ "One can, for example, convert a "
#~ "list of floating-point numbers to "
#~ "a JSON string, then send the JSON"
#~ " string using the configuration dictionary,"
#~ " and then convert the JSON string "
#~ "back to a list of floating-point"
#~ " numbers on the client."
#~ msgstr "例如，可以将浮点数列表转换为 JSON 字符串，然后使用配置字典发送 JSON 字符串，再在客户端将 JSON 字符串转换回浮点数列表。"

#~ msgid ""
#~ "The easiest way to send configuration"
#~ " values to clients is to use a"
#~ " built-in strategy like ``FedAvg``. "
#~ "Built-in strategies support so-called "
#~ "configuration functions. A configuration "
#~ "function is a function that the "
#~ "built-in strategy calls to get the"
#~ " configuration dictionary for the current"
#~ " round. It then forwards the "
#~ "configuration dictionary to all the "
#~ "clients selected during that round."
#~ msgstr ""
#~ "向客户端发送配置值的最简单方法是使用内置策略，如 "
#~ ":code:`FedAvg`。内置策略支持所谓的配置函数。配置函数是内置策略调用的函数，用于获取当前轮的配置字典。然后，它会将配置字典转发给该轮中选择的所有客户端。"

#~ msgid ""
#~ "To make the built-in strategies "
#~ "use this function, we can pass it"
#~ " to ``FedAvg`` during initialization using"
#~ " the parameter ``on_fit_config_fn``:"
#~ msgstr "为了让内置策略使用这个函数，我们可以在初始化时使用参数 :code:`on_fit_config_fn` 将它传递给 ``FedAvg`` ："

#~ msgid ""
#~ "One the client side, we receive "
#~ "the configuration dictionary in ``fit``:"
#~ msgstr "在客户端，我们在 ``fit`` 中接收配置字典："

#~ msgid ""
#~ "There is also an `on_evaluate_config_fn` "
#~ "to configure evaluation, which works the"
#~ " same way. They are separate "
#~ "functions because one might want to "
#~ "send different configuration values to "
#~ "`evaluate` (for example, to use a "
#~ "different batch size)."
#~ msgstr ""
#~ "还有一个 `on_evaluate_config_fn` "
#~ "用于配置评估，其工作方式相同。它们是不同的函数，因为可能需要向 `evaluate` "
#~ "发送不同的配置值（例如，使用不同的批量大小）。"

#~ msgid ""
#~ "The built-in strategies call this "
#~ "function every round (that is, every "
#~ "time `Strategy.configure_fit` or "
#~ "`Strategy.configure_evaluate` runs). Calling "
#~ "`on_evaluate_config_fn` every round allows us"
#~ " to vary/change the config dict over"
#~ " consecutive rounds. If we wanted to"
#~ " implement a hyperparameter schedule, for"
#~ " example, to increase the number of"
#~ " local epochs during later rounds, we"
#~ " could do the following:"
#~ msgstr ""
#~ "内置策略每轮都会调用此函数（即每次运行 `Strategy.configure_fit` 或 "
#~ "`Strategy.configure_evaluate` 时）。每轮调用 "
#~ "`on_evaluate_config_fn` "
#~ "允许我们在连续几轮中改变配置指令。例如，如果我们想实现一个超参数时间表，以增加后几轮的本地遍历次数，我们可以这样做："

#~ msgid "The ``FedAvg`` strategy will call this function *every round*."
#~ msgstr "代码:`FedAvg`策略*每轮*都会调用该函数。"

#~ msgid "Configuring individual clients"
#~ msgstr "配置个别客户端"

#~ msgid ""
#~ "In some cases, it is necessary to"
#~ " send different configuration values to "
#~ "different clients."
#~ msgstr "在某些情况下，有必要向不同的客户端发送不同的配置值。"

#~ msgid ""
#~ "This can be achieved by customizing "
#~ "an existing strategy or by "
#~ ":doc:`implementing a custom strategy from "
#~ "scratch <how-to-implement-strategies>`. "
#~ "Here's a nonsensical example that "
#~ "customizes ``FedAvg`` by adding a custom"
#~ " ``\"hello\": \"world\"`` configuration key/value"
#~ " pair to the config dict of a"
#~ " *single client* (only the first "
#~ "client in the list, the other "
#~ "clients in this round to not "
#~ "receive this \"special\" config value):"
#~ msgstr ""
#~ "这可以通过定制现有策略或 `从头开始实施一个定制策略 "
#~ "<https://flower.ai/docs/framework/how-to-implement-"
#~ "strategies.html>`_来实现。下面是一个无厘头的例子，`FedAvg`通过在*单个客户端*的配置指令（config "
#~ "dict）中添加自定义的``\"hello\"： \"world\"``配置键/值对添加到此的配置 dict "
#~ "中（仅列表中的第一个客户端，本轮中的其他客户端不会收到此 \"特殊 \"配置值）："

#~ msgid "Configure logging"
#~ msgstr "配置日志记录"

#~ msgid ""
#~ "The Flower logger keeps track of "
#~ "all core events that take place in"
#~ " federated learning workloads. It presents"
#~ " information by default following a "
#~ "standard message format:"
#~ msgstr "Flower 日志记录器会跟踪联邦学习工作负载中发生的所有核心事件。它默认按照标准信息格式提供信息："

#~ msgid ""
#~ "containing relevant information including: log"
#~ " message level (e.g. ``INFO``, ``DEBUG``),"
#~ " a timestamp, the line where the "
#~ "logging took place from, as well "
#~ "as the log message itself. In this"
#~ " way, the logger would typically "
#~ "display information on your terminal as"
#~ " follows:"
#~ msgstr ""
#~ "相关信息包括：日志信息级别（例如 "
#~ ":code:`INFO`、:code:`DEBUG`）、时间戳、日志记录的行以及日志信息本身。这样，日志记录器通常会在终端上显示如下信息："

#~ msgid "Saving log to file"
#~ msgstr "将日志保存到文件"

#~ msgid ""
#~ "By default, the Flower log is "
#~ "outputted to the terminal where you "
#~ "launch your Federated Learning workload "
#~ "from. This applies for both gRPC-"
#~ "based federation (i.e. when you do "
#~ "``fl.server.start_server``) and when using the"
#~ " ``VirtualClientEngine`` (i.e. when you do"
#~ " ``fl.simulation.start_simulation``). In some "
#~ "situations you might want to save "
#~ "this log to disk. You can do "
#~ "so by calling the "
#~ "`fl.common.logger.configure() "
#~ "<https://github.com/adap/flower/blob/main/src/py/flwr/common/logger.py>`_"
#~ " function. For example:"
#~ msgstr ""
#~ "默认情况下，Flower 日志会输出到启动联邦学习工作负载的终端。这既适用于基于 gRPC "
#~ "的联邦学习（即执行 :code:`fl.server.start_server` 时），也适用于使用 "
#~ ":code:`VirtualClientEngine` 时（即执行 "
#~ ":code:`fl.simulation.start_simulation` "
#~ "时）。在某些情况下，您可能希望将此日志保存到磁盘。为此，您可以调用 `fl.common.logger.configure()"
#~ " "
#~ "<https://github.com/adap/flower/blob/main/src/py/flwr/common/logger.py>`_"
#~ " 函数。例如："

#~ msgid ""
#~ "With the above, Flower will record "
#~ "the log you see on your terminal"
#~ " to ``log.txt``. This file will be"
#~ " created in the same directory as "
#~ "were you are running the code "
#~ "from. If we inspect we see the "
#~ "log above is also recorded but "
#~ "prefixing with ``identifier`` each line:"
#~ msgstr ""
#~ "通过上述操作，Flower 会将您在终端上看到的日志记录到 "
#~ ":code:`log.txt`。该文件将创建在运行代码的同一目录下。如果我们检查一下，就会发现上面的日志也被记录了下来，但每一行都以 "
#~ ":code:`identifier` 作为前缀："

#~ msgid "Log your own messages"
#~ msgstr "记录自己的信息"

#~ msgid ""
#~ "You might expand the information shown"
#~ " by default with the Flower logger"
#~ " by adding more messages relevant to"
#~ " your application. You can achieve "
#~ "this easily as follows."
#~ msgstr "您可以通过添加更多与应用程序相关的信息来扩展 Flower 日志记录器默认显示的信息。您可以通过以下方法轻松实现这一目标。"

#~ msgid ""
#~ "In this way your logger will show,"
#~ " in addition to the default messages,"
#~ " the ones introduced by the clients"
#~ " as specified above."
#~ msgstr "这样，除默认信息外，您的日志记录器还将显示由客户引入的信息，如上文所述。"

#~ msgid "Log to a remote service"
#~ msgstr "登录远程服务"

#~ msgid ""
#~ "The ``fl.common.logger.configure`` function, also"
#~ " allows specifying a host to which"
#~ " logs can be pushed (via ``POST``)"
#~ " through a native Python "
#~ "``logging.handler.HTTPHandler``. This is a "
#~ "particularly useful feature in ``gRPC``-based"
#~ " Federated Learning workloads where "
#~ "otherwise gathering logs from all "
#~ "entities (i.e. the server and the "
#~ "clients) might be cumbersome. Note that"
#~ " in Flower simulation, the server "
#~ "automatically displays all logs. You can"
#~ " still specify a ``HTTPHandler`` should "
#~ "you wish to backup or analyze the"
#~ " logs somewhere else."
#~ msgstr ""
#~ "此外，:code:`fl.common.logger.configure`函数还允许指定主机，通过本地 Python "
#~ ":code:`logging.handler.HTTPHandler`，向该主机推送日志（通过 "
#~ ":code:`POST`）。在基于 :code:`gRPC` "
#~ "的联邦学习工作负载中，这是一个特别有用的功能，否则从所有实体（即服务器和客户端）收集日志可能会很麻烦。请注意，在 Flower"
#~ " 模拟器中，服务器会自动显示所有日志。如果希望在其他地方备份或分析日志，仍可指定 :code:`HTTPHandler`。"

#~ msgid "Monitor simulation"
#~ msgstr "监控模拟"

#~ msgid ""
#~ "Flower allows you to monitor system "
#~ "resources while running your simulation. "
#~ "Moreover, the Flower simulation engine "
#~ "is powerful and enables you to "
#~ "decide how to allocate resources per "
#~ "client manner and constrain the total"
#~ " usage. Insights from resource consumption"
#~ " can help you make smarter decisions"
#~ " and speed up the execution time."
#~ msgstr ""
#~ "Flower 允许您在运行模拟时监控系统资源。此外，Flower "
#~ "仿真引擎功能强大，能让您决定如何按客户端方式分配资源并限制总使用量。从资源消耗中获得的观察可以帮助您做出更明智的决策，并加快执行时间。"

#~ msgid ""
#~ "The specific instructions assume you are"
#~ " using macOS and have the `Homebrew"
#~ " <https://brew.sh/>`_ package manager installed."
#~ msgstr "具体说明假定你使用的是 macOS，并且安装了 `Homebrew <https://brew.sh/>`_ 软件包管理器。"

#~ msgid "Downloads"
#~ msgstr "下载"

#~ msgid ""
#~ "`Prometheus <https://prometheus.io/>`_ is used "
#~ "for data collection, while `Grafana "
#~ "<https://grafana.com/>`_ will enable you to"
#~ " visualize the collected data. They "
#~ "are both well integrated with `Ray "
#~ "<https://www.ray.io/>`_ which Flower uses "
#~ "under the hood."
#~ msgstr ""
#~ "`Prometheus <https://prometheus.io/>`_ 用于收集数据，而 "
#~ "`Grafana <https://grafana.com/>`_ 则能让你将收集到的数据可视化。它们都与 "
#~ "Flower 在引擎下使用的 `Ray <https://www.ray.io/>`_ "
#~ "紧密集成。"

#~ msgid ""
#~ "Overwrite the configuration files (depending"
#~ " on your device, it might be "
#~ "installed on a different path)."
#~ msgstr "重写配置文件（根据设备的不同，可能安装在不同的路径上）。"

#~ msgid "If you are on an M1 Mac, it should be:"
#~ msgstr "如果你使用的是 M1 Mac，应该是这样："

#~ msgid "On the previous generation Intel Mac devices, it should be:"
#~ msgstr "在上一代英特尔 Mac 设备上，应该是这样："

#~ msgid ""
#~ "Open the respective configuration files "
#~ "and change them. Depending on your "
#~ "device, use one of the two "
#~ "following commands:"
#~ msgstr "打开相应的配置文件并修改它们。根据设备情况，使用以下两个命令之一："

#~ msgid ""
#~ "and then delete all the text in"
#~ " the file and paste a new "
#~ "Prometheus config you see below. You "
#~ "may adjust the time intervals to "
#~ "your requirements:"
#~ msgstr "然后删除文件中的所有文本，粘贴一个新的 Prometheus 配置文件，如下所示。您可以根据需要调整时间间隔："

#~ msgid ""
#~ "Now after you have edited the "
#~ "Prometheus configuration, do the same "
#~ "with the Grafana configuration files. "
#~ "Open those using one of the "
#~ "following commands as before:"
#~ msgstr "编辑完 Prometheus 配置后，请对 Grafana 配置文件执行同样的操作。与之前一样，使用以下命令之一打开这些文件："

#~ msgid ""
#~ "Your terminal editor should open and "
#~ "allow you to apply the following "
#~ "configuration as before."
#~ msgstr "您的终端编辑器应该会打开，并允许您像之前一样应用以下配置。"

#~ msgid ""
#~ "Congratulations, you just downloaded all "
#~ "the necessary software needed for "
#~ "metrics tracking. Now, let’s start it."
#~ msgstr "恭喜您，您刚刚下载了指标跟踪所需的所有软件。现在，让我们开始吧。"

#~ msgid "Tracking metrics"
#~ msgstr "跟踪指标"

#~ msgid ""
#~ "Before running your Flower simulation, "
#~ "you have to start the monitoring "
#~ "tools you have just installed and "
#~ "configured."
#~ msgstr "在运行 Flower 模拟之前，您必须启动刚刚安装和配置的监控工具。"

#~ msgid ""
#~ "Please include the following argument in"
#~ " your Python code when starting a "
#~ "simulation."
#~ msgstr "开始模拟时，请在 Python 代码中加入以下参数。"

#~ msgid "Now, you are ready to start your workload."
#~ msgstr "现在，您可以开始工作了。"

#~ msgid ""
#~ "Shortly after the simulation starts, you"
#~ " should see the following logs in "
#~ "your terminal:"
#~ msgstr "模拟启动后不久，您就会在终端中看到以下日志："

#~ msgid "You can look at everything at http://127.0.0.1:8265 ."
#~ msgstr "您可以在 `<http://127.0.0.1:8265>`_ 查看所有内容。"

#~ msgid ""
#~ "It's a Ray Dashboard. You can "
#~ "navigate to Metrics (on the left "
#~ "panel, the lowest option)."
#~ msgstr "这是一个 Ray Dashboard。您可以导航到 \"度量标准\"（左侧面板，最低选项）。"

#~ msgid ""
#~ "Or alternatively, you can just see "
#~ "them in Grafana by clicking on the"
#~ " right-up corner, “View in Grafana”."
#~ " Please note that the Ray dashboard"
#~ " is only accessible during the "
#~ "simulation. After the simulation ends, "
#~ "you can only use Grafana to "
#~ "explore the metrics. You can start "
#~ "Grafana by going to "
#~ "``http://localhost:3000/``."
#~ msgstr ""
#~ "或者，您也可以点击右上角的 \"在 Grafana 中查看\"，在 Grafana "
#~ "中查看它们。请注意，Ray 仪表盘只能在模拟期间访问。模拟结束后，您只能使用 Grafana "
#~ "浏览指标。您可以访问 ``http://localhost:3000/``启动 Grafana。"

#~ msgid ""
#~ "After you finish the visualization, stop"
#~ " Prometheus and Grafana. This is "
#~ "important as they will otherwise block,"
#~ " for example port ``3000`` on your"
#~ " machine as long as they are "
#~ "running."
#~ msgstr ""
#~ "完成可视化后，请停止 Prometheus 和 "
#~ "Grafana。这一点很重要，否则只要它们在运行，就会阻塞机器上的端口 :code:`3000`。"

#~ msgid "Resource allocation"
#~ msgstr "资源分配"

#~ msgid ""
#~ "You must understand how the Ray "
#~ "library works to efficiently allocate "
#~ "system resources to simulation clients "
#~ "on your own."
#~ msgstr "您必须了解 Ray 库是如何工作的，才能有效地为自己的仿真客户端分配系统资源。"

#~ msgid ""
#~ "Initially, the simulation (which Ray "
#~ "handles under the hood) starts by "
#~ "default with all the available resources"
#~ " on the system, which it shares "
#~ "among the clients. It doesn't mean "
#~ "it divides it equally among all of"
#~ " them, nor that the model training"
#~ " happens at all of them "
#~ "simultaneously. You will learn more "
#~ "about that in the later part of"
#~ " this blog. You can check the "
#~ "system resources by running the "
#~ "following:"
#~ msgstr ""
#~ "最初，模拟（由 Ray "
#~ "在引擎下处理）默认使用系统上的所有可用资源启动，并在客户端之间共享。但这并不意味着它会将资源平均分配给所有客户端，也不意味着模型训练会在所有客户端同时进行。您将在本博客的后半部分了解到更多相关信息。您可以运行以下命令检查系统资源："

#~ msgid "In Google Colab, the result you see might be similar to this:"
#~ msgstr "在 Google Colab 中，您看到的结果可能与此类似："

#~ msgid ""
#~ "However, you can overwrite the defaults."
#~ " When starting a simulation, do the"
#~ " following (you don't need to "
#~ "overwrite all of them):"
#~ msgstr "不过，您可以覆盖默认值。开始模拟时，请执行以下操作（不必全部覆盖）："

#~ msgid "Let’s also specify the resource for a single client."
#~ msgstr "我们还可以为单个客户指定资源。"

#~ msgid ""
#~ "Now comes the crucial part. Ray "
#~ "will start a new client only when"
#~ " it has all the required resources"
#~ " (such that they run in parallel) "
#~ "when the resources allow."
#~ msgstr "现在到了关键部分。只有在资源允许的情况下，Ray 才会在拥有所有所需资源（如并行运行）时启动新客户端。"

#~ msgid ""
#~ "In the example above, only one "
#~ "client will be run, so your "
#~ "clients won't run concurrently. Setting "
#~ "``client_num_gpus = 0.5`` would allow "
#~ "running two clients and therefore enable"
#~ " them to run concurrently. Be careful"
#~ " not to require more resources than"
#~ " available. If you specified "
#~ "``client_num_gpus = 2``, the simulation "
#~ "wouldn't start (even if you had 2"
#~ " GPUs but decided to set 1 in"
#~ " ``ray_init_args``)."
#~ msgstr ""
#~ "在上面的示例中，将只运行一个客户端，因此您的客户端不会并发运行。设置 :code:`client_num_gpus "
#~ "= 0.5` 将允许运行两个客户端，从而使它们能够并发运行。请注意，所需的资源不要超过可用资源。如果您指定 "
#~ ":code:`client_num_gpus = 2`，模拟将无法启动（即使您有 2 个"
#~ " GPU，但决定在 :code:`ray_init_args` 中设置为 1）。"

#~ msgid "Q: I don't see any metrics logged."
#~ msgstr "问：我没有看到任何指标记录。"

#~ msgid ""
#~ "A: The timeframe might not be "
#~ "properly set. The setting is in "
#~ "the top right corner (\"Last 30 "
#~ "minutes\" by default). Please change the"
#~ " timeframe to reflect the period when"
#~ " the simulation was running."
#~ msgstr "答：时间范围可能没有正确设置。设置在右上角（默认为 \"最后 30 分钟\"）。请更改时间框架，以反映模拟运行的时间段。"

#~ msgid ""
#~ "Q: I see “Grafana server not "
#~ "detected. Please make sure the Grafana"
#~ " server is running and refresh this"
#~ " page” after going to the Metrics "
#~ "tab in Ray Dashboard."
#~ msgstr "问：我看到 \"未检测到 Grafana 服务器。请确保 Grafana 服务器正在运行并刷新此页面\"。"

#~ msgid ""
#~ "A: You probably don't have Grafana "
#~ "running. Please check the running "
#~ "services"
#~ msgstr "答：您可能没有运行 Grafana。请检查正在运行的服务"

#~ msgid ""
#~ "Q: I see \"This site can't be "
#~ "reached\" when going to http://127.0.0.1:8265."
#~ msgstr "问：在访问 `<http://127.0.0.1:8265>`_时，我看到 \"无法访问该网站\"。"

#~ msgid ""
#~ "A: Either the simulation has already "
#~ "finished, or you still need to "
#~ "start Prometheus."
#~ msgstr "答：要么模拟已经完成，要么您还需要启动Prometheus。"

#~ msgid "Resources"
#~ msgstr "资源"

#~ msgid ""
#~ "Ray Dashboard: https://docs.ray.io/en/latest/ray-"
#~ "observability/getting-started.html"
#~ msgstr "Ray 仪表盘: `<https://docs.ray.io/en/latest/ray-core/ray-dashboard.html>`_"

#~ msgid "Ray Metrics: https://docs.ray.io/en/latest/cluster/metrics.html"
#~ msgstr ""
#~ "Ray 指标: `<https://docs.ray.io/en/latest/ray-"
#~ "observability/ray-metrics.html>`_"

#~ msgid ""
#~ "The ``VirtualClientEngine`` schedules, launches "
#~ "and manages `virtual` clients. These "
#~ "clients are identical to `non-virtual`"
#~ " clients (i.e. the ones you launch"
#~ " via the command `flwr.client.start_client "
#~ "<ref-api-flwr.html#start-client>`_) in the"
#~ " sense that they can be configure "
#~ "by creating a class inheriting, for "
#~ "example, from `flwr.client.NumPyClient <ref-"
#~ "api-flwr.html#flwr.client.NumPyClient>`_ and therefore"
#~ " behave in an identical way. In "
#~ "addition to that, clients managed by "
#~ "the ``VirtualClientEngine`` are:"
#~ msgstr ""
#~ ":code:`VirtualClientEngine`用来规划，启动和管理`虚拟`客户端。这些客户端跟`非虚拟`客户端是一样的（即为您通过`flwr.client.start_client"
#~ " <ref-api-flwr.html#start-"
#~ "client>`_启动的客户端），因为它们可以通过创建一个继承自 `flwr.client.NumPyClient "
#~ "<ref-api-flwr.html#flwr.client.NumPyClient>`_ "
#~ "的类进行配置，因此其行为方式相同。另外，由 `VirtualClientEngine` 管理的客户端有："

#~ msgid ""
#~ "Running Flower simulations still require "
#~ "you to define your client class, a"
#~ " strategy, and utility functions to "
#~ "download and load (and potentially "
#~ "partition) your dataset. With that out"
#~ " of the way, launching your "
#~ "simulation is done with `start_simulation "
#~ "<ref-api-flwr.html#flwr.simulation.start_simulation>`_ "
#~ "and a minimal example looks as "
#~ "follows:"
#~ msgstr ""
#~ "运行 Flower "
#~ "模拟器仍然需要定义客户端类、策略以及下载和加载（可能还需要分割）数据集的实用程序。在完成这些工作后，就可以使用 "
#~ "\"start_simulation <ref-api-"
#~ "flwr.html#flwr.simulation.start_simulation>`_\" "
#~ "来启动模拟了，一个最简单的示例如下："

#~ msgid ""
#~ "By default the VCE has access to"
#~ " all system resources (i.e. all CPUs,"
#~ " all GPUs, etc) since that is "
#~ "also the default behavior when starting"
#~ " Ray. However, in some settings you"
#~ " might want to limit how many "
#~ "of your system resources are used "
#~ "for simulation. You can do this "
#~ "via the ``ray_init_args`` input argument "
#~ "to ``start_simulation`` which the VCE "
#~ "internally passes to Ray's ``ray.init`` "
#~ "command. For a complete list of "
#~ "settings you can configure check the "
#~ "`ray.init <https://docs.ray.io/en/latest/ray-"
#~ "core/api/doc/ray.init.html#ray-init>`_ documentation. "
#~ "Do not set ``ray_init_args`` if you "
#~ "want the VCE to use all your "
#~ "system's CPUs and GPUs."
#~ msgstr ""
#~ "默认情况下，VCE 可以访问所有系统资源（即所有 CPU、所有 GPU 等），因为这也是启动"
#~ " Ray 时的默认行为。不过，在某些设置中，您可能希望限制有多少系统资源用于模拟。您可以通过 "
#~ ":code:`ray_init_args` 输入到 :code:`start_simulation` "
#~ "的参数来做到这一点，VCE 会在内部将该参数传递给 Ray 的 "
#~ ":code:`ray.init` 命令。有关您可以配置的设置的完整列表，请查看 `ray.init "
#~ "<https://docs.ray.io/en/latest/ray-core/api/doc/ray.init.html"
#~ "#ray-init>`_ 文档。如果希望 VCE 使用系统中所有的 CPU "
#~ "和 GPU，请不要设置 :code:`ray_init_args`。"

#~ msgid ""
#~ "By default the ``VirtualClientEngine`` assigns"
#~ " a single CPU core (and nothing "
#~ "else) to each virtual client. This "
#~ "means that if your system has 10"
#~ " cores, that many virtual clients can"
#~ " be concurrently running."
#~ msgstr ""
#~ "默认情况下，:code:`VirtualClientEngine` 会为每个虚拟客户端分配一个 CPU "
#~ "内核（不分配其他任何内核）。这意味着，如果系统有 10 个内核，那么可以同时运行这么多虚拟客户端。"

#~ msgid "``num_cpus`` indicates the number of CPU cores a client would get."
#~ msgstr ":code:`num_cpus` 表示客户端将获得的 CPU 内核数量。"

#~ msgid ""
#~ "``num_gpus`` indicates the **ratio** of "
#~ "GPU memory a client gets assigned."
#~ msgstr ":code:`num_gpus` 表示分配给客户端的 GPU 内存的**比例**。"

#~ msgid "Let's see a few examples:"
#~ msgstr "让我们来看几个例子："

#~ msgid ""
#~ "To understand all the intricate details"
#~ " on how resources are used to "
#~ "schedule FL clients and how to "
#~ "define custom resources, please take a"
#~ " look at the `Ray documentation "
#~ "<https://docs.ray.io/en/latest/ray-"
#~ "core/scheduling/resources.html>`_."
#~ msgstr ""
#~ "要了解资源如何用于调度 FL 客户端以及如何定义自定义资源的所有复杂细节，请查看 `Ray "
#~ "文档 <https://docs.ray.io/en/latest/ray-"
#~ "core/scheduling/resources.html>`_。"

#~ msgid ""
#~ "A few ready-to-run complete "
#~ "examples for Flower simulation in "
#~ "Tensorflow/Keras and PyTorch are provided "
#~ "in the `Flower repository "
#~ "<https://github.com/adap/flower>`_. You can run "
#~ "them on Google Colab too:"
#~ msgstr ""
#~ "在 Tensorflow/Keras 和 PyTorch 中进行 Flower"
#~ " 模拟的几个可随时运行的完整示例已在 `Flower 库 "
#~ "<https://github.com/adap/flower>`_ 中提供。您也可以在 Google "
#~ "Colab 上运行它们："

#~ msgid ""
#~ "`Tensorflow/Keras Simulation "
#~ "<https://github.com/adap/flower/tree/main/examples/simulation-"
#~ "tensorflow>`_: 100 clients collaboratively "
#~ "train a MLP model on MNIST."
#~ msgstr ""
#~ "Tensorflow/Keras模拟 "
#~ "<https://github.com/adap/flower/tree/main/examples/simulation-"
#~ "tensorflow>`_：100个客户端在MNIST上协作训练一个MLP模型。"

#~ msgid ""
#~ "`PyTorch Simulation "
#~ "<https://github.com/adap/flower/tree/main/examples/simulation-"
#~ "pytorch>`_: 100 clients collaboratively train"
#~ " a CNN model on MNIST."
#~ msgstr ""
#~ "PyTorch 模拟 "
#~ "<https://github.com/adap/flower/tree/main/examples/simulation-"
#~ "pytorch>`_：100 个客户端在 MNIST 上协作训练一个 CNN "
#~ "模型。"

#~ msgid ""
#~ "Have a copy of your dataset in "
#~ "all nodes (more about this in "
#~ ":ref:`simulation considerations <considerations-"
#~ "for-simulations>`)"
#~ msgstr ""
#~ "在所有节点中都有一份数据集副本（更多相关信息请参阅 :ref:`模拟注意事项<considerations-"
#~ "for-simulations>`）"

#~ msgid ""
#~ "Pass ``ray_init_args={\"address\"=\"auto\"}`` to "
#~ "`start_simulation <ref-api-"
#~ "flwr.html#flwr.simulation.start_simulation>`_ so the "
#~ "``VirtualClientEngine`` attaches to a running"
#~ " Ray instance."
#~ msgstr ""
#~ "将 :code:`ray_init_args={\"address\"=\"auto\"}`传递给 "
#~ "`start_simulation <ref-api-"
#~ "flwr.html#flwr.simulation.start_simulation>`_ ，这样 "
#~ ":code:`VirtualClientEngine`就会连接到正在运行的 Ray 实例。"

#~ msgid "Multi-node simulation good-to-know"
#~ msgstr "了解多节点模拟"

#~ msgid ""
#~ "Here we list a few interesting "
#~ "functionality when running multi-node FL"
#~ " simulations:"
#~ msgstr "在此，我们列举了运行多节点 FL 模拟时的一些有趣功能："

#~ msgid ""
#~ "User ``ray status`` to check all "
#~ "nodes connected to your head node "
#~ "as well as the total resources "
#~ "available to the ``VirtualClientEngine``."
#~ msgstr ""
#~ "使用 :code:`ray status` 查看连接到头部节点的所有节点，以及 "
#~ ":code:`VirtualClientEngine` 可用的总资源。"

#~ msgid "Considerations for simulations"
#~ msgstr "模拟的注意事项"

#~ msgid ""
#~ "We are actively working on these "
#~ "fronts so to make it trivial to"
#~ " run any FL workload with Flower "
#~ "simulation."
#~ msgstr "我们正在积极开展这些方面的工作，以便使 FL 工作负载与 Flower 模拟的运行变得轻而易举。"

#~ msgid ""
#~ "The current VCE allows you to run"
#~ " Federated Learning workloads in simulation"
#~ " mode whether you are prototyping "
#~ "simple scenarios on your personal laptop"
#~ " or you want to train a complex"
#~ " FL pipeline across multiple high-"
#~ "performance GPU nodes. While we add "
#~ "more capabilities to the VCE, the "
#~ "points below highlight some of the "
#~ "considerations to keep in mind when "
#~ "designing your FL pipeline with Flower."
#~ " We also highlight a couple of "
#~ "current limitations in our implementation."
#~ msgstr ""
#~ "当前的 VCE "
#~ "允许您在模拟模式下运行联邦学习工作负载，无论您是在个人笔记本电脑上建立简单的场景原型，还是要在多个高性能 GPU "
#~ "节点上训练复杂的 FL情景。虽然我们为 VCE 增加了更多的功能，但以下几点强调了在使用 "
#~ "Flower 设计 FL 时需要注意的一些事项。我们还强调了我们的实现中目前存在的一些局限性。"

#~ msgid "GPU resources"
#~ msgstr "GPU 资源"

#~ msgid ""
#~ "The VCE assigns a share of GPU "
#~ "memory to a client that specifies "
#~ "the key ``num_gpus`` in ``client_resources``."
#~ " This being said, Ray (used "
#~ "internally by the VCE) is by "
#~ "default:"
#~ msgstr ""
#~ "VCE 会为指定 :code:`client_resources` 中 "
#~ ":code:`num_gpus` 关键字的客户端分配 GPU 内存份额。也就是说，Ray（VCE "
#~ "内部使用）是默认的："

#~ msgid ""
#~ "not aware of the total VRAM "
#~ "available on the GPUs. This means "
#~ "that if you set ``num_gpus=0.5`` and "
#~ "you have two GPUs in your system"
#~ " with different (e.g. 32GB and 8GB)"
#~ " VRAM amounts, they both would run"
#~ " 2 clients concurrently."
#~ msgstr ""
#~ "不知道 GPU 上可用的总 VRAM。这意味着，如果您设置 "
#~ ":code:`num_gpus=0.5`，而系统中有两个不同（如 32GB 和 8GB）VRAM "
#~ "的 GPU，它们都将同时运行 2 个客户端。"

#~ msgid ""
#~ "not aware of other unrelated (i.e. "
#~ "not created by the VCE) workloads "
#~ "are running on the GPU. Two "
#~ "takeaways from this are:"
#~ msgstr "不知道 GPU 上正在运行其他无关（即不是由 VCE 创建）的工作负载。从中可以得到以下两点启示："

#~ msgid ""
#~ "Your Flower server might need a "
#~ "GPU to evaluate the `global model` "
#~ "after aggregation (by instance when "
#~ "making use of the `evaluate method "
#~ "<how-to-implement-strategies.html#the-"
#~ "evaluate-method>`_)"
#~ msgstr ""
#~ "您的 Flower 服务器可能需要 GPU 来评估聚合后的 "
#~ "\"全局模型\"（例如在使用 \"评估方法\"<how-to-implement-"
#~ "strategies.html#the-evaluate-method>`_时）"

#~ msgid ""
#~ "If you want to run several "
#~ "independent Flower simulations on the "
#~ "same machine you need to mask-out"
#~ " your GPUs with "
#~ "``CUDA_VISIBLE_DEVICES=\"<GPU_IDs>\"`` when launching "
#~ "your experiment."
#~ msgstr ""
#~ "如果您想在同一台机器上运行多个独立的 Flower 模拟，则需要在启动实验时使用 "
#~ ":code:`CUDA_VISIBLE_DEVICES=\"<GPU_IDs>\"` 屏蔽 GPU。"

#~ msgid ""
#~ "In addition, the GPU resource limits "
#~ "passed to ``client_resources`` are not "
#~ "`enforced` (i.e. they can be exceeded)"
#~ " which can result in the situation"
#~ " of client using more VRAM than "
#~ "the ratio specified when starting the"
#~ " simulation."
#~ msgstr ""
#~ "此外，传递给 :code:`client_resources` 的 GPU 资源限制并不是"
#~ " \"强制 \"的（即可以超出），这可能导致客户端使用的 VRAM 超过启动模拟时指定的比例。"

#~ msgid "TensorFlow with GPUs"
#~ msgstr "使用 GPU 的 TensorFlow"

#~ msgid ""
#~ "When `using a GPU with TensorFlow "
#~ "<https://www.tensorflow.org/guide/gpu>`_ nearly your "
#~ "entire GPU memory of all your GPUs"
#~ " visible to the process will be "
#~ "mapped. This is done by TensorFlow "
#~ "for optimization purposes. However, in "
#~ "settings such as FL simulations where"
#~ " we want to split the GPU into"
#~ " multiple `virtual` clients, this is "
#~ "not a desirable mechanism. Luckily we"
#~ " can disable this default behavior by"
#~ " `enabling memory growth "
#~ "<https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth>`_."
#~ msgstr ""
#~ "在 TensorFlow <https://www.tensorflow.org/guide/gpu>`_ "
#~ "中使用 GPU 时，几乎所有进程可见的 GPU 内存都将被映射。TensorFlow "
#~ "这样做是出于优化目的。然而，在 FL 模拟等设置中，我们希望将 GPU 分割成多个 "
#~ "\"虚拟 \"客户端，这并不是一个理想的机制。幸运的是，我们可以通过 `启用内存增长 "
#~ "<https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth>`_来禁用这一默认行为。"

#~ msgid ""
#~ "This would need to be done in "
#~ "the main process (which is where "
#~ "the server would run) and in each"
#~ " Actor created by the VCE. By "
#~ "means of ``actor_kwargs`` we can pass"
#~ " the reserved key `\"on_actor_init_fn\"` in"
#~ " order to specify a function to "
#~ "be executed upon actor initialization. "
#~ "In this case, to enable GPU growth"
#~ " for TF workloads. It would look "
#~ "as follows:"
#~ msgstr ""
#~ "这需要在主进程（也就是服务器运行的地方）和 VCE 创建的每个角色中完成。通过 "
#~ ":code:`actor_kwargs`，我们可以传递保留关键字`\"on_actor_init_fn\"`，以指定在角色初始化时执行的函数。在本例中，为了使"
#~ " TF 工作负载的 GPU 增长，它看起来如下："

#~ msgid ""
#~ "This is precisely the mechanism used "
#~ "in `Tensorflow/Keras Simulation "
#~ "<https://github.com/adap/flower/tree/main/examples/simulation-"
#~ "tensorflow>`_ example."
#~ msgstr ""
#~ "这正是 \"Tensorflow/Keras 模拟 "
#~ "<https://github.com/adap/flower/tree/main/examples/simulation-"
#~ "tensorflow>`_\"示例中使用的机制。"

#~ msgid "Multi-node setups"
#~ msgstr "多节点设置"

#~ msgid ""
#~ "The VCE does not currently offer a"
#~ " way to control on which node a"
#~ " particular `virtual` client is executed."
#~ " In other words, if more than a"
#~ " single node have the resources "
#~ "needed by a client to run, then"
#~ " any of those nodes could get "
#~ "the client workload scheduled onto. "
#~ "Later in the FL process (i.e. in"
#~ " a different round) the same client"
#~ " could be executed by a different "
#~ "node. Depending on how your clients "
#~ "access their datasets, this might "
#~ "require either having a copy of "
#~ "all dataset partitions on all nodes "
#~ "or a dataset serving mechanism (e.g. "
#~ "using nfs, a database) to circumvent "
#~ "data duplication."
#~ msgstr ""
#~ "VCE 目前不提供控制特定 \"虚拟 "
#~ "\"客户端在哪个节点上执行的方法。换句话说，如果不止一个节点拥有客户端运行所需的资源，那么这些节点中的任何一个都可能被调度到客户端工作负载上。在"
#~ " FL "
#~ "进程的稍后阶段（即在另一轮中），同一客户端可以由不同的节点执行。根据客户访问数据集的方式，这可能需要在所有节点上复制所有数据集分区，或采用数据集服务机制（如使用"
#~ " nfs 或数据库）来避免数据重复。"

#~ msgid ""
#~ "By definition virtual clients are "
#~ "`stateless` due to their ephemeral "
#~ "nature. A client state can be "
#~ "implemented as part of the Flower "
#~ "client class but users need to "
#~ "ensure this saved to persistent storage"
#~ " (e.g. a database, disk) and that "
#~ "can be retrieve later by the same"
#~ " client regardless on which node it"
#~ " is running from. This is related "
#~ "to the point above also since, in"
#~ " some way, the client's dataset could"
#~ " be seen as a type of `state`."
#~ msgstr ""
#~ "根据定义，虚拟客户端是 \"无状态 \"的，因为它们具有即时性。客户机状态可以作为 Flower "
#~ "客户机类的一部分来实现，但用户需要确保将其保存到持久存储（如数据库、磁盘）中，而且无论客户机在哪个节点上运行，都能在以后检索到。这也与上述观点有关，因为在某种程度上，客户端的数据集可以被视为一种"
#~ " \"状态\"。"

#~ msgid ""
#~ "This creates a strategy with all "
#~ "parameters left at their default values"
#~ " and passes it to the "
#~ "``start_server`` function. It is usually "
#~ "recommended to adjust a few parameters"
#~ " during instantiation:"
#~ msgstr "这会创建一个所有参数都保持默认值的策略，并将其传递给 :code:`start_server` 函数。通常建议在实例化过程中调整一些参数："

#~ msgid "Legacy example guides"
#~ msgstr "旧版指南范例"

#~ msgid "flwr is the Flower command line interface."
#~ msgstr "注册 Flower ClientProxy 实例。"

#~ msgid "Options"
#~ msgstr "解决方案"

#~ msgid "Install completion for the current shell."
#~ msgstr "当前运行的标识符。"

#~ msgid ""
#~ "Show completion for the current shell,"
#~ " to copy it or customize the "
#~ "installation."
#~ msgstr ""

#~ msgid "Build a Flower App into a Flower App Bundle (FAB)."
#~ msgstr ""

#~ msgid ""
#~ "You can run ``flwr build`` without "
#~ "any arguments to bundle the app "
#~ "located in the current directory. "
#~ "Alternatively, you can you can specify"
#~ " a path using the ``--app`` option"
#~ " to bundle an app located at "
#~ "the provided path. For example:"
#~ msgstr ""

#~ msgid "``flwr build --app ./apps/flower-hello-world``."
#~ msgstr ""

#~ msgid "Path of the Flower App to bundle into a FAB"
#~ msgstr ""

#~ msgid "Install a Flower App Bundle."
#~ msgstr "安装Flower"

#~ msgid "It can be ran with a single FAB file argument:"
#~ msgstr ""

#~ msgid "``flwr install ./target_project.fab``"
#~ msgstr ""

#~ msgid "The target install directory can be specified with ``--flwr-dir``:"
#~ msgstr ""

#~ msgid "``flwr install ./target_project.fab --flwr-dir ./docs/flwr``"
#~ msgstr ""

#~ msgid ""
#~ "This will install ``target_project`` to "
#~ "``./docs/flwr/``. By default, ``flwr-dir`` "
#~ "is equal to:"
#~ msgstr ""

#~ msgid "``$FLWR_HOME/`` if ``$FLWR_HOME`` is defined"
#~ msgstr ""

#~ msgid "``$XDG_DATA_HOME/.flwr/`` if ``$XDG_DATA_HOME`` is defined"
#~ msgstr ""

#~ msgid "``$HOME/.flwr/`` in all other cases"
#~ msgstr ""

#~ msgid "The desired install path."
#~ msgstr ""

#~ msgid "Arguments"
#~ msgstr "参数解析器"

#~ msgid "Optional argument"
#~ msgstr "可选的改进措施"

#~ msgid "The source FAB file to install."
#~ msgstr ""

#~ msgid "Get logs from a Flower project run."
#~ msgstr ""

#~ msgid "Flag to stream or print logs from the Flower run"
#~ msgstr ""

#~ msgid "default"
#~ msgstr "工作流程"

#~ msgid "``True``"
#~ msgstr ""

#~ msgid "Required argument"
#~ msgstr "构建文档"

#~ msgid "The Flower run ID to query"
#~ msgstr "加入 Flower 社区"

#~ msgid "Path of the Flower project to run"
#~ msgstr ""

#~ msgid "Name of the federation to run the app on"
#~ msgstr ""

#~ msgid "Create new Flower App."
#~ msgstr "Flower 服务器。"

#~ msgid "The ML framework to use"
#~ msgstr ""

#~ msgid "options"
#~ msgstr "解决方案"

#~ msgid ""
#~ "PyTorch | TensorFlow | sklearn | "
#~ "HuggingFace | JAX | MLX | NumPy"
#~ " | FlowerTune | Flower Baseline"
#~ msgstr ""

#~ msgid "The Flower username of the author"
#~ msgstr ""

#~ msgid "The name of the Flower App"
#~ msgstr "基础镜像的存储库名称。"

#~ msgid "Run Flower App."
#~ msgstr "Flower 服务器。"

#~ msgid "Override configuration key-value pairs, should be of the format:"
#~ msgstr ""

#~ msgid ""
#~ "`--run-config 'key1=\"value1\" key2=\"value2\"' "
#~ "--run-config 'key3=\"value3\"'`"
#~ msgstr ""

#~ msgid ""
#~ "Note that `key1`, `key2`, and `key3` "
#~ "in this example need to exist "
#~ "inside the `pyproject.toml` in order to"
#~ " be properly overriden."
#~ msgstr ""

#~ msgid ""
#~ "Use `--stream` with `flwr run` to "
#~ "display logs; logs are not streamed "
#~ "by default."
#~ msgstr ""

#~ msgid "``False``"
#~ msgstr "``FLWR_VERSION``"

#~ msgid "Path of the Flower App to run."
#~ msgstr "基础镜像的存储库名称。"

#~ msgid "Name of the federation to run the app on."
#~ msgstr ""

#~ msgid ""
#~ "Note that since version ``1.11.0``, "
#~ "``flower-server-app`` no longer supports"
#~ " passing a reference to a `ServerApp`"
#~ " attribute. Instead, you need to pass"
#~ " the path to Flower app via the"
#~ " argument ``--app``. This is the path"
#~ " to a directory containing a "
#~ "`pyproject.toml`. You can create a valid"
#~ " Flower app by executing ``flwr new``"
#~ " and following the prompt."
#~ msgstr ""

#~ msgid ""
#~ "A config (key/value mapping) held by "
#~ "the entity in a given run and "
#~ "that will stay local. It can be"
#~ " used at any point during the "
#~ "lifecycle of this entity (e.g. across"
#~ " multiple rounds)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`RUN_SUPEREXEC_ENTER "
#~ "<flwr.common.EventType.RUN_SUPEREXEC_ENTER>`\\"
#~ msgstr ""
#~ ":py:obj:`RUN_SUPERLINK_ENTER "
#~ "<flwr.common.EventType.RUN_SUPERLINK_ENTER>`\\"

#~ msgid ""
#~ ":py:obj:`RUN_SUPEREXEC_LEAVE "
#~ "<flwr.common.EventType.RUN_SUPEREXEC_LEAVE>`\\"
#~ msgstr ""
#~ ":py:obj:`RUN_SUPERLINK_LEAVE "
#~ "<flwr.common.EventType.RUN_SUPERLINK_LEAVE>`\\"

#~ msgid "Log error stating that module `ray` could not be imported."
#~ msgstr ""

#~ msgid ""
#~ "This tutorial will show you how to"
#~ " use Flower to build a federated "
#~ "version of an existing JAX workload. "
#~ "We are using JAX to train a "
#~ "linear regression model on a scikit-"
#~ "learn dataset. We will structure the "
#~ "example similar to our `PyTorch - "
#~ "From Centralized To Federated "
#~ "<https://github.com/adap/flower/blob/main/examples/pytorch-"
#~ "from-centralized-to-federated>`_ walkthrough. "
#~ "First, we build a centralized training"
#~ " approach based on the `Linear "
#~ "Regression with JAX "
#~ "<https://coax.readthedocs.io/en/latest/examples/linear_regression/jax.html>`_"
#~ " tutorial`. Then, we build upon the"
#~ " centralized training code to run the"
#~ " training in a federated fashion."
#~ msgstr ""
#~ "本教程将向您展示如何使用 Flower 构建现有 JAX 的联邦学习版本。我们将使用 "
#~ "JAX 在 scikit-learn 数据集上训练线性回归模型。我们将采用与 "
#~ "`PyTorch - 从集中式到联邦式 "
#~ "<https://github.com/adap/flower/blob/main/examples/pytorch-"
#~ "from-centralized-to-federated>`_ "
#~ "教程中类似的示例结构。首先，我们根据 `JAX 的线性回归 "
#~ "<https://coax.readthedocs.io/en/latest/examples/linear_regression/jax.html>`_"
#~ " 教程构建集中式训练方法。然后，我们在集中式训练代码的基础上以联邦方式运行训练。"

#~ msgid ""
#~ "Before we start building our JAX "
#~ "example, we need install the packages"
#~ " ``jax``, ``jaxlib``, ``scikit-learn``, and"
#~ " ``flwr``:"
#~ msgstr ""
#~ "在开始构建 JAX 示例之前，我们需要安装软件包 "
#~ ":code:`jax`、:code:`jaxlib`、:code:`scikit-learn` 和 "
#~ ":code:`flwr`："

#~ msgid "Linear Regression with JAX"
#~ msgstr "使用 JAX 进行线性回归"

#~ msgid ""
#~ "We begin with a brief description "
#~ "of the centralized training code based"
#~ " on a ``Linear Regression`` model. If"
#~ " you want a more in-depth "
#~ "explanation of what's going on then "
#~ "have a look at the official `JAX"
#~ " documentation <https://jax.readthedocs.io/>`_."
#~ msgstr ""
#~ "首先，我们将简要介绍基于 :code:`Linear Regression` "
#~ "模型的集中式训练代码。如果您想获得更深入的解释，请参阅官方的 `JAX 文档 "
#~ "<https://jax.readthedocs.io/>`_。"

#~ msgid ""
#~ "Let's create a new file called "
#~ "``jax_training.py`` with all the components"
#~ " required for a traditional (centralized)"
#~ " linear regression training. First, the "
#~ "JAX packages ``jax`` and ``jaxlib`` need"
#~ " to be imported. In addition, we "
#~ "need to import ``sklearn`` since we "
#~ "use ``make_regression`` for the dataset "
#~ "and ``train_test_split`` to split the "
#~ "dataset into a training and test "
#~ "set. You can see that we do "
#~ "not yet import the ``flwr`` package "
#~ "for federated learning. This will be "
#~ "done later."
#~ msgstr ""
#~ "让我们创建一个名为 :code:`jax_training.py` "
#~ "的新文件，其中包含传统（集中式）线性回归训练所需的所有组件。首先，需要导入 JAX 包 "
#~ ":code:`jax` 和 :code:`jaxlib`。此外，我们还需要导入 "
#~ ":code:`sklearn`，因为我们使用 :code:`make_regression` 创建数据集，并使用"
#~ " :code:`train_test_split` 将数据集拆分成训练集和测试集。您可以看到，我们还没有导入用于联邦学习的"
#~ " :code:`flwr` 软件包，这将在稍后完成。"

#~ msgid ""
#~ "The ``load_data()`` function loads the "
#~ "mentioned training and test sets."
#~ msgstr ":code:`load_data()` 函数会加载上述训练集和测试集。"

#~ msgid ""
#~ "The model architecture (a very simple"
#~ " ``Linear Regression`` model) is defined"
#~ " in ``load_model()``."
#~ msgstr ""
#~ "模型结构（一个非常简单的 :code:`Linear Regression` 线性回归模型）在 "
#~ ":code:`load_model()` 中定义。"

#~ msgid ""
#~ "We now need to define the training"
#~ " (function ``train()``), which loops over"
#~ " the training set and measures the"
#~ " loss (function ``loss_fn()``) for each "
#~ "batch of training examples. The loss "
#~ "function is separate since JAX takes "
#~ "derivatives with a ``grad()`` function "
#~ "(defined in the ``main()`` function and"
#~ " called in ``train()``)."
#~ msgstr ""
#~ "现在，我们需要定义训练函数（ :code:`train()`）。它循环遍历训练集，并计算每批训练数据的损失值（函数 "
#~ ":code:`loss_fn()`）。由于 JAX 使用 :code:`grad()` "
#~ "函数提取导数（在 :code:`main()` 函数中定义，并在 :code:`train()` "
#~ "中调用），因此损失函数是独立的。"

#~ msgid ""
#~ "The evaluation of the model is "
#~ "defined in the function ``evaluation()``. "
#~ "The function takes all test examples "
#~ "and measures the loss of the "
#~ "linear regression model."
#~ msgstr "模型的评估在函数 :code:`evaluation()` 中定义。该函数获取所有测试数据，并计算线性回归模型的损失值。"

#~ msgid ""
#~ "Having defined the data loading, model"
#~ " architecture, training, and evaluation we"
#~ " can put everything together and "
#~ "train our model using JAX. As "
#~ "already mentioned, the ``jax.grad()`` function"
#~ " is defined in ``main()`` and passed"
#~ " to ``train()``."
#~ msgstr ""
#~ "在定义了数据加载、模型架构、训练和评估之后，我们就可以把这些放在一起，使用 JAX "
#~ "训练我们的模型了。如前所述，:code:`jax.grad()` 函数在 :code:`main()` "
#~ "中定义，并传递给 :code:`train()`。"

#~ msgid "You can now run your (centralized) JAX linear regression workload:"
#~ msgstr "现在您可以运行（集中式）JAX 线性回归工作了："

#~ msgid ""
#~ "So far this should all look fairly"
#~ " familiar if you've used JAX before."
#~ " Let's take the next step and "
#~ "use what we've built to create a"
#~ " simple federated learning system "
#~ "consisting of one server and two "
#~ "clients."
#~ msgstr ""
#~ "到目前为止，如果你以前使用过 "
#~ "JAX，就会对这一切感到很熟悉。下一步，让我们利用已构建的代码创建一个简单的联邦学习系统（一个服务器和两个客户端）。"

#~ msgid "JAX meets Flower"
#~ msgstr "JAX 结合 Flower"

#~ msgid ""
#~ "The concept of federating an existing"
#~ " workload is always the same and "
#~ "easy to understand. We have to "
#~ "start a *server* and then use the"
#~ " code in ``jax_training.py`` for the "
#~ "*clients* that are connected to the "
#~ "*server*. The *server* sends model "
#~ "parameters to the clients. The *clients*"
#~ " run the training and update the "
#~ "parameters. The updated parameters are "
#~ "sent back to the *server*, which "
#~ "averages all received parameter updates. "
#~ "This describes one round of the "
#~ "federated learning process, and we "
#~ "repeat this for multiple rounds."
#~ msgstr ""
#~ "把现有工作联邦化的概念始终是相同的，也很容易理解。我们要启动一个*服务器*，然后对连接到*服务器*的*客户端*运行 "
#~ ":code:`jax_training.py`中的代码。*服务器*向客户端发送模型参数，*客户端*运行训练并更新参数。更新后的参数被发回*服务器*，然后服务器对所有收到的参数进行平均聚合。以上的描述构成了一轮联邦学习，我们将重复进行多轮学习。"

#~ msgid ""
#~ "Finally, we will define our *client* "
#~ "logic in ``client.py`` and build upon"
#~ " the previously defined JAX training "
#~ "in ``jax_training.py``. Our *client* needs "
#~ "to import ``flwr``, but also ``jax`` "
#~ "and ``jaxlib`` to update the parameters"
#~ " on our JAX model:"
#~ msgstr ""
#~ "最后，我们将在 :code:`client.py` 中定义我们的 *client* "
#~ "逻辑，并以之前在 :code:`jax_training.py` 中定义的 JAX "
#~ "训练为基础。我们的 *client* 需要导入 :code:`flwr`，还需要导入 "
#~ ":code:`jax` 和 :code:`jaxlib` 以更新 JAX "
#~ "模型的参数："

#~ msgid ""
#~ "Implementing a Flower *client* basically "
#~ "means implementing a subclass of either"
#~ " ``flwr.client.Client`` or ``flwr.client.NumPyClient``."
#~ " Our implementation will be based on"
#~ " ``flwr.client.NumPyClient`` and we'll call "
#~ "it ``FlowerClient``. ``NumPyClient`` is "
#~ "slightly easier to implement than "
#~ "``Client`` if you use a framework "
#~ "with good NumPy interoperability (like "
#~ "JAX) because it avoids some of the"
#~ " boilerplate that would otherwise be "
#~ "necessary. ``FlowerClient`` needs to implement"
#~ " four methods, two methods for "
#~ "getting/setting model parameters, one method"
#~ " for training the model, and one "
#~ "method for testing the model:"
#~ msgstr ""
#~ "实现一个 Flower *client*基本上意味着去实现一个 "
#~ ":code:`flwr.client.Client` 或 "
#~ ":code:`flwr.client.NumPyClient` 的子类。我们的代码实现将基于 "
#~ ":code:`flwr.client.NumPyClient`，并将其命名为 "
#~ ":code:`FlowerClient`。如果使用具有良好 NumPy 互操作性的框架（如 "
#~ "JAX），:code:`NumPyClient` 比 "
#~ ":code:`Client`更容易实现，因为它避免了一些不必要的操作。:code:`FlowerClient` "
#~ "需要实现四个方法，两个用于获取/设置模型参数，一个用于训练模型，一个用于测试模型："

#~ msgid "``set_parameters (optional)``"
#~ msgstr ":code:`set_parameters (可选)`"

#~ msgid "transform parameters to NumPy ``ndarray``'s"
#~ msgstr "将参数转换为 NumPy :code:`ndarray`格式"

#~ msgid "get the updated local model parameters and return them to the server"
#~ msgstr "获取更新后的本地模型参数并返回服务器"

#~ msgid "return the local loss to the server"
#~ msgstr "向服务器返回本地损失值"

#~ msgid ""
#~ "The challenging part is to transform "
#~ "the JAX model parameters from "
#~ "``DeviceArray`` to ``NumPy ndarray`` to "
#~ "make them compatible with `NumPyClient`."
#~ msgstr ""
#~ "具有挑战性的部分是将 JAX 模型参数从 :code:`DeviceArray` 转换为"
#~ " :code:`NumPy ndarray`，使其与 `NumPyClient` 兼容。"

#~ msgid ""
#~ "The two ``NumPyClient`` methods ``fit`` "
#~ "and ``evaluate`` make use of the "
#~ "functions ``train()`` and ``evaluate()`` "
#~ "previously defined in ``jax_training.py``. So"
#~ " what we really do here is we"
#~ " tell Flower through our ``NumPyClient``"
#~ " subclass which of our already "
#~ "defined functions to call for training"
#~ " and evaluation. We included type "
#~ "annotations to give you a better "
#~ "understanding of the data types that "
#~ "get passed around."
#~ msgstr ""
#~ "这两个 :code:`NumPyClient` 方法 :code:`fit` 和 "
#~ ":code:`evaluate` 使用了之前在 :code:`jax_training.py` "
#~ "中定义的函数 :code:`train()` 和 "
#~ ":code:`evaluate()`。因此，我们在这里要做的就是通过 :code:`NumPyClient` "
#~ "子类告知 Flower 在训练和评估时要调用哪些已定义的函数。我们加入了类型注解，以便让您更好地理解传递的数据类型。"

#~ msgid "Having defined the federation process, we can run it."
#~ msgstr "定义了联邦进程后，我们就可以运行它了。"

#~ msgid ""
#~ "in each window (make sure that the"
#~ " server is still running before you"
#~ " do so) and see your JAX "
#~ "project run federated learning across "
#~ "two clients. Congratulations!"
#~ msgstr "确保服务器仍在运行，然后在每个客户端窗口就能看到你的 JAX 项目在两个客户端上运行联邦学习了。祝贺!"

#~ msgid ""
#~ "The source code of this example "
#~ "was improved over time and can be"
#~ " found here: `Quickstart JAX "
#~ "<https://github.com/adap/flower/blob/main/examples/quickstart-"
#~ "jax>`_. Our example is somewhat over-"
#~ "simplified because both clients load the"
#~ " same dataset."
#~ msgstr ""
#~ "此示例的源代码经过长期改进，可在此处找到： `Quickstart JAX "
#~ "<https://github.com/adap/flower/blob/main/examples/quickstart-"
#~ "jax>`_。我们的示例有些过于简单，因为两个客户端都加载了相同的数据集。"

#~ msgid ""
#~ "You're now prepared to explore this "
#~ "topic further. How about using a "
#~ "more sophisticated model or using a "
#~ "different dataset? How about adding more"
#~ " clients?"
#~ msgstr "现在，您已准备好进行更深一步探索了。例如使用更复杂的模型或使用不同的数据集会如何？增加更多客户端会如何？"

#~ msgid ""
#~ "In this tutorial, we will learn "
#~ "how to train a ``Logistic Regression``"
#~ " model on MNIST using Flower and "
#~ "scikit-learn."
#~ msgstr ""
#~ "在本教程中，我们将学习如何使用 Flower 和 scikit-learn 在"
#~ " MNIST 上训练一个 :code:`Logistic Regression` "
#~ "模型。"

#~ msgid ""
#~ "Our example consists of one *server* "
#~ "and two *clients* all having the "
#~ "same model."
#~ msgstr "我们的例子包括一个*服务器*和两个*客户端*，它们都有相同的模型。"

#~ msgid ""
#~ "*Clients* are responsible for generating "
#~ "individual model parameter updates for "
#~ "the model based on their local "
#~ "datasets. These updates are then sent"
#~ " to the *server* which will aggregate"
#~ " them to produce an updated global"
#~ " model. Finally, the *server* sends "
#~ "this improved version of the model "
#~ "back to each *client*. A complete "
#~ "cycle of parameters updates is called"
#~ " a *round*."
#~ msgstr "*客户端*负责根据其本地数据集为模型生成单独的模型参数更新。然后，这些参数更新将被发送到*服务器*，由*服务器*汇总后生成一个更新的全局模型。最后，*服务器*将这一改进版模型发回给每个*客户端*。一个完整的参数更新周期称为一*轮*。"

#~ msgid ""
#~ "Now that we have a rough idea "
#~ "of what is going on, let's get "
#~ "started. We first need to install "
#~ "Flower. You can do this by "
#~ "running:"
#~ msgstr "现在，我们已经有了一个大致的概念，让我们开始吧。首先，我们需要安装 Flower。运行："

#~ msgid "Since we want to use scikit-learn, let's go ahead and install it:"
#~ msgstr "既然我们要使用 scikt-learn，那就继续安装吧："

#~ msgid "Or simply install all dependencies using Poetry:"
#~ msgstr "或者直接使用 Poetry 安装所有依赖项："

#~ msgid ""
#~ "Now that we have all our "
#~ "dependencies installed, let's run a "
#~ "simple distributed training with two "
#~ "clients and one server. However, before"
#~ " setting up the client and server,"
#~ " we will define all functionalities "
#~ "that we need for our federated "
#~ "learning setup within ``utils.py``. The "
#~ "``utils.py`` contains different functions "
#~ "defining all the machine learning "
#~ "basics:"
#~ msgstr ""
#~ "现在我们已经安装了所有的依赖项，让我们用两个客户端和一个服务器来运行一个简单的分布式训练。不过，在设置客户端和服务器之前，我们将在 "
#~ ":code:`utils.py` "
#~ "中定义联邦学习设置所需的所有功能。:code:`utils.py`包含定义所有机器学习基础知识的不同函数："

#~ msgid "``get_model_parameters()``"
#~ msgstr ":code:`get_model_parameters()`"

#~ msgid "Returns the parameters of a ``sklearn`` LogisticRegression model"
#~ msgstr "返回 :code:`sklearn` LogisticRegression 模型的参数"

#~ msgid "``set_model_params()``"
#~ msgstr ":code:`set_model_params()`"

#~ msgid "Sets the parameters of a ``sklearn`` LogisticRegression model"
#~ msgstr "设置:code:`sklean`的LogisticRegression模型的参数"

#~ msgid "``set_initial_params()``"
#~ msgstr ":code:`set_initial_params()`"

#~ msgid "Initializes the model parameters that the Flower server will ask for"
#~ msgstr "初始化 Flower 服务器将要求的模型参数"

#~ msgid ""
#~ "Please check out ``utils.py`` `here "
#~ "<https://github.com/adap/flower/blob/main/examples/sklearn-"
#~ "logreg-mnist/utils.py>`_ for more details. "
#~ "The pre-defined functions are used "
#~ "in the ``client.py`` and imported. The"
#~ " ``client.py`` also requires to import "
#~ "several packages such as Flower and "
#~ "scikit-learn:"
#~ msgstr ""
#~ "更多详情请查看 :code:`utils.py`` 这里 "
#~ "<https://github.com/adap/flower/blob/main/examples/sklearn-"
#~ "logreg-mnist/utils.py>`_。在 :code:`client.py` "
#~ "中使用并导入了预定义函数。:code:`client.py` 还需要导入几个软件包，如 Flower 和"
#~ " scikit-learn："

#~ msgid ""
#~ "Prior to local training, we need "
#~ "to load the MNIST dataset, a "
#~ "popular image classification dataset of "
#~ "handwritten digits for machine learning, "
#~ "and partition the dataset for FL. "
#~ "This can be conveniently achieved using"
#~ " `Flower Datasets <https://flower.ai/docs/datasets>`_."
#~ " The ``FederatedDataset.load_partition()`` method "
#~ "loads the partitioned training set for"
#~ " each partition ID defined in the "
#~ "``--partition-id`` argument."
#~ msgstr ""
#~ "在本地训练之前，我们需要加载 MNIST 数据集（一个用于机器学习的流行手写数字图像分类数据集），并对数据集进行"
#~ " FL 分区。使用 \"Flower Datasets "
#~ "<https://flower.ai/docs/datasets>`_\"可以方便地实现这一点。:code:`FederatedDataset.load_partition()`"
#~ " 方法为 :code:`--partition-id` 参数中定义的每个分区 ID"
#~ " 加载分区训练集。"

#~ msgid ""
#~ "Next, the logistic regression model is"
#~ " defined and initialized with "
#~ "``utils.set_initial_params()``."
#~ msgstr "接下来，使用 :code:`utils.set_initial_params()` 对逻辑回归模型进行定义和初始化。"

#~ msgid ""
#~ "The Flower server interacts with clients"
#~ " through an interface called ``Client``."
#~ " When the server selects a particular"
#~ " client for training, it sends "
#~ "training instructions over the network. "
#~ "The client receives those instructions "
#~ "and calls one of the ``Client`` "
#~ "methods to run your code (i.e., to"
#~ " fit the logistic regression we "
#~ "defined earlier)."
#~ msgstr ""
#~ "Flower 服务器通过一个名为 :code:`Client` "
#~ "的接口与客户端交互。当服务器选择一个特定的客户端进行训练时，它会通过网络发送训练指令。客户端接收到这些指令后，会调用 "
#~ ":code:`Client` 方法之一来运行您的代码（即拟合我们之前定义的逻辑回归）。"

#~ msgid ""
#~ "Flower provides a convenience class "
#~ "called ``NumPyClient`` which makes it "
#~ "easier to implement the ``Client`` "
#~ "interface when your workload uses "
#~ "scikit-learn. Implementing ``NumPyClient`` "
#~ "usually means defining the following "
#~ "methods (``set_parameters`` is optional "
#~ "though):"
#~ msgstr ""
#~ "Flower 提供了一个名为 :code:`NumPyClient` 的便捷类，当你的工作负载使用"
#~ " scikit-learn 时，它可以让你更容易地实现 :code:`Client` "
#~ "接口。实现 :code:`NumPyClient` "
#~ "通常意味着定义以下方法（:code:`set_parameters` 是可选的）："

#~ msgid "return the model weight as a list of NumPy ndarrays"
#~ msgstr "以 NumPy ndarrays 列表形式返回模型参数"

#~ msgid "``set_parameters`` (optional)"
#~ msgstr ":code:`set_parameters` （可选）"

#~ msgid ""
#~ "update the local model weights with "
#~ "the parameters received from the server"
#~ msgstr "用从服务器接收到的参数更新本地模型参数"

#~ msgid "is directly imported with ``utils.set_model_params()``"
#~ msgstr "直接导入 :code:`utils.set_model_params()`"

#~ msgid "set the local model weights"
#~ msgstr "设置本地模型参数"

#~ msgid "train the local model"
#~ msgstr "训练本地模型"

#~ msgid "return the updated local model weights"
#~ msgstr "接收更新的本地模型参数"

#~ msgid "test the local model"
#~ msgstr "测试本地模型"

#~ msgid "The methods can be implemented in the following way:"
#~ msgstr "这些方法可以通过以下方式实现："

#~ msgid ""
#~ "We can now create an instance of"
#~ " our class ``MnistClient`` and add "
#~ "one line to actually run this "
#~ "client:"
#~ msgstr "现在我们可以创建一个 :code:`MnistClient` 类的实例，并添加一行来实际运行该客户端："

#~ msgid ""
#~ "That's it for the client. We only"
#~ " have to implement ``Client`` or "
#~ "``NumPyClient`` and call "
#~ "``fl.client.start_client()``. If you implement "
#~ "a client of type ``NumPyClient`` you'll"
#~ " need to first call its "
#~ "``to_client()`` method. The string "
#~ "``\"0.0.0.0:8080\"`` tells the client which"
#~ " server to connect to. In our "
#~ "case we can run the server and "
#~ "the client on the same machine, "
#~ "therefore we use ``\"0.0.0.0:8080\"``. If "
#~ "we run a truly federated workload "
#~ "with the server and clients running "
#~ "on different machines, all that needs"
#~ " to change is the ``server_address`` "
#~ "we pass to the client."
#~ msgstr ""
#~ "这就是客户端。我们只需实现 :code:`Client` 或 :code:`NumPyClient`"
#~ " 并调用 :code:`fl.client.start_client()` 或 "
#~ ":code:`fl.client.start_numpy_client()`。字符串 "
#~ ":code:`\"0.0.0.0:8080\"`会告诉客户端要连接的服务器。在本例中，我们可以在同一台机器上运行服务器和客户端，因此我们使用"
#~ " "
#~ ":code:`\"0.0.0.0:8080\"`。如果我们运行的是真正的联邦工作负载，服务器和客户端运行在不同的机器上，那么需要改变的只是传递给客户端的"
#~ " :code:`server_address`。"

#~ msgid ""
#~ "The following Flower server is a "
#~ "little bit more advanced and returns "
#~ "an evaluation function for the "
#~ "server-side evaluation. First, we import"
#~ " again all required libraries such as"
#~ " Flower and scikit-learn."
#~ msgstr ""
#~ "下面的 Flower 服务器更先进一些，会返回一个用于服务器端评估的评估函数。首先，我们再次导入所有需要的库，如"
#~ " Flower 和 scikit-learn。"

#~ msgid "``server.py``, import Flower and start the server:"
#~ msgstr ":code:`server.py`, 导入 Flower 并启动服务器："

#~ msgid ""
#~ "The number of federated learning rounds"
#~ " is set in ``fit_round()`` and the"
#~ " evaluation is defined in "
#~ "``get_evaluate_fn()``. The evaluation function "
#~ "is called after each federated learning"
#~ " round and gives you information "
#~ "about loss and accuracy. Note that "
#~ "we also make use of Flower "
#~ "Datasets here to load the test "
#~ "split of the MNIST dataset for "
#~ "server-side evaluation."
#~ msgstr ""
#~ "联邦学习轮数在 :code:`fit_round()` 中设置，评估在 "
#~ ":code:`get_evaluate_fn()` 中定义。每轮联邦学习后都会调用评估函数，并提供有关损失值和准确率的信息。"

#~ msgid ""
#~ "The ``main`` contains the server-side"
#~ " parameter initialization "
#~ "``utils.set_initial_params()`` as well as the"
#~ " aggregation strategy ``fl.server.strategy:FedAvg()``."
#~ " The strategy is the default one, "
#~ "federated averaging (or FedAvg), with "
#~ "two clients and evaluation after each"
#~ " federated learning round. The server "
#~ "can be started with the command "
#~ "``fl.server.start_server(server_address=\"0.0.0.0:8080\", "
#~ "strategy=strategy, "
#~ "config=fl.server.ServerConfig(num_rounds=3))``."
#~ msgstr ""
#~ ":code:`main`包含服务器端参数初始化:code:`utils.set_initial_params()`以及聚合策略 "
#~ ":code:`fl.server.strategy:FedAvg()`。该策略是默认的联邦平均（或 "
#~ "FedAvg）策略，有两个客户端，在每轮联邦学习后进行评估。可以使用 "
#~ ":code:`fl.server.start_server(server_address=\"0.0.0.0:8080\", "
#~ "strategy=strategy, config=fl.server.ServerConfig(num_rounds=3))`"
#~ " 命令启动服务器。"

#~ msgid ""
#~ "With both client and server ready, "
#~ "we can now run everything and see"
#~ " federated learning in action. Federated"
#~ " learning systems usually have a "
#~ "server and multiple clients. We, "
#~ "therefore, have to start the server "
#~ "first:"
#~ msgstr "客户端和服务器都准备就绪后，我们现在就可以运行一切，看看联邦学习的运行情况。联邦学习系统通常有一个服务器和多个客户端。因此，我们必须先启动服务器："

#~ msgid ""
#~ "Once the server is running we can"
#~ " start the clients in different "
#~ "terminals. Open a new terminal and "
#~ "start the first client:"
#~ msgstr "服务器运行后，我们就可以在不同终端启动客户端了。打开一个新终端，启动第一个客户端："

#~ msgid "Open another terminal and start the second client:"
#~ msgstr "打开另一台终端，启动第二个客户端："

#~ msgid ""
#~ "Each client will have its own "
#~ "dataset. You should now see how "
#~ "the training does in the very "
#~ "first terminal (the one that started "
#~ "the server):"
#~ msgstr "每个客户端都有自己的数据集。现在你应该看到第一个终端（启动服务器的终端）的训练效果了："

#~ msgid ""
#~ "Congratulations! You've successfully built and"
#~ " run your first federated learning "
#~ "system. The full `source code "
#~ "<https://github.com/adap/flower/tree/main/examples/sklearn-"
#~ "logreg-mnist>`_ for this example can "
#~ "be found in ``examples/sklearn-logreg-"
#~ "mnist``."
#~ msgstr ""
#~ "恭喜您！您已经成功构建并运行了第一个联邦学习系统。本示例的`完整源代码 "
#~ "<https://github.com/adap/flower/tree/main/examples/sklearn-"
#~ "logreg-mnist>`_ 可以在 :code:`examples/sklearn-"
#~ "logreg-mnist` 中找到。"

#~ msgid "Federated XGBoost"
#~ msgstr "联邦化 XGBoost"

#~ msgid ""
#~ "First of all, it is recommended to"
#~ " create a virtual environment and run"
#~ " everything within a :doc:`virtualenv "
#~ "<contributor-how-to-set-up-a-virtual-env>`."
#~ msgstr ""
#~ "首先，建议创建一个虚拟环境，并在 `virtualenv <https://flower.ai/docs"
#~ "/recommended-env-setup.html>`_ 中运行一切。"

#~ msgid ""
#~ "*Clients* are responsible for generating "
#~ "individual weight-updates for the model"
#~ " based on their local datasets. Now"
#~ " that we have all our dependencies"
#~ " installed, let's run a simple "
#~ "distributed training with two clients "
#~ "and one server."
#~ msgstr "*客户端*负责根据其本地数据集为模型生成单独的模型参数更新。现在我们已经安装了所有的依赖项，让我们用两个客户端和一个服务器来运行一个简单的分布式训练。"

#~ msgid ""
#~ "In a file called ``client.py``, import"
#~ " xgboost, Flower, Flower Datasets and "
#~ "other related functions:"
#~ msgstr "在名为 :code:`client.py` 的文件中，导入 xgboost、Flower、Flower Datasets 和其他相关函数："

#~ msgid "Dataset partition and hyper-parameter selection"
#~ msgstr "数据集划分和超参数选择"

#~ msgid ""
#~ "Prior to local training, we require "
#~ "loading the HIGGS dataset from Flower"
#~ " Datasets and conduct data partitioning "
#~ "for FL:"
#~ msgstr "在本地训练之前，我们需要从 Flower Datasets 加载 HIGGS 数据集，并对 FL 进行数据分区："

#~ msgid "Finally, we define the hyper-parameters used for XGBoost training."
#~ msgstr "最后，我们定义了用于 XGBoost 训练的超参数。"

#~ msgid "Flower client definition for XGBoost"
#~ msgstr "用于 XGBoost 的 Flower 客户端定义"

#~ msgid ""
#~ "All required parameters defined above "
#~ "are passed to ``XgbClient``'s constructor."
#~ msgstr ""

#~ msgid ""
#~ "Unlike neural network training, XGBoost "
#~ "trees are not started from a "
#~ "specified random weights. In this case,"
#~ " we do not use ``get_parameters`` and"
#~ " ``set_parameters`` to initialise model "
#~ "parameters for XGBoost. As a result, "
#~ "let's return an empty tensor in "
#~ "``get_parameters`` when it is called by"
#~ " the server at the first round."
#~ msgstr ""
#~ "与神经网络训练不同，XGBoost 树不是从指定的随机参数开始的。在这种情况下，我们不使用 "
#~ ":code:`get_parameters` 和 :code:`set_parameters` 来初始化"
#~ " XGBoost 的模型参数。因此，当服务器在第一轮调用 :code:`get_parameters` "
#~ "时，让我们在 :code:`get_parameters` 中返回一个空张量。"

#~ msgid ""
#~ "Now, we can create an instance of"
#~ " our class ``XgbClient`` and add one"
#~ " line to actually run this client:"
#~ msgstr "现在，我们可以创建一个 :code:`XgbClient` 类的实例，并添加一行来实际运行该客户端："

#~ msgid ""
#~ "That's it for the client. We only"
#~ " have to implement ``Client`` and "
#~ "call ``fl.client.start_client()``. The string "
#~ "``\"[::]:8080\"`` tells the client which "
#~ "server to connect to. In our case"
#~ " we can run the server and the"
#~ " client on the same machine, "
#~ "therefore we use ``\"[::]:8080\"``. If "
#~ "we run a truly federated workload "
#~ "with the server and clients running "
#~ "on different machines, all that needs"
#~ " to change is the ``server_address`` "
#~ "we point the client at."
#~ msgstr ""
#~ "这就是客户端。我们只需实现 :code:`客户端`并调用 "
#~ ":code:`fl.client.start_client()`。字符串 "
#~ ":code:`\"[::]:8080\"`会告诉客户端要连接的服务器。在本例中，我们可以在同一台机器上运行服务器和客户端，因此我们使用"
#~ " "
#~ ":code:`\"[::]:8080\"`。如果我们运行的是真正的联邦工作负载，服务器和客户端运行在不同的机器上，那么需要改变的只是客户端指向的"
#~ " :code:`server_address`。"

#~ msgid ""
#~ "In a file named ``server.py``, import"
#~ " Flower and FedXgbBagging from "
#~ "``flwr.server.strategy``."
#~ msgstr ""
#~ "在名为 :code:`server.py` 的文件中，从 "
#~ ":code:`flwr.server.strategy` 导入 Flower 和 "
#~ "FedXgbBagging。"

#~ msgid "Then, we start the server:"
#~ msgstr "然后，我们启动服务器："

#~ msgid ""
#~ "We also provide an example code "
#~ "(``sim.py``) to use the simulation "
#~ "capabilities of Flower to simulate "
#~ "federated XGBoost training on either a"
#~ " single machine or a cluster of "
#~ "machines."
#~ msgstr ""
#~ "我们还提供了一个示例代码（:code:`sim.py`），用于使用 Flower "
#~ "的模拟功能在单台机器或机器集群上模拟联合 XGBoost 训练。"

#~ msgid ""
#~ "After importing all required packages, "
#~ "we define a ``main()`` function to "
#~ "perform the simulation process:"
#~ msgstr "导入所有需要的软件包后，我们定义了一个 :code:`main()` 函数来执行模拟程序："

#~ msgid ""
#~ "We first load the dataset and "
#~ "perform data partitioning, and the "
#~ "pre-processed data is stored in a "
#~ "``list``. After the simulation begins, "
#~ "the clients won't need to pre-"
#~ "process their partitions again."
#~ msgstr "我们首先加载数据集并执行数据分区，预处理后的数据存储在 :code:`list` 中。模拟开始后，客户端就不需要再预处理分区了。"

#~ msgid "Then, we define the strategies and other hyper-parameters:"
#~ msgstr "然后，我们定义策略和其他超参数："

#~ msgid ""
#~ "After that, we start the simulation "
#~ "by calling ``fl.simulation.start_simulation``:"
#~ msgstr "然后，我们调用 :code:`fl.simulation.start_simulation` 开始模拟："

#~ msgid ""
#~ "One of key parameters for "
#~ "``start_simulation`` is ``client_fn`` which "
#~ "returns a function to construct a "
#~ "client. We define it as follows:"
#~ msgstr ""
#~ ":code:`start_simulation` 的一个关键参数是 "
#~ ":code:`client_fn`，它返回一个用于构建客户端的函数。我们将其定义如下："

#~ msgid ""
#~ "In ``utils.py``, we define the arguments"
#~ " parsers for clients, server and "
#~ "simulation, allowing users to specify "
#~ "different experimental settings. Let's first"
#~ " see the sever side:"
#~ msgstr "在 :code:`utils.py` 中，我们定义了客户端和服务器端的参数解析器，允许用户指定不同的实验设置。让我们先看看服务器端："

#~ msgid "Then, the argument parser on client side:"
#~ msgstr "然后是客户端的参数解析器："

#~ msgid "We also have an argument parser for simulation:"
#~ msgstr "我们还有一个用于模拟的参数解析器："

#~ msgid "This integrates all arguments for both client and server sides."
#~ msgstr "这整合了客户端和服务器端的所有参数。"

#~ msgid ""
#~ "To run a centralised evaluated "
#~ "experiment with bagging strategy on 5"
#~ " clients with exponential distribution for"
#~ " 50 rounds, we first start the "
#~ "server as below:"
#~ msgstr "为了在 5 个客户端上进行 50 轮指数分布的集中评估实验，我们首先启动服务器，如下所示："

#~ msgid "Then, on each client terminal, we start the clients:"
#~ msgstr "然后，我们在每个客户终端上启动客户机："

#~ msgid "To run the same experiment with Flower simulation:"
#~ msgstr "运行与 Flower 模拟相同的实验："

#~ msgid "|ac0a9766e26044d6aea222a829859b20|"
#~ msgstr ""

#~ msgid "|36cd6e248b1443ce8a82b5a025bba368|"
#~ msgstr ""

#~ msgid "|bf4fb057f4774df39e1dcb5c71fd804a|"
#~ msgstr ""

#~ msgid "|71bb9f3c74c04f959b9bc1f02b736c95|"
#~ msgstr ""

#~ msgid "|7605632e1b0f49599ffacf841491fcfb|"
#~ msgstr ""

#~ msgid "|91b1b5a7d3484eb7a2350c1923f18307|"
#~ msgstr ""

#~ msgid "|5405ed430e4746e28b083b146fb71731|"
#~ msgstr ""

#~ msgid "|a389e87dab394eb48a8949aa2397687b|"
#~ msgstr ""

#~ msgid "|89c412136a5146ec8dc32c0973729f12|"
#~ msgstr ""

#~ msgid "|9503d3dc3a144e8aa295f8800cd8a766|"
#~ msgstr ""

#~ msgid "|aadb59e29b9e445d8e239d9a8a7045cb|"
#~ msgstr ""

#~ msgid "|a7579ad7734347508e959d9e14f2f53d|"
#~ msgstr ""

#~ msgid "|73d15dd1d4fc41678b2d54815503fbe8|"
#~ msgstr ""

#~ msgid "|55472eef61274ba1b739408607e109df|"
#~ msgstr ""

